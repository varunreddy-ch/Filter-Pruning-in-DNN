{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "btpfinal.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f08a1dfcb2124e8f8880d7c673eefc35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0dc23f5142204f51b2345e404e48a12a",
              "IPY_MODEL_cf866795916240ff99d3fc3398b802c8",
              "IPY_MODEL_89e6ecd7de274bd2ba4cd42e96993dfb"
            ],
            "layout": "IPY_MODEL_e95cc7cc596a4b4bb738a2ce52407ac4"
          }
        },
        "0dc23f5142204f51b2345e404e48a12a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64d6ffcb7f8e46ff851272ce0df49659",
            "placeholder": "​",
            "style": "IPY_MODEL_7f1a4c1ca102495c8b6e66c150908b3d",
            "value": ""
          }
        },
        "cf866795916240ff99d3fc3398b802c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38ee1e89efa540948904e75d905ba677",
            "max": 170498071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ef3b461901f1483abca37bba9bf47f2a",
            "value": 170498071
          }
        },
        "89e6ecd7de274bd2ba4cd42e96993dfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_37acf43398a948b79bac25e69d3006df",
            "placeholder": "​",
            "style": "IPY_MODEL_0aaa1423d76f4c1382e0f2d2bfc8f4f3",
            "value": " 170499072/? [00:02&lt;00:00, 68058263.79it/s]"
          }
        },
        "e95cc7cc596a4b4bb738a2ce52407ac4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64d6ffcb7f8e46ff851272ce0df49659": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f1a4c1ca102495c8b6e66c150908b3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "38ee1e89efa540948904e75d905ba677": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef3b461901f1483abca37bba9bf47f2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "37acf43398a948b79bac25e69d3006df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0aaa1423d76f4c1382e0f2d2bfc8f4f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Parameters"
      ],
      "metadata": {
        "id": "GteN3iZaq7mn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZSXGJhrWq08-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import argparse\n",
        "\n",
        "import torch\n",
        "\n",
        "def build_parser():\n",
        "    parser = argparse.ArgumentParser()\n",
        "\n",
        "    parser.add_argument('--gpu-no', type=int,\n",
        "                    help='cpu: -1, gpu: 0 ~ n ', default=0)\n",
        "\n",
        "    parser.add_argument('--train-flag', action='store_true',\n",
        "                    help='flag for training  network', default=False)\n",
        "\n",
        "    parser.add_argument('--resume-flag', action='store_true',\n",
        "                    help='flag for resume training', default=False)\n",
        "\n",
        "    parser.add_argument('--prune-flag',action='store_true',\n",
        "                    help='flag for pruning network', default=False)\n",
        "\n",
        "    parser.add_argument('--retrain-flag',action='store_true',\n",
        "                    help='flag for retraining pruned network', default=False)\n",
        "\n",
        "    parser.add_argument('--retrain-epoch',type=int,\n",
        "                    help='number of epoch for retraining pruned network', default=20)\n",
        "\n",
        "    parser.add_argument('--retrain-lr',type=float,\n",
        "                    help='learning rate for retraining pruned network', default=0.001)\n",
        "\n",
        "    parser.add_argument('--data-set', type=str,\n",
        "                    help='Data set for training network', default='CIFAR10')\n",
        "\n",
        "    parser.add_argument('--data-path', type=str,\n",
        "                    help='Path of dataset', default='../')\n",
        "\n",
        "    parser.add_argument('--vgg', type=str,\n",
        "                    help='version of vgg network', default='vgg16_bn')\n",
        "    \n",
        "    parser.add_argument('--start-epoch', type=int,\n",
        "                    help='start epoch for training network', default=0)\n",
        "\n",
        "    parser.add_argument('--epoch', type=int,\n",
        "                    help='number of epoch for training network', default=350)\n",
        "    \n",
        "    parser.add_argument('--batch-size', type=int,\n",
        "                    help='batch size', default=128)\n",
        "\n",
        "    parser.add_argument('--num-workers', type=int,\n",
        "                    help='number of workers for data loader', default=2)\n",
        "\n",
        "    parser.add_argument('--lr', type=float,\n",
        "                    help='learning rate', default=0.1)\n",
        "\n",
        "    parser.add_argument('--lr-milestone', type=list,\n",
        "                    help='list of epoch for adjust learning rate', default=[150, 250])\n",
        "\n",
        "    parser.add_argument('--lr-gamma', type=float,\n",
        "                    help='factor for decay learning rate', default=0.1)\n",
        "\n",
        "    parser.add_argument('--momentum', type=float,\n",
        "                    help='momentum for optimizer', default=0.9)\n",
        "\n",
        "    parser.add_argument('--weight-decay', type=float,\n",
        "                    help='factor for weight decay in optimizer', default=5e-4)\n",
        "\n",
        "    parser.add_argument('--imsize', type=int,\n",
        "                    help='size for image resize', default=None)\n",
        "\n",
        "    parser.add_argument('--cropsize', type=int,\n",
        "                    help='size for image crop', default=32)\n",
        "\n",
        "    parser.add_argument('--crop-padding', type=int,\n",
        "                    help='size for padding in image crop', default=4)\n",
        "\n",
        "    parser.add_argument('--hflip', type=float,\n",
        "                    help='probability of random horizontal flip', default=0.5)\n",
        "\n",
        "    parser.add_argument('--print-freq', type=int,\n",
        "                    help='print frequency during training', default=100)\n",
        "\n",
        "    parser.add_argument('--load-path', type=str,\n",
        "                    help='trained model load path to prune', default=None)\n",
        "\n",
        "    parser.add_argument('--save-path',type=str,\n",
        "                    help='model save path', required=True)\n",
        "\n",
        "    parser.add_argument('--independent-prune-flag', action='store_true',\n",
        "                    help='prune multiple layers by \"independent strategy\"', default=False)\n",
        "\n",
        "    parser.add_argument('--prune-layers', nargs='+',\n",
        "                    help='layer index for pruning', default=None)\n",
        "\n",
        "    parser.add_argument('--prune-channels', nargs='+', type=int,\n",
        "                    help='number of channel to prune layers', default=None)\n",
        "\n",
        "\n",
        "    return parser\n",
        "\n",
        "def get_parameter():\n",
        "    parser = build_parser()\n",
        "    args = parser.parse_args()\n",
        "    os.environ['CUDA_VISIBLE_DEVICES'] = str(args.gpu_no)\n",
        "    \n",
        "    print(\"-*-\"*10 + \"\\n\\tArguments\\n\" + \"-*-\"*10)\n",
        "    for key,value in vars(args).items():\n",
        "        print(\"%s: %s\"%(key, value))\n",
        "\n",
        "    if not os.path.exists(args.save_path):\n",
        "        os.makedirs(args.save_path)\n",
        "        print(\"Make dir: \",args.save_path)\n",
        "\n",
        "    torch.save(args, args.save_path+\"arguments.pth\")\n",
        "\n",
        "    return args"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Network"
      ],
      "metadata": {
        "id": "YxIsgM67rEsW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.models as models\n",
        "\n",
        "class VGG(torch.nn.Module):\n",
        "    def __init__(self, vgg='vgg16_bn', data_set='CIFAR10', pretrained=False):\n",
        "        super(VGG, self).__init__()\n",
        "        self.features = models.__dict__[vgg](pretrained=pretrained).features\n",
        "        \n",
        "        classifier = []\n",
        "        if 'CIFAR' in data_set:\n",
        "            num_class = int(data_set.split(\"CIFAR\")[1])\n",
        "            \n",
        "            classifier.append(torch.nn.Linear(512, 512))\n",
        "            classifier.append(torch.nn.BatchNorm1d(512))\n",
        "            classifier.append(torch.nn.Linear(512, num_class))\n",
        "        else:\n",
        "            raise RuntimeError(\"Not expected data flag !!!\")\n",
        "\n",
        "        self.classifier = torch.nn.Sequential(*classifier)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "AnMA2LI9q-nh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optimizer"
      ],
      "metadata": {
        "id": "1dmZDWaurMum"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def get_optimizer(network, args):\n",
        "    optimizer = torch.optim.SGD(network.parameters(),\n",
        "                                lr=args.lr, \n",
        "                                momentum=args.momentum, \n",
        "                                weight_decay=args.weight_decay)    \n",
        "\n",
        "    scheduler = None\n",
        "    if args.lr_milestone is not None:\n",
        "        scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=args.lr_milestone, gamma=args.lr_gamma)\n",
        "\n",
        "    return optimizer, scheduler"
      ],
      "metadata": {
        "id": "Abc_3k-2rHL3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loss Calculation"
      ],
      "metadata": {
        "id": "rz5_Cu5orwen"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Loss_Calculator(object):\n",
        "    def __init__(self):\n",
        "        self.criterion = torch.nn.CrossEntropyLoss()        \n",
        "        self.loss_seq = []\n",
        "    \n",
        "    def calc_loss(self, output, target):\n",
        "        loss = self.criterion(output, target)        \n",
        "        self.loss_seq.append(loss.item())\n",
        "        return loss\n",
        "\n",
        "    def get_loss_log(self, length=100):\n",
        "        # get recent average loss values\n",
        "        if len(self.loss_seq) < length:\n",
        "            length = len(self.loss_seq)\n",
        "        return sum(self.loss_seq[-length:])/length"
      ],
      "metadata": {
        "id": "QSMgm2LJrN2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utils"
      ],
      "metadata": {
        "id": "Pupi4YossEpm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "class AverageMeter(object):    \n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "def get_normalizer(data_set, inverse=False):\n",
        "    if data_set == 'CIFAR10':\n",
        "        MEAN = (0.4914, 0.4822, 0.4465)\n",
        "        STD = (0.2023, 0.1994, 0.2010)\n",
        "\n",
        "    else:\n",
        "        raise RuntimeError(\"Not expected data flag !!!\")\n",
        "\n",
        "    if inverse:\n",
        "        MEAN = [-mean/std for mean, std in zip(MEAN, STD)]\n",
        "        STD = [1/std for std in STD]\n",
        "\n",
        "    return transforms.Normalize(MEAN, STD)\n",
        "\n",
        "def get_transformer(data_set, imsize=None, cropsize=None, crop_padding=None, hflip=None):\n",
        "    transformers = [] \n",
        "    if imsize:\n",
        "        transformers.append(transforms.Resize(imsize))\n",
        "    if cropsize:\n",
        "        ## https://github.com/kuangliu/pytorch-cifar\n",
        "        transformers.append(transforms.RandomCrop(cropsize, padding=crop_padding))\n",
        "    if hflip:\n",
        "        transformers.append(transforms.RandomHorizontalFlip(hflip))\n",
        "\n",
        "    transformers.append(transforms.ToTensor())\n",
        "    transformers.append(get_normalizer(data_set))\n",
        "    \n",
        "    return transforms.Compose(transformers)\n",
        "\n",
        "def get_data_set(args, train_flag=True):\n",
        "    if train_flag:\n",
        "        data_set = torchvision.datasets.__dict__[args.data_set](root=args.data_path, train=True, \n",
        "                                       transform=get_transformer(args.data_set, args.imsize,\n",
        "                                           args.cropsize, args.crop_padding, args.hflip), download=True)\n",
        "    else:\n",
        "        data_set = torchvision.datasets.__dict__[args.data_set](root=args.data_path, train=False, \n",
        "                                           transform=get_transformer(args.data_set), download=True)    \n",
        "    return data_set\n"
      ],
      "metadata": {
        "id": "s7xbpKu-sFuk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train\n",
        "\n"
      ],
      "metadata": {
        "id": "WaIrZPMwQSWj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "def train_network(args, network=None, data_set=None):\n",
        "    device = torch.device(\"cuda\" if args.gpu_no >= 0 else \"cpu\")\n",
        "\n",
        "    if network is None:\n",
        "        network = VGG(args.vgg, args.data_set)\n",
        "    network = network.to(device)\n",
        "\n",
        "    summary(network, (3, 32, 32))\n",
        "    print(network)\n",
        "\n",
        "    if data_set is None:\n",
        "        data_set = get_data_set(args, train_flag=True)\n",
        "    \n",
        "    loss_calculator = Loss_Calculator()\n",
        "    \n",
        "    optimizer, scheduler = get_optimizer(network, args)\n",
        "    \n",
        "    if args.resume_flag:\n",
        "        check_point = torch.load(args.load_path)\n",
        "        network.load_state_dict(check_point['state_dict'])\n",
        "        loss_calculator.loss_seq = check_point['loss_seq']\n",
        "        args.start_epoch = check_point['epoch'] # update start epoch\n",
        "                \n",
        "    print(\"-*-\"*10 + \"\\n\\tTrain network\\n\" + \"-*-\"*10)\n",
        "    for epoch in range(args.start_epoch, args.epoch):\n",
        "        # make shuffled data loader\n",
        "        data_loader = torch.utils.data.DataLoader(data_set, batch_size=args.batch_size, shuffle=True)\n",
        "\n",
        "        # train one epoch\n",
        "        train_step(network, data_loader, loss_calculator, optimizer, device, epoch, args.print_freq)\n",
        "\n",
        "        # adjust learning rate\n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "\n",
        "        torch.save({'epoch': epoch+1, \n",
        "                   'state_dict': network.state_dict(),\n",
        "                   'loss_seq': loss_calculator.loss_seq},\n",
        "                   args.save_path+\"check_point.pth\")\n",
        "        \n",
        "    return network\n",
        "\n",
        "def train_step(network, data_loader, loss_calculator, optimizer, device, epoch, print_freq=100):\n",
        "    network.train()\n",
        "    # set benchmark flag to faster runtime\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "        \n",
        "    data_time = AverageMeter()\n",
        "    loss_time = AverageMeter()    \n",
        "    forward_time = AverageMeter()\n",
        "    backward_time = AverageMeter()\n",
        "    \n",
        "    top1 = AverageMeter()\n",
        "    top5 = AverageMeter()\n",
        "    \n",
        "    tic = time.time()\n",
        "    for iteration, (inputs, targets) in enumerate(data_loader):\n",
        "        data_time.update(time.time() - tic)\n",
        "        \n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        \n",
        "        tic = time.time()\n",
        "        outputs = network(inputs)\n",
        "        forward_time.update(time.time() - tic)\n",
        "        \n",
        "        tic = time.time()\n",
        "        loss = loss_calculator.calc_loss(outputs, targets)\n",
        "        loss_time.update(time.time() - tic)\n",
        "        \n",
        "        tic = time.time()\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        backward_time.update(time.time() - tic)\n",
        "        \n",
        "        prec1, prec5 = accuracy(outputs.data, targets, topk=(1,5))\n",
        "        top1.update(prec1.item(), inputs.size(0))\n",
        "        top5.update(prec5.item(), inputs.size(0))\n",
        "                        \n",
        "        if iteration % print_freq == 0:\n",
        "            logs_ = '%s: '%time.ctime()\n",
        "            logs_ += 'Epoch [%d], '%epoch\n",
        "            logs_ += 'Iteration [%d/%d/], '%(iteration, len(data_loader))\n",
        "            logs_ += 'Data(s): %2.3f, Loss(s): %2.3f, '%(data_time.avg, loss_time.avg)\n",
        "            logs_ += 'Forward(s): %2.3f, Backward(s): %2.3f, '%(forward_time.avg, backward_time.avg)\n",
        "            logs_ += 'Top1: %2.3f, Top5: %2.4f, '%(top1.avg, top5.avg)\n",
        "            logs_ += 'Loss: %2.3f'%loss_calculator.get_loss_log()\n",
        "            print(logs_)            \n",
        "                        \n",
        "        tic = time.time()\n",
        "    return None"
      ],
      "metadata": {
        "id": "XTaLxmOSQSIs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ],
      "metadata": {
        "id": "rOYT3fyGsMfO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "import torch\n",
        "\n",
        "from torchsummary import summary\n",
        "\n",
        "# from network import VGG\n",
        "# from utils import AverageMeter, get_data_set\n",
        "\n",
        "def test_network(args, network=None, data_set=None):\n",
        "    device = torch.device(\"cuda\" if args.gpu_no >= 0 else \"cpu\")\n",
        "\n",
        "    # summary(network, (3, 32, 32))\n",
        "    # print(network)\n",
        "    \n",
        "    if network is None:\n",
        "        network = VGG(args.vgg, args.data_set)\n",
        "        if args.load_path:\n",
        "            check_point = torch.load(args.load_path)\n",
        "            network.load_state_dict(check_point['state_dict'])\n",
        "    network.to(device)\n",
        "\n",
        "    if data_set is None:\n",
        "        data_set = get_data_set(args, train_flag=False)\n",
        "    data_loader = torch.utils.data.DataLoader(data_set, batch_size=100, shuffle=False)\n",
        "\n",
        "    top1, top5 = test_step(network, data_loader, device)\n",
        "    \n",
        "    return network, data_set, (top1, top5)\n",
        "    \n",
        "def test_step(network, data_loader, device):\n",
        "    network.eval()\n",
        "        \n",
        "    data_time = AverageMeter()\n",
        "    forward_time = AverageMeter()    \n",
        "    top1 = AverageMeter()\n",
        "    top5 = AverageMeter()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        tic = time.time()\n",
        "        for inputs, targets in data_loader:\n",
        "            data_time.update(time.time() - tic)\n",
        "\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            \n",
        "            tic = time.time()\n",
        "            outputs = network(inputs)\n",
        "            forward_time.update(time.time() - tic)\n",
        "            \n",
        "            prec1, prec5 = accuracy(outputs, targets, topk=(1,5))\n",
        "            \n",
        "            top1.update(prec1.item(), inputs.size(0))\n",
        "            top5.update(prec5.item(), inputs.size(0))\n",
        "            \n",
        "            tic = time.time()\n",
        "\n",
        "    str_ = '%s: Test information, '%time.ctime()\n",
        "    str_ += 'Data(s): %2.3f, Forward(s): %2.3f, '%(data_time.sum, forward_time.sum)\n",
        "    str_ += 'Top1: %2.3f, Top5: %2.3f, '%(top1.avg, top5.avg)\n",
        "    print(\"-*-\"*10 + \"\\n\\tEvalute network\\n\" + \"-*-\"*10)\n",
        "    print(str_)\n",
        "    \n",
        "    return top1.avg, top5.avg\n",
        "\n",
        "def accuracy(output, target, topk=(1,)):\n",
        "    \"\"\"\n",
        "        Computes the precision@k for the specified values of k\n",
        "        ref: https://github.com/chengyangfu/pytorch-vgg-cifar10\n",
        "    \"\"\"\n",
        "    maxk = max(topk)\n",
        "    batch_size = target.size(0)\n",
        "\n",
        "    _, pred = output.topk(maxk, 1, True, True)\n",
        "    pred = pred.t()\n",
        "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "\n",
        "    res = []\n",
        "    for k in topk:\n",
        "        correct_k = correct[:k].reshape(-1).float().sum(0)\n",
        "        res.append(correct_k.mul_(100.0 / batch_size))\n",
        "    return res"
      ],
      "metadata": {
        "id": "2yFas_Z7sIBU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Image"
      ],
      "metadata": {
        "id": "dN-HXXhaw53u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import torch\n",
        "from torchsummary import summary\n",
        "from scipy import misc\n",
        "import imageio\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "label = [\"airplane\" , \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\" , \"horse\", \"ship\", \"truck\"]\n",
        "\n",
        "def image_network(args,image , network=None, data_set=None):\n",
        "    device = torch.device(\"cuda\" if args.gpu_no >= 0 else \"cpu\")\n",
        "    \n",
        "    # print(summary(network, (3, 32, 32)))\n",
        "    print(network)\n",
        "    if network is None:\n",
        "        network = VGG(args.vgg, args.data_set)\n",
        "        if args.load_path:\n",
        "            check_point = torch.load(args.load_path)\n",
        "            network.load_state_dict(check_point['state_dict'])\n",
        "    network.to(device)\n",
        "\n",
        "    output = test_step(network, image , device)\n",
        "    print(\"Class : \"+ label[np.argmax(output)])\n",
        "\n",
        "    \n",
        "def test_step(network, image, device):\n",
        "    network.eval()\n",
        "        \n",
        "    data_time = AverageMeter()\n",
        "    forward_time = AverageMeter()    \n",
        "    top1 = AverageMeter()\n",
        "    top5 = AverageMeter()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        \n",
        "        # test_image = misc.imread(image)\n",
        "        # test_image = imageio.imread(image)\n",
        "\n",
        "        # tlabel = label.to(device)\n",
        "\n",
        "        image = Image.open(image)\n",
        "        test_image = image.resize((32, 32),Image.ANTIALIAS)\n",
        "\n",
        "        test_image = np.asarray(test_image)\n",
        "        tensor = torch.from_numpy(test_image).float()\n",
        "\n",
        "        reshaped = tensor.permute(2, 0, 1).unsqueeze(0)\n",
        "        \n",
        "        tic = time.time()\n",
        "        data_time.update(time.time() - tic)\n",
        "\n",
        "        reshaped = reshaped.to(device)\n",
        "        \n",
        "        tic = time.time()\n",
        "        output = network(reshaped)\n",
        "        # print(output)\n",
        "        forward_time.update(time.time() - tic)\n",
        "\n",
        "        index = output.cpu().data.numpy().argmax()\n",
        "        \n",
        "        tic = time.time()\n",
        "    str_ = '%s: Test information, '%time.ctime()\n",
        "    str_ += 'Data(s): %2.3f, Forward(s): %2.3f, '%(data_time.sum, forward_time.sum)\n",
        "    # str_ += 'Top1: %2.3f, Top5: %2.3f, '%(top1.avg, top5.avg)\n",
        "    print(\"-*-\"*10 + \"\\n\\tEvalute network\\n\" + \"-*-\"*10)\n",
        "    print(str_)\n",
        "\n",
        "    return index"
      ],
      "metadata": {
        "id": "lckMtCUbw5g2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prune"
      ],
      "metadata": {
        "id": "TRqkugAvs1te"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prune_network(args, network=None):\n",
        "    device = torch.device(\"cuda\" if args.gpu_no >= 0 else \"cpu\")\n",
        "\n",
        "    if network is None:\n",
        "        network = VGG(args.vgg, args.data_set)\n",
        "        if args.load_path:\n",
        "            check_point = torch.load(args.load_path)\n",
        "            network.load_state_dict(check_point['state_dict'])\n",
        "\n",
        "    # prune network\n",
        "    network = prune_step(network, args.prune_layers, args.prune_channels, args.independent_prune_flag)\n",
        "    network = network.to(device)\n",
        "    print(\"-*-\"*10 + \"\\n\\tPrune network\\n\" + \"-*-\"*10)\n",
        "    print(network)\n",
        "\n",
        "    if args.retrain_flag:\n",
        "        # update arguemtns for retraing pruned network\n",
        "        args.epoch = args.retrain_epoch\n",
        "        args.lr = args.retrain_lr\n",
        "        args.lr_milestone = None # don't decay learning rate\n",
        "\n",
        "        network = train_network(args, network)\n",
        "\n",
        "    return network\n",
        "\n",
        "def prune_step(network, prune_layers, prune_channels, independent_prune_flag):\n",
        "    network = network.cpu()\n",
        "\n",
        "    count = 0 # count for indexing 'prune_channels'\n",
        "    conv_count = 1 # conv count for 'indexing_prune_layers'\n",
        "    dim = 0 # 0: prune corresponding dim of filter weight [out_ch, in_ch, k1, k2]\n",
        "    residue = None # residue is need to prune by 'independent strategy'\n",
        "    for i in range(len(network.features)):\n",
        "        if isinstance(network.features[i], torch.nn.Conv2d):\n",
        "            if dim == 1:\n",
        "                new_, residue = get_new_conv(network.features[i], dim, channel_index, independent_prune_flag)\n",
        "                network.features[i] = new_\n",
        "                dim ^= 1\n",
        "\n",
        "            if 'conv%d'%conv_count in prune_layers:         \n",
        "                channel_index = get_channel_index(network.features[i].weight.data, prune_channels[count], residue)\n",
        "                new_ = get_new_conv(network.features[i], dim, channel_index, independent_prune_flag)\n",
        "                network.features[i] = new_\n",
        "                dim ^= 1\n",
        "                count += 1\n",
        "            else:\n",
        "                residue = None\n",
        "            conv_count += 1\n",
        "\n",
        "        elif dim == 1 and isinstance(network.features[i], torch.nn.BatchNorm2d):\n",
        "            new_ = get_new_norm(network.features[i], channel_index)\n",
        "            network.features[i] = new_\n",
        "\n",
        "    # update to check last conv layer pruned\n",
        "    if 'conv13' in prune_layers:\n",
        "        network.classifier[0] = get_new_linear(network.classifier[0], channel_index)\n",
        "\n",
        "    return network\n",
        "\n",
        "def get_channel_index(kernel, num_elimination, residue=None):\n",
        "    # get cadidate channel index for pruning\n",
        "    ## 'residue' is needed for pruning by 'independent strategy'\n",
        "\n",
        "    sum_of_kernel = torch.sum(torch.abs(kernel.view(kernel.size(0), -1)), dim=1)\n",
        "    if residue is not None:\n",
        "        sum_of_kernel += torch.sum(torch.abs(residue.view(residue.size(0), -1)), dim=1)\n",
        "    \n",
        "    vals, args = torch.sort(sum_of_kernel)\n",
        "\n",
        "    return args[:num_elimination].tolist()\n",
        "\n",
        "def index_remove(tensor, dim, index, removed=False):\n",
        "    if tensor.is_cuda:\n",
        "        tensor = tensor.cpu()\n",
        "    size_ = list(tensor.size())\n",
        "    new_size = tensor.size(dim) - len(index)\n",
        "    size_[dim] = new_size\n",
        "    new_size = size_\n",
        "\n",
        "    select_index = list(set(range(tensor.size(dim))) - set(index))\n",
        "    new_tensor = torch.index_select(tensor, dim, torch.tensor(select_index))\n",
        "    \n",
        "    if removed:\n",
        "        return new_tensor, torch.index_select(tensor, dim, torch.tensor(index))\n",
        "\n",
        "    return new_tensor\n",
        "\n",
        "def get_new_conv(conv, dim, channel_index, independent_prune_flag=False):\n",
        "    if dim == 0:\n",
        "        new_conv = torch.nn.Conv2d(in_channels=conv.in_channels,\n",
        "                                   out_channels=int(conv.out_channels - len(channel_index)),\n",
        "                                   kernel_size=conv.kernel_size,\n",
        "                                   stride=conv.stride, padding=conv.padding, dilation=conv.dilation)\n",
        "        \n",
        "        new_conv.weight.data = index_remove(conv.weight.data, dim, channel_index)\n",
        "        new_conv.bias.data = index_remove(conv.bias.data, dim, channel_index)\n",
        "\n",
        "        return new_conv\n",
        "\n",
        "    elif dim == 1:\n",
        "        new_conv = torch.nn.Conv2d(in_channels=int(conv.in_channels - len(channel_index)),\n",
        "                                   out_channels=conv.out_channels,\n",
        "                                   kernel_size=conv.kernel_size,\n",
        "                                   stride=conv.stride, padding=conv.padding, dilation=conv.dilation)\n",
        "        \n",
        "        new_weight = index_remove(conv.weight.data, dim, channel_index, independent_prune_flag)\n",
        "        residue = None\n",
        "        if independent_prune_flag:\n",
        "            new_weight, residue = new_weight\n",
        "        new_conv.weight.data = new_weight\n",
        "        new_conv.bias.data = conv.bias.data\n",
        "\n",
        "        return new_conv, residue\n",
        "\n",
        "def get_new_norm(norm, channel_index):\n",
        "    new_norm = torch.nn.BatchNorm2d(num_features=int(norm.num_features - len(channel_index)),\n",
        "                                    eps=norm.eps,\n",
        "                                    momentum=norm.momentum,\n",
        "                                    affine=norm.affine,\n",
        "                                    track_running_stats=norm.track_running_stats)\n",
        "\n",
        "    new_norm.weight.data = index_remove(norm.weight.data, 0, channel_index)\n",
        "    new_norm.bias.data = index_remove(norm.bias.data, 0, channel_index)\n",
        "\n",
        "    if norm.track_running_stats:\n",
        "        new_norm.running_mean.data = index_remove(norm.running_mean.data, 0, channel_index)\n",
        "        new_norm.running_var.data = index_remove(norm.running_var.data, 0, channel_index)\n",
        "        \n",
        "    return new_norm\n",
        "\n",
        "def get_new_linear(linear, channel_index):\n",
        "    new_linear = torch.nn.Linear(in_features=int(linear.in_features - len(channel_index)),\n",
        "                                out_features=linear.out_features,\n",
        "                                bias=linear.bias is not None)\n",
        "    new_linear.weight.data = index_remove(linear.weight.data, 1, channel_index)\n",
        "    new_linear.bias.data = linear.bias.data\n",
        "    \n",
        "    return new_linear"
      ],
      "metadata": {
        "id": "2XgHL5EZsbC6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train VGG on CIFAR-10 Data set"
      ],
      "metadata": {
        "id": "IDAuPRlgkiIS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py --train-flag --data-set CIFAR10 --vgg vgg16_bn --save-path ./trained_models/ --epoch 30"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GXidsWgHQAq2",
        "outputId": "2431953b-a5e7-48c3-95dd-00212c4769db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tArguments\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "gpu_no: 0\n",
            "train_flag: True\n",
            "resume_flag: False\n",
            "prune_flag: False\n",
            "retrain_flag: False\n",
            "retrain_epoch: 20\n",
            "retrain_lr: 0.001\n",
            "data_set: CIFAR10\n",
            "data_path: ../\n",
            "vgg: vgg16_bn\n",
            "start_epoch: 0\n",
            "epoch: 30\n",
            "batch_size: 128\n",
            "num_workers: 2\n",
            "lr: 0.1\n",
            "lr_milestone: [150, 250]\n",
            "lr_gamma: 0.1\n",
            "momentum: 0.9\n",
            "weight_decay: 0.0005\n",
            "imsize: None\n",
            "cropsize: 32\n",
            "crop_padding: 4\n",
            "hflip: 0.5\n",
            "print_freq: 100\n",
            "load_path: None\n",
            "save_path: ./trained_models/\n",
            "independent_prune_flag: False\n",
            "prune_layers: None\n",
            "prune_channels: None\n",
            "Make dir:  ./trained_models/\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 06:48:46 2022: Epoch [0], Iteration [0/391/], Data(s): 0.037, Loss(s): 0.000, Forward(s): 0.447, Backward(s): 0.568, Top1: 7.031, Top5: 47.6562, Loss: 2.513\n",
            "Mon Apr 25 06:48:54 2022: Epoch [0], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.007, Backward(s): 0.011, Top1: 12.415, Top5: 55.3914, Loss: 3.929\n",
            "Mon Apr 25 06:49:02 2022: Epoch [0], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.005, Backward(s): 0.009, Top1: 13.340, Top5: 59.1029, Loss: 2.590\n",
            "Mon Apr 25 06:49:10 2022: Epoch [0], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.005, Backward(s): 0.008, Top1: 14.831, Top5: 64.2546, Loss: 2.159\n",
            "Mon Apr 25 06:49:18 2022: Epoch [1], Iteration [0/391/], Data(s): 0.043, Loss(s): 0.011, Forward(s): 0.004, Backward(s): 0.006, Top1: 21.094, Top5: 79.6875, Loss: 2.089\n",
            "Mon Apr 25 06:49:26 2022: Epoch [1], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 21.140, Top5: 81.5362, Loss: 1.961\n",
            "Mon Apr 25 06:49:34 2022: Epoch [1], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 22.062, Top5: 82.1012, Loss: 1.920\n",
            "Mon Apr 25 06:49:42 2022: Epoch [1], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 23.910, Top5: 83.1032, Loss: 1.823\n",
            "Mon Apr 25 06:49:50 2022: Epoch [2], Iteration [0/391/], Data(s): 0.037, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 32.812, Top5: 89.8438, Loss: 1.751\n",
            "Mon Apr 25 06:49:58 2022: Epoch [2], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 33.284, Top5: 87.3453, Loss: 1.710\n",
            "Mon Apr 25 06:50:06 2022: Epoch [2], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 34.659, Top5: 87.9820, Loss: 1.654\n",
            "Mon Apr 25 06:50:14 2022: Epoch [2], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 35.600, Top5: 88.6628, Loss: 1.619\n",
            "Mon Apr 25 06:50:22 2022: Epoch [3], Iteration [0/391/], Data(s): 0.036, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.007, Top1: 36.719, Top5: 89.0625, Loss: 1.572\n",
            "Mon Apr 25 06:50:30 2022: Epoch [3], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 42.899, Top5: 91.5996, Loss: 1.511\n",
            "Mon Apr 25 06:50:38 2022: Epoch [3], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 44.601, Top5: 92.2652, Loss: 1.425\n",
            "Mon Apr 25 06:50:46 2022: Epoch [3], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 46.506, Top5: 92.7741, Loss: 1.331\n",
            "Mon Apr 25 06:50:54 2022: Epoch [4], Iteration [0/391/], Data(s): 0.035, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 54.688, Top5: 96.8750, Loss: 1.274\n",
            "Mon Apr 25 06:51:02 2022: Epoch [4], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 55.376, Top5: 95.0882, Loss: 1.220\n",
            "Mon Apr 25 06:51:10 2022: Epoch [4], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 57.369, Top5: 95.4369, Loss: 1.122\n",
            "Mon Apr 25 06:51:18 2022: Epoch [4], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 58.518, Top5: 95.6343, Loss: 1.091\n",
            "Mon Apr 25 06:51:26 2022: Epoch [5], Iteration [0/391/], Data(s): 0.037, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 69.531, Top5: 96.0938, Loss: 1.031\n",
            "Mon Apr 25 06:51:34 2022: Epoch [5], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 64.975, Top5: 96.6662, Loss: 0.971\n",
            "Mon Apr 25 06:51:42 2022: Epoch [5], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 65.738, Top5: 96.7195, Loss: 0.953\n",
            "Mon Apr 25 06:51:50 2022: Epoch [5], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 66.302, Top5: 96.7842, Loss: 0.916\n",
            "Mon Apr 25 06:51:58 2022: Epoch [6], Iteration [0/391/], Data(s): 0.037, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.007, Top1: 67.188, Top5: 98.4375, Loss: 0.890\n",
            "Mon Apr 25 06:52:06 2022: Epoch [6], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 69.686, Top5: 97.0452, Loss: 0.879\n",
            "Mon Apr 25 06:52:14 2022: Epoch [6], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 70.425, Top5: 97.1859, Loss: 0.849\n",
            "Mon Apr 25 06:52:22 2022: Epoch [6], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 70.920, Top5: 97.2539, Loss: 0.826\n",
            "Mon Apr 25 06:52:30 2022: Epoch [7], Iteration [0/391/], Data(s): 0.037, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 67.969, Top5: 99.2188, Loss: 0.800\n",
            "Mon Apr 25 06:52:38 2022: Epoch [7], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 74.056, Top5: 97.5093, Loss: 0.777\n",
            "Mon Apr 25 06:52:46 2022: Epoch [7], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 74.110, Top5: 97.5669, Loss: 0.767\n",
            "Mon Apr 25 06:52:54 2022: Epoch [7], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 74.252, Top5: 97.5784, Loss: 0.753\n",
            "Mon Apr 25 06:53:02 2022: Epoch [8], Iteration [0/391/], Data(s): 0.036, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 75.000, Top5: 96.0938, Loss: 0.756\n",
            "Mon Apr 25 06:53:10 2022: Epoch [8], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 76.153, Top5: 97.6408, Loss: 0.728\n",
            "Mon Apr 25 06:53:18 2022: Epoch [8], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 76.197, Top5: 97.6368, Loss: 0.715\n",
            "Mon Apr 25 06:53:26 2022: Epoch [8], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 76.331, Top5: 97.6017, Loss: 0.726\n",
            "Mon Apr 25 06:53:34 2022: Epoch [9], Iteration [0/391/], Data(s): 0.035, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 82.031, Top5: 100.0000, Loss: 0.703\n",
            "Mon Apr 25 06:53:42 2022: Epoch [9], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 77.375, Top5: 98.0507, Loss: 0.683\n",
            "Mon Apr 25 06:53:50 2022: Epoch [9], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 77.309, Top5: 97.8856, Loss: 0.697\n",
            "Mon Apr 25 06:53:58 2022: Epoch [9], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 77.279, Top5: 97.9054, Loss: 0.682\n",
            "Mon Apr 25 06:54:06 2022: Epoch [10], Iteration [0/391/], Data(s): 0.037, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 86.719, Top5: 99.2188, Loss: 0.661\n",
            "Mon Apr 25 06:54:14 2022: Epoch [10], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 78.048, Top5: 97.8883, Loss: 0.668\n",
            "Mon Apr 25 06:54:22 2022: Epoch [10], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 78.646, Top5: 97.9050, Loss: 0.642\n",
            "Mon Apr 25 06:54:30 2022: Epoch [10], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 78.688, Top5: 97.9729, Loss: 0.644\n",
            "Mon Apr 25 06:54:38 2022: Epoch [11], Iteration [0/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.004, Backward(s): 0.006, Top1: 84.375, Top5: 99.2188, Loss: 0.641\n",
            "Mon Apr 25 06:54:46 2022: Epoch [11], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 79.664, Top5: 98.4298, Loss: 0.621\n",
            "Mon Apr 25 06:54:54 2022: Epoch [11], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 79.155, Top5: 98.3092, Loss: 0.638\n",
            "Mon Apr 25 06:55:02 2022: Epoch [11], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 79.296, Top5: 98.2169, Loss: 0.632\n",
            "Mon Apr 25 06:55:10 2022: Epoch [12], Iteration [0/391/], Data(s): 0.038, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 78.906, Top5: 100.0000, Loss: 0.612\n",
            "Mon Apr 25 06:55:18 2022: Epoch [12], Iteration [100/391/], Data(s): 0.036, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 80.183, Top5: 98.0972, Loss: 0.612\n",
            "Mon Apr 25 06:55:26 2022: Epoch [12], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 80.500, Top5: 98.2548, Loss: 0.591\n",
            "Mon Apr 25 06:55:34 2022: Epoch [12], Iteration [300/391/], Data(s): 0.035, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 80.381, Top5: 98.2325, Loss: 0.606\n",
            "Mon Apr 25 06:55:42 2022: Epoch [13], Iteration [0/391/], Data(s): 0.036, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 81.250, Top5: 97.6562, Loss: 0.612\n",
            "Mon Apr 25 06:55:50 2022: Epoch [13], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 81.265, Top5: 98.2751, Loss: 0.571\n",
            "Mon Apr 25 06:55:58 2022: Epoch [13], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 80.624, Top5: 98.2082, Loss: 0.600\n",
            "Mon Apr 25 06:56:06 2022: Epoch [13], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 80.723, Top5: 98.2454, Loss: 0.583\n",
            "Mon Apr 25 06:56:14 2022: Epoch [14], Iteration [0/391/], Data(s): 0.036, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 81.250, Top5: 98.4375, Loss: 0.570\n",
            "Mon Apr 25 06:56:22 2022: Epoch [14], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 80.608, Top5: 98.2751, Loss: 0.590\n",
            "Mon Apr 25 06:56:30 2022: Epoch [14], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 80.955, Top5: 98.3364, Loss: 0.580\n",
            "Mon Apr 25 06:56:38 2022: Epoch [14], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 80.941, Top5: 98.3363, Loss: 0.581\n",
            "Mon Apr 25 06:56:46 2022: Epoch [15], Iteration [0/391/], Data(s): 0.035, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 84.375, Top5: 100.0000, Loss: 0.565\n",
            "Mon Apr 25 06:56:54 2022: Epoch [15], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 81.289, Top5: 98.4839, Loss: 0.563\n",
            "Mon Apr 25 06:57:02 2022: Epoch [15], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 81.456, Top5: 98.3753, Loss: 0.571\n",
            "Mon Apr 25 06:57:10 2022: Epoch [15], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 81.463, Top5: 98.4115, Loss: 0.561\n",
            "Mon Apr 25 06:57:18 2022: Epoch [16], Iteration [0/391/], Data(s): 0.046, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 83.594, Top5: 98.4375, Loss: 0.552\n",
            "Mon Apr 25 06:57:26 2022: Epoch [16], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 82.627, Top5: 98.4298, Loss: 0.538\n",
            "Mon Apr 25 06:57:34 2022: Epoch [16], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 82.198, Top5: 98.4530, Loss: 0.560\n",
            "Mon Apr 25 06:57:42 2022: Epoch [16], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 82.109, Top5: 98.4245, Loss: 0.556\n",
            "Mon Apr 25 06:57:49 2022: Epoch [17], Iteration [0/391/], Data(s): 0.037, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 82.031, Top5: 97.6562, Loss: 0.546\n",
            "Mon Apr 25 06:57:58 2022: Epoch [17], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 83.068, Top5: 98.6077, Loss: 0.519\n",
            "Mon Apr 25 06:58:06 2022: Epoch [17], Iteration [200/391/], Data(s): 0.033, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 82.859, Top5: 98.5930, Loss: 0.531\n",
            "Mon Apr 25 06:58:14 2022: Epoch [17], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 82.413, Top5: 98.4790, Loss: 0.561\n",
            "Mon Apr 25 06:58:21 2022: Epoch [18], Iteration [0/391/], Data(s): 0.036, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 82.812, Top5: 97.6562, Loss: 0.567\n",
            "Mon Apr 25 06:58:29 2022: Epoch [18], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 82.812, Top5: 98.4839, Loss: 0.530\n",
            "Mon Apr 25 06:58:37 2022: Epoch [18], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 82.657, Top5: 98.5191, Loss: 0.536\n",
            "Mon Apr 25 06:58:46 2022: Epoch [18], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 82.833, Top5: 98.5309, Loss: 0.516\n",
            "Mon Apr 25 06:58:53 2022: Epoch [19], Iteration [0/391/], Data(s): 0.037, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 85.156, Top5: 99.2188, Loss: 0.537\n",
            "Mon Apr 25 06:59:01 2022: Epoch [19], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 83.555, Top5: 98.7392, Loss: 0.509\n",
            "Mon Apr 25 06:59:10 2022: Epoch [19], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 83.182, Top5: 98.6824, Loss: 0.519\n",
            "Mon Apr 25 06:59:18 2022: Epoch [19], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 83.036, Top5: 98.6140, Loss: 0.533\n",
            "Mon Apr 25 06:59:25 2022: Epoch [20], Iteration [0/391/], Data(s): 0.035, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 81.250, Top5: 99.2188, Loss: 0.516\n",
            "Mon Apr 25 06:59:33 2022: Epoch [20], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 82.232, Top5: 98.3060, Loss: 0.549\n",
            "Mon Apr 25 06:59:41 2022: Epoch [20], Iteration [200/391/], Data(s): 0.033, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 83.050, Top5: 98.4375, Loss: 0.501\n",
            "Mon Apr 25 06:59:50 2022: Epoch [20], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 83.246, Top5: 98.4661, Loss: 0.514\n",
            "Mon Apr 25 06:59:57 2022: Epoch [21], Iteration [0/391/], Data(s): 0.037, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 89.062, Top5: 98.4375, Loss: 0.524\n",
            "Mon Apr 25 07:00:05 2022: Epoch [21], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 84.027, Top5: 98.6386, Loss: 0.487\n",
            "Mon Apr 25 07:00:13 2022: Epoch [21], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 83.749, Top5: 98.5774, Loss: 0.511\n",
            "Mon Apr 25 07:00:21 2022: Epoch [21], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 83.469, Top5: 98.5180, Loss: 0.527\n",
            "Mon Apr 25 07:00:29 2022: Epoch [22], Iteration [0/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 85.938, Top5: 100.0000, Loss: 0.536\n",
            "Mon Apr 25 07:00:37 2022: Epoch [22], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 83.864, Top5: 98.6618, Loss: 0.489\n",
            "Mon Apr 25 07:00:45 2022: Epoch [22], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 83.749, Top5: 98.6552, Loss: 0.502\n",
            "Mon Apr 25 07:00:53 2022: Epoch [22], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 83.461, Top5: 98.5854, Loss: 0.523\n",
            "Mon Apr 25 07:01:01 2022: Epoch [23], Iteration [0/391/], Data(s): 0.036, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 82.812, Top5: 99.2188, Loss: 0.503\n",
            "Mon Apr 25 07:01:09 2022: Epoch [23], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 84.352, Top5: 98.6696, Loss: 0.486\n",
            "Mon Apr 25 07:01:17 2022: Epoch [23], Iteration [200/391/], Data(s): 0.033, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 84.021, Top5: 98.6552, Loss: 0.499\n",
            "Mon Apr 25 07:01:25 2022: Epoch [23], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 83.975, Top5: 98.6296, Loss: 0.504\n",
            "Mon Apr 25 07:01:33 2022: Epoch [24], Iteration [0/391/], Data(s): 0.039, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.007, Top1: 87.500, Top5: 100.0000, Loss: 0.514\n",
            "Mon Apr 25 07:01:41 2022: Epoch [24], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 84.530, Top5: 98.6773, Loss: 0.480\n",
            "Mon Apr 25 07:01:49 2022: Epoch [24], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 84.278, Top5: 98.6552, Loss: 0.496\n",
            "Mon Apr 25 07:01:57 2022: Epoch [24], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 84.087, Top5: 98.6815, Loss: 0.494\n",
            "Mon Apr 25 07:02:04 2022: Epoch [25], Iteration [0/391/], Data(s): 0.037, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 81.250, Top5: 97.6562, Loss: 0.503\n",
            "Mon Apr 25 07:02:13 2022: Epoch [25], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 83.826, Top5: 98.6309, Loss: 0.498\n",
            "Mon Apr 25 07:02:21 2022: Epoch [25], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 84.208, Top5: 98.7212, Loss: 0.476\n",
            "Mon Apr 25 07:02:29 2022: Epoch [25], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 84.243, Top5: 98.6607, Loss: 0.486\n",
            "Mon Apr 25 07:02:36 2022: Epoch [26], Iteration [0/391/], Data(s): 0.037, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 81.250, Top5: 97.6562, Loss: 0.504\n",
            "Mon Apr 25 07:02:44 2022: Epoch [26], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 84.506, Top5: 98.7469, Loss: 0.473\n",
            "Mon Apr 25 07:02:53 2022: Epoch [26], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 84.153, Top5: 98.7174, Loss: 0.491\n",
            "Mon Apr 25 07:03:01 2022: Epoch [26], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 84.069, Top5: 98.6633, Loss: 0.508\n",
            "Mon Apr 25 07:03:08 2022: Epoch [27], Iteration [0/391/], Data(s): 0.037, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 90.625, Top5: 99.2188, Loss: 0.503\n",
            "Mon Apr 25 07:03:16 2022: Epoch [27], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 84.684, Top5: 98.7469, Loss: 0.476\n",
            "Mon Apr 25 07:03:24 2022: Epoch [27], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 84.352, Top5: 98.6940, Loss: 0.492\n",
            "Mon Apr 25 07:03:33 2022: Epoch [27], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 84.474, Top5: 98.7360, Loss: 0.462\n",
            "Mon Apr 25 07:03:40 2022: Epoch [28], Iteration [0/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 85.938, Top5: 100.0000, Loss: 0.493\n",
            "Mon Apr 25 07:03:48 2022: Epoch [28], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 85.094, Top5: 98.8011, Loss: 0.455\n",
            "Mon Apr 25 07:03:56 2022: Epoch [28], Iteration [200/391/], Data(s): 0.033, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 84.834, Top5: 98.7757, Loss: 0.476\n",
            "Mon Apr 25 07:04:04 2022: Epoch [28], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 84.515, Top5: 98.7386, Loss: 0.504\n",
            "Mon Apr 25 07:04:12 2022: Epoch [29], Iteration [0/391/], Data(s): 0.035, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 85.938, Top5: 99.2188, Loss: 0.481\n",
            "Mon Apr 25 07:04:20 2022: Epoch [29], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 85.156, Top5: 98.7392, Loss: 0.455\n",
            "Mon Apr 25 07:04:28 2022: Epoch [29], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 84.923, Top5: 98.7601, Loss: 0.475\n",
            "Mon Apr 25 07:04:36 2022: Epoch [29], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 84.699, Top5: 98.7152, Loss: 0.489\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 07:04:48 2022: Test information, Data(s): 1.608, Forward(s): 0.503, Top1: 77.870, Top5: 97.560, \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prune VGG by 'greedy strategy'"
      ],
      "metadata": {
        "id": "ACmihQ_dkmJx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python \"/content/drive/MyDrive/BTP /main.py\" --prune-flag --load-path \"/content/drive/MyDrive/BTP /trained_models/check_point.pth\" --save-path ./trained_models/greedy_pruning_results/ --prune-layers conv1 conv2 conv3 conv4 conv5 conv6 conv7 conv8 conv9 conv10 conv11 conv12 conv13 --prune-channels 20 20 20 20 20 20 20 20 20 20 20 20 20"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPvW9048j50-",
        "outputId": "5febd8f6-60b7-44c9-d774-336a2b3a4cf5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tArguments\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "gpu_no: 0\n",
            "train_flag: False\n",
            "resume_flag: False\n",
            "prune_flag: True\n",
            "retrain_flag: False\n",
            "retrain_epoch: 20\n",
            "retrain_lr: 0.001\n",
            "data_set: CIFAR10\n",
            "data_path: ../\n",
            "vgg: vgg16_bn\n",
            "start_epoch: 0\n",
            "epoch: 350\n",
            "batch_size: 128\n",
            "num_workers: 2\n",
            "lr: 0.1\n",
            "lr_milestone: [150, 250]\n",
            "lr_gamma: 0.1\n",
            "momentum: 0.9\n",
            "weight_decay: 0.0005\n",
            "imsize: None\n",
            "cropsize: 32\n",
            "crop_padding: 4\n",
            "hflip: 0.5\n",
            "print_freq: 100\n",
            "load_path: /content/drive/MyDrive/BTP /trained_models/check_point.pth\n",
            "save_path: ./trained_models/greedy_pruning_results/\n",
            "independent_prune_flag: False\n",
            "prune_layers: ['conv1', 'conv2', 'conv3', 'conv4', 'conv5', 'conv6', 'conv7', 'conv8', 'conv9', 'conv10', 'conv11', 'conv12', 'conv13']\n",
            "prune_channels: [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20]\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 44, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(44, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(44, 44, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(44, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(44, 108, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(108, 108, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(108, 236, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(236, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(236, 236, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(236, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(236, 236, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(236, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(236, 492, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(492, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(492, 492, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(492, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(492, 492, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(492, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(492, 492, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(492, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(492, 492, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(492, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(492, 492, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(492, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=492, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 44, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(44, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(44, 44, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(44, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(44, 108, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(108, 108, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(108, 236, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(236, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(236, 236, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(236, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(236, 236, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(236, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(236, 492, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(492, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(492, 492, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(492, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(492, 492, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(492, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(492, 492, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(492, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(492, 492, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(492, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(492, 492, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(492, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=492, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Tue Apr 26 03:14:26 2022: Test information, Data(s): 2.997, Forward(s): 0.554, Top1: 70.240, Top5: 94.760, \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prune VGG by 'independent strategy'"
      ],
      "metadata": {
        "id": "BG6ot3I-kvHp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python \"/content/drive/MyDrive/BTP /main.py\" --prune-flag --load-path \"/content/drive/MyDrive/BTP /trained_models/check_point.pth\" --save-path ./trained_models/independent_pruning_results/ --prune-layers conv1 conv2 conv3 conv4 conv5 conv6 conv7 conv8 conv9 conv10 conv11 conv12 conv13 --prune-channels 20 20 20 20 20 20 20 20 20 20 20 20 20 --independent-prune-flag"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgSnxfwnkV7W",
        "outputId": "1e193f1e-5aee-4f9d-fa9b-5a3ccc48f68d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tArguments\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "gpu_no: 0\n",
            "train_flag: False\n",
            "resume_flag: False\n",
            "prune_flag: True\n",
            "retrain_flag: False\n",
            "retrain_epoch: 20\n",
            "retrain_lr: 0.001\n",
            "data_set: CIFAR10\n",
            "data_path: ../\n",
            "vgg: vgg16_bn\n",
            "start_epoch: 0\n",
            "epoch: 350\n",
            "batch_size: 128\n",
            "num_workers: 2\n",
            "lr: 0.1\n",
            "lr_milestone: [150, 250]\n",
            "lr_gamma: 0.1\n",
            "momentum: 0.9\n",
            "weight_decay: 0.0005\n",
            "imsize: None\n",
            "cropsize: 32\n",
            "crop_padding: 4\n",
            "hflip: 0.5\n",
            "print_freq: 100\n",
            "load_path: /content/drive/MyDrive/BTP /trained_models/check_point.pth\n",
            "save_path: ./trained_models/independent_pruning_results/\n",
            "independent_prune_flag: True\n",
            "prune_layers: ['conv1', 'conv2', 'conv3', 'conv4', 'conv5', 'conv6', 'conv7', 'conv8', 'conv9', 'conv10', 'conv11', 'conv12', 'conv13']\n",
            "prune_channels: [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20]\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 44, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(44, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(44, 44, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(44, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(44, 108, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(108, 108, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(108, 236, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(236, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(236, 236, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(236, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(236, 236, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(236, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(236, 492, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(492, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(492, 492, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(492, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(492, 492, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(492, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(492, 492, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(492, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(492, 492, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(492, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(492, 492, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(492, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=492, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 44, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(44, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(44, 44, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(44, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(44, 108, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(108, 108, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(108, 236, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(236, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(236, 236, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(236, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(236, 236, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(236, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(236, 492, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(492, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(492, 492, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(492, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(492, 492, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(492, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(492, 492, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(492, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(492, 492, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(492, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(492, 492, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(492, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=492, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Tue Apr 26 03:14:49 2022: Test information, Data(s): 2.980, Forward(s): 0.566, Top1: 70.430, Top5: 94.890, \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Retrain the pruned network"
      ],
      "metadata": {
        "id": "CwSsnBqv5vIP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !python main.py --prune-flag --load-path ./trained_models/check_point.pth --save-path ./trained_models/pruning_reusults/ --prune-layers conv1 --prune-channels 1 --retrain-flag --retrain-epoch 20 --retrain-lr 0.001"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EeDUEsws5zsn",
        "outputId": "76a338e1-382f-4947-bbb3-8c26b05d8f0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tArguments\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "gpu_no: 0\n",
            "train_flag: False\n",
            "resume_flag: False\n",
            "prune_flag: True\n",
            "retrain_flag: True\n",
            "retrain_epoch: 20\n",
            "retrain_lr: 0.001\n",
            "data_set: CIFAR10\n",
            "data_path: ../\n",
            "vgg: vgg16_bn\n",
            "start_epoch: 0\n",
            "epoch: 350\n",
            "batch_size: 128\n",
            "num_workers: 2\n",
            "lr: 0.1\n",
            "lr_milestone: [150, 250]\n",
            "lr_gamma: 0.1\n",
            "momentum: 0.9\n",
            "weight_decay: 0.0005\n",
            "imsize: None\n",
            "cropsize: 32\n",
            "crop_padding: 4\n",
            "hflip: 0.5\n",
            "print_freq: 100\n",
            "load_path: ./trained_models/check_point.pth\n",
            "save_path: ./trained_models/pruning_reuslts/\n",
            "independent_prune_flag: False\n",
            "prune_layers: ['conv1']\n",
            "prune_channels: [1]\n",
            "Make dir:  ./trained_models/pruning_reuslts/\n",
            "Traceback (most recent call last):\n",
            "  File \"main.py\", line 14, in <module>\n",
            "    network = prune_network(args, network=network)\n",
            "  File \"/content/prune.py\", line 12, in prune_network\n",
            "    check_point = torch.load(args.load_path)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/serialization.py\", line 594, in load\n",
            "    with _open_file_like(f, 'rb') as opened_file:\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/serialization.py\", line 230, in _open_file_like\n",
            "    return _open_file(name_or_buffer, mode)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/serialization.py\", line 211, in __init__\n",
            "    super(_open_file, self).__init__(open(name, mode))\n",
            "FileNotFoundError: [Errno 2] No such file or directory: './trained_models/check_point.pth'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9w48wZdRuosO",
        "outputId": "31c1b2b4-df52-48fb-c46f-7f89c03d6308"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualization"
      ],
      "metadata": {
        "id": "CJzDcSxo526e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
        "\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "device = torch.device('cuda')"
      ],
      "metadata": {
        "id": "3grNbrG657kJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Arguments"
      ],
      "metadata": {
        "id": "W5OtV06Z6epm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "load_path = '/content/drive/MyDrive/BTP /trained_models/'\n",
        "\n",
        "args = torch.load(load_path+'arguments.pth')\n",
        "for key, value in vars(args).items():\n",
        "    print(\"%s: %s\"%(key, value))\n",
        "\n",
        "args.load_path = load_path + 'check_point.pth'\n",
        "args.save_path = load_path+'%s/'%time.ctime().replace(' ', '_')\n",
        "if not os.path.exists(args.save_path):\n",
        "    os.makedirs(args.save_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_jT0LUt6AT7",
        "outputId": "8cee498f-f81b-49b2-985b-fb8f948f7ea9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gpu_no: 0\n",
            "train_flag: True\n",
            "resume_flag: False\n",
            "prune_flag: False\n",
            "retrain_flag: False\n",
            "retrain_epoch: 20\n",
            "retrain_lr: 0.001\n",
            "data_set: CIFAR10\n",
            "data_path: ../\n",
            "vgg: vgg16_bn\n",
            "start_epoch: 0\n",
            "epoch: 30\n",
            "batch_size: 128\n",
            "num_workers: 2\n",
            "lr: 0.1\n",
            "lr_milestone: [150, 250]\n",
            "lr_gamma: 0.1\n",
            "momentum: 0.9\n",
            "weight_decay: 0.0005\n",
            "imsize: None\n",
            "cropsize: 32\n",
            "crop_padding: 4\n",
            "hflip: 0.5\n",
            "print_freq: 100\n",
            "load_path: None\n",
            "save_path: ./trained_models/\n",
            "independent_prune_flag: False\n",
            "prune_layers: None\n",
            "prune_channels: None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check: accuracy of test data"
      ],
      "metadata": {
        "id": "JsP2gk7j7gJf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "network, test_set, (top1, top5) = test_network(args)"
      ],
      "metadata": {
        "id": "l8MB0Xzu6iN-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173,
          "referenced_widgets": [
            "f08a1dfcb2124e8f8880d7c673eefc35",
            "0dc23f5142204f51b2345e404e48a12a",
            "cf866795916240ff99d3fc3398b802c8",
            "89e6ecd7de274bd2ba4cd42e96993dfb",
            "e95cc7cc596a4b4bb738a2ce52407ac4",
            "64d6ffcb7f8e46ff851272ce0df49659",
            "7f1a4c1ca102495c8b6e66c150908b3d",
            "38ee1e89efa540948904e75d905ba677",
            "ef3b461901f1483abca37bba9bf47f2a",
            "37acf43398a948b79bac25e69d3006df",
            "0aaa1423d76f4c1382e0f2d2bfc8f4f3"
          ]
        },
        "outputId": "b776df28-3d03-4f77-a833-96d4db5a2f23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ../cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f08a1dfcb2124e8f8880d7c673eefc35"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../cifar-10-python.tar.gz to ../\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Tue Apr 26 02:41:25 2022: Test information, Data(s): 3.059, Forward(s): 0.699, Top1: 77.870, Top5: 97.560, \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "colors = ['r', 'g', 'b', 'k', 'y', 'm', 'c']\n",
        "lines = ['-', '--', '-.']"
      ],
      "metadata": {
        "id": "7Al_A8MoAaRe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "plt.figure(figsize=(7,5))\n",
        "conv_count = 0\n",
        "for layer in network.features:\n",
        "    if isinstance(layer, torch.nn.Conv2d):\n",
        "        line_style = colors[conv_count%len(colors)] + lines[conv_count//len(colors)]\n",
        "        \n",
        "        # filter weight dimension info: out_ch, in_ch, k1, k2\n",
        "        fw = layer.weight.data.cpu().numpy()\n",
        "        \n",
        "        # sort descending order\n",
        "        sorted_abs_sum = np.sort(np.sum(np.abs(fw.reshape(fw.shape[0], -1)), axis=1))[::-1]\n",
        "        \n",
        "        # normalize with maximum value\n",
        "        normalized_abs_sum = sorted_abs_sum/sorted_abs_sum[0]\n",
        "        conv_count += 1\n",
        "        plt.plot(np.linspace(0, 100, normalized_abs_sum.shape[0]), normalized_abs_sum, line_style, label='conv %d'%conv_count)\n",
        "        \n",
        "plt.title(\"Data: %s, Model: %s\"%(args.data_set, args.vgg))        \n",
        "plt.ylabel(\"normalized abs sum of filter weight\")\n",
        "plt.xlabel(\"filter index / # filters (%)\")\n",
        "plt.legend(loc='upper right')\n",
        "plt.xlim([0, 140])\n",
        "plt.grid()\n",
        "plt.savefig(\"figure1.png\", dpi=150, bbox_inches='tight')\n",
        "plt.show()        "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "G0AmMWl8Buuc",
        "outputId": "27555cdc-5fea-4afc-d03f-f3c2b62485b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 504x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## check: accuracy of the pruned network"
      ],
      "metadata": {
        "id": "Jo2lP85_CCOu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prune_step_ratio = 1/8\n",
        "max_channel_ratio = 0.90 \n",
        "\n",
        "prune_channels = [64, 64, 128, 128, 256, 256, 256, 512, 512, 512, 512, 512, 512]\n",
        "prune_layers = ['conv1', 'conv2', 'conv3', 'conv4', 'conv5', 'conv6', 'conv7', 'conv8', 'conv9', 'conv10', 'conv11', 'conv12', 'conv13']"
      ],
      "metadata": {
        "id": "GwZvqX6QBwto"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check accuracy of the pruned network"
      ],
      "metadata": {
        "id": "95-dEHSECJom"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "top1_accuracies = {}\n",
        "top5_accuracies = {}\n",
        "\n",
        "for conv, channel in zip(prune_layers, prune_channels):    \n",
        "    top1_accuracies[conv] = []\n",
        "    top5_accuracies[conv] = []\n",
        "    \n",
        "    # load new network and check accuracy\n",
        "    network, _, _ = test_network(args, data_set=test_set)\n",
        "        \n",
        "    # remove 0 channels ~ M (max_channel_ratio) % of total channels\n",
        "    step = np.linspace(0, int(channel*max_channel_ratio), int(1/prune_step_ratio), dtype=np.int)\n",
        "    steps = (step[1:] - step[:-1]).tolist()\n",
        "    \n",
        "    for i in range(len(steps)):\n",
        "        print(\"\\n%s: %s Layer, %d Channels pruned\"%(time.ctime(), conv, sum(steps[:i+1])))\n",
        "        \n",
        "        # set prune information\n",
        "        args.prune_layers = [conv]\n",
        "        args.prune_channels =[steps[i]]\n",
        "\n",
        "        network = prune_network(args, network)\n",
        "        \n",
        "        network, _, (top1, top5) = test_network(args, network, test_set)\n",
        "            \n",
        "        top1_accuracies[conv].append(top1)\n",
        "        top5_accuracies[conv].append(top5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fAhucx6xCE-L",
        "outputId": "5cefeca2-a273-48c8-f3b6-ff9aa3946b9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 09:25:30 2022: Test information, Data(s): 1.611, Forward(s): 0.211, Top1: 77.870, Top5: 97.560, \n",
            "\n",
            "Mon Apr 25 09:25:30 2022: conv1 Layer, 8 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 56, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(56, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  if sys.path[0] == '':\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(24, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 09:26:10 2022: Test information, Data(s): 1.687, Forward(s): 0.223, Top1: 52.860, Top5: 84.360, \n",
            "\n",
            "Mon Apr 25 09:26:10 2022: conv2 Layer, 48 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(16, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 09:26:13 2022: Test information, Data(s): 1.732, Forward(s): 0.219, Top1: 32.500, Top5: 65.890, \n",
            "\n",
            "Mon Apr 25 09:26:13 2022: conv2 Layer, 57 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(7, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 09:26:16 2022: Test information, Data(s): 1.631, Forward(s): 0.217, Top1: 21.250, Top5: 65.660, \n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 09:26:21 2022: Test information, Data(s): 2.019, Forward(s): 0.243, Top1: 77.870, Top5: 97.560, \n",
            "\n",
            "Mon Apr 25 09:26:21 2022: conv3 Layer, 16 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 112, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(112, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 09:26:25 2022: Test information, Data(s): 2.287, Forward(s): 0.286, Top1: 77.460, Top5: 97.440, \n",
            "\n",
            "Mon Apr 25 09:26:25 2022: conv3 Layer, 32 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 09:26:28 2022: Test information, Data(s): 1.670, Forward(s): 0.213, Top1: 75.630, Top5: 97.120, \n",
            "\n",
            "Mon Apr 25 09:26:28 2022: conv3 Layer, 49 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 79, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(79, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(79, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 09:26:31 2022: Test information, Data(s): 1.621, Forward(s): 0.213, Top1: 71.170, Top5: 95.770, \n",
            "\n",
            "Mon Apr 25 09:26:31 2022: conv3 Layer, 65 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 63, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(63, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(63, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 09:26:34 2022: Test information, Data(s): 1.664, Forward(s): 0.218, Top1: 68.280, Top5: 94.910, \n",
            "\n",
            "Mon Apr 25 09:26:34 2022: conv3 Layer, 82 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 46, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(46, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(46, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 09:26:37 2022: Test information, Data(s): 1.652, Forward(s): 0.215, Top1: 53.130, Top5: 91.300, \n",
            "\n",
            "Mon Apr 25 09:26:37 2022: conv3 Layer, 98 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(30, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 09:26:40 2022: Test information, Data(s): 1.646, Forward(s): 0.213, Top1: 40.260, Top5: 87.290, \n",
            "\n",
            "Mon Apr 25 09:26:40 2022: conv3 Layer, 115 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 13, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(13, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 09:26:43 2022: Test information, Data(s): 1.610, Forward(s): 0.213, Top1: 18.020, Top5: 69.340, \n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 09:26:48 2022: Test information, Data(s): 1.634, Forward(s): 0.212, Top1: 77.870, Top5: 97.560, \n",
            "\n",
            "Mon Apr 25 09:26:48 2022: conv4 Layer, 16 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 112, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(112, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 09:26:51 2022: Test information, Data(s): 1.666, Forward(s): 0.215, Top1: 76.740, Top5: 97.110, \n",
            "\n",
            "Mon Apr 25 09:26:51 2022: conv4 Layer, 32 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(96, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 09:26:54 2022: Test information, Data(s): 2.101, Forward(s): 0.259, Top1: 74.030, Top5: 96.450, \n",
            "\n",
            "Mon Apr 25 09:26:54 2022: conv4 Layer, 49 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 79, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(79, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(79, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 09:26:57 2022: Test information, Data(s): 1.641, Forward(s): 0.215, Top1: 67.580, Top5: 94.360, \n",
            "\n",
            "Mon Apr 25 09:26:57 2022: conv4 Layer, 65 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 63, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(63, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(63, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 09:27:00 2022: Test information, Data(s): 1.646, Forward(s): 0.214, Top1: 64.910, Top5: 93.170, \n",
            "\n",
            "Mon Apr 25 09:27:00 2022: conv4 Layer, 82 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 46, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(46, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(46, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 09:27:03 2022: Test information, Data(s): 1.653, Forward(s): 0.220, Top1: 58.450, Top5: 89.620, \n",
            "\n",
            "Mon Apr 25 09:27:03 2022: conv4 Layer, 98 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(30, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 09:27:06 2022: Test information, Data(s): 1.678, Forward(s): 0.219, Top1: 40.920, Top5: 83.560, \n",
            "\n",
            "Mon Apr 25 09:27:06 2022: conv4 Layer, 115 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 13, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(13, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 09:27:09 2022: Test information, Data(s): 1.640, Forward(s): 0.216, Top1: 18.850, Top5: 54.390, \n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 09:27:15 2022: Test information, Data(s): 2.399, Forward(s): 0.299, Top1: 77.870, Top5: 97.560, \n",
            "\n",
            "Mon Apr 25 09:27:15 2022: conv5 Layer, 32 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(224, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 09:27:18 2022: Test information, Data(s): 1.610, Forward(s): 0.212, Top1: 77.350, Top5: 97.450, \n",
            "\n",
            "Mon Apr 25 09:27:18 2022: conv5 Layer, 65 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 191, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(191, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(191, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 09:27:21 2022: Test information, Data(s): 1.960, Forward(s): 0.248, Top1: 75.100, Top5: 96.630, \n",
            "\n",
            "Mon Apr 25 09:27:21 2022: conv5 Layer, 98 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 158, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(158, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(158, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 09:27:25 2022: Test information, Data(s): 1.986, Forward(s): 0.248, Top1: 70.200, Top5: 93.770, \n",
            "\n",
            "Mon Apr 25 09:27:25 2022: conv5 Layer, 131 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 125, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(125, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(125, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 09:27:28 2022: Test information, Data(s): 1.634, Forward(s): 0.213, Top1: 66.700, Top5: 91.980, \n",
            "\n",
            "Mon Apr 25 09:27:28 2022: conv5 Layer, 164 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 92, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(92, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(92, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 09:27:31 2022: Test information, Data(s): 2.001, Forward(s): 0.237, Top1: 58.070, Top5: 87.120, \n",
            "\n",
            "Mon Apr 25 09:27:31 2022: conv5 Layer, 197 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 59, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(59, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(59, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 09:27:34 2022: Test information, Data(s): 1.616, Forward(s): 0.211, Top1: 38.990, Top5: 78.500, \n",
            "\n",
            "Mon Apr 25 09:27:34 2022: conv5 Layer, 230 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 26, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(26, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 09:27:37 2022: Test information, Data(s): 1.685, Forward(s): 0.234, Top1: 12.530, Top5: 61.740, \n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 09:27:42 2022: Test information, Data(s): 1.626, Forward(s): 0.211, Top1: 77.870, Top5: 97.560, \n",
            "\n",
            "Mon Apr 25 09:27:42 2022: conv6 Layer, 32 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(224, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 09:27:45 2022: Test information, Data(s): 1.823, Forward(s): 0.234, Top1: 78.350, Top5: 97.760, \n",
            "\n",
            "Mon Apr 25 09:27:45 2022: conv6 Layer, 65 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 191, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(191, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(191, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 09:27:48 2022: Test information, Data(s): 1.897, Forward(s): 0.251, Top1: 78.600, Top5: 97.710, \n",
            "\n",
            "Mon Apr 25 09:27:48 2022: conv6 Layer, 98 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 158, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(158, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(158, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 09:27:51 2022: Test information, Data(s): 1.635, Forward(s): 0.218, Top1: 79.080, Top5: 97.810, \n",
            "\n",
            "Mon Apr 25 09:27:51 2022: conv6 Layer, 131 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 125, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(125, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(125, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 09:27:54 2022: Test information, Data(s): 1.650, Forward(s): 0.215, Top1: 79.050, Top5: 97.850, \n",
            "\n",
            "Mon Apr 25 09:27:54 2022: conv6 Layer, 164 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 92, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(92, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(92, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 09:27:57 2022: Test information, Data(s): 1.639, Forward(s): 0.210, Top1: 74.480, Top5: 97.480, \n",
            "\n",
            "Mon Apr 25 09:27:57 2022: conv6 Layer, 197 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 59, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(59, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(59, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 09:28:00 2022: Test information, Data(s): 1.617, Forward(s): 0.216, Top1: 63.820, Top5: 95.280, \n",
            "\n",
            "Mon Apr 25 09:28:00 2022: conv6 Layer, 230 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 26, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(26, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 09:28:03 2022: Test information, Data(s): 1.688, Forward(s): 0.224, Top1: 32.080, Top5: 74.710, \n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 09:28:08 2022: Test information, Data(s): 1.628, Forward(s): 0.215, Top1: 77.870, Top5: 97.560, \n",
            "\n",
            "Mon Apr 25 09:28:08 2022: conv7 Layer, 32 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(224, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 09:28:11 2022: Test information, Data(s): 1.645, Forward(s): 0.207, Top1: 78.500, Top5: 97.670, \n",
            "\n",
            "Mon Apr 25 09:28:11 2022: conv7 Layer, 65 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 191, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(191, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(191, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 09:28:14 2022: Test information, Data(s): 1.710, Forward(s): 0.224, Top1: 78.990, Top5: 97.790, \n",
            "\n",
            "Mon Apr 25 09:28:14 2022: conv7 Layer, 98 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 158, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(158, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(158, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 09:28:17 2022: Test information, Data(s): 1.633, Forward(s): 0.214, Top1: 78.280, Top5: 97.730, \n",
            "\n",
            "Mon Apr 25 09:28:17 2022: conv7 Layer, 131 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 125, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(125, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(125, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 09:28:20 2022: Test information, Data(s): 1.629, Forward(s): 0.212, Top1: 77.410, Top5: 97.720, \n",
            "\n",
            "Mon Apr 25 09:28:20 2022: conv7 Layer, 164 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 92, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(92, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(92, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 09:28:23 2022: Test information, Data(s): 1.637, Forward(s): 0.211, Top1: 74.840, Top5: 97.530, \n",
            "\n",
            "Mon Apr 25 09:28:23 2022: conv7 Layer, 197 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 59, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(59, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(59, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 09:28:26 2022: Test information, Data(s): 1.633, Forward(s): 0.208, Top1: 59.960, Top5: 94.520, \n",
            "\n",
            "Mon Apr 25 09:28:26 2022: conv7 Layer, 230 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 26, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(26, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 09:28:29 2022: Test information, Data(s): 1.626, Forward(s): 0.208, Top1: 41.770, Top5: 82.950, \n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 09:28:34 2022: Test information, Data(s): 1.679, Forward(s): 0.210, Top1: 77.870, Top5: 97.560, \n",
            "\n",
            "Mon Apr 25 09:28:34 2022: conv8 Layer, 65 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 447, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(447, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(447, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 09:28:37 2022: Test information, Data(s): 1.662, Forward(s): 0.214, Top1: 77.630, Top5: 97.600, \n",
            "\n",
            "Mon Apr 25 09:28:37 2022: conv8 Layer, 131 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 381, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(381, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(381, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 09:28:40 2022: Test information, Data(s): 1.621, Forward(s): 0.216, Top1: 77.010, Top5: 97.600, \n",
            "\n",
            "Mon Apr 25 09:28:40 2022: conv8 Layer, 197 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 315, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(315, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(315, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 09:28:43 2022: Test information, Data(s): 1.652, Forward(s): 0.212, Top1: 75.930, Top5: 97.460, \n",
            "\n",
            "Mon Apr 25 09:28:43 2022: conv8 Layer, 262 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 250, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(250, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(250, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 09:28:46 2022: Test information, Data(s): 1.644, Forward(s): 0.217, Top1: 73.440, Top5: 97.190, \n",
            "\n",
            "Mon Apr 25 09:28:46 2022: conv8 Layer, 328 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(184, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 09:28:49 2022: Test information, Data(s): 1.645, Forward(s): 0.214, Top1: 69.780, Top5: 96.700, \n",
            "\n",
            "Mon Apr 25 09:28:49 2022: conv8 Layer, 394 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 118, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(118, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(118, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 09:28:52 2022: Test information, Data(s): 1.626, Forward(s): 0.212, Top1: 61.960, Top5: 95.840, \n",
            "\n",
            "Mon Apr 25 09:28:52 2022: conv8 Layer, 460 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 52, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(52, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 09:28:55 2022: Test information, Data(s): 1.634, Forward(s): 0.218, Top1: 42.290, Top5: 80.780, \n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 09:29:00 2022: Test information, Data(s): 1.629, Forward(s): 0.209, Top1: 77.870, Top5: 97.560, \n",
            "\n",
            "Mon Apr 25 09:29:00 2022: conv9 Layer, 65 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 447, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(447, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(447, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 09:29:03 2022: Test information, Data(s): 1.602, Forward(s): 0.210, Top1: 77.770, Top5: 97.570, \n",
            "\n",
            "Mon Apr 25 09:29:03 2022: conv9 Layer, 131 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 381, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(381, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(381, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 09:29:06 2022: Test information, Data(s): 1.605, Forward(s): 0.211, Top1: 77.440, Top5: 97.610, \n",
            "\n",
            "Mon Apr 25 09:29:06 2022: conv9 Layer, 197 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 315, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(315, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(315, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 09:29:09 2022: Test information, Data(s): 1.654, Forward(s): 0.213, Top1: 77.220, Top5: 97.550, \n",
            "\n",
            "Mon Apr 25 09:29:09 2022: conv9 Layer, 262 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 250, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(250, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(250, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 09:29:12 2022: Test information, Data(s): 1.608, Forward(s): 0.211, Top1: 76.680, Top5: 97.550, \n",
            "\n",
            "Mon Apr 25 09:29:12 2022: conv9 Layer, 328 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(184, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 09:29:14 2022: Test information, Data(s): 1.612, Forward(s): 0.213, Top1: 74.640, Top5: 97.190, \n",
            "\n",
            "Mon Apr 25 09:29:14 2022: conv9 Layer, 394 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 118, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(118, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(118, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 09:29:17 2022: Test information, Data(s): 1.589, Forward(s): 0.207, Top1: 70.560, Top5: 96.470, \n",
            "\n",
            "Mon Apr 25 09:29:17 2022: conv9 Layer, 460 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 52, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(52, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 09:29:20 2022: Test information, Data(s): 1.626, Forward(s): 0.208, Top1: 58.370, Top5: 94.060, \n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 09:29:25 2022: Test information, Data(s): 1.625, Forward(s): 0.214, Top1: 77.870, Top5: 97.560, \n",
            "\n",
            "Mon Apr 25 09:29:25 2022: conv10 Layer, 65 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 447, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(447, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(447, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 09:29:28 2022: Test information, Data(s): 1.635, Forward(s): 0.212, Top1: 77.640, Top5: 97.620, \n",
            "\n",
            "Mon Apr 25 09:29:28 2022: conv10 Layer, 131 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 381, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(381, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(381, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 09:29:31 2022: Test information, Data(s): 1.644, Forward(s): 0.213, Top1: 76.950, Top5: 97.440, \n",
            "\n",
            "Mon Apr 25 09:29:31 2022: conv10 Layer, 197 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 315, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(315, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(315, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 09:29:34 2022: Test information, Data(s): 1.637, Forward(s): 0.214, Top1: 75.210, Top5: 97.190, \n",
            "\n",
            "Mon Apr 25 09:29:34 2022: conv10 Layer, 262 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 250, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(250, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(250, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 09:29:37 2022: Test information, Data(s): 1.610, Forward(s): 0.210, Top1: 71.380, Top5: 96.320, \n",
            "\n",
            "Mon Apr 25 09:29:37 2022: conv10 Layer, 328 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(184, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 09:29:40 2022: Test information, Data(s): 1.644, Forward(s): 0.213, Top1: 61.910, Top5: 94.460, \n",
            "\n",
            "Mon Apr 25 09:29:40 2022: conv10 Layer, 394 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 118, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(118, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(118, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 09:29:43 2022: Test information, Data(s): 1.625, Forward(s): 0.214, Top1: 47.200, Top5: 88.920, \n",
            "\n",
            "Mon Apr 25 09:29:43 2022: conv10 Layer, 460 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 52, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(52, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 09:29:46 2022: Test information, Data(s): 1.630, Forward(s): 0.213, Top1: 18.300, Top5: 82.060, \n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 09:29:51 2022: Test information, Data(s): 1.604, Forward(s): 0.213, Top1: 77.870, Top5: 97.560, \n",
            "\n",
            "Mon Apr 25 09:29:51 2022: conv11 Layer, 65 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 447, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(447, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(447, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 09:29:54 2022: Test information, Data(s): 1.640, Forward(s): 0.213, Top1: 77.180, Top5: 97.490, \n",
            "\n",
            "Mon Apr 25 09:29:54 2022: conv11 Layer, 131 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 381, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(381, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(381, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 09:29:57 2022: Test information, Data(s): 1.616, Forward(s): 0.210, Top1: 75.180, Top5: 96.890, \n",
            "\n",
            "Mon Apr 25 09:29:57 2022: conv11 Layer, 197 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 315, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(315, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(315, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 09:30:00 2022: Test information, Data(s): 1.634, Forward(s): 0.210, Top1: 69.740, Top5: 95.810, \n",
            "\n",
            "Mon Apr 25 09:30:00 2022: conv11 Layer, 262 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 250, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(250, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(250, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 09:30:03 2022: Test information, Data(s): 1.608, Forward(s): 0.207, Top1: 54.820, Top5: 91.620, \n",
            "\n",
            "Mon Apr 25 09:30:03 2022: conv11 Layer, 328 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(184, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 09:30:06 2022: Test information, Data(s): 1.619, Forward(s): 0.214, Top1: 39.390, Top5: 85.680, \n",
            "\n",
            "Mon Apr 25 09:30:06 2022: conv11 Layer, 394 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 118, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(118, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(118, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 09:30:08 2022: Test information, Data(s): 1.645, Forward(s): 0.217, Top1: 31.730, Top5: 78.460, \n",
            "\n",
            "Mon Apr 25 09:30:08 2022: conv11 Layer, 460 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 52, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(52, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 09:30:11 2022: Test information, Data(s): 1.611, Forward(s): 0.214, Top1: 18.440, Top5: 63.470, \n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 09:30:16 2022: Test information, Data(s): 1.607, Forward(s): 0.206, Top1: 77.870, Top5: 97.560, \n",
            "\n",
            "Mon Apr 25 09:30:16 2022: conv12 Layer, 65 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 447, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(447, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(447, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 09:30:19 2022: Test information, Data(s): 1.583, Forward(s): 0.208, Top1: 77.030, Top5: 97.550, \n",
            "\n",
            "Mon Apr 25 09:30:19 2022: conv12 Layer, 131 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 381, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(381, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(381, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 09:30:22 2022: Test information, Data(s): 1.613, Forward(s): 0.210, Top1: 74.270, Top5: 97.130, \n",
            "\n",
            "Mon Apr 25 09:30:22 2022: conv12 Layer, 197 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 315, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(315, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(315, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 09:30:25 2022: Test information, Data(s): 1.609, Forward(s): 0.209, Top1: 66.580, Top5: 95.760, \n",
            "\n",
            "Mon Apr 25 09:30:25 2022: conv12 Layer, 262 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 250, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(250, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(250, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 09:30:28 2022: Test information, Data(s): 1.618, Forward(s): 0.210, Top1: 48.690, Top5: 90.730, \n",
            "\n",
            "Mon Apr 25 09:30:28 2022: conv12 Layer, 328 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(184, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 09:30:31 2022: Test information, Data(s): 1.611, Forward(s): 0.210, Top1: 36.620, Top5: 79.650, \n",
            "\n",
            "Mon Apr 25 09:30:31 2022: conv12 Layer, 394 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 118, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(118, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(118, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 09:30:34 2022: Test information, Data(s): 1.609, Forward(s): 0.212, Top1: 23.710, Top5: 67.010, \n",
            "\n",
            "Mon Apr 25 09:30:34 2022: conv12 Layer, 460 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 52, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(52, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 09:30:37 2022: Test information, Data(s): 1.632, Forward(s): 0.213, Top1: 19.530, Top5: 58.450, \n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 09:30:42 2022: Test information, Data(s): 1.631, Forward(s): 0.210, Top1: 77.870, Top5: 97.560, \n",
            "\n",
            "Mon Apr 25 09:30:42 2022: conv13 Layer, 65 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 447, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(447, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=447, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 09:30:45 2022: Test information, Data(s): 1.625, Forward(s): 0.211, Top1: 77.310, Top5: 97.400, \n",
            "\n",
            "Mon Apr 25 09:30:45 2022: conv13 Layer, 131 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 381, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(381, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=381, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 09:30:48 2022: Test information, Data(s): 1.621, Forward(s): 0.211, Top1: 71.050, Top5: 95.910, \n",
            "\n",
            "Mon Apr 25 09:30:48 2022: conv13 Layer, 197 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 315, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(315, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=315, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 09:30:51 2022: Test information, Data(s): 1.637, Forward(s): 0.206, Top1: 54.090, Top5: 91.920, \n",
            "\n",
            "Mon Apr 25 09:30:51 2022: conv13 Layer, 262 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 250, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(250, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=250, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 09:30:54 2022: Test information, Data(s): 1.662, Forward(s): 0.209, Top1: 35.100, Top5: 86.880, \n",
            "\n",
            "Mon Apr 25 09:30:54 2022: conv13 Layer, 328 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=184, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 09:30:57 2022: Test information, Data(s): 1.634, Forward(s): 0.208, Top1: 23.100, Top5: 83.850, \n",
            "\n",
            "Mon Apr 25 09:30:57 2022: conv13 Layer, 394 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 118, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(118, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=118, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 09:31:00 2022: Test information, Data(s): 1.664, Forward(s): 0.210, Top1: 17.570, Top5: 83.480, \n",
            "\n",
            "Mon Apr 25 09:31:00 2022: conv13 Layer, 460 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 52, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=52, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 09:31:03 2022: Test information, Data(s): 1.649, Forward(s): 0.208, Top1: 10.000, Top5: 77.500, \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot accuracy graph"
      ],
      "metadata": {
        "id": "VlrVYXYmCtex"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(7,5))\n",
        "for index, (key, value) in enumerate(top1_accuracies.items()):\n",
        "    line_style = colors[index%len(colors)] + lines[index//len(colors)] +'o'\n",
        "    plt.plot(np.linspace(0, 95, len(value)), value, line_style, label=key)\n",
        "\n",
        "plt.title(\"Data: %s, Model: %s, pruned smallest filters\"%(args.data_set, args.vgg))        \n",
        "plt.ylabel(\"Top1 Accuracy\")\n",
        "plt.xlabel(\"Filters Pruned Away (%)\")\n",
        "plt.legend(loc='lower left')\n",
        "plt.grid()\n",
        "plt.xlim(0, 100)\n",
        "plt.savefig(\"figure2_top1.png\", dpi=150, bbox_inches='tight')\n",
        "plt.show()                \n",
        "\n",
        "plt.figure(figsize=(7,5))\n",
        "for index, (key, value) in enumerate(top5_accuracies.items()):\n",
        "    line_style = colors[index%len(colors)] + lines[index//len(colors)] +'o'\n",
        "    plt.plot(np.linspace(0, 95, len(value)), value, line_style, label=key)\n",
        "\n",
        "plt.title(\"Data: %s, Model: %s, pruned smallest filters\"%(args.data_set, args.vgg))        \n",
        "plt.ylabel(\"Top5 Accuracy\")\n",
        "plt.xlabel(\"Filters Pruned Away (%)\")\n",
        "plt.legend(loc='lower left')\n",
        "plt.grid()\n",
        "plt.xlim(0, 100)\n",
        "plt.savefig(\"figure2_top5.png\", dpi=150, bbox_inches='tight')\n",
        "plt.show()      "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        },
        "id": "Hzd2VfE5CjBd",
        "outputId": "933ae336-c8c1-4dae-9404-80047023c412"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 504x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 504x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check: Accuracy of retrained the pruned network"
      ],
      "metadata": {
        "id": "DHNU7NCRC4y2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "args.retrain_flag = True\n",
        "args.retrain_epoch = 10\n",
        "args.independent_prune_flag = False\n",
        "args.retrain_lr = 0.001"
      ],
      "metadata": {
        "id": "KMzlxr2fCxK2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top1_accuracies = {}\n",
        "top5_accuracies = {}\n",
        "\n",
        "for conv, channel in zip(prune_layers, prune_channels):    \n",
        "    top1_accuracies[conv] = []\n",
        "    top5_accuracies[conv] = []\n",
        "    \n",
        "    # load new network and check accuracy\n",
        "    network, _, _ = test_network(args, data_set=test_set)\n",
        "        \n",
        "    # remove 0 channels ~ M (max_channel_ratio) % of total channels\n",
        "    step = np.linspace(0, int(channel*max_channel_ratio), int(1/prune_step_ratio), dtype=np.int)\n",
        "    steps = (step[1:] - step[:-1]).tolist()\n",
        "    \n",
        "    for i in range(len(steps)):\n",
        "        print(\"\\n%s: %s Layer, %d Channels pruned\"%(time.ctime(), conv, sum(steps[:i+1])))\n",
        "        \n",
        "        # set prune information\n",
        "        args.prune_layers = [conv]\n",
        "        args.prune_channels =[steps[i]]\n",
        "\n",
        "        network = prune_network(args, network)\n",
        "        \n",
        "        network, _, (top1, top5) = test_network(args, network, test_set)\n",
        "            \n",
        "        top1_accuracies[conv].append(top1)\n",
        "        top5_accuracies[conv].append(top5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcBT3HQyC9bA",
        "outputId": "344af5bf-0ba9-45eb-b835-8a48c5ccd012"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 09:31:09 2022: Test information, Data(s): 1.691, Forward(s): 0.218, Top1: 77.870, Top5: 97.560, \n",
            "\n",
            "Mon Apr 25 09:31:09 2022: conv1 Layer, 8 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 56, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(56, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 56, 32, 32]           1,568\n",
            "       BatchNorm2d-2           [-1, 56, 32, 32]             112\n",
            "              ReLU-3           [-1, 56, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          32,320\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]          73,856\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "             ReLU-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]         147,584\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         295,168\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]       1,180,160\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 14,987,098\n",
            "Trainable params: 14,987,098\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 6.39\n",
            "Params size (MB): 57.17\n",
            "Estimated Total Size (MB): 63.57\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 56, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(56, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  if sys.path[0] == '':\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 48, 32, 32]          27,696\n",
            "       BatchNorm2d-5           [-1, 48, 32, 32]              96\n",
            "              ReLU-6           [-1, 48, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 48, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]          55,424\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "             ReLU-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]         147,584\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         295,168\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]       1,180,160\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 14,964,250\n",
            "Trainable params: 14,964,250\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 6.17\n",
            "Params size (MB): 57.08\n",
            "Estimated Total Size (MB): 63.26\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(48, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 10:13:04 2022: Epoch [0], Iteration [0/391/], Data(s): 0.035, Loss(s): 0.005, Forward(s): 0.054, Backward(s): 0.114, Top1: 89.062, Top5: 100.0000, Loss: 0.295\n",
            "Mon Apr 25 10:13:12 2022: Epoch [0], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.008, Top1: 92.365, Top5: 99.6751, Loss: 0.234\n",
            "Mon Apr 25 10:13:20 2022: Epoch [0], Iteration [200/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.428, Top5: 99.6968, Loss: 0.227\n",
            "Mon Apr 25 10:13:27 2022: Epoch [0], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.429, Top5: 99.6937, Loss: 0.230\n",
            "Mon Apr 25 10:13:35 2022: Epoch [1], Iteration [0/391/], Data(s): 0.052, Loss(s): 0.010, Forward(s): 0.004, Backward(s): 0.007, Top1: 92.188, Top5: 100.0000, Loss: 0.227\n",
            "Mon Apr 25 10:13:42 2022: Epoch [1], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.837, Top5: 99.6674, Loss: 0.220\n",
            "Mon Apr 25 10:13:50 2022: Epoch [1], Iteration [200/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.794, Top5: 99.6852, Loss: 0.220\n",
            "Mon Apr 25 10:13:58 2022: Epoch [1], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.777, Top5: 99.6366, Loss: 0.221\n",
            "Mon Apr 25 10:14:06 2022: Epoch [2], Iteration [0/391/], Data(s): 0.054, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.531, Top5: 100.0000, Loss: 0.223\n",
            "Mon Apr 25 10:14:13 2022: Epoch [2], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.729, Top5: 99.5900, Loss: 0.224\n",
            "Mon Apr 25 10:14:21 2022: Epoch [2], Iteration [200/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.969, Top5: 99.6424, Loss: 0.205\n",
            "Mon Apr 25 10:14:29 2022: Epoch [2], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.964, Top5: 99.6548, Loss: 0.215\n",
            "Mon Apr 25 10:14:36 2022: Epoch [3], Iteration [0/391/], Data(s): 0.060, Loss(s): 0.010, Forward(s): 0.004, Backward(s): 0.007, Top1: 89.062, Top5: 99.2188, Loss: 0.217\n",
            "Mon Apr 25 10:14:44 2022: Epoch [3], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.340, Top5: 99.7215, Loss: 0.209\n",
            "Mon Apr 25 10:14:52 2022: Epoch [3], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.093, Top5: 99.6696, Loss: 0.224\n",
            "Mon Apr 25 10:15:00 2022: Epoch [3], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.099, Top5: 99.6859, Loss: 0.213\n",
            "Mon Apr 25 10:15:07 2022: Epoch [4], Iteration [0/391/], Data(s): 0.056, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 95.312, Top5: 100.0000, Loss: 0.200\n",
            "Mon Apr 25 10:15:15 2022: Epoch [4], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.209, Top5: 99.6829, Loss: 0.205\n",
            "Mon Apr 25 10:15:23 2022: Epoch [4], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.159, Top5: 99.6929, Loss: 0.211\n",
            "Mon Apr 25 10:15:31 2022: Epoch [4], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.174, Top5: 99.6885, Loss: 0.212\n",
            "Mon Apr 25 10:15:38 2022: Epoch [5], Iteration [0/391/], Data(s): 0.054, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 95.312, Top5: 100.0000, Loss: 0.209\n",
            "Mon Apr 25 10:15:46 2022: Epoch [5], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.487, Top5: 99.7061, Loss: 0.197\n",
            "Mon Apr 25 10:15:54 2022: Epoch [5], Iteration [200/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.532, Top5: 99.7163, Loss: 0.196\n",
            "Mon Apr 25 10:16:02 2022: Epoch [5], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.368, Top5: 99.6859, Loss: 0.212\n",
            "Mon Apr 25 10:16:09 2022: Epoch [6], Iteration [0/391/], Data(s): 0.056, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.008, Top1: 92.969, Top5: 100.0000, Loss: 0.209\n",
            "Mon Apr 25 10:16:17 2022: Epoch [6], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.325, Top5: 99.7138, Loss: 0.201\n",
            "Mon Apr 25 10:16:25 2022: Epoch [6], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.357, Top5: 99.7046, Loss: 0.201\n",
            "Mon Apr 25 10:16:33 2022: Epoch [6], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.454, Top5: 99.7119, Loss: 0.191\n",
            "Mon Apr 25 10:16:40 2022: Epoch [7], Iteration [0/391/], Data(s): 0.055, Loss(s): 0.010, Forward(s): 0.004, Backward(s): 0.007, Top1: 96.875, Top5: 100.0000, Loss: 0.210\n",
            "Mon Apr 25 10:16:48 2022: Epoch [7], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.735, Top5: 99.7215, Loss: 0.197\n",
            "Mon Apr 25 10:16:56 2022: Epoch [7], Iteration [200/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.458, Top5: 99.6852, Loss: 0.202\n",
            "Mon Apr 25 10:17:04 2022: Epoch [7], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.529, Top5: 99.7041, Loss: 0.194\n",
            "Mon Apr 25 10:17:11 2022: Epoch [8], Iteration [0/391/], Data(s): 0.061, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 90.625, Top5: 99.2188, Loss: 0.202\n",
            "Mon Apr 25 10:17:19 2022: Epoch [8], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.611, Top5: 99.6983, Loss: 0.201\n",
            "Mon Apr 25 10:17:27 2022: Epoch [8], Iteration [200/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.851, Top5: 99.7279, Loss: 0.186\n",
            "Mon Apr 25 10:17:35 2022: Epoch [8], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.875, Top5: 99.7430, Loss: 0.190\n",
            "Mon Apr 25 10:17:42 2022: Epoch [9], Iteration [0/391/], Data(s): 0.053, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.750, Top5: 100.0000, Loss: 0.190\n",
            "Mon Apr 25 10:17:50 2022: Epoch [9], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.595, Top5: 99.6287, Loss: 0.193\n",
            "Mon Apr 25 10:17:58 2022: Epoch [9], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.731, Top5: 99.6929, Loss: 0.188\n",
            "Mon Apr 25 10:18:06 2022: Epoch [9], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.680, Top5: 99.7015, Loss: 0.196\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 10:18:16 2022: Test information, Data(s): 1.551, Forward(s): 0.210, Top1: 90.570, Top5: 99.310, \n",
            "\n",
            "Mon Apr 25 10:18:16 2022: conv2 Layer, 24 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(40, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 40, 32, 32]          23,080\n",
            "       BatchNorm2d-5           [-1, 40, 32, 32]              80\n",
            "              ReLU-6           [-1, 40, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 40, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]          46,208\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "             ReLU-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]         147,584\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         295,168\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]       1,180,160\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 14,950,402\n",
            "Trainable params: 14,950,402\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 5.96\n",
            "Params size (MB): 57.03\n",
            "Estimated Total Size (MB): 63.01\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(40, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 10:18:17 2022: Epoch [0], Iteration [0/391/], Data(s): 0.037, Loss(s): 0.007, Forward(s): 0.051, Backward(s): 0.104, Top1: 96.094, Top5: 100.0000, Loss: 0.128\n",
            "Mon Apr 25 10:18:25 2022: Epoch [0], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.008, Top1: 93.247, Top5: 99.6829, Loss: 0.202\n",
            "Mon Apr 25 10:18:32 2022: Epoch [0], Iteration [200/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.237, Top5: 99.6657, Loss: 0.206\n",
            "Mon Apr 25 10:18:40 2022: Epoch [0], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.221, Top5: 99.6730, Loss: 0.206\n",
            "Mon Apr 25 10:18:47 2022: Epoch [1], Iteration [0/391/], Data(s): 0.056, Loss(s): 0.009, Forward(s): 0.004, Backward(s): 0.007, Top1: 91.406, Top5: 100.0000, Loss: 0.195\n",
            "Mon Apr 25 10:18:55 2022: Epoch [1], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.549, Top5: 99.8221, Loss: 0.187\n",
            "Mon Apr 25 10:19:03 2022: Epoch [1], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.668, Top5: 99.7823, Loss: 0.192\n",
            "Mon Apr 25 10:19:11 2022: Epoch [1], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.644, Top5: 99.7508, Loss: 0.197\n",
            "Mon Apr 25 10:19:18 2022: Epoch [2], Iteration [0/391/], Data(s): 0.059, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 96.094, Top5: 100.0000, Loss: 0.199\n",
            "Mon Apr 25 10:19:26 2022: Epoch [2], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.572, Top5: 99.7912, Loss: 0.195\n",
            "Mon Apr 25 10:19:34 2022: Epoch [2], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.746, Top5: 99.7746, Loss: 0.185\n",
            "Mon Apr 25 10:19:42 2022: Epoch [2], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.714, Top5: 99.7482, Loss: 0.195\n",
            "Mon Apr 25 10:19:49 2022: Epoch [3], Iteration [0/391/], Data(s): 0.066, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.969, Top5: 100.0000, Loss: 0.187\n",
            "Mon Apr 25 10:19:57 2022: Epoch [3], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.758, Top5: 99.7370, Loss: 0.189\n",
            "Mon Apr 25 10:20:04 2022: Epoch [3], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.773, Top5: 99.7357, Loss: 0.191\n",
            "Mon Apr 25 10:20:12 2022: Epoch [3], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.724, Top5: 99.7560, Loss: 0.191\n",
            "Mon Apr 25 10:20:19 2022: Epoch [4], Iteration [0/391/], Data(s): 0.063, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.008, Top1: 93.750, Top5: 100.0000, Loss: 0.180\n",
            "Mon Apr 25 10:20:27 2022: Epoch [4], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.253, Top5: 99.7370, Loss: 0.176\n",
            "Mon Apr 25 10:20:35 2022: Epoch [4], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.189, Top5: 99.7240, Loss: 0.177\n",
            "Mon Apr 25 10:20:43 2022: Epoch [4], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.015, Top5: 99.7223, Loss: 0.192\n",
            "Mon Apr 25 10:20:50 2022: Epoch [5], Iteration [0/391/], Data(s): 0.064, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 97.656, Top5: 99.2188, Loss: 0.177\n",
            "Mon Apr 25 10:20:58 2022: Epoch [5], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.905, Top5: 99.7215, Loss: 0.181\n",
            "Mon Apr 25 10:21:06 2022: Epoch [5], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.843, Top5: 99.7590, Loss: 0.181\n",
            "Mon Apr 25 10:21:13 2022: Epoch [5], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.932, Top5: 99.7638, Loss: 0.179\n",
            "Mon Apr 25 10:21:21 2022: Epoch [6], Iteration [0/391/], Data(s): 0.057, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 96.875, Top5: 100.0000, Loss: 0.174\n",
            "Mon Apr 25 10:21:29 2022: Epoch [6], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.191, Top5: 99.8376, Loss: 0.174\n",
            "Mon Apr 25 10:21:36 2022: Epoch [6], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.092, Top5: 99.8018, Loss: 0.179\n",
            "Mon Apr 25 10:21:44 2022: Epoch [6], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.064, Top5: 99.8053, Loss: 0.181\n",
            "Mon Apr 25 10:21:51 2022: Epoch [7], Iteration [0/391/], Data(s): 0.056, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 95.312, Top5: 100.0000, Loss: 0.176\n",
            "Mon Apr 25 10:21:59 2022: Epoch [7], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.191, Top5: 99.8221, Loss: 0.177\n",
            "Mon Apr 25 10:22:07 2022: Epoch [7], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.244, Top5: 99.7785, Loss: 0.174\n",
            "Mon Apr 25 10:22:15 2022: Epoch [7], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.295, Top5: 99.7846, Loss: 0.170\n",
            "Mon Apr 25 10:22:22 2022: Epoch [8], Iteration [0/391/], Data(s): 0.055, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.531, Top5: 100.0000, Loss: 0.174\n",
            "Mon Apr 25 10:22:30 2022: Epoch [8], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.508, Top5: 99.7525, Loss: 0.170\n",
            "Mon Apr 25 10:22:38 2022: Epoch [8], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.481, Top5: 99.7901, Loss: 0.173\n",
            "Mon Apr 25 10:22:46 2022: Epoch [8], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.433, Top5: 99.8053, Loss: 0.171\n",
            "Mon Apr 25 10:22:53 2022: Epoch [9], Iteration [0/391/], Data(s): 0.053, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 90.625, Top5: 98.4375, Loss: 0.172\n",
            "Mon Apr 25 10:23:01 2022: Epoch [9], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.338, Top5: 99.6906, Loss: 0.169\n",
            "Mon Apr 25 10:23:09 2022: Epoch [9], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.310, Top5: 99.7590, Loss: 0.170\n",
            "Mon Apr 25 10:23:17 2022: Epoch [9], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.357, Top5: 99.7664, Loss: 0.169\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 10:23:27 2022: Test information, Data(s): 1.595, Forward(s): 0.212, Top1: 90.960, Top5: 99.270, \n",
            "\n",
            "Mon Apr 25 10:23:27 2022: conv2 Layer, 32 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 32, 32, 32]          18,464\n",
            "       BatchNorm2d-5           [-1, 32, 32, 32]              64\n",
            "              ReLU-6           [-1, 32, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 32, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]          36,992\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "             ReLU-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]         147,584\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         295,168\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]       1,180,160\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 14,936,554\n",
            "Trainable params: 14,936,554\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 5.76\n",
            "Params size (MB): 56.98\n",
            "Estimated Total Size (MB): 62.75\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 10:23:28 2022: Epoch [0], Iteration [0/391/], Data(s): 0.035, Loss(s): 0.008, Forward(s): 0.036, Backward(s): 0.090, Top1: 96.875, Top5: 100.0000, Loss: 0.107\n",
            "Mon Apr 25 10:23:36 2022: Epoch [0], Iteration [100/391/], Data(s): 0.035, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.008, Top1: 93.936, Top5: 99.6364, Loss: 0.189\n",
            "Mon Apr 25 10:23:43 2022: Epoch [0], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.567, Top5: 99.6813, Loss: 0.197\n",
            "Mon Apr 25 10:23:51 2022: Epoch [0], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.745, Top5: 99.7041, Loss: 0.173\n",
            "Mon Apr 25 10:23:58 2022: Epoch [1], Iteration [0/391/], Data(s): 0.064, Loss(s): 0.008, Forward(s): 0.004, Backward(s): 0.007, Top1: 96.875, Top5: 98.4375, Loss: 0.186\n",
            "Mon Apr 25 10:24:06 2022: Epoch [1], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.028, Top5: 99.7447, Loss: 0.182\n",
            "Mon Apr 25 10:24:13 2022: Epoch [1], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.065, Top5: 99.7357, Loss: 0.180\n",
            "Mon Apr 25 10:24:21 2022: Epoch [1], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.139, Top5: 99.7456, Loss: 0.173\n",
            "Mon Apr 25 10:24:28 2022: Epoch [2], Iteration [0/391/], Data(s): 0.054, Loss(s): 0.009, Forward(s): 0.003, Backward(s): 0.007, Top1: 97.656, Top5: 100.0000, Loss: 0.171\n",
            "Mon Apr 25 10:24:36 2022: Epoch [2], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.361, Top5: 99.7138, Loss: 0.176\n",
            "Mon Apr 25 10:24:43 2022: Epoch [2], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.325, Top5: 99.7746, Loss: 0.171\n",
            "Mon Apr 25 10:24:51 2022: Epoch [2], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.308, Top5: 99.7690, Loss: 0.173\n",
            "Mon Apr 25 10:24:58 2022: Epoch [3], Iteration [0/391/], Data(s): 0.064, Loss(s): 0.009, Forward(s): 0.004, Backward(s): 0.008, Top1: 94.531, Top5: 100.0000, Loss: 0.173\n",
            "Mon Apr 25 10:25:06 2022: Epoch [3], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.632, Top5: 99.7679, Loss: 0.169\n",
            "Mon Apr 25 10:25:14 2022: Epoch [3], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.391, Top5: 99.7707, Loss: 0.174\n",
            "Mon Apr 25 10:25:21 2022: Epoch [3], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.311, Top5: 99.7820, Loss: 0.172\n",
            "Mon Apr 25 10:25:28 2022: Epoch [4], Iteration [0/391/], Data(s): 0.051, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.750, Top5: 100.0000, Loss: 0.166\n",
            "Mon Apr 25 10:25:36 2022: Epoch [4], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.477, Top5: 99.7757, Loss: 0.167\n",
            "Mon Apr 25 10:25:44 2022: Epoch [4], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.454, Top5: 99.8173, Loss: 0.165\n",
            "Mon Apr 25 10:25:51 2022: Epoch [4], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.409, Top5: 99.8209, Loss: 0.164\n",
            "Mon Apr 25 10:25:58 2022: Epoch [5], Iteration [0/391/], Data(s): 0.063, Loss(s): 0.009, Forward(s): 0.004, Backward(s): 0.008, Top1: 89.062, Top5: 100.0000, Loss: 0.157\n",
            "Mon Apr 25 10:26:06 2022: Epoch [5], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.431, Top5: 99.7525, Loss: 0.167\n",
            "Mon Apr 25 10:26:14 2022: Epoch [5], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.454, Top5: 99.7940, Loss: 0.162\n",
            "Mon Apr 25 10:26:21 2022: Epoch [5], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.549, Top5: 99.8105, Loss: 0.156\n",
            "Mon Apr 25 10:26:28 2022: Epoch [6], Iteration [0/391/], Data(s): 0.052, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.531, Top5: 99.2188, Loss: 0.170\n",
            "Mon Apr 25 10:26:36 2022: Epoch [6], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.802, Top5: 99.7912, Loss: 0.156\n",
            "Mon Apr 25 10:26:44 2022: Epoch [6], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.741, Top5: 99.8057, Loss: 0.160\n",
            "Mon Apr 25 10:26:51 2022: Epoch [6], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.718, Top5: 99.8287, Loss: 0.161\n",
            "Mon Apr 25 10:26:58 2022: Epoch [7], Iteration [0/391/], Data(s): 0.056, Loss(s): 0.009, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.531, Top5: 100.0000, Loss: 0.157\n",
            "Mon Apr 25 10:27:06 2022: Epoch [7], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.787, Top5: 99.8298, Loss: 0.162\n",
            "Mon Apr 25 10:27:14 2022: Epoch [7], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.885, Top5: 99.8290, Loss: 0.151\n",
            "Mon Apr 25 10:27:21 2022: Epoch [7], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.843, Top5: 99.8339, Loss: 0.158\n",
            "Mon Apr 25 10:27:28 2022: Epoch [8], Iteration [0/391/], Data(s): 0.052, Loss(s): 0.009, Forward(s): 0.003, Backward(s): 0.007, Top1: 96.875, Top5: 100.0000, Loss: 0.157\n",
            "Mon Apr 25 10:27:36 2022: Epoch [8], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.647, Top5: 99.8840, Loss: 0.157\n",
            "Mon Apr 25 10:27:44 2022: Epoch [8], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.772, Top5: 99.8601, Loss: 0.154\n",
            "Mon Apr 25 10:27:51 2022: Epoch [8], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.773, Top5: 99.8598, Loss: 0.157\n",
            "Mon Apr 25 10:27:58 2022: Epoch [9], Iteration [0/391/], Data(s): 0.055, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.969, Top5: 100.0000, Loss: 0.156\n",
            "Mon Apr 25 10:28:06 2022: Epoch [9], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.756, Top5: 99.8221, Loss: 0.156\n",
            "Mon Apr 25 10:28:14 2022: Epoch [9], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.807, Top5: 99.8018, Loss: 0.152\n",
            "Mon Apr 25 10:28:21 2022: Epoch [9], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.882, Top5: 99.8183, Loss: 0.151\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 10:28:31 2022: Test information, Data(s): 1.589, Forward(s): 0.214, Top1: 90.990, Top5: 99.210, \n",
            "\n",
            "Mon Apr 25 10:28:31 2022: conv2 Layer, 40 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(24, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 24, 32, 32]          13,848\n",
            "       BatchNorm2d-5           [-1, 24, 32, 32]              48\n",
            "              ReLU-6           [-1, 24, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 24, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]          27,776\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "             ReLU-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]         147,584\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         295,168\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]       1,180,160\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 14,922,706\n",
            "Trainable params: 14,922,706\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 5.56\n",
            "Params size (MB): 56.93\n",
            "Estimated Total Size (MB): 62.50\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(24, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 10:28:32 2022: Epoch [0], Iteration [0/391/], Data(s): 0.036, Loss(s): 0.007, Forward(s): 0.032, Backward(s): 0.084, Top1: 92.188, Top5: 99.2188, Loss: 0.205\n",
            "Mon Apr 25 10:28:40 2022: Epoch [0], Iteration [100/391/], Data(s): 0.035, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.008, Top1: 93.472, Top5: 99.7370, Loss: 0.194\n",
            "Mon Apr 25 10:28:48 2022: Epoch [0], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.781, Top5: 99.7823, Loss: 0.177\n",
            "Mon Apr 25 10:28:55 2022: Epoch [0], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.843, Top5: 99.7872, Loss: 0.177\n",
            "Mon Apr 25 10:29:02 2022: Epoch [1], Iteration [0/391/], Data(s): 0.047, Loss(s): 0.009, Forward(s): 0.004, Backward(s): 0.007, Top1: 96.094, Top5: 100.0000, Loss: 0.170\n",
            "Mon Apr 25 10:29:10 2022: Epoch [1], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.284, Top5: 99.7679, Loss: 0.170\n",
            "Mon Apr 25 10:29:18 2022: Epoch [1], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.376, Top5: 99.7862, Loss: 0.170\n",
            "Mon Apr 25 10:29:25 2022: Epoch [1], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.383, Top5: 99.7846, Loss: 0.169\n",
            "Mon Apr 25 10:29:32 2022: Epoch [2], Iteration [0/391/], Data(s): 0.057, Loss(s): 0.009, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.969, Top5: 100.0000, Loss: 0.176\n",
            "Mon Apr 25 10:29:40 2022: Epoch [2], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.616, Top5: 99.7834, Loss: 0.160\n",
            "Mon Apr 25 10:29:47 2022: Epoch [2], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.597, Top5: 99.7979, Loss: 0.158\n",
            "Mon Apr 25 10:29:55 2022: Epoch [2], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.578, Top5: 99.7950, Loss: 0.168\n",
            "Mon Apr 25 10:30:02 2022: Epoch [3], Iteration [0/391/], Data(s): 0.059, Loss(s): 0.009, Forward(s): 0.003, Backward(s): 0.007, Top1: 95.312, Top5: 100.0000, Loss: 0.161\n",
            "Mon Apr 25 10:30:10 2022: Epoch [3], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.833, Top5: 99.8453, Loss: 0.158\n",
            "Mon Apr 25 10:30:17 2022: Epoch [3], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.838, Top5: 99.8212, Loss: 0.151\n",
            "Mon Apr 25 10:30:25 2022: Epoch [3], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.721, Top5: 99.8235, Loss: 0.162\n",
            "Mon Apr 25 10:30:32 2022: Epoch [4], Iteration [0/391/], Data(s): 0.055, Loss(s): 0.009, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.531, Top5: 100.0000, Loss: 0.159\n",
            "Mon Apr 25 10:30:39 2022: Epoch [4], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.918, Top5: 99.8530, Loss: 0.152\n",
            "Mon Apr 25 10:30:47 2022: Epoch [4], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.675, Top5: 99.8290, Loss: 0.168\n",
            "Mon Apr 25 10:30:55 2022: Epoch [4], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.793, Top5: 99.8443, Loss: 0.150\n",
            "Mon Apr 25 10:31:02 2022: Epoch [5], Iteration [0/391/], Data(s): 0.053, Loss(s): 0.009, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.750, Top5: 97.6562, Loss: 0.153\n",
            "Mon Apr 25 10:31:09 2022: Epoch [5], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 95.258, Top5: 99.8917, Loss: 0.147\n",
            "Mon Apr 25 10:31:17 2022: Epoch [5], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 95.118, Top5: 99.8640, Loss: 0.150\n",
            "Mon Apr 25 10:31:24 2022: Epoch [5], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.941, Top5: 99.8391, Loss: 0.155\n",
            "Mon Apr 25 10:31:31 2022: Epoch [6], Iteration [0/391/], Data(s): 0.054, Loss(s): 0.009, Forward(s): 0.003, Backward(s): 0.007, Top1: 97.656, Top5: 100.0000, Loss: 0.146\n",
            "Mon Apr 25 10:31:39 2022: Epoch [6], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.964, Top5: 99.7757, Loss: 0.153\n",
            "Mon Apr 25 10:31:46 2022: Epoch [6], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.963, Top5: 99.7862, Loss: 0.152\n",
            "Mon Apr 25 10:31:54 2022: Epoch [6], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 95.084, Top5: 99.8053, Loss: 0.143\n",
            "Mon Apr 25 10:32:01 2022: Epoch [7], Iteration [0/391/], Data(s): 0.054, Loss(s): 0.009, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.969, Top5: 100.0000, Loss: 0.145\n",
            "Mon Apr 25 10:32:08 2022: Epoch [7], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 95.792, Top5: 99.9072, Loss: 0.131\n",
            "Mon Apr 25 10:32:16 2022: Epoch [7], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 95.386, Top5: 99.8795, Loss: 0.148\n",
            "Mon Apr 25 10:32:24 2022: Epoch [7], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 95.263, Top5: 99.8728, Loss: 0.148\n",
            "Mon Apr 25 10:32:31 2022: Epoch [8], Iteration [0/391/], Data(s): 0.056, Loss(s): 0.009, Forward(s): 0.003, Backward(s): 0.007, Top1: 96.875, Top5: 100.0000, Loss: 0.151\n",
            "Mon Apr 25 10:32:38 2022: Epoch [8], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 95.266, Top5: 99.9149, Loss: 0.140\n",
            "Mon Apr 25 10:32:46 2022: Epoch [8], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 95.157, Top5: 99.8756, Loss: 0.149\n",
            "Mon Apr 25 10:32:53 2022: Epoch [8], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 95.307, Top5: 99.8780, Loss: 0.138\n",
            "Mon Apr 25 10:33:00 2022: Epoch [9], Iteration [0/391/], Data(s): 0.054, Loss(s): 0.009, Forward(s): 0.003, Backward(s): 0.007, Top1: 99.219, Top5: 100.0000, Loss: 0.145\n",
            "Mon Apr 25 10:33:08 2022: Epoch [9], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 95.398, Top5: 99.8685, Loss: 0.139\n",
            "Mon Apr 25 10:33:15 2022: Epoch [9], Iteration [200/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 95.266, Top5: 99.8756, Loss: 0.147\n",
            "Mon Apr 25 10:33:23 2022: Epoch [9], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 95.258, Top5: 99.8702, Loss: 0.144\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 10:33:33 2022: Test information, Data(s): 1.558, Forward(s): 0.211, Top1: 90.840, Top5: 99.240, \n",
            "\n",
            "Mon Apr 25 10:33:33 2022: conv2 Layer, 48 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(16, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 16, 32, 32]           9,232\n",
            "       BatchNorm2d-5           [-1, 16, 32, 32]              32\n",
            "              ReLU-6           [-1, 16, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 16, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]          18,560\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "             ReLU-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]         147,584\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         295,168\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]       1,180,160\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 14,908,858\n",
            "Trainable params: 14,908,858\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 5.36\n",
            "Params size (MB): 56.87\n",
            "Estimated Total Size (MB): 62.24\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(16, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 10:33:34 2022: Epoch [0], Iteration [0/391/], Data(s): 0.039, Loss(s): 0.007, Forward(s): 0.029, Backward(s): 0.080, Top1: 91.406, Top5: 99.2188, Loss: 0.283\n",
            "Mon Apr 25 10:33:41 2022: Epoch [0], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.008, Top1: 90.037, Top5: 99.3116, Loss: 0.315\n",
            "Mon Apr 25 10:33:49 2022: Epoch [0], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 91.014, Top5: 99.4286, Loss: 0.238\n",
            "Mon Apr 25 10:33:56 2022: Epoch [0], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 91.679, Top5: 99.5198, Loss: 0.208\n",
            "Mon Apr 25 10:34:03 2022: Epoch [1], Iteration [0/391/], Data(s): 0.058, Loss(s): 0.008, Forward(s): 0.004, Backward(s): 0.007, Top1: 96.094, Top5: 100.0000, Loss: 0.209\n",
            "Mon Apr 25 10:34:11 2022: Epoch [1], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.379, Top5: 99.7293, Loss: 0.198\n",
            "Mon Apr 25 10:34:18 2022: Epoch [1], Iteration [200/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.797, Top5: 99.7201, Loss: 0.187\n",
            "Mon Apr 25 10:34:26 2022: Epoch [1], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.698, Top5: 99.7430, Loss: 0.189\n",
            "Mon Apr 25 10:34:32 2022: Epoch [2], Iteration [0/391/], Data(s): 0.057, Loss(s): 0.009, Forward(s): 0.003, Backward(s): 0.008, Top1: 94.531, Top5: 99.2188, Loss: 0.173\n",
            "Mon Apr 25 10:34:40 2022: Epoch [2], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.098, Top5: 99.7912, Loss: 0.179\n",
            "Mon Apr 25 10:34:47 2022: Epoch [2], Iteration [200/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.026, Top5: 99.7940, Loss: 0.176\n",
            "Mon Apr 25 10:34:55 2022: Epoch [2], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.178, Top5: 99.7898, Loss: 0.172\n",
            "Mon Apr 25 10:35:02 2022: Epoch [3], Iteration [0/391/], Data(s): 0.054, Loss(s): 0.009, Forward(s): 0.003, Backward(s): 0.007, Top1: 97.656, Top5: 100.0000, Loss: 0.168\n",
            "Mon Apr 25 10:35:09 2022: Epoch [3], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.431, Top5: 99.7912, Loss: 0.170\n",
            "Mon Apr 25 10:35:17 2022: Epoch [3], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.372, Top5: 99.7823, Loss: 0.170\n",
            "Mon Apr 25 10:35:24 2022: Epoch [3], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.370, Top5: 99.7820, Loss: 0.171\n",
            "Mon Apr 25 10:35:31 2022: Epoch [4], Iteration [0/391/], Data(s): 0.051, Loss(s): 0.009, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.750, Top5: 100.0000, Loss: 0.172\n",
            "Mon Apr 25 10:35:39 2022: Epoch [4], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.477, Top5: 99.8298, Loss: 0.160\n",
            "Mon Apr 25 10:35:46 2022: Epoch [4], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.652, Top5: 99.8640, Loss: 0.154\n",
            "Mon Apr 25 10:35:54 2022: Epoch [4], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.651, Top5: 99.8650, Loss: 0.163\n",
            "Mon Apr 25 10:36:01 2022: Epoch [5], Iteration [0/391/], Data(s): 0.053, Loss(s): 0.009, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.969, Top5: 100.0000, Loss: 0.166\n",
            "Mon Apr 25 10:36:08 2022: Epoch [5], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.547, Top5: 99.8762, Loss: 0.154\n",
            "Mon Apr 25 10:36:16 2022: Epoch [5], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.527, Top5: 99.8562, Loss: 0.162\n",
            "Mon Apr 25 10:36:23 2022: Epoch [5], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.542, Top5: 99.8754, Loss: 0.158\n",
            "Mon Apr 25 10:36:30 2022: Epoch [6], Iteration [0/391/], Data(s): 0.054, Loss(s): 0.009, Forward(s): 0.004, Backward(s): 0.007, Top1: 91.406, Top5: 100.0000, Loss: 0.157\n",
            "Mon Apr 25 10:36:37 2022: Epoch [6], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 95.019, Top5: 99.8221, Loss: 0.153\n",
            "Mon Apr 25 10:36:45 2022: Epoch [6], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.943, Top5: 99.8484, Loss: 0.150\n",
            "Mon Apr 25 10:36:52 2022: Epoch [6], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.856, Top5: 99.8547, Loss: 0.158\n",
            "Mon Apr 25 10:36:59 2022: Epoch [7], Iteration [0/391/], Data(s): 0.056, Loss(s): 0.009, Forward(s): 0.003, Backward(s): 0.007, Top1: 89.062, Top5: 100.0000, Loss: 0.155\n",
            "Mon Apr 25 10:37:07 2022: Epoch [7], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.694, Top5: 99.8530, Loss: 0.154\n",
            "Mon Apr 25 10:37:14 2022: Epoch [7], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.729, Top5: 99.8406, Loss: 0.157\n",
            "Mon Apr 25 10:37:22 2022: Epoch [7], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.869, Top5: 99.8417, Loss: 0.146\n",
            "Mon Apr 25 10:37:29 2022: Epoch [8], Iteration [0/391/], Data(s): 0.063, Loss(s): 0.009, Forward(s): 0.003, Backward(s): 0.007, Top1: 95.312, Top5: 100.0000, Loss: 0.146\n",
            "Mon Apr 25 10:37:36 2022: Epoch [8], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 95.111, Top5: 99.8685, Loss: 0.147\n",
            "Mon Apr 25 10:37:44 2022: Epoch [8], Iteration [200/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 95.037, Top5: 99.8756, Loss: 0.148\n",
            "Mon Apr 25 10:37:51 2022: Epoch [8], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 95.074, Top5: 99.8910, Loss: 0.147\n",
            "Mon Apr 25 10:37:58 2022: Epoch [9], Iteration [0/391/], Data(s): 0.053, Loss(s): 0.009, Forward(s): 0.004, Backward(s): 0.007, Top1: 98.438, Top5: 99.2188, Loss: 0.151\n",
            "Mon Apr 25 10:38:06 2022: Epoch [9], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 95.297, Top5: 99.8994, Loss: 0.137\n",
            "Mon Apr 25 10:38:13 2022: Epoch [9], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 95.153, Top5: 99.8873, Loss: 0.148\n",
            "Mon Apr 25 10:38:21 2022: Epoch [9], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 95.219, Top5: 99.8884, Loss: 0.137\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 10:38:30 2022: Test information, Data(s): 1.587, Forward(s): 0.209, Top1: 90.550, Top5: 99.290, \n",
            "\n",
            "Mon Apr 25 10:38:30 2022: conv2 Layer, 57 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(7, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4            [-1, 7, 32, 32]           4,039\n",
            "       BatchNorm2d-5            [-1, 7, 32, 32]              14\n",
            "              ReLU-6            [-1, 7, 32, 32]               0\n",
            "         MaxPool2d-7            [-1, 7, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]           8,192\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "             ReLU-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]         147,584\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         295,168\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]       1,180,160\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 14,893,279\n",
            "Trainable params: 14,893,279\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 5.13\n",
            "Params size (MB): 56.81\n",
            "Estimated Total Size (MB): 61.95\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(7, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 10:38:31 2022: Epoch [0], Iteration [0/391/], Data(s): 0.034, Loss(s): 0.007, Forward(s): 0.027, Backward(s): 0.073, Top1: 69.531, Top5: 95.3125, Loss: 1.541\n",
            "Mon Apr 25 10:38:39 2022: Epoch [0], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.009, Forward(s): 0.003, Backward(s): 0.008, Top1: 79.633, Top5: 97.5712, Loss: 0.758\n",
            "Mon Apr 25 10:38:46 2022: Epoch [0], Iteration [200/391/], Data(s): 0.033, Loss(s): 0.009, Forward(s): 0.003, Backward(s): 0.007, Top1: 82.354, Top5: 98.1849, Loss: 0.479\n",
            "Mon Apr 25 10:38:53 2022: Epoch [0], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.009, Forward(s): 0.003, Backward(s): 0.007, Top1: 83.765, Top5: 98.4635, Loss: 0.423\n",
            "Mon Apr 25 10:39:00 2022: Epoch [1], Iteration [0/391/], Data(s): 0.053, Loss(s): 0.008, Forward(s): 0.004, Backward(s): 0.008, Top1: 86.719, Top5: 99.2188, Loss: 0.412\n",
            "Mon Apr 25 10:39:07 2022: Epoch [1], Iteration [100/391/], Data(s): 0.032, Loss(s): 0.009, Forward(s): 0.003, Backward(s): 0.007, Top1: 88.127, Top5: 99.1955, Loss: 0.356\n",
            "Mon Apr 25 10:39:15 2022: Epoch [1], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.009, Forward(s): 0.003, Backward(s): 0.007, Top1: 88.398, Top5: 99.2460, Loss: 0.331\n",
            "Mon Apr 25 10:39:22 2022: Epoch [1], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.009, Forward(s): 0.003, Backward(s): 0.007, Top1: 88.806, Top5: 99.2421, Loss: 0.321\n",
            "Mon Apr 25 10:39:29 2022: Epoch [2], Iteration [0/391/], Data(s): 0.057, Loss(s): 0.009, Forward(s): 0.003, Backward(s): 0.007, Top1: 91.406, Top5: 100.0000, Loss: 0.319\n",
            "Mon Apr 25 10:39:36 2022: Epoch [2], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.009, Forward(s): 0.003, Backward(s): 0.007, Top1: 89.867, Top5: 99.3735, Loss: 0.291\n",
            "Mon Apr 25 10:39:44 2022: Epoch [2], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.009, Forward(s): 0.003, Backward(s): 0.007, Top1: 90.023, Top5: 99.3742, Loss: 0.297\n",
            "Mon Apr 25 10:39:51 2022: Epoch [2], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.009, Forward(s): 0.003, Backward(s): 0.007, Top1: 90.199, Top5: 99.3875, Loss: 0.292\n",
            "Mon Apr 25 10:39:58 2022: Epoch [3], Iteration [0/391/], Data(s): 0.053, Loss(s): 0.009, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.188, Top5: 99.2188, Loss: 0.294\n",
            "Mon Apr 25 10:40:05 2022: Epoch [3], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.009, Forward(s): 0.003, Backward(s): 0.007, Top1: 90.903, Top5: 99.5050, Loss: 0.271\n",
            "Mon Apr 25 10:40:13 2022: Epoch [3], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.009, Forward(s): 0.003, Backward(s): 0.007, Top1: 91.068, Top5: 99.4947, Loss: 0.268\n",
            "Mon Apr 25 10:40:20 2022: Epoch [3], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.009, Forward(s): 0.003, Backward(s): 0.007, Top1: 91.092, Top5: 99.4991, Loss: 0.267\n",
            "Mon Apr 25 10:40:27 2022: Epoch [4], Iteration [0/391/], Data(s): 0.054, Loss(s): 0.009, Forward(s): 0.003, Backward(s): 0.007, Top1: 90.625, Top5: 100.0000, Loss: 0.273\n",
            "Mon Apr 25 10:40:34 2022: Epoch [4], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.009, Forward(s): 0.003, Backward(s): 0.007, Top1: 91.422, Top5: 99.4817, Loss: 0.255\n",
            "Mon Apr 25 10:40:42 2022: Epoch [4], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.009, Forward(s): 0.003, Backward(s): 0.007, Top1: 91.445, Top5: 99.5219, Loss: 0.258\n",
            "Mon Apr 25 10:40:49 2022: Epoch [4], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.009, Forward(s): 0.003, Backward(s): 0.007, Top1: 91.510, Top5: 99.5354, Loss: 0.253\n",
            "Mon Apr 25 10:40:56 2022: Epoch [5], Iteration [0/391/], Data(s): 0.054, Loss(s): 0.009, Forward(s): 0.003, Backward(s): 0.007, Top1: 91.406, Top5: 100.0000, Loss: 0.262\n",
            "Mon Apr 25 10:41:03 2022: Epoch [5], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.009, Forward(s): 0.003, Backward(s): 0.007, Top1: 91.979, Top5: 99.6519, Loss: 0.244\n",
            "Mon Apr 25 10:41:11 2022: Epoch [5], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.009, Forward(s): 0.003, Backward(s): 0.007, Top1: 91.896, Top5: 99.6346, Loss: 0.246\n",
            "Mon Apr 25 10:41:18 2022: Epoch [5], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.009, Forward(s): 0.003, Backward(s): 0.007, Top1: 91.936, Top5: 99.6522, Loss: 0.238\n",
            "Mon Apr 25 10:41:25 2022: Epoch [6], Iteration [0/391/], Data(s): 0.056, Loss(s): 0.009, Forward(s): 0.003, Backward(s): 0.011, Top1: 94.531, Top5: 100.0000, Loss: 0.253\n",
            "Mon Apr 25 10:41:32 2022: Epoch [6], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.009, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.358, Top5: 99.6364, Loss: 0.227\n",
            "Mon Apr 25 10:41:40 2022: Epoch [6], Iteration [200/391/], Data(s): 0.033, Loss(s): 0.009, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.320, Top5: 99.6346, Loss: 0.231\n",
            "Mon Apr 25 10:41:47 2022: Epoch [6], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.009, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.252, Top5: 99.6081, Loss: 0.236\n",
            "Mon Apr 25 10:41:54 2022: Epoch [7], Iteration [0/391/], Data(s): 0.053, Loss(s): 0.009, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.188, Top5: 100.0000, Loss: 0.235\n",
            "Mon Apr 25 10:42:01 2022: Epoch [7], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.009, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.582, Top5: 99.6519, Loss: 0.223\n",
            "Mon Apr 25 10:42:08 2022: Epoch [7], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.009, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.600, Top5: 99.6774, Loss: 0.225\n",
            "Mon Apr 25 10:42:16 2022: Epoch [7], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.009, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.460, Top5: 99.6859, Loss: 0.225\n",
            "Mon Apr 25 10:42:22 2022: Epoch [8], Iteration [0/391/], Data(s): 0.054, Loss(s): 0.009, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.750, Top5: 100.0000, Loss: 0.223\n",
            "Mon Apr 25 10:42:30 2022: Epoch [8], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.009, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.915, Top5: 99.7215, Loss: 0.213\n",
            "Mon Apr 25 10:42:37 2022: Epoch [8], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.009, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.809, Top5: 99.6968, Loss: 0.216\n",
            "Mon Apr 25 10:42:44 2022: Epoch [8], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.009, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.655, Top5: 99.6963, Loss: 0.222\n",
            "Mon Apr 25 10:42:51 2022: Epoch [9], Iteration [0/391/], Data(s): 0.056, Loss(s): 0.009, Forward(s): 0.003, Backward(s): 0.007, Top1: 90.625, Top5: 100.0000, Loss: 0.214\n",
            "Mon Apr 25 10:42:59 2022: Epoch [9], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.009, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.420, Top5: 99.6364, Loss: 0.223\n",
            "Mon Apr 25 10:43:06 2022: Epoch [9], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.009, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.526, Top5: 99.6696, Loss: 0.214\n",
            "Mon Apr 25 10:43:13 2022: Epoch [9], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.009, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.582, Top5: 99.6963, Loss: 0.215\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 10:43:23 2022: Test information, Data(s): 1.570, Forward(s): 0.211, Top1: 88.840, Top5: 99.110, \n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 10:43:28 2022: Test information, Data(s): 1.531, Forward(s): 0.205, Top1: 77.870, Top5: 97.560, \n",
            "\n",
            "Mon Apr 25 10:43:28 2022: conv3 Layer, 16 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 112, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(112, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8          [-1, 112, 16, 16]          64,624\n",
            "       BatchNorm2d-9          [-1, 112, 16, 16]             224\n",
            "             ReLU-10          [-1, 112, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]         129,152\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         295,168\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]       1,180,160\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 14,964,250\n",
            "Trainable params: 14,964,250\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 6.48\n",
            "Params size (MB): 57.08\n",
            "Estimated Total Size (MB): 63.58\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 112, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(112, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 10:43:29 2022: Epoch [0], Iteration [0/391/], Data(s): 0.039, Loss(s): 0.007, Forward(s): 0.077, Backward(s): 0.163, Top1: 83.594, Top5: 97.6562, Loss: 0.472\n",
            "Mon Apr 25 10:43:37 2022: Epoch [0], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.004, Backward(s): 0.008, Top1: 86.873, Top5: 98.8707, Loss: 0.408\n",
            "Mon Apr 25 10:43:45 2022: Epoch [0], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.008, Top1: 87.636, Top5: 99.0361, Loss: 0.360\n",
            "Mon Apr 25 10:43:53 2022: Epoch [0], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 88.206, Top5: 99.1565, Loss: 0.331\n",
            "Mon Apr 25 10:44:00 2022: Epoch [1], Iteration [0/391/], Data(s): 0.064, Loss(s): 0.010, Forward(s): 0.005, Backward(s): 0.008, Top1: 90.625, Top5: 98.4375, Loss: 0.323\n",
            "Mon Apr 25 10:44:08 2022: Epoch [1], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 90.091, Top5: 99.3502, Loss: 0.310\n",
            "Mon Apr 25 10:44:16 2022: Epoch [1], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 90.042, Top5: 99.4170, Loss: 0.308\n",
            "Mon Apr 25 10:44:24 2022: Epoch [1], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 90.090, Top5: 99.4368, Loss: 0.299\n",
            "Mon Apr 25 10:44:32 2022: Epoch [2], Iteration [0/391/], Data(s): 0.065, Loss(s): 0.011, Forward(s): 0.004, Backward(s): 0.008, Top1: 86.719, Top5: 100.0000, Loss: 0.293\n",
            "Mon Apr 25 10:44:40 2022: Epoch [2], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 90.981, Top5: 99.4740, Loss: 0.280\n",
            "Mon Apr 25 10:44:48 2022: Epoch [2], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 90.773, Top5: 99.4714, Loss: 0.287\n",
            "Mon Apr 25 10:44:56 2022: Epoch [2], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 90.768, Top5: 99.4731, Loss: 0.278\n",
            "Mon Apr 25 10:45:03 2022: Epoch [3], Iteration [0/391/], Data(s): 0.053, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 86.719, Top5: 98.4375, Loss: 0.273\n",
            "Mon Apr 25 10:45:11 2022: Epoch [3], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 91.105, Top5: 99.4972, Loss: 0.278\n",
            "Mon Apr 25 10:45:19 2022: Epoch [3], Iteration [200/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 91.317, Top5: 99.4714, Loss: 0.270\n",
            "Mon Apr 25 10:45:27 2022: Epoch [3], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 91.396, Top5: 99.4757, Loss: 0.268\n",
            "Mon Apr 25 10:45:34 2022: Epoch [4], Iteration [0/391/], Data(s): 0.057, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.008, Top1: 88.281, Top5: 98.4375, Loss: 0.262\n",
            "Mon Apr 25 10:45:42 2022: Epoch [4], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 91.569, Top5: 99.4817, Loss: 0.260\n",
            "Mon Apr 25 10:45:51 2022: Epoch [4], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 91.721, Top5: 99.5569, Loss: 0.254\n",
            "Mon Apr 25 10:45:58 2022: Epoch [4], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 91.671, Top5: 99.5588, Loss: 0.259\n",
            "Mon Apr 25 10:46:06 2022: Epoch [5], Iteration [0/391/], Data(s): 0.074, Loss(s): 0.010, Forward(s): 0.004, Backward(s): 0.007, Top1: 92.188, Top5: 100.0000, Loss: 0.259\n",
            "Mon Apr 25 10:46:14 2022: Epoch [5], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.007, Top1: 91.731, Top5: 99.6674, Loss: 0.252\n",
            "Mon Apr 25 10:46:22 2022: Epoch [5], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 91.748, Top5: 99.5958, Loss: 0.254\n",
            "Mon Apr 25 10:46:30 2022: Epoch [5], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.060, Top5: 99.6029, Loss: 0.237\n",
            "Mon Apr 25 10:46:37 2022: Epoch [6], Iteration [0/391/], Data(s): 0.054, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 87.500, Top5: 100.0000, Loss: 0.255\n",
            "Mon Apr 25 10:46:45 2022: Epoch [6], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.211, Top5: 99.6287, Loss: 0.237\n",
            "Mon Apr 25 10:46:53 2022: Epoch [6], Iteration [200/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.067, Top5: 99.5997, Loss: 0.246\n",
            "Mon Apr 25 10:47:01 2022: Epoch [6], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.084, Top5: 99.5951, Loss: 0.240\n",
            "Mon Apr 25 10:47:08 2022: Epoch [7], Iteration [0/391/], Data(s): 0.061, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.750, Top5: 100.0000, Loss: 0.244\n",
            "Mon Apr 25 10:47:16 2022: Epoch [7], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.373, Top5: 99.6055, Loss: 0.235\n",
            "Mon Apr 25 10:47:24 2022: Epoch [7], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.428, Top5: 99.6269, Loss: 0.232\n",
            "Mon Apr 25 10:47:32 2022: Epoch [7], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.416, Top5: 99.6003, Loss: 0.240\n",
            "Mon Apr 25 10:47:40 2022: Epoch [8], Iteration [0/391/], Data(s): 0.054, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.750, Top5: 100.0000, Loss: 0.238\n",
            "Mon Apr 25 10:47:48 2022: Epoch [8], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.713, Top5: 99.6287, Loss: 0.227\n",
            "Mon Apr 25 10:47:56 2022: Epoch [8], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.646, Top5: 99.5725, Loss: 0.228\n",
            "Mon Apr 25 10:48:04 2022: Epoch [8], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.600, Top5: 99.5769, Loss: 0.228\n",
            "Mon Apr 25 10:48:11 2022: Epoch [9], Iteration [0/391/], Data(s): 0.053, Loss(s): 0.010, Forward(s): 0.004, Backward(s): 0.007, Top1: 93.750, Top5: 100.0000, Loss: 0.232\n",
            "Mon Apr 25 10:48:19 2022: Epoch [9], Iteration [100/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.551, Top5: 99.6287, Loss: 0.230\n",
            "Mon Apr 25 10:48:27 2022: Epoch [9], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.479, Top5: 99.6541, Loss: 0.230\n",
            "Mon Apr 25 10:48:35 2022: Epoch [9], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.530, Top5: 99.6314, Loss: 0.227\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 10:48:45 2022: Test information, Data(s): 1.580, Forward(s): 0.211, Top1: 90.010, Top5: 99.280, \n",
            "\n",
            "Mon Apr 25 10:48:45 2022: conv3 Layer, 32 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8           [-1, 96, 16, 16]          55,392\n",
            "       BatchNorm2d-9           [-1, 96, 16, 16]             192\n",
            "             ReLU-10           [-1, 96, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]         110,720\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         295,168\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]       1,180,160\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 14,936,554\n",
            "Trainable params: 14,936,554\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 6.39\n",
            "Params size (MB): 56.98\n",
            "Estimated Total Size (MB): 63.38\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 10:48:47 2022: Epoch [0], Iteration [0/391/], Data(s): 0.036, Loss(s): 0.007, Forward(s): 0.034, Backward(s): 0.086, Top1: 92.188, Top5: 99.2188, Loss: 0.231\n",
            "Mon Apr 25 10:48:55 2022: Epoch [0], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.008, Top1: 92.574, Top5: 99.6364, Loss: 0.222\n",
            "Mon Apr 25 10:49:02 2022: Epoch [0], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.230, Top5: 99.6541, Loss: 0.234\n",
            "Mon Apr 25 10:49:10 2022: Epoch [0], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.476, Top5: 99.6392, Loss: 0.220\n",
            "Mon Apr 25 10:49:18 2022: Epoch [1], Iteration [0/391/], Data(s): 0.054, Loss(s): 0.010, Forward(s): 0.004, Backward(s): 0.007, Top1: 96.094, Top5: 98.4375, Loss: 0.226\n",
            "Mon Apr 25 10:49:26 2022: Epoch [1], Iteration [100/391/], Data(s): 0.032, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.659, Top5: 99.6210, Loss: 0.227\n",
            "Mon Apr 25 10:49:34 2022: Epoch [1], Iteration [200/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.724, Top5: 99.6385, Loss: 0.216\n",
            "Mon Apr 25 10:49:41 2022: Epoch [1], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.797, Top5: 99.6392, Loss: 0.220\n",
            "Mon Apr 25 10:49:49 2022: Epoch [2], Iteration [0/391/], Data(s): 0.066, Loss(s): 0.008, Forward(s): 0.006, Backward(s): 0.008, Top1: 89.844, Top5: 100.0000, Loss: 0.222\n",
            "Mon Apr 25 10:49:57 2022: Epoch [2], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.116, Top5: 99.6210, Loss: 0.214\n",
            "Mon Apr 25 10:50:05 2022: Epoch [2], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.907, Top5: 99.6230, Loss: 0.226\n",
            "Mon Apr 25 10:50:13 2022: Epoch [2], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.997, Top5: 99.6237, Loss: 0.210\n",
            "Mon Apr 25 10:50:20 2022: Epoch [3], Iteration [0/391/], Data(s): 0.054, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 95.312, Top5: 98.4375, Loss: 0.218\n",
            "Mon Apr 25 10:50:28 2022: Epoch [3], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.984, Top5: 99.6751, Loss: 0.211\n",
            "Mon Apr 25 10:50:36 2022: Epoch [3], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.148, Top5: 99.6813, Loss: 0.205\n",
            "Mon Apr 25 10:50:44 2022: Epoch [3], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.122, Top5: 99.6756, Loss: 0.216\n",
            "Mon Apr 25 10:50:51 2022: Epoch [4], Iteration [0/391/], Data(s): 0.058, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.750, Top5: 99.2188, Loss: 0.210\n",
            "Mon Apr 25 10:50:59 2022: Epoch [4], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.162, Top5: 99.7370, Loss: 0.204\n",
            "Mon Apr 25 10:51:07 2022: Epoch [4], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.163, Top5: 99.7046, Loss: 0.210\n",
            "Mon Apr 25 10:51:15 2022: Epoch [4], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.205, Top5: 99.7067, Loss: 0.204\n",
            "Mon Apr 25 10:51:22 2022: Epoch [5], Iteration [0/391/], Data(s): 0.054, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 96.094, Top5: 100.0000, Loss: 0.206\n",
            "Mon Apr 25 10:51:30 2022: Epoch [5], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.193, Top5: 99.6519, Loss: 0.204\n",
            "Mon Apr 25 10:51:38 2022: Epoch [5], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.396, Top5: 99.6424, Loss: 0.202\n",
            "Mon Apr 25 10:51:46 2022: Epoch [5], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.296, Top5: 99.6808, Loss: 0.207\n",
            "Mon Apr 25 10:51:53 2022: Epoch [6], Iteration [0/391/], Data(s): 0.053, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.188, Top5: 100.0000, Loss: 0.204\n",
            "Mon Apr 25 10:52:01 2022: Epoch [6], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.487, Top5: 99.7293, Loss: 0.203\n",
            "Mon Apr 25 10:52:09 2022: Epoch [6], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.392, Top5: 99.7201, Loss: 0.205\n",
            "Mon Apr 25 10:52:17 2022: Epoch [6], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.405, Top5: 99.6885, Loss: 0.202\n",
            "Mon Apr 25 10:52:24 2022: Epoch [7], Iteration [0/391/], Data(s): 0.054, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.008, Top1: 94.531, Top5: 100.0000, Loss: 0.198\n",
            "Mon Apr 25 10:52:32 2022: Epoch [7], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.309, Top5: 99.6983, Loss: 0.202\n",
            "Mon Apr 25 10:52:40 2022: Epoch [7], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.392, Top5: 99.6929, Loss: 0.194\n",
            "Mon Apr 25 10:52:48 2022: Epoch [7], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.475, Top5: 99.7015, Loss: 0.191\n",
            "Mon Apr 25 10:52:56 2022: Epoch [8], Iteration [0/391/], Data(s): 0.053, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.531, Top5: 100.0000, Loss: 0.203\n",
            "Mon Apr 25 10:53:03 2022: Epoch [8], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.588, Top5: 99.6519, Loss: 0.202\n",
            "Mon Apr 25 10:53:11 2022: Epoch [8], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.711, Top5: 99.7046, Loss: 0.187\n",
            "Mon Apr 25 10:53:19 2022: Epoch [8], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.649, Top5: 99.7249, Loss: 0.195\n",
            "Mon Apr 25 10:53:27 2022: Epoch [9], Iteration [0/391/], Data(s): 0.054, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.188, Top5: 100.0000, Loss: 0.198\n",
            "Mon Apr 25 10:53:34 2022: Epoch [9], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.657, Top5: 99.7525, Loss: 0.190\n",
            "Mon Apr 25 10:53:42 2022: Epoch [9], Iteration [200/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.766, Top5: 99.7163, Loss: 0.187\n",
            "Mon Apr 25 10:53:50 2022: Epoch [9], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.651, Top5: 99.7353, Loss: 0.194\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 10:54:00 2022: Test information, Data(s): 1.568, Forward(s): 0.212, Top1: 90.580, Top5: 99.300, \n",
            "\n",
            "Mon Apr 25 10:54:00 2022: conv3 Layer, 49 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 79, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(79, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(79, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8           [-1, 79, 16, 16]          45,583\n",
            "       BatchNorm2d-9           [-1, 79, 16, 16]             158\n",
            "             ReLU-10           [-1, 79, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]          91,136\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         295,168\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]       1,180,160\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 14,907,127\n",
            "Trainable params: 14,907,127\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 6.29\n",
            "Params size (MB): 56.87\n",
            "Estimated Total Size (MB): 63.17\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 79, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(79, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(79, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 10:54:02 2022: Epoch [0], Iteration [0/391/], Data(s): 0.036, Loss(s): 0.006, Forward(s): 0.033, Backward(s): 0.086, Top1: 91.406, Top5: 99.2188, Loss: 0.237\n",
            "Mon Apr 25 10:54:10 2022: Epoch [0], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.008, Top1: 93.162, Top5: 99.5823, Loss: 0.206\n",
            "Mon Apr 25 10:54:17 2022: Epoch [0], Iteration [200/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.361, Top5: 99.6580, Loss: 0.196\n",
            "Mon Apr 25 10:54:25 2022: Epoch [0], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.449, Top5: 99.6937, Loss: 0.192\n",
            "Mon Apr 25 10:54:33 2022: Epoch [1], Iteration [0/391/], Data(s): 0.055, Loss(s): 0.008, Forward(s): 0.005, Backward(s): 0.008, Top1: 92.969, Top5: 100.0000, Loss: 0.197\n",
            "Mon Apr 25 10:54:40 2022: Epoch [1], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.005, Top5: 99.7138, Loss: 0.191\n",
            "Mon Apr 25 10:54:48 2022: Epoch [1], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.742, Top5: 99.7240, Loss: 0.196\n",
            "Mon Apr 25 10:54:56 2022: Epoch [1], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.698, Top5: 99.6989, Loss: 0.194\n",
            "Mon Apr 25 10:55:04 2022: Epoch [2], Iteration [0/391/], Data(s): 0.056, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 89.062, Top5: 99.2188, Loss: 0.198\n",
            "Mon Apr 25 10:55:11 2022: Epoch [2], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.402, Top5: 99.7447, Loss: 0.193\n",
            "Mon Apr 25 10:55:19 2022: Epoch [2], Iteration [200/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.598, Top5: 99.7512, Loss: 0.190\n",
            "Mon Apr 25 10:55:27 2022: Epoch [2], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.631, Top5: 99.7664, Loss: 0.187\n",
            "Mon Apr 25 10:55:34 2022: Epoch [3], Iteration [0/391/], Data(s): 0.052, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 95.312, Top5: 100.0000, Loss: 0.187\n",
            "Mon Apr 25 10:55:42 2022: Epoch [3], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.114, Top5: 99.7989, Loss: 0.179\n",
            "Mon Apr 25 10:55:50 2022: Epoch [3], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.069, Top5: 99.7512, Loss: 0.182\n",
            "Mon Apr 25 10:55:58 2022: Epoch [3], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.025, Top5: 99.7820, Loss: 0.182\n",
            "Mon Apr 25 10:56:05 2022: Epoch [4], Iteration [0/391/], Data(s): 0.056, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.531, Top5: 99.2188, Loss: 0.184\n",
            "Mon Apr 25 10:56:13 2022: Epoch [4], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.052, Top5: 99.7834, Loss: 0.173\n",
            "Mon Apr 25 10:56:21 2022: Epoch [4], Iteration [200/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.925, Top5: 99.7474, Loss: 0.184\n",
            "Mon Apr 25 10:56:29 2022: Epoch [4], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.838, Top5: 99.7638, Loss: 0.192\n",
            "Mon Apr 25 10:56:36 2022: Epoch [5], Iteration [0/391/], Data(s): 0.065, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.531, Top5: 99.2188, Loss: 0.182\n",
            "Mon Apr 25 10:56:44 2022: Epoch [5], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.144, Top5: 99.7834, Loss: 0.175\n",
            "Mon Apr 25 10:56:52 2022: Epoch [5], Iteration [200/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.014, Top5: 99.7785, Loss: 0.185\n",
            "Mon Apr 25 10:57:00 2022: Epoch [5], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.981, Top5: 99.7768, Loss: 0.181\n",
            "Mon Apr 25 10:57:07 2022: Epoch [6], Iteration [0/391/], Data(s): 0.051, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.531, Top5: 99.2188, Loss: 0.181\n",
            "Mon Apr 25 10:57:15 2022: Epoch [6], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.928, Top5: 99.7447, Loss: 0.183\n",
            "Mon Apr 25 10:57:23 2022: Epoch [6], Iteration [200/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.108, Top5: 99.7512, Loss: 0.182\n",
            "Mon Apr 25 10:57:31 2022: Epoch [6], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.056, Top5: 99.7638, Loss: 0.178\n",
            "Mon Apr 25 10:57:38 2022: Epoch [7], Iteration [0/391/], Data(s): 0.055, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 91.406, Top5: 99.2188, Loss: 0.174\n",
            "Mon Apr 25 10:57:46 2022: Epoch [7], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.191, Top5: 99.8221, Loss: 0.173\n",
            "Mon Apr 25 10:57:54 2022: Epoch [7], Iteration [200/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.069, Top5: 99.8057, Loss: 0.181\n",
            "Mon Apr 25 10:58:02 2022: Epoch [7], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.176, Top5: 99.7846, Loss: 0.173\n",
            "Mon Apr 25 10:58:09 2022: Epoch [8], Iteration [0/391/], Data(s): 0.058, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.008, Top1: 93.750, Top5: 99.2188, Loss: 0.175\n",
            "Mon Apr 25 10:58:17 2022: Epoch [8], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.616, Top5: 99.8066, Loss: 0.167\n",
            "Mon Apr 25 10:58:25 2022: Epoch [8], Iteration [200/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.422, Top5: 99.8095, Loss: 0.172\n",
            "Mon Apr 25 10:58:32 2022: Epoch [8], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.388, Top5: 99.8001, Loss: 0.169\n",
            "Mon Apr 25 10:58:40 2022: Epoch [9], Iteration [0/391/], Data(s): 0.054, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 95.312, Top5: 100.0000, Loss: 0.172\n",
            "Mon Apr 25 10:58:47 2022: Epoch [9], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.562, Top5: 99.8221, Loss: 0.164\n",
            "Mon Apr 25 10:58:55 2022: Epoch [9], Iteration [200/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.504, Top5: 99.8173, Loss: 0.172\n",
            "Mon Apr 25 10:59:03 2022: Epoch [9], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.536, Top5: 99.8287, Loss: 0.165\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 10:59:13 2022: Test information, Data(s): 1.600, Forward(s): 0.213, Top1: 90.780, Top5: 99.280, \n",
            "\n",
            "Mon Apr 25 10:59:13 2022: conv3 Layer, 65 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 63, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(63, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(63, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8           [-1, 63, 16, 16]          36,351\n",
            "       BatchNorm2d-9           [-1, 63, 16, 16]             126\n",
            "             ReLU-10           [-1, 63, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]          72,704\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         295,168\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]       1,180,160\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 14,879,431\n",
            "Trainable params: 14,879,431\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 6.19\n",
            "Params size (MB): 56.76\n",
            "Estimated Total Size (MB): 62.97\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 63, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(63, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(63, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 10:59:15 2022: Epoch [0], Iteration [0/391/], Data(s): 0.040, Loss(s): 0.006, Forward(s): 0.032, Backward(s): 0.071, Top1: 95.312, Top5: 100.0000, Loss: 0.148\n",
            "Mon Apr 25 10:59:23 2022: Epoch [0], Iteration [100/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.008, Top1: 93.773, Top5: 99.6983, Loss: 0.188\n",
            "Mon Apr 25 10:59:30 2022: Epoch [0], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.843, Top5: 99.7124, Loss: 0.184\n",
            "Mon Apr 25 10:59:38 2022: Epoch [0], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.012, Top5: 99.7456, Loss: 0.172\n",
            "Mon Apr 25 10:59:45 2022: Epoch [1], Iteration [0/391/], Data(s): 0.057, Loss(s): 0.007, Forward(s): 0.007, Backward(s): 0.007, Top1: 94.531, Top5: 100.0000, Loss: 0.180\n",
            "Mon Apr 25 10:59:53 2022: Epoch [1], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.858, Top5: 99.7525, Loss: 0.185\n",
            "Mon Apr 25 11:00:01 2022: Epoch [1], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.022, Top5: 99.7396, Loss: 0.179\n",
            "Mon Apr 25 11:00:09 2022: Epoch [1], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.030, Top5: 99.7664, Loss: 0.174\n",
            "Mon Apr 25 11:00:16 2022: Epoch [2], Iteration [0/391/], Data(s): 0.062, Loss(s): 0.010, Forward(s): 0.004, Backward(s): 0.008, Top1: 91.406, Top5: 100.0000, Loss: 0.177\n",
            "Mon Apr 25 11:00:23 2022: Epoch [2], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.191, Top5: 99.7447, Loss: 0.170\n",
            "Mon Apr 25 11:00:31 2022: Epoch [2], Iteration [200/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.337, Top5: 99.7629, Loss: 0.163\n",
            "Mon Apr 25 11:00:39 2022: Epoch [2], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.305, Top5: 99.7586, Loss: 0.173\n",
            "Mon Apr 25 11:00:46 2022: Epoch [3], Iteration [0/391/], Data(s): 0.058, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 95.312, Top5: 100.0000, Loss: 0.170\n",
            "Mon Apr 25 11:00:54 2022: Epoch [3], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.647, Top5: 99.8376, Loss: 0.165\n",
            "Mon Apr 25 11:01:02 2022: Epoch [3], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.671, Top5: 99.8173, Loss: 0.161\n",
            "Mon Apr 25 11:01:10 2022: Epoch [3], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.648, Top5: 99.8287, Loss: 0.166\n",
            "Mon Apr 25 11:01:17 2022: Epoch [4], Iteration [0/391/], Data(s): 0.053, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.531, Top5: 100.0000, Loss: 0.177\n",
            "Mon Apr 25 11:01:24 2022: Epoch [4], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.415, Top5: 99.9072, Loss: 0.161\n",
            "Mon Apr 25 11:01:32 2022: Epoch [4], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.508, Top5: 99.8251, Loss: 0.168\n",
            "Mon Apr 25 11:01:40 2022: Epoch [4], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.596, Top5: 99.8001, Loss: 0.163\n",
            "Mon Apr 25 11:01:47 2022: Epoch [5], Iteration [0/391/], Data(s): 0.054, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.750, Top5: 100.0000, Loss: 0.161\n",
            "Mon Apr 25 11:01:55 2022: Epoch [5], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.732, Top5: 99.8221, Loss: 0.161\n",
            "Mon Apr 25 11:02:03 2022: Epoch [5], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.815, Top5: 99.8329, Loss: 0.156\n",
            "Mon Apr 25 11:02:10 2022: Epoch [5], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.778, Top5: 99.8313, Loss: 0.158\n",
            "Mon Apr 25 11:02:18 2022: Epoch [6], Iteration [0/391/], Data(s): 0.054, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 96.875, Top5: 100.0000, Loss: 0.165\n",
            "Mon Apr 25 11:02:25 2022: Epoch [6], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.562, Top5: 99.8453, Loss: 0.163\n",
            "Mon Apr 25 11:02:33 2022: Epoch [6], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.609, Top5: 99.8406, Loss: 0.159\n",
            "Mon Apr 25 11:02:41 2022: Epoch [6], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.625, Top5: 99.8183, Loss: 0.160\n",
            "Mon Apr 25 11:02:48 2022: Epoch [7], Iteration [0/391/], Data(s): 0.056, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.969, Top5: 100.0000, Loss: 0.162\n",
            "Mon Apr 25 11:02:56 2022: Epoch [7], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.817, Top5: 99.8453, Loss: 0.152\n",
            "Mon Apr 25 11:03:04 2022: Epoch [7], Iteration [200/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.819, Top5: 99.8445, Loss: 0.155\n",
            "Mon Apr 25 11:03:11 2022: Epoch [7], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.804, Top5: 99.8365, Loss: 0.158\n",
            "Mon Apr 25 11:03:18 2022: Epoch [8], Iteration [0/391/], Data(s): 0.059, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.008, Top1: 93.750, Top5: 100.0000, Loss: 0.161\n",
            "Mon Apr 25 11:03:26 2022: Epoch [8], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.833, Top5: 99.8144, Loss: 0.155\n",
            "Mon Apr 25 11:03:34 2022: Epoch [8], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.998, Top5: 99.8095, Loss: 0.150\n",
            "Mon Apr 25 11:03:42 2022: Epoch [8], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.921, Top5: 99.8235, Loss: 0.155\n",
            "Mon Apr 25 11:03:49 2022: Epoch [9], Iteration [0/391/], Data(s): 0.055, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 95.312, Top5: 98.4375, Loss: 0.147\n",
            "Mon Apr 25 11:03:57 2022: Epoch [9], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 95.026, Top5: 99.8376, Loss: 0.150\n",
            "Mon Apr 25 11:04:05 2022: Epoch [9], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.990, Top5: 99.8018, Loss: 0.151\n",
            "Mon Apr 25 11:04:12 2022: Epoch [9], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.949, Top5: 99.8183, Loss: 0.157\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 11:04:22 2022: Test information, Data(s): 1.620, Forward(s): 0.210, Top1: 91.020, Top5: 99.210, \n",
            "\n",
            "Mon Apr 25 11:04:22 2022: conv3 Layer, 82 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 46, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(46, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(46, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8           [-1, 46, 16, 16]          26,542\n",
            "       BatchNorm2d-9           [-1, 46, 16, 16]              92\n",
            "             ReLU-10           [-1, 46, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]          53,120\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         295,168\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]       1,180,160\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 14,850,004\n",
            "Trainable params: 14,850,004\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 6.09\n",
            "Params size (MB): 56.65\n",
            "Estimated Total Size (MB): 62.75\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 46, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(46, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(46, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 11:04:23 2022: Epoch [0], Iteration [0/391/], Data(s): 0.035, Loss(s): 0.006, Forward(s): 0.026, Backward(s): 0.069, Top1: 92.188, Top5: 100.0000, Loss: 0.207\n",
            "Mon Apr 25 11:04:31 2022: Epoch [0], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.510, Top5: 99.7525, Loss: 0.189\n",
            "Mon Apr 25 11:04:39 2022: Epoch [0], Iteration [200/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.734, Top5: 99.7512, Loss: 0.184\n",
            "Mon Apr 25 11:04:46 2022: Epoch [0], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.843, Top5: 99.7690, Loss: 0.179\n",
            "Mon Apr 25 11:04:54 2022: Epoch [1], Iteration [0/391/], Data(s): 0.053, Loss(s): 0.009, Forward(s): 0.004, Backward(s): 0.008, Top1: 94.531, Top5: 100.0000, Loss: 0.177\n",
            "Mon Apr 25 11:05:01 2022: Epoch [1], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.524, Top5: 99.8685, Loss: 0.164\n",
            "Mon Apr 25 11:05:09 2022: Epoch [1], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.516, Top5: 99.8212, Loss: 0.168\n",
            "Mon Apr 25 11:05:17 2022: Epoch [1], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.508, Top5: 99.8105, Loss: 0.171\n",
            "Mon Apr 25 11:05:24 2022: Epoch [2], Iteration [0/391/], Data(s): 0.059, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.969, Top5: 99.2188, Loss: 0.173\n",
            "Mon Apr 25 11:05:32 2022: Epoch [2], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.825, Top5: 99.8144, Loss: 0.153\n",
            "Mon Apr 25 11:05:39 2022: Epoch [2], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.597, Top5: 99.8018, Loss: 0.167\n",
            "Mon Apr 25 11:05:47 2022: Epoch [2], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.565, Top5: 99.7950, Loss: 0.169\n",
            "Mon Apr 25 11:05:54 2022: Epoch [3], Iteration [0/391/], Data(s): 0.039, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.750, Top5: 100.0000, Loss: 0.164\n",
            "Mon Apr 25 11:06:02 2022: Epoch [3], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.446, Top5: 99.8298, Loss: 0.161\n",
            "Mon Apr 25 11:06:10 2022: Epoch [3], Iteration [200/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.729, Top5: 99.8406, Loss: 0.155\n",
            "Mon Apr 25 11:06:17 2022: Epoch [3], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.645, Top5: 99.8157, Loss: 0.163\n",
            "Mon Apr 25 11:06:24 2022: Epoch [4], Iteration [0/391/], Data(s): 0.055, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 90.625, Top5: 100.0000, Loss: 0.151\n",
            "Mon Apr 25 11:06:32 2022: Epoch [4], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 95.026, Top5: 99.8530, Loss: 0.154\n",
            "Mon Apr 25 11:06:40 2022: Epoch [4], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 95.060, Top5: 99.8834, Loss: 0.151\n",
            "Mon Apr 25 11:06:48 2022: Epoch [4], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 95.079, Top5: 99.8598, Loss: 0.147\n",
            "Mon Apr 25 11:06:55 2022: Epoch [5], Iteration [0/391/], Data(s): 0.052, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 96.094, Top5: 100.0000, Loss: 0.159\n",
            "Mon Apr 25 11:07:02 2022: Epoch [5], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 95.057, Top5: 99.8376, Loss: 0.148\n",
            "Mon Apr 25 11:07:10 2022: Epoch [5], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.924, Top5: 99.8095, Loss: 0.159\n",
            "Mon Apr 25 11:07:18 2022: Epoch [5], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.967, Top5: 99.8183, Loss: 0.150\n",
            "Mon Apr 25 11:07:25 2022: Epoch [6], Iteration [0/391/], Data(s): 0.053, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 98.438, Top5: 100.0000, Loss: 0.145\n",
            "Mon Apr 25 11:07:33 2022: Epoch [6], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 95.111, Top5: 99.8530, Loss: 0.145\n",
            "Mon Apr 25 11:07:40 2022: Epoch [6], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 95.103, Top5: 99.8406, Loss: 0.149\n",
            "Mon Apr 25 11:07:48 2022: Epoch [6], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 95.123, Top5: 99.8443, Loss: 0.146\n",
            "Mon Apr 25 11:07:55 2022: Epoch [7], Iteration [0/391/], Data(s): 0.055, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.750, Top5: 99.2188, Loss: 0.145\n",
            "Mon Apr 25 11:08:03 2022: Epoch [7], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 95.258, Top5: 99.8530, Loss: 0.141\n",
            "Mon Apr 25 11:08:11 2022: Epoch [7], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.947, Top5: 99.8368, Loss: 0.154\n",
            "Mon Apr 25 11:08:19 2022: Epoch [7], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 95.050, Top5: 99.8572, Loss: 0.142\n",
            "Mon Apr 25 11:08:26 2022: Epoch [8], Iteration [0/391/], Data(s): 0.054, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 96.094, Top5: 100.0000, Loss: 0.137\n",
            "Mon Apr 25 11:08:33 2022: Epoch [8], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 95.142, Top5: 99.8994, Loss: 0.139\n",
            "Mon Apr 25 11:08:41 2022: Epoch [8], Iteration [200/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 95.161, Top5: 99.8989, Loss: 0.142\n",
            "Mon Apr 25 11:08:49 2022: Epoch [8], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 95.242, Top5: 99.8858, Loss: 0.136\n",
            "Mon Apr 25 11:08:56 2022: Epoch [9], Iteration [0/391/], Data(s): 0.066, Loss(s): 0.009, Forward(s): 0.004, Backward(s): 0.008, Top1: 97.656, Top5: 100.0000, Loss: 0.150\n",
            "Mon Apr 25 11:09:04 2022: Epoch [9], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 95.289, Top5: 99.8917, Loss: 0.139\n",
            "Mon Apr 25 11:09:11 2022: Epoch [9], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 95.266, Top5: 99.8640, Loss: 0.143\n",
            "Mon Apr 25 11:09:19 2022: Epoch [9], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 95.146, Top5: 99.8624, Loss: 0.145\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 11:09:29 2022: Test information, Data(s): 1.564, Forward(s): 0.213, Top1: 90.910, Top5: 99.300, \n",
            "\n",
            "Mon Apr 25 11:09:29 2022: conv3 Layer, 98 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(30, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8           [-1, 30, 16, 16]          17,310\n",
            "       BatchNorm2d-9           [-1, 30, 16, 16]              60\n",
            "             ReLU-10           [-1, 30, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]          34,688\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         295,168\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]       1,180,160\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 14,822,308\n",
            "Trainable params: 14,822,308\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 6.00\n",
            "Params size (MB): 56.54\n",
            "Estimated Total Size (MB): 62.55\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(30, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 11:09:30 2022: Epoch [0], Iteration [0/391/], Data(s): 0.034, Loss(s): 0.005, Forward(s): 0.022, Backward(s): 0.062, Top1: 92.969, Top5: 99.2188, Loss: 0.198\n",
            "Mon Apr 25 11:09:38 2022: Epoch [0], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.008, Top1: 92.164, Top5: 99.5668, Loss: 0.239\n",
            "Mon Apr 25 11:09:46 2022: Epoch [0], Iteration [200/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.592, Top5: 99.6541, Loss: 0.209\n",
            "Mon Apr 25 11:09:53 2022: Epoch [0], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.940, Top5: 99.6989, Loss: 0.192\n",
            "Mon Apr 25 11:10:00 2022: Epoch [1], Iteration [0/391/], Data(s): 0.058, Loss(s): 0.009, Forward(s): 0.004, Backward(s): 0.008, Top1: 90.625, Top5: 100.0000, Loss: 0.189\n",
            "Mon Apr 25 11:10:08 2022: Epoch [1], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.928, Top5: 99.8144, Loss: 0.183\n",
            "Mon Apr 25 11:10:15 2022: Epoch [1], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.100, Top5: 99.8095, Loss: 0.170\n",
            "Mon Apr 25 11:10:23 2022: Epoch [1], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.116, Top5: 99.7898, Loss: 0.181\n",
            "Mon Apr 25 11:10:30 2022: Epoch [2], Iteration [0/391/], Data(s): 0.063, Loss(s): 0.009, Forward(s): 0.003, Backward(s): 0.007, Top1: 95.312, Top5: 100.0000, Loss: 0.179\n",
            "Mon Apr 25 11:10:38 2022: Epoch [2], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.268, Top5: 99.7293, Loss: 0.177\n",
            "Mon Apr 25 11:10:45 2022: Epoch [2], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.356, Top5: 99.7668, Loss: 0.171\n",
            "Mon Apr 25 11:10:53 2022: Epoch [2], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.303, Top5: 99.7716, Loss: 0.175\n",
            "Mon Apr 25 11:11:00 2022: Epoch [3], Iteration [0/391/], Data(s): 0.058, Loss(s): 0.009, Forward(s): 0.003, Backward(s): 0.008, Top1: 94.531, Top5: 100.0000, Loss: 0.166\n",
            "Mon Apr 25 11:11:08 2022: Epoch [3], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.663, Top5: 99.8608, Loss: 0.164\n",
            "Mon Apr 25 11:11:15 2022: Epoch [3], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.473, Top5: 99.8523, Loss: 0.168\n",
            "Mon Apr 25 11:11:23 2022: Epoch [3], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.490, Top5: 99.8287, Loss: 0.164\n",
            "Mon Apr 25 11:11:30 2022: Epoch [4], Iteration [0/391/], Data(s): 0.053, Loss(s): 0.009, Forward(s): 0.003, Backward(s): 0.007, Top1: 95.312, Top5: 100.0000, Loss: 0.159\n",
            "Mon Apr 25 11:11:37 2022: Epoch [4], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.740, Top5: 99.8066, Loss: 0.162\n",
            "Mon Apr 25 11:11:45 2022: Epoch [4], Iteration [200/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.854, Top5: 99.8018, Loss: 0.153\n",
            "Mon Apr 25 11:11:53 2022: Epoch [4], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.786, Top5: 99.8209, Loss: 0.161\n",
            "Mon Apr 25 11:12:00 2022: Epoch [5], Iteration [0/391/], Data(s): 0.052, Loss(s): 0.009, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.969, Top5: 99.2188, Loss: 0.157\n",
            "Mon Apr 25 11:12:07 2022: Epoch [5], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.918, Top5: 99.8066, Loss: 0.149\n",
            "Mon Apr 25 11:12:15 2022: Epoch [5], Iteration [200/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 95.044, Top5: 99.7901, Loss: 0.149\n",
            "Mon Apr 25 11:12:22 2022: Epoch [5], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.874, Top5: 99.8001, Loss: 0.159\n",
            "Mon Apr 25 11:12:29 2022: Epoch [6], Iteration [0/391/], Data(s): 0.056, Loss(s): 0.009, Forward(s): 0.003, Backward(s): 0.007, Top1: 96.094, Top5: 100.0000, Loss: 0.149\n",
            "Mon Apr 25 11:12:37 2022: Epoch [6], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 95.158, Top5: 99.8221, Loss: 0.147\n",
            "Mon Apr 25 11:12:45 2022: Epoch [6], Iteration [200/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 95.095, Top5: 99.8484, Loss: 0.143\n",
            "Mon Apr 25 11:12:52 2022: Epoch [6], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 95.089, Top5: 99.8391, Loss: 0.148\n",
            "Mon Apr 25 11:12:59 2022: Epoch [7], Iteration [0/391/], Data(s): 0.059, Loss(s): 0.009, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.188, Top5: 100.0000, Loss: 0.146\n",
            "Mon Apr 25 11:13:07 2022: Epoch [7], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.964, Top5: 99.8762, Loss: 0.147\n",
            "Mon Apr 25 11:13:15 2022: Epoch [7], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 95.048, Top5: 99.8834, Loss: 0.146\n",
            "Mon Apr 25 11:13:22 2022: Epoch [7], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 95.035, Top5: 99.8832, Loss: 0.144\n",
            "Mon Apr 25 11:13:29 2022: Epoch [8], Iteration [0/391/], Data(s): 0.064, Loss(s): 0.009, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.531, Top5: 100.0000, Loss: 0.140\n",
            "Mon Apr 25 11:13:37 2022: Epoch [8], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 95.467, Top5: 99.8917, Loss: 0.135\n",
            "Mon Apr 25 11:13:44 2022: Epoch [8], Iteration [200/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 95.449, Top5: 99.8601, Loss: 0.142\n",
            "Mon Apr 25 11:13:52 2022: Epoch [8], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 95.390, Top5: 99.8702, Loss: 0.137\n",
            "Mon Apr 25 11:13:59 2022: Epoch [9], Iteration [0/391/], Data(s): 0.060, Loss(s): 0.009, Forward(s): 0.004, Backward(s): 0.008, Top1: 96.094, Top5: 100.0000, Loss: 0.151\n",
            "Mon Apr 25 11:14:07 2022: Epoch [9], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 95.506, Top5: 99.8840, Loss: 0.135\n",
            "Mon Apr 25 11:14:14 2022: Epoch [9], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 95.406, Top5: 99.9067, Loss: 0.140\n",
            "Mon Apr 25 11:14:22 2022: Epoch [9], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 95.385, Top5: 99.8988, Loss: 0.137\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 11:14:32 2022: Test information, Data(s): 1.601, Forward(s): 0.214, Top1: 90.750, Top5: 99.300, \n",
            "\n",
            "Mon Apr 25 11:14:32 2022: conv3 Layer, 115 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 13, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(13, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8           [-1, 13, 16, 16]           7,501\n",
            "       BatchNorm2d-9           [-1, 13, 16, 16]              26\n",
            "             ReLU-10           [-1, 13, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]          15,104\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         295,168\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]       1,180,160\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 14,792,881\n",
            "Trainable params: 14,792,881\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 5.90\n",
            "Params size (MB): 56.43\n",
            "Estimated Total Size (MB): 62.34\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 13, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(13, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 11:14:33 2022: Epoch [0], Iteration [0/391/], Data(s): 0.038, Loss(s): 0.006, Forward(s): 0.019, Backward(s): 0.054, Top1: 77.344, Top5: 98.4375, Loss: 0.812\n",
            "Mon Apr 25 11:14:40 2022: Epoch [0], Iteration [100/391/], Data(s): 0.035, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 86.038, Top5: 98.5535, Loss: 0.473\n",
            "Mon Apr 25 11:14:48 2022: Epoch [0], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 87.558, Top5: 98.9661, Loss: 0.336\n",
            "Mon Apr 25 11:14:55 2022: Epoch [0], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 88.349, Top5: 99.0968, Loss: 0.317\n",
            "Mon Apr 25 11:15:02 2022: Epoch [1], Iteration [0/391/], Data(s): 0.057, Loss(s): 0.008, Forward(s): 0.005, Backward(s): 0.007, Top1: 89.844, Top5: 99.2188, Loss: 0.289\n",
            "Mon Apr 25 11:15:10 2022: Epoch [1], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 91.050, Top5: 99.5514, Loss: 0.266\n",
            "Mon Apr 25 11:15:18 2022: Epoch [1], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 91.262, Top5: 99.5569, Loss: 0.255\n",
            "Mon Apr 25 11:15:25 2022: Epoch [1], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 91.404, Top5: 99.5951, Loss: 0.246\n",
            "Mon Apr 25 11:15:32 2022: Epoch [2], Iteration [0/391/], Data(s): 0.058, Loss(s): 0.009, Forward(s): 0.004, Backward(s): 0.007, Top1: 92.188, Top5: 99.2188, Loss: 0.251\n",
            "Mon Apr 25 11:15:40 2022: Epoch [2], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.079, Top5: 99.6055, Loss: 0.234\n",
            "Mon Apr 25 11:15:47 2022: Epoch [2], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.102, Top5: 99.6502, Loss: 0.231\n",
            "Mon Apr 25 11:15:55 2022: Epoch [2], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.076, Top5: 99.6496, Loss: 0.228\n",
            "Mon Apr 25 11:16:02 2022: Epoch [3], Iteration [0/391/], Data(s): 0.053, Loss(s): 0.009, Forward(s): 0.003, Backward(s): 0.008, Top1: 90.625, Top5: 100.0000, Loss: 0.216\n",
            "Mon Apr 25 11:16:09 2022: Epoch [3], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.706, Top5: 99.6674, Loss: 0.215\n",
            "Mon Apr 25 11:16:17 2022: Epoch [3], Iteration [200/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.872, Top5: 99.6657, Loss: 0.210\n",
            "Mon Apr 25 11:16:24 2022: Epoch [3], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.956, Top5: 99.6911, Loss: 0.207\n",
            "Mon Apr 25 11:16:31 2022: Epoch [4], Iteration [0/391/], Data(s): 0.057, Loss(s): 0.009, Forward(s): 0.003, Backward(s): 0.007, Top1: 90.625, Top5: 98.4375, Loss: 0.216\n",
            "Mon Apr 25 11:16:38 2022: Epoch [4], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.472, Top5: 99.7370, Loss: 0.193\n",
            "Mon Apr 25 11:16:46 2022: Epoch [4], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.233, Top5: 99.7124, Loss: 0.206\n",
            "Mon Apr 25 11:16:54 2022: Epoch [4], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.343, Top5: 99.6937, Loss: 0.199\n",
            "Mon Apr 25 11:17:01 2022: Epoch [5], Iteration [0/391/], Data(s): 0.053, Loss(s): 0.009, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.531, Top5: 99.2188, Loss: 0.198\n",
            "Mon Apr 25 11:17:08 2022: Epoch [5], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.967, Top5: 99.7834, Loss: 0.183\n",
            "Mon Apr 25 11:17:16 2022: Epoch [5], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.863, Top5: 99.8057, Loss: 0.186\n",
            "Mon Apr 25 11:17:23 2022: Epoch [5], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.807, Top5: 99.7690, Loss: 0.190\n",
            "Mon Apr 25 11:17:30 2022: Epoch [6], Iteration [0/391/], Data(s): 0.057, Loss(s): 0.009, Forward(s): 0.003, Backward(s): 0.007, Top1: 89.844, Top5: 100.0000, Loss: 0.190\n",
            "Mon Apr 25 11:17:38 2022: Epoch [6], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.129, Top5: 99.7293, Loss: 0.177\n",
            "Mon Apr 25 11:17:45 2022: Epoch [6], Iteration [200/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.170, Top5: 99.7785, Loss: 0.170\n",
            "Mon Apr 25 11:17:53 2022: Epoch [6], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.043, Top5: 99.7768, Loss: 0.189\n",
            "Mon Apr 25 11:18:00 2022: Epoch [7], Iteration [0/391/], Data(s): 0.055, Loss(s): 0.009, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.188, Top5: 100.0000, Loss: 0.189\n",
            "Mon Apr 25 11:18:07 2022: Epoch [7], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.106, Top5: 99.7215, Loss: 0.178\n",
            "Mon Apr 25 11:18:15 2022: Epoch [7], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.143, Top5: 99.7823, Loss: 0.174\n",
            "Mon Apr 25 11:18:22 2022: Epoch [7], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.025, Top5: 99.7664, Loss: 0.178\n",
            "Mon Apr 25 11:18:29 2022: Epoch [8], Iteration [0/391/], Data(s): 0.053, Loss(s): 0.009, Forward(s): 0.003, Backward(s): 0.007, Top1: 96.094, Top5: 100.0000, Loss: 0.174\n",
            "Mon Apr 25 11:18:37 2022: Epoch [8], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.322, Top5: 99.8685, Loss: 0.171\n",
            "Mon Apr 25 11:18:44 2022: Epoch [8], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.321, Top5: 99.8406, Loss: 0.166\n",
            "Mon Apr 25 11:18:52 2022: Epoch [8], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.337, Top5: 99.8443, Loss: 0.169\n",
            "Mon Apr 25 11:18:59 2022: Epoch [9], Iteration [0/391/], Data(s): 0.052, Loss(s): 0.009, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.969, Top5: 100.0000, Loss: 0.176\n",
            "Mon Apr 25 11:19:06 2022: Epoch [9], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.717, Top5: 99.8066, Loss: 0.156\n",
            "Mon Apr 25 11:19:14 2022: Epoch [9], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.582, Top5: 99.7862, Loss: 0.168\n",
            "Mon Apr 25 11:19:22 2022: Epoch [9], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.588, Top5: 99.7794, Loss: 0.165\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 11:19:31 2022: Test information, Data(s): 1.586, Forward(s): 0.213, Top1: 89.830, Top5: 99.300, \n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 11:19:36 2022: Test information, Data(s): 1.557, Forward(s): 0.211, Top1: 77.870, Top5: 97.560, \n",
            "\n",
            "Mon Apr 25 11:19:36 2022: conv4 Layer, 16 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 112, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(112, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]          73,856\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "             ReLU-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11          [-1, 112, 16, 16]         129,136\n",
            "      BatchNorm2d-12          [-1, 112, 16, 16]             224\n",
            "             ReLU-13          [-1, 112, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 112, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         258,304\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]       1,180,160\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 14,936,602\n",
            "Trainable params: 14,936,602\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 6.47\n",
            "Params size (MB): 56.98\n",
            "Estimated Total Size (MB): 63.46\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 112, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(112, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 11:19:37 2022: Epoch [0], Iteration [0/391/], Data(s): 0.035, Loss(s): 0.005, Forward(s): 0.046, Backward(s): 0.089, Top1: 88.281, Top5: 98.4375, Loss: 0.426\n",
            "Mon Apr 25 11:19:45 2022: Epoch [0], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.008, Top1: 86.742, Top5: 98.8707, Loss: 0.409\n",
            "Mon Apr 25 11:19:53 2022: Epoch [0], Iteration [200/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 87.671, Top5: 99.0050, Loss: 0.356\n",
            "Mon Apr 25 11:20:01 2022: Epoch [0], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.007, Top1: 88.227, Top5: 99.0890, Loss: 0.331\n",
            "Mon Apr 25 11:20:09 2022: Epoch [1], Iteration [0/391/], Data(s): 0.053, Loss(s): 0.010, Forward(s): 0.004, Backward(s): 0.007, Top1: 89.062, Top5: 100.0000, Loss: 0.318\n",
            "Mon Apr 25 11:20:17 2022: Epoch [1], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.007, Top1: 89.805, Top5: 99.3348, Loss: 0.317\n",
            "Mon Apr 25 11:20:25 2022: Epoch [1], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.007, Top1: 90.201, Top5: 99.3859, Loss: 0.295\n",
            "Mon Apr 25 11:20:33 2022: Epoch [1], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.007, Top1: 90.189, Top5: 99.4056, Loss: 0.298\n",
            "Mon Apr 25 11:20:40 2022: Epoch [2], Iteration [0/391/], Data(s): 0.059, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.009, Top1: 92.969, Top5: 100.0000, Loss: 0.298\n",
            "Mon Apr 25 11:20:48 2022: Epoch [2], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 91.019, Top5: 99.5204, Loss: 0.278\n",
            "Mon Apr 25 11:20:56 2022: Epoch [2], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 90.963, Top5: 99.5141, Loss: 0.283\n",
            "Mon Apr 25 11:21:04 2022: Epoch [2], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.007, Top1: 91.007, Top5: 99.5017, Loss: 0.273\n",
            "Mon Apr 25 11:21:11 2022: Epoch [3], Iteration [0/391/], Data(s): 0.056, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 96.094, Top5: 100.0000, Loss: 0.279\n",
            "Mon Apr 25 11:21:19 2022: Epoch [3], Iteration [100/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 90.911, Top5: 99.5359, Loss: 0.277\n",
            "Mon Apr 25 11:21:27 2022: Epoch [3], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.007, Top1: 91.181, Top5: 99.5297, Loss: 0.260\n",
            "Mon Apr 25 11:21:35 2022: Epoch [3], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.007, Top1: 91.219, Top5: 99.4887, Loss: 0.271\n",
            "Mon Apr 25 11:21:42 2022: Epoch [4], Iteration [0/391/], Data(s): 0.057, Loss(s): 0.011, Forward(s): 0.004, Backward(s): 0.007, Top1: 93.750, Top5: 99.2188, Loss: 0.269\n",
            "Mon Apr 25 11:21:51 2022: Epoch [4], Iteration [100/391/], Data(s): 0.035, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.007, Top1: 91.576, Top5: 99.4508, Loss: 0.267\n",
            "Mon Apr 25 11:21:58 2022: Epoch [4], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.007, Top1: 91.562, Top5: 99.4831, Loss: 0.257\n",
            "Mon Apr 25 11:22:06 2022: Epoch [4], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.007, Top1: 91.580, Top5: 99.4887, Loss: 0.258\n",
            "Mon Apr 25 11:22:14 2022: Epoch [5], Iteration [0/391/], Data(s): 0.053, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 90.625, Top5: 100.0000, Loss: 0.250\n",
            "Mon Apr 25 11:22:22 2022: Epoch [5], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.007, Top1: 91.778, Top5: 99.6829, Loss: 0.252\n",
            "Mon Apr 25 11:22:30 2022: Epoch [5], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.153, Top5: 99.6113, Loss: 0.238\n",
            "Mon Apr 25 11:22:38 2022: Epoch [5], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.007, Top1: 91.928, Top5: 99.5614, Loss: 0.258\n",
            "Mon Apr 25 11:22:45 2022: Epoch [6], Iteration [0/391/], Data(s): 0.055, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 89.062, Top5: 100.0000, Loss: 0.248\n",
            "Mon Apr 25 11:22:53 2022: Epoch [6], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.180, Top5: 99.5746, Loss: 0.243\n",
            "Mon Apr 25 11:23:01 2022: Epoch [6], Iteration [200/391/], Data(s): 0.033, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.071, Top5: 99.5608, Loss: 0.246\n",
            "Mon Apr 25 11:23:09 2022: Epoch [6], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.007, Top1: 91.962, Top5: 99.5510, Loss: 0.249\n",
            "Mon Apr 25 11:23:16 2022: Epoch [7], Iteration [0/391/], Data(s): 0.052, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 97.656, Top5: 100.0000, Loss: 0.238\n",
            "Mon Apr 25 11:23:24 2022: Epoch [7], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.597, Top5: 99.7061, Loss: 0.227\n",
            "Mon Apr 25 11:23:32 2022: Epoch [7], Iteration [200/391/], Data(s): 0.033, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.533, Top5: 99.6735, Loss: 0.235\n",
            "Mon Apr 25 11:23:40 2022: Epoch [7], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.338, Top5: 99.6133, Loss: 0.242\n",
            "Mon Apr 25 11:23:47 2022: Epoch [8], Iteration [0/391/], Data(s): 0.053, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.750, Top5: 100.0000, Loss: 0.238\n",
            "Mon Apr 25 11:23:55 2022: Epoch [8], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.899, Top5: 99.5978, Loss: 0.220\n",
            "Mon Apr 25 11:24:03 2022: Epoch [8], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.611, Top5: 99.6696, Loss: 0.232\n",
            "Mon Apr 25 11:24:11 2022: Epoch [8], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.546, Top5: 99.6652, Loss: 0.236\n",
            "Mon Apr 25 11:24:19 2022: Epoch [9], Iteration [0/391/], Data(s): 0.054, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.188, Top5: 99.2188, Loss: 0.234\n",
            "Mon Apr 25 11:24:27 2022: Epoch [9], Iteration [100/391/], Data(s): 0.032, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.512, Top5: 99.5591, Loss: 0.223\n",
            "Mon Apr 25 11:24:34 2022: Epoch [9], Iteration [200/391/], Data(s): 0.033, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.580, Top5: 99.5841, Loss: 0.223\n",
            "Mon Apr 25 11:24:42 2022: Epoch [9], Iteration [300/391/], Data(s): 0.032, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.639, Top5: 99.5873, Loss: 0.223\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 11:24:53 2022: Test information, Data(s): 1.612, Forward(s): 0.214, Top1: 90.040, Top5: 99.230, \n",
            "\n",
            "Mon Apr 25 11:24:53 2022: conv4 Layer, 32 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(96, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]          73,856\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "             ReLU-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11           [-1, 96, 16, 16]         110,688\n",
            "      BatchNorm2d-12           [-1, 96, 16, 16]             192\n",
            "             ReLU-13           [-1, 96, 16, 16]               0\n",
            "        MaxPool2d-14             [-1, 96, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         221,440\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]       1,180,160\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 14,881,258\n",
            "Trainable params: 14,881,258\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 6.37\n",
            "Params size (MB): 56.77\n",
            "Estimated Total Size (MB): 63.15\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(96, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 11:24:54 2022: Epoch [0], Iteration [0/391/], Data(s): 0.034, Loss(s): 0.004, Forward(s): 0.042, Backward(s): 0.088, Top1: 95.312, Top5: 100.0000, Loss: 0.171\n",
            "Mon Apr 25 11:25:02 2022: Epoch [0], Iteration [100/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.126, Top5: 99.5746, Loss: 0.239\n",
            "Mon Apr 25 11:25:10 2022: Epoch [0], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.374, Top5: 99.5919, Loss: 0.229\n",
            "Mon Apr 25 11:25:17 2022: Epoch [0], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.403, Top5: 99.6185, Loss: 0.223\n",
            "Mon Apr 25 11:25:25 2022: Epoch [1], Iteration [0/391/], Data(s): 0.053, Loss(s): 0.010, Forward(s): 0.004, Backward(s): 0.007, Top1: 92.969, Top5: 100.0000, Loss: 0.236\n",
            "Mon Apr 25 11:25:33 2022: Epoch [1], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.278, Top5: 99.7912, Loss: 0.208\n",
            "Mon Apr 25 11:25:41 2022: Epoch [1], Iteration [200/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.926, Top5: 99.7201, Loss: 0.229\n",
            "Mon Apr 25 11:25:49 2022: Epoch [1], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.779, Top5: 99.6756, Loss: 0.227\n",
            "Mon Apr 25 11:25:56 2022: Epoch [2], Iteration [0/391/], Data(s): 0.054, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.008, Top1: 90.625, Top5: 99.2188, Loss: 0.229\n",
            "Mon Apr 25 11:26:04 2022: Epoch [2], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.435, Top5: 99.6674, Loss: 0.225\n",
            "Mon Apr 25 11:26:12 2022: Epoch [2], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.576, Top5: 99.6580, Loss: 0.223\n",
            "Mon Apr 25 11:26:20 2022: Epoch [2], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.681, Top5: 99.6704, Loss: 0.218\n",
            "Mon Apr 25 11:26:27 2022: Epoch [3], Iteration [0/391/], Data(s): 0.056, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 91.406, Top5: 100.0000, Loss: 0.214\n",
            "Mon Apr 25 11:26:35 2022: Epoch [3], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.077, Top5: 99.6055, Loss: 0.212\n",
            "Mon Apr 25 11:26:43 2022: Epoch [3], Iteration [200/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.992, Top5: 99.6774, Loss: 0.210\n",
            "Mon Apr 25 11:26:51 2022: Epoch [3], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.816, Top5: 99.6937, Loss: 0.222\n",
            "Mon Apr 25 11:26:58 2022: Epoch [4], Iteration [0/391/], Data(s): 0.053, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.008, Top1: 89.844, Top5: 100.0000, Loss: 0.214\n",
            "Mon Apr 25 11:27:06 2022: Epoch [4], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.799, Top5: 99.7138, Loss: 0.214\n",
            "Mon Apr 25 11:27:14 2022: Epoch [4], Iteration [200/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.054, Top5: 99.6968, Loss: 0.206\n",
            "Mon Apr 25 11:27:21 2022: Epoch [4], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.119, Top5: 99.6989, Loss: 0.208\n",
            "Mon Apr 25 11:27:29 2022: Epoch [5], Iteration [0/391/], Data(s): 0.056, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.531, Top5: 100.0000, Loss: 0.210\n",
            "Mon Apr 25 11:27:37 2022: Epoch [5], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.093, Top5: 99.7757, Loss: 0.203\n",
            "Mon Apr 25 11:27:45 2022: Epoch [5], Iteration [200/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.140, Top5: 99.7240, Loss: 0.210\n",
            "Mon Apr 25 11:27:52 2022: Epoch [5], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.137, Top5: 99.6885, Loss: 0.212\n",
            "Mon Apr 25 11:28:00 2022: Epoch [6], Iteration [0/391/], Data(s): 0.054, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.188, Top5: 100.0000, Loss: 0.214\n",
            "Mon Apr 25 11:28:08 2022: Epoch [6], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.526, Top5: 99.6597, Loss: 0.204\n",
            "Mon Apr 25 11:28:16 2022: Epoch [6], Iteration [200/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.400, Top5: 99.7007, Loss: 0.199\n",
            "Mon Apr 25 11:28:23 2022: Epoch [6], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.296, Top5: 99.7119, Loss: 0.205\n",
            "Mon Apr 25 11:28:31 2022: Epoch [7], Iteration [0/391/], Data(s): 0.057, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 95.312, Top5: 100.0000, Loss: 0.209\n",
            "Mon Apr 25 11:28:38 2022: Epoch [7], Iteration [100/391/], Data(s): 0.032, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.038, Top5: 99.6674, Loss: 0.213\n",
            "Mon Apr 25 11:28:46 2022: Epoch [7], Iteration [200/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.284, Top5: 99.7124, Loss: 0.197\n",
            "Mon Apr 25 11:28:54 2022: Epoch [7], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.337, Top5: 99.7145, Loss: 0.199\n",
            "Mon Apr 25 11:29:02 2022: Epoch [8], Iteration [0/391/], Data(s): 0.054, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.750, Top5: 100.0000, Loss: 0.197\n",
            "Mon Apr 25 11:29:09 2022: Epoch [8], Iteration [100/391/], Data(s): 0.032, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.193, Top5: 99.6055, Loss: 0.204\n",
            "Mon Apr 25 11:29:17 2022: Epoch [8], Iteration [200/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.424, Top5: 99.6657, Loss: 0.190\n",
            "Mon Apr 25 11:29:25 2022: Epoch [8], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.459, Top5: 99.6626, Loss: 0.203\n",
            "Mon Apr 25 11:29:32 2022: Epoch [9], Iteration [0/391/], Data(s): 0.059, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.008, Top1: 89.062, Top5: 100.0000, Loss: 0.194\n",
            "Mon Apr 25 11:29:40 2022: Epoch [9], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.851, Top5: 99.7061, Loss: 0.188\n",
            "Mon Apr 25 11:29:48 2022: Epoch [9], Iteration [200/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.591, Top5: 99.7240, Loss: 0.196\n",
            "Mon Apr 25 11:29:56 2022: Epoch [9], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.477, Top5: 99.7197, Loss: 0.198\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 11:30:06 2022: Test information, Data(s): 1.555, Forward(s): 0.209, Top1: 90.400, Top5: 99.310, \n",
            "\n",
            "Mon Apr 25 11:30:06 2022: conv4 Layer, 49 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 79, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(79, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(79, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]          73,856\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "             ReLU-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11           [-1, 79, 16, 16]          91,087\n",
            "      BatchNorm2d-12           [-1, 79, 16, 16]             158\n",
            "             ReLU-13           [-1, 79, 16, 16]               0\n",
            "        MaxPool2d-14             [-1, 79, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         182,272\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]       1,180,160\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 14,822,455\n",
            "Trainable params: 14,822,455\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 6.26\n",
            "Params size (MB): 56.54\n",
            "Estimated Total Size (MB): 62.82\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 79, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(79, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(79, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 11:30:07 2022: Epoch [0], Iteration [0/391/], Data(s): 0.035, Loss(s): 0.004, Forward(s): 0.040, Backward(s): 0.079, Top1: 92.188, Top5: 99.2188, Loss: 0.236\n",
            "Mon Apr 25 11:30:15 2022: Epoch [0], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.008, Top1: 92.265, Top5: 99.5668, Loss: 0.232\n",
            "Mon Apr 25 11:30:23 2022: Epoch [0], Iteration [200/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.533, Top5: 99.5919, Loss: 0.217\n",
            "Mon Apr 25 11:30:31 2022: Epoch [0], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.668, Top5: 99.6392, Loss: 0.209\n",
            "Mon Apr 25 11:30:38 2022: Epoch [1], Iteration [0/391/], Data(s): 0.052, Loss(s): 0.010, Forward(s): 0.004, Backward(s): 0.007, Top1: 89.844, Top5: 100.0000, Loss: 0.220\n",
            "Mon Apr 25 11:30:46 2022: Epoch [1], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.031, Top5: 99.7138, Loss: 0.206\n",
            "Mon Apr 25 11:30:54 2022: Epoch [1], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.039, Top5: 99.6929, Loss: 0.208\n",
            "Mon Apr 25 11:31:02 2022: Epoch [1], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.259, Top5: 99.6911, Loss: 0.199\n",
            "Mon Apr 25 11:31:10 2022: Epoch [2], Iteration [0/391/], Data(s): 0.055, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 95.312, Top5: 99.2188, Loss: 0.210\n",
            "Mon Apr 25 11:31:18 2022: Epoch [2], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.038, Top5: 99.7525, Loss: 0.208\n",
            "Mon Apr 25 11:31:26 2022: Epoch [2], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.070, Top5: 99.7240, Loss: 0.208\n",
            "Mon Apr 25 11:31:34 2022: Epoch [2], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.239, Top5: 99.7067, Loss: 0.199\n",
            "Mon Apr 25 11:31:41 2022: Epoch [3], Iteration [0/391/], Data(s): 0.061, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.531, Top5: 100.0000, Loss: 0.196\n",
            "Mon Apr 25 11:31:49 2022: Epoch [3], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.363, Top5: 99.7215, Loss: 0.201\n",
            "Mon Apr 25 11:31:57 2022: Epoch [3], Iteration [200/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.509, Top5: 99.7551, Loss: 0.190\n",
            "Mon Apr 25 11:32:05 2022: Epoch [3], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.376, Top5: 99.7534, Loss: 0.200\n",
            "Mon Apr 25 11:32:12 2022: Epoch [4], Iteration [0/391/], Data(s): 0.059, Loss(s): 0.010, Forward(s): 0.004, Backward(s): 0.008, Top1: 96.094, Top5: 99.2188, Loss: 0.197\n",
            "Mon Apr 25 11:32:20 2022: Epoch [4], Iteration [100/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.394, Top5: 99.7370, Loss: 0.202\n",
            "Mon Apr 25 11:32:28 2022: Epoch [4], Iteration [200/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.602, Top5: 99.7279, Loss: 0.188\n",
            "Mon Apr 25 11:32:36 2022: Epoch [4], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.550, Top5: 99.7249, Loss: 0.197\n",
            "Mon Apr 25 11:32:43 2022: Epoch [5], Iteration [0/391/], Data(s): 0.053, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.008, Top1: 96.094, Top5: 100.0000, Loss: 0.197\n",
            "Mon Apr 25 11:32:51 2022: Epoch [5], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.356, Top5: 99.6210, Loss: 0.198\n",
            "Mon Apr 25 11:32:59 2022: Epoch [5], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.501, Top5: 99.7124, Loss: 0.193\n",
            "Mon Apr 25 11:33:07 2022: Epoch [5], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.592, Top5: 99.7223, Loss: 0.189\n",
            "Mon Apr 25 11:33:14 2022: Epoch [6], Iteration [0/391/], Data(s): 0.057, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 96.094, Top5: 100.0000, Loss: 0.189\n",
            "Mon Apr 25 11:33:22 2022: Epoch [6], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.796, Top5: 99.7447, Loss: 0.188\n",
            "Mon Apr 25 11:33:30 2022: Epoch [6], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.847, Top5: 99.7201, Loss: 0.186\n",
            "Mon Apr 25 11:33:38 2022: Epoch [6], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.903, Top5: 99.7301, Loss: 0.181\n",
            "Mon Apr 25 11:33:45 2022: Epoch [7], Iteration [0/391/], Data(s): 0.054, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 95.312, Top5: 100.0000, Loss: 0.189\n",
            "Mon Apr 25 11:33:53 2022: Epoch [7], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.013, Top5: 99.6906, Loss: 0.187\n",
            "Mon Apr 25 11:34:01 2022: Epoch [7], Iteration [200/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.158, Top5: 99.7318, Loss: 0.177\n",
            "Mon Apr 25 11:34:09 2022: Epoch [7], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.103, Top5: 99.7430, Loss: 0.183\n",
            "Mon Apr 25 11:34:17 2022: Epoch [8], Iteration [0/391/], Data(s): 0.055, Loss(s): 0.008, Forward(s): 0.006, Backward(s): 0.009, Top1: 92.969, Top5: 100.0000, Loss: 0.193\n",
            "Mon Apr 25 11:34:24 2022: Epoch [8], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.928, Top5: 99.8066, Loss: 0.178\n",
            "Mon Apr 25 11:34:32 2022: Epoch [8], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.018, Top5: 99.7551, Loss: 0.184\n",
            "Mon Apr 25 11:34:40 2022: Epoch [8], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.919, Top5: 99.7508, Loss: 0.187\n",
            "Mon Apr 25 11:34:48 2022: Epoch [9], Iteration [0/391/], Data(s): 0.053, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 96.094, Top5: 100.0000, Loss: 0.187\n",
            "Mon Apr 25 11:34:56 2022: Epoch [9], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.237, Top5: 99.7525, Loss: 0.176\n",
            "Mon Apr 25 11:35:04 2022: Epoch [9], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.384, Top5: 99.7940, Loss: 0.173\n",
            "Mon Apr 25 11:35:12 2022: Epoch [9], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.285, Top5: 99.7716, Loss: 0.179\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 11:35:22 2022: Test information, Data(s): 1.629, Forward(s): 0.216, Top1: 90.880, Top5: 99.380, \n",
            "\n",
            "Mon Apr 25 11:35:22 2022: conv4 Layer, 65 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 63, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(63, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(63, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]          73,856\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "             ReLU-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11           [-1, 63, 16, 16]          72,639\n",
            "      BatchNorm2d-12           [-1, 63, 16, 16]             126\n",
            "             ReLU-13           [-1, 63, 16, 16]               0\n",
            "        MaxPool2d-14             [-1, 63, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         145,408\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]       1,180,160\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 14,767,111\n",
            "Trainable params: 14,767,111\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 6.16\n",
            "Params size (MB): 56.33\n",
            "Estimated Total Size (MB): 62.51\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 63, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(63, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(63, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 11:35:23 2022: Epoch [0], Iteration [0/391/], Data(s): 0.040, Loss(s): 0.003, Forward(s): 0.037, Backward(s): 0.068, Top1: 92.188, Top5: 99.2188, Loss: 0.208\n",
            "Mon Apr 25 11:35:31 2022: Epoch [0], Iteration [100/391/], Data(s): 0.035, Loss(s): 0.010, Forward(s): 0.004, Backward(s): 0.008, Top1: 92.729, Top5: 99.6597, Loss: 0.216\n",
            "Mon Apr 25 11:35:39 2022: Epoch [0], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.113, Top5: 99.7124, Loss: 0.200\n",
            "Mon Apr 25 11:35:46 2022: Epoch [0], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.179, Top5: 99.7145, Loss: 0.201\n",
            "Mon Apr 25 11:35:54 2022: Epoch [1], Iteration [0/391/], Data(s): 0.055, Loss(s): 0.009, Forward(s): 0.004, Backward(s): 0.007, Top1: 92.969, Top5: 100.0000, Loss: 0.199\n",
            "Mon Apr 25 11:36:01 2022: Epoch [1], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.541, Top5: 99.7525, Loss: 0.198\n",
            "Mon Apr 25 11:36:09 2022: Epoch [1], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.299, Top5: 99.7357, Loss: 0.204\n",
            "Mon Apr 25 11:36:17 2022: Epoch [1], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.568, Top5: 99.7379, Loss: 0.179\n",
            "Mon Apr 25 11:36:25 2022: Epoch [2], Iteration [0/391/], Data(s): 0.062, Loss(s): 0.010, Forward(s): 0.004, Backward(s): 0.008, Top1: 96.094, Top5: 100.0000, Loss: 0.192\n",
            "Mon Apr 25 11:36:32 2022: Epoch [2], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.773, Top5: 99.7989, Loss: 0.188\n",
            "Mon Apr 25 11:36:40 2022: Epoch [2], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.637, Top5: 99.7435, Loss: 0.195\n",
            "Mon Apr 25 11:36:48 2022: Epoch [2], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.732, Top5: 99.7534, Loss: 0.183\n",
            "Mon Apr 25 11:36:55 2022: Epoch [3], Iteration [0/391/], Data(s): 0.055, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.008, Top1: 94.531, Top5: 99.2188, Loss: 0.191\n",
            "Mon Apr 25 11:37:03 2022: Epoch [3], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.052, Top5: 99.7602, Loss: 0.185\n",
            "Mon Apr 25 11:37:11 2022: Epoch [3], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.781, Top5: 99.7474, Loss: 0.195\n",
            "Mon Apr 25 11:37:19 2022: Epoch [3], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.792, Top5: 99.7353, Loss: 0.186\n",
            "Mon Apr 25 11:37:26 2022: Epoch [4], Iteration [0/391/], Data(s): 0.055, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 96.875, Top5: 100.0000, Loss: 0.181\n",
            "Mon Apr 25 11:37:34 2022: Epoch [4], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.059, Top5: 99.7912, Loss: 0.179\n",
            "Mon Apr 25 11:37:42 2022: Epoch [4], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.162, Top5: 99.7979, Loss: 0.178\n",
            "Mon Apr 25 11:37:50 2022: Epoch [4], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.038, Top5: 99.7975, Loss: 0.182\n",
            "Mon Apr 25 11:37:57 2022: Epoch [5], Iteration [0/391/], Data(s): 0.054, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 95.312, Top5: 100.0000, Loss: 0.179\n",
            "Mon Apr 25 11:38:05 2022: Epoch [5], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.090, Top5: 99.7525, Loss: 0.179\n",
            "Mon Apr 25 11:38:13 2022: Epoch [5], Iteration [200/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.080, Top5: 99.7746, Loss: 0.175\n",
            "Mon Apr 25 11:38:20 2022: Epoch [5], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.264, Top5: 99.7794, Loss: 0.169\n",
            "Mon Apr 25 11:38:28 2022: Epoch [6], Iteration [0/391/], Data(s): 0.061, Loss(s): 0.010, Forward(s): 0.004, Backward(s): 0.008, Top1: 92.188, Top5: 99.2188, Loss: 0.183\n",
            "Mon Apr 25 11:38:36 2022: Epoch [6], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.245, Top5: 99.7989, Loss: 0.173\n",
            "Mon Apr 25 11:38:43 2022: Epoch [6], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.267, Top5: 99.7668, Loss: 0.172\n",
            "Mon Apr 25 11:38:51 2022: Epoch [6], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.165, Top5: 99.7612, Loss: 0.180\n",
            "Mon Apr 25 11:38:59 2022: Epoch [7], Iteration [0/391/], Data(s): 0.062, Loss(s): 0.010, Forward(s): 0.004, Backward(s): 0.008, Top1: 95.312, Top5: 100.0000, Loss: 0.173\n",
            "Mon Apr 25 11:39:06 2022: Epoch [7], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.493, Top5: 99.7602, Loss: 0.167\n",
            "Mon Apr 25 11:39:14 2022: Epoch [7], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.407, Top5: 99.7707, Loss: 0.169\n",
            "Mon Apr 25 11:39:22 2022: Epoch [7], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.401, Top5: 99.7846, Loss: 0.167\n",
            "Mon Apr 25 11:39:29 2022: Epoch [8], Iteration [0/391/], Data(s): 0.052, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 96.094, Top5: 100.0000, Loss: 0.169\n",
            "Mon Apr 25 11:39:37 2022: Epoch [8], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.361, Top5: 99.8144, Loss: 0.166\n",
            "Mon Apr 25 11:39:45 2022: Epoch [8], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.267, Top5: 99.7901, Loss: 0.177\n",
            "Mon Apr 25 11:39:53 2022: Epoch [8], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.357, Top5: 99.8131, Loss: 0.162\n",
            "Mon Apr 25 11:40:00 2022: Epoch [9], Iteration [0/391/], Data(s): 0.053, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 91.406, Top5: 100.0000, Loss: 0.165\n",
            "Mon Apr 25 11:40:08 2022: Epoch [9], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.554, Top5: 99.8066, Loss: 0.163\n",
            "Mon Apr 25 11:40:16 2022: Epoch [9], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.714, Top5: 99.8251, Loss: 0.155\n",
            "Mon Apr 25 11:40:24 2022: Epoch [9], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.474, Top5: 99.8053, Loss: 0.175\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 11:40:34 2022: Test information, Data(s): 1.584, Forward(s): 0.217, Top1: 90.540, Top5: 99.400, \n",
            "\n",
            "Mon Apr 25 11:40:34 2022: conv4 Layer, 82 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 46, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(46, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(46, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]          73,856\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "             ReLU-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11           [-1, 46, 16, 16]          53,038\n",
            "      BatchNorm2d-12           [-1, 46, 16, 16]              92\n",
            "             ReLU-13           [-1, 46, 16, 16]               0\n",
            "        MaxPool2d-14             [-1, 46, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         106,240\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]       1,180,160\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 14,708,308\n",
            "Trainable params: 14,708,308\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 6.05\n",
            "Params size (MB): 56.11\n",
            "Estimated Total Size (MB): 62.17\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 46, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(46, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(46, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 11:40:35 2022: Epoch [0], Iteration [0/391/], Data(s): 0.039, Loss(s): 0.003, Forward(s): 0.036, Backward(s): 0.065, Top1: 89.844, Top5: 100.0000, Loss: 0.288\n",
            "Mon Apr 25 11:40:43 2022: Epoch [0], Iteration [100/391/], Data(s): 0.035, Loss(s): 0.010, Forward(s): 0.004, Backward(s): 0.008, Top1: 92.002, Top5: 99.6674, Loss: 0.243\n",
            "Mon Apr 25 11:40:51 2022: Epoch [0], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.008, Top1: 92.530, Top5: 99.6774, Loss: 0.212\n",
            "Mon Apr 25 11:40:59 2022: Epoch [0], Iteration [300/391/], Data(s): 0.035, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.476, Top5: 99.6678, Loss: 0.227\n",
            "Mon Apr 25 11:41:06 2022: Epoch [1], Iteration [0/391/], Data(s): 0.053, Loss(s): 0.009, Forward(s): 0.004, Backward(s): 0.007, Top1: 92.188, Top5: 100.0000, Loss: 0.218\n",
            "Mon Apr 25 11:41:14 2022: Epoch [1], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.224, Top5: 99.6906, Loss: 0.201\n",
            "Mon Apr 25 11:41:22 2022: Epoch [1], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.132, Top5: 99.7163, Loss: 0.209\n",
            "Mon Apr 25 11:41:30 2022: Epoch [1], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.218, Top5: 99.7275, Loss: 0.200\n",
            "Mon Apr 25 11:41:37 2022: Epoch [2], Iteration [0/391/], Data(s): 0.054, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.969, Top5: 100.0000, Loss: 0.203\n",
            "Mon Apr 25 11:41:45 2022: Epoch [2], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.959, Top5: 99.7215, Loss: 0.187\n",
            "Mon Apr 25 11:41:53 2022: Epoch [2], Iteration [200/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.863, Top5: 99.7201, Loss: 0.189\n",
            "Mon Apr 25 11:42:00 2022: Epoch [2], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.683, Top5: 99.7430, Loss: 0.203\n",
            "Mon Apr 25 11:42:08 2022: Epoch [3], Iteration [0/391/], Data(s): 0.052, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 95.312, Top5: 100.0000, Loss: 0.196\n",
            "Mon Apr 25 11:42:15 2022: Epoch [3], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.899, Top5: 99.7447, Loss: 0.208\n",
            "Mon Apr 25 11:42:23 2022: Epoch [3], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.330, Top5: 99.7512, Loss: 0.187\n",
            "Mon Apr 25 11:42:31 2022: Epoch [3], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.509, Top5: 99.7560, Loss: 0.187\n",
            "Mon Apr 25 11:42:38 2022: Epoch [4], Iteration [0/391/], Data(s): 0.055, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.750, Top5: 99.2188, Loss: 0.184\n",
            "Mon Apr 25 11:42:46 2022: Epoch [4], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.804, Top5: 99.7912, Loss: 0.181\n",
            "Mon Apr 25 11:42:54 2022: Epoch [4], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.727, Top5: 99.7668, Loss: 0.192\n",
            "Mon Apr 25 11:43:02 2022: Epoch [4], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.727, Top5: 99.7716, Loss: 0.183\n",
            "Mon Apr 25 11:43:09 2022: Epoch [5], Iteration [0/391/], Data(s): 0.053, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.008, Top1: 91.406, Top5: 100.0000, Loss: 0.177\n",
            "Mon Apr 25 11:43:17 2022: Epoch [5], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.998, Top5: 99.7834, Loss: 0.183\n",
            "Mon Apr 25 11:43:25 2022: Epoch [5], Iteration [200/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.084, Top5: 99.7979, Loss: 0.174\n",
            "Mon Apr 25 11:43:32 2022: Epoch [5], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.025, Top5: 99.7975, Loss: 0.178\n",
            "Mon Apr 25 11:43:39 2022: Epoch [6], Iteration [0/391/], Data(s): 0.053, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.008, Top1: 95.312, Top5: 100.0000, Loss: 0.173\n",
            "Mon Apr 25 11:43:47 2022: Epoch [6], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.028, Top5: 99.7757, Loss: 0.179\n",
            "Mon Apr 25 11:43:55 2022: Epoch [6], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.220, Top5: 99.7551, Loss: 0.166\n",
            "Mon Apr 25 11:44:03 2022: Epoch [6], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.155, Top5: 99.7508, Loss: 0.177\n",
            "Mon Apr 25 11:44:10 2022: Epoch [7], Iteration [0/391/], Data(s): 0.061, Loss(s): 0.010, Forward(s): 0.004, Backward(s): 0.007, Top1: 95.312, Top5: 99.2188, Loss: 0.175\n",
            "Mon Apr 25 11:44:18 2022: Epoch [7], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.353, Top5: 99.7757, Loss: 0.169\n",
            "Mon Apr 25 11:44:26 2022: Epoch [7], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.403, Top5: 99.8018, Loss: 0.168\n",
            "Mon Apr 25 11:44:33 2022: Epoch [7], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.469, Top5: 99.8053, Loss: 0.165\n",
            "Mon Apr 25 11:44:40 2022: Epoch [8], Iteration [0/391/], Data(s): 0.053, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 96.094, Top5: 100.0000, Loss: 0.173\n",
            "Mon Apr 25 11:44:48 2022: Epoch [8], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.446, Top5: 99.8221, Loss: 0.162\n",
            "Mon Apr 25 11:44:56 2022: Epoch [8], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.384, Top5: 99.8290, Loss: 0.168\n",
            "Mon Apr 25 11:45:04 2022: Epoch [8], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.334, Top5: 99.8235, Loss: 0.171\n",
            "Mon Apr 25 11:45:11 2022: Epoch [9], Iteration [0/391/], Data(s): 0.057, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 96.875, Top5: 100.0000, Loss: 0.167\n",
            "Mon Apr 25 11:45:19 2022: Epoch [9], Iteration [100/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.763, Top5: 99.8376, Loss: 0.157\n",
            "Mon Apr 25 11:45:26 2022: Epoch [9], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.636, Top5: 99.8601, Loss: 0.158\n",
            "Mon Apr 25 11:45:34 2022: Epoch [9], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.552, Top5: 99.8339, Loss: 0.169\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 11:45:44 2022: Test information, Data(s): 1.616, Forward(s): 0.218, Top1: 90.570, Top5: 99.300, \n",
            "\n",
            "Mon Apr 25 11:45:44 2022: conv4 Layer, 98 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(30, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]          73,856\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "             ReLU-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11           [-1, 30, 16, 16]          34,590\n",
            "      BatchNorm2d-12           [-1, 30, 16, 16]              60\n",
            "             ReLU-13           [-1, 30, 16, 16]               0\n",
            "        MaxPool2d-14             [-1, 30, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]          69,376\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]       1,180,160\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 14,652,964\n",
            "Trainable params: 14,652,964\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 5.95\n",
            "Params size (MB): 55.90\n",
            "Estimated Total Size (MB): 61.86\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(30, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 11:45:45 2022: Epoch [0], Iteration [0/391/], Data(s): 0.037, Loss(s): 0.003, Forward(s): 0.032, Backward(s): 0.059, Top1: 93.750, Top5: 100.0000, Loss: 0.245\n",
            "Mon Apr 25 11:45:53 2022: Epoch [0], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 90.231, Top5: 99.4044, Loss: 0.298\n",
            "Mon Apr 25 11:46:01 2022: Epoch [0], Iteration [200/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 90.711, Top5: 99.4325, Loss: 0.271\n",
            "Mon Apr 25 11:46:08 2022: Epoch [0], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 91.030, Top5: 99.4809, Loss: 0.254\n",
            "Mon Apr 25 11:46:15 2022: Epoch [1], Iteration [0/391/], Data(s): 0.055, Loss(s): 0.009, Forward(s): 0.004, Backward(s): 0.008, Top1: 91.406, Top5: 99.2188, Loss: 0.241\n",
            "Mon Apr 25 11:46:23 2022: Epoch [1], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.234, Top5: 99.6597, Loss: 0.234\n",
            "Mon Apr 25 11:46:31 2022: Epoch [1], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.296, Top5: 99.6696, Loss: 0.226\n",
            "Mon Apr 25 11:46:39 2022: Epoch [1], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.250, Top5: 99.6652, Loss: 0.228\n",
            "Mon Apr 25 11:46:46 2022: Epoch [2], Iteration [0/391/], Data(s): 0.058, Loss(s): 0.010, Forward(s): 0.004, Backward(s): 0.007, Top1: 94.531, Top5: 100.0000, Loss: 0.222\n",
            "Mon Apr 25 11:46:53 2022: Epoch [2], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.992, Top5: 99.7293, Loss: 0.208\n",
            "Mon Apr 25 11:47:01 2022: Epoch [2], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.806, Top5: 99.7279, Loss: 0.213\n",
            "Mon Apr 25 11:47:09 2022: Epoch [2], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.836, Top5: 99.7145, Loss: 0.213\n",
            "Mon Apr 25 11:47:16 2022: Epoch [3], Iteration [0/391/], Data(s): 0.057, Loss(s): 0.009, Forward(s): 0.004, Backward(s): 0.007, Top1: 95.312, Top5: 100.0000, Loss: 0.211\n",
            "Mon Apr 25 11:47:23 2022: Epoch [3], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.193, Top5: 99.6829, Loss: 0.201\n",
            "Mon Apr 25 11:47:31 2022: Epoch [3], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.303, Top5: 99.7124, Loss: 0.197\n",
            "Mon Apr 25 11:47:39 2022: Epoch [3], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.163, Top5: 99.7145, Loss: 0.208\n",
            "Mon Apr 25 11:47:46 2022: Epoch [4], Iteration [0/391/], Data(s): 0.059, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 90.625, Top5: 100.0000, Loss: 0.212\n",
            "Mon Apr 25 11:47:54 2022: Epoch [4], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.201, Top5: 99.7757, Loss: 0.198\n",
            "Mon Apr 25 11:48:02 2022: Epoch [4], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.381, Top5: 99.7746, Loss: 0.193\n",
            "Mon Apr 25 11:48:09 2022: Epoch [4], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.457, Top5: 99.7768, Loss: 0.189\n",
            "Mon Apr 25 11:48:16 2022: Epoch [5], Iteration [0/391/], Data(s): 0.055, Loss(s): 0.009, Forward(s): 0.004, Backward(s): 0.007, Top1: 96.094, Top5: 100.0000, Loss: 0.197\n",
            "Mon Apr 25 11:48:24 2022: Epoch [5], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.059, Top5: 99.8221, Loss: 0.181\n",
            "Mon Apr 25 11:48:32 2022: Epoch [5], Iteration [200/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.750, Top5: 99.7823, Loss: 0.192\n",
            "Mon Apr 25 11:48:39 2022: Epoch [5], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.602, Top5: 99.7638, Loss: 0.201\n",
            "Mon Apr 25 11:48:46 2022: Epoch [6], Iteration [0/391/], Data(s): 0.052, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.531, Top5: 100.0000, Loss: 0.203\n",
            "Mon Apr 25 11:48:54 2022: Epoch [6], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.765, Top5: 99.7602, Loss: 0.192\n",
            "Mon Apr 25 11:49:02 2022: Epoch [6], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.664, Top5: 99.7590, Loss: 0.191\n",
            "Mon Apr 25 11:49:09 2022: Epoch [6], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.776, Top5: 99.7794, Loss: 0.179\n",
            "Mon Apr 25 11:49:16 2022: Epoch [7], Iteration [0/391/], Data(s): 0.057, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.969, Top5: 100.0000, Loss: 0.182\n",
            "Mon Apr 25 11:49:24 2022: Epoch [7], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.152, Top5: 99.7602, Loss: 0.175\n",
            "Mon Apr 25 11:49:32 2022: Epoch [7], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.053, Top5: 99.7746, Loss: 0.181\n",
            "Mon Apr 25 11:49:40 2022: Epoch [7], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.064, Top5: 99.7742, Loss: 0.181\n",
            "Mon Apr 25 11:49:47 2022: Epoch [8], Iteration [0/391/], Data(s): 0.064, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.750, Top5: 100.0000, Loss: 0.175\n",
            "Mon Apr 25 11:49:54 2022: Epoch [8], Iteration [100/391/], Data(s): 0.032, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.090, Top5: 99.8221, Loss: 0.176\n",
            "Mon Apr 25 11:50:02 2022: Epoch [8], Iteration [200/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.314, Top5: 99.8290, Loss: 0.167\n",
            "Mon Apr 25 11:50:10 2022: Epoch [8], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.277, Top5: 99.8183, Loss: 0.182\n",
            "Mon Apr 25 11:50:17 2022: Epoch [9], Iteration [0/391/], Data(s): 0.060, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 96.094, Top5: 100.0000, Loss: 0.173\n",
            "Mon Apr 25 11:50:24 2022: Epoch [9], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.121, Top5: 99.7989, Loss: 0.173\n",
            "Mon Apr 25 11:50:32 2022: Epoch [9], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.271, Top5: 99.8057, Loss: 0.170\n",
            "Mon Apr 25 11:50:40 2022: Epoch [9], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.204, Top5: 99.7950, Loss: 0.180\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 11:50:50 2022: Test information, Data(s): 1.630, Forward(s): 0.213, Top1: 89.930, Top5: 99.320, \n",
            "\n",
            "Mon Apr 25 11:50:50 2022: conv4 Layer, 115 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 13, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(13, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]          73,856\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "             ReLU-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11           [-1, 13, 16, 16]          14,989\n",
            "      BatchNorm2d-12           [-1, 13, 16, 16]              26\n",
            "             ReLU-13           [-1, 13, 16, 16]               0\n",
            "        MaxPool2d-14             [-1, 13, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]          30,208\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]       1,180,160\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 14,594,161\n",
            "Trainable params: 14,594,161\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 5.84\n",
            "Params size (MB): 55.67\n",
            "Estimated Total Size (MB): 61.53\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 13, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(13, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 11:50:51 2022: Epoch [0], Iteration [0/391/], Data(s): 0.036, Loss(s): 0.003, Forward(s): 0.030, Backward(s): 0.052, Top1: 76.562, Top5: 98.4375, Loss: 0.919\n",
            "Mon Apr 25 11:50:59 2022: Epoch [0], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 81.993, Top5: 98.1745, Loss: 0.619\n",
            "Mon Apr 25 11:51:06 2022: Epoch [0], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 83.617, Top5: 98.5697, Loss: 0.467\n",
            "Mon Apr 25 11:51:14 2022: Epoch [0], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 84.318, Top5: 98.7334, Loss: 0.435\n",
            "Mon Apr 25 11:51:21 2022: Epoch [1], Iteration [0/391/], Data(s): 0.054, Loss(s): 0.008, Forward(s): 0.005, Backward(s): 0.008, Top1: 79.688, Top5: 99.2188, Loss: 0.418\n",
            "Mon Apr 25 11:51:28 2022: Epoch [1], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 87.407, Top5: 99.2342, Loss: 0.373\n",
            "Mon Apr 25 11:51:36 2022: Epoch [1], Iteration [200/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 87.597, Top5: 99.2110, Loss: 0.371\n",
            "Mon Apr 25 11:51:44 2022: Epoch [1], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 87.710, Top5: 99.2369, Loss: 0.370\n",
            "Mon Apr 25 11:51:51 2022: Epoch [2], Iteration [0/391/], Data(s): 0.054, Loss(s): 0.009, Forward(s): 0.003, Backward(s): 0.008, Top1: 89.062, Top5: 100.0000, Loss: 0.355\n",
            "Mon Apr 25 11:51:58 2022: Epoch [2], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 89.078, Top5: 99.4431, Loss: 0.329\n",
            "Mon Apr 25 11:52:06 2022: Epoch [2], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 89.016, Top5: 99.4092, Loss: 0.326\n",
            "Mon Apr 25 11:52:13 2022: Epoch [2], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 89.172, Top5: 99.3926, Loss: 0.319\n",
            "Mon Apr 25 11:52:20 2022: Epoch [3], Iteration [0/391/], Data(s): 0.057, Loss(s): 0.009, Forward(s): 0.004, Backward(s): 0.007, Top1: 90.625, Top5: 100.0000, Loss: 0.335\n",
            "Mon Apr 25 11:52:28 2022: Epoch [3], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 89.906, Top5: 99.5746, Loss: 0.300\n",
            "Mon Apr 25 11:52:36 2022: Epoch [3], Iteration [200/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 89.956, Top5: 99.5647, Loss: 0.298\n",
            "Mon Apr 25 11:52:43 2022: Epoch [3], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 89.828, Top5: 99.5120, Loss: 0.311\n",
            "Mon Apr 25 11:52:50 2022: Epoch [4], Iteration [0/391/], Data(s): 0.052, Loss(s): 0.009, Forward(s): 0.003, Backward(s): 0.007, Top1: 90.625, Top5: 99.2188, Loss: 0.298\n",
            "Mon Apr 25 11:52:58 2022: Epoch [4], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 90.223, Top5: 99.5127, Loss: 0.300\n",
            "Mon Apr 25 11:53:05 2022: Epoch [4], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 90.155, Top5: 99.5297, Loss: 0.289\n",
            "Mon Apr 25 11:53:13 2022: Epoch [4], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 90.298, Top5: 99.5458, Loss: 0.285\n",
            "Mon Apr 25 11:53:20 2022: Epoch [5], Iteration [0/391/], Data(s): 0.062, Loss(s): 0.009, Forward(s): 0.004, Backward(s): 0.009, Top1: 91.406, Top5: 100.0000, Loss: 0.282\n",
            "Mon Apr 25 11:53:28 2022: Epoch [5], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 91.166, Top5: 99.5127, Loss: 0.271\n",
            "Mon Apr 25 11:53:35 2022: Epoch [5], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 91.010, Top5: 99.5608, Loss: 0.271\n",
            "Mon Apr 25 11:53:43 2022: Epoch [5], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 90.874, Top5: 99.5276, Loss: 0.281\n",
            "Mon Apr 25 11:53:50 2022: Epoch [6], Iteration [0/391/], Data(s): 0.053, Loss(s): 0.009, Forward(s): 0.003, Backward(s): 0.007, Top1: 95.312, Top5: 100.0000, Loss: 0.270\n",
            "Mon Apr 25 11:53:57 2022: Epoch [6], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 91.576, Top5: 99.6519, Loss: 0.249\n",
            "Mon Apr 25 11:54:05 2022: Epoch [6], Iteration [200/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 91.290, Top5: 99.6308, Loss: 0.266\n",
            "Mon Apr 25 11:54:13 2022: Epoch [6], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 91.318, Top5: 99.6159, Loss: 0.261\n",
            "Mon Apr 25 11:54:20 2022: Epoch [7], Iteration [0/391/], Data(s): 0.053, Loss(s): 0.009, Forward(s): 0.004, Backward(s): 0.007, Top1: 92.188, Top5: 100.0000, Loss: 0.272\n",
            "Mon Apr 25 11:54:27 2022: Epoch [7], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 91.453, Top5: 99.5668, Loss: 0.260\n",
            "Mon Apr 25 11:54:35 2022: Epoch [7], Iteration [200/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 91.430, Top5: 99.5841, Loss: 0.254\n",
            "Mon Apr 25 11:54:42 2022: Epoch [7], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 91.437, Top5: 99.6133, Loss: 0.256\n",
            "Mon Apr 25 11:54:49 2022: Epoch [8], Iteration [0/391/], Data(s): 0.057, Loss(s): 0.009, Forward(s): 0.003, Backward(s): 0.009, Top1: 89.062, Top5: 100.0000, Loss: 0.264\n",
            "Mon Apr 25 11:54:57 2022: Epoch [8], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 91.499, Top5: 99.6210, Loss: 0.252\n",
            "Mon Apr 25 11:55:05 2022: Epoch [8], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 91.566, Top5: 99.6735, Loss: 0.245\n",
            "Mon Apr 25 11:55:12 2022: Epoch [8], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 91.629, Top5: 99.6989, Loss: 0.241\n",
            "Mon Apr 25 11:55:19 2022: Epoch [9], Iteration [0/391/], Data(s): 0.052, Loss(s): 0.009, Forward(s): 0.003, Backward(s): 0.007, Top1: 96.875, Top5: 100.0000, Loss: 0.233\n",
            "Mon Apr 25 11:55:27 2022: Epoch [9], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.033, Top5: 99.6983, Loss: 0.239\n",
            "Mon Apr 25 11:55:34 2022: Epoch [9], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.016, Top5: 99.7007, Loss: 0.240\n",
            "Mon Apr 25 11:55:42 2022: Epoch [9], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.016, Top5: 99.6782, Loss: 0.239\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 11:55:52 2022: Test information, Data(s): 1.600, Forward(s): 0.216, Top1: 88.950, Top5: 99.320, \n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 11:55:56 2022: Test information, Data(s): 1.580, Forward(s): 0.210, Top1: 77.870, Top5: 97.560, \n",
            "\n",
            "Mon Apr 25 11:55:56 2022: conv5 Layer, 32 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(224, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]          73,856\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "             ReLU-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]         147,584\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15            [-1, 224, 8, 8]         258,272\n",
            "      BatchNorm2d-16            [-1, 224, 8, 8]             448\n",
            "             ReLU-17            [-1, 224, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         516,352\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]       1,180,160\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 14,881,258\n",
            "Trainable params: 14,881,258\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 6.53\n",
            "Params size (MB): 56.77\n",
            "Estimated Total Size (MB): 63.31\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(224, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 11:55:58 2022: Epoch [0], Iteration [0/391/], Data(s): 0.035, Loss(s): 0.004, Forward(s): 0.051, Backward(s): 0.099, Top1: 84.375, Top5: 96.8750, Loss: 0.593\n",
            "Mon Apr 25 11:56:06 2022: Epoch [0], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.008, Top1: 86.959, Top5: 99.0254, Loss: 0.400\n",
            "Mon Apr 25 11:56:14 2022: Epoch [0], Iteration [200/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 87.846, Top5: 99.0827, Loss: 0.347\n",
            "Mon Apr 25 11:56:22 2022: Epoch [0], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.007, Top1: 88.395, Top5: 99.1720, Loss: 0.324\n",
            "Mon Apr 25 11:56:29 2022: Epoch [1], Iteration [0/391/], Data(s): 0.051, Loss(s): 0.010, Forward(s): 0.005, Backward(s): 0.008, Top1: 90.625, Top5: 99.2188, Loss: 0.325\n",
            "Mon Apr 25 11:56:37 2022: Epoch [1], Iteration [100/391/], Data(s): 0.032, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.007, Top1: 90.176, Top5: 99.4044, Loss: 0.310\n",
            "Mon Apr 25 11:56:45 2022: Epoch [1], Iteration [200/391/], Data(s): 0.033, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.007, Top1: 90.326, Top5: 99.3937, Loss: 0.296\n",
            "Mon Apr 25 11:56:53 2022: Epoch [1], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.007, Top1: 90.363, Top5: 99.3745, Loss: 0.301\n",
            "Mon Apr 25 11:57:00 2022: Epoch [2], Iteration [0/391/], Data(s): 0.066, Loss(s): 0.011, Forward(s): 0.004, Backward(s): 0.008, Top1: 89.062, Top5: 99.2188, Loss: 0.299\n",
            "Mon Apr 25 11:57:08 2022: Epoch [2], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.007, Top1: 91.081, Top5: 99.5282, Loss: 0.275\n",
            "Mon Apr 25 11:57:16 2022: Epoch [2], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.007, Top1: 90.959, Top5: 99.4597, Loss: 0.286\n",
            "Mon Apr 25 11:57:24 2022: Epoch [2], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.007, Top1: 90.942, Top5: 99.4809, Loss: 0.279\n",
            "Mon Apr 25 11:57:32 2022: Epoch [3], Iteration [0/391/], Data(s): 0.051, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 88.281, Top5: 100.0000, Loss: 0.280\n",
            "Mon Apr 25 11:57:39 2022: Epoch [3], Iteration [100/391/], Data(s): 0.032, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.007, Top1: 91.476, Top5: 99.4817, Loss: 0.266\n",
            "Mon Apr 25 11:57:47 2022: Epoch [3], Iteration [200/391/], Data(s): 0.033, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.007, Top1: 91.597, Top5: 99.4792, Loss: 0.262\n",
            "Mon Apr 25 11:57:55 2022: Epoch [3], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.007, Top1: 91.531, Top5: 99.4991, Loss: 0.265\n",
            "Mon Apr 25 11:58:03 2022: Epoch [4], Iteration [0/391/], Data(s): 0.053, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 88.281, Top5: 100.0000, Loss: 0.271\n",
            "Mon Apr 25 11:58:11 2022: Epoch [4], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.007, Top1: 91.491, Top5: 99.5746, Loss: 0.258\n",
            "Mon Apr 25 11:58:19 2022: Epoch [4], Iteration [200/391/], Data(s): 0.033, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.007, Top1: 91.597, Top5: 99.5297, Loss: 0.259\n",
            "Mon Apr 25 11:58:27 2022: Epoch [4], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.007, Top1: 91.567, Top5: 99.5458, Loss: 0.259\n",
            "Mon Apr 25 11:58:34 2022: Epoch [5], Iteration [0/391/], Data(s): 0.051, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 88.281, Top5: 100.0000, Loss: 0.255\n",
            "Mon Apr 25 11:58:42 2022: Epoch [5], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.025, Top5: 99.6442, Loss: 0.247\n",
            "Mon Apr 25 11:58:50 2022: Epoch [5], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.032, Top5: 99.6269, Loss: 0.244\n",
            "Mon Apr 25 11:58:58 2022: Epoch [5], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.007, Top1: 91.993, Top5: 99.6237, Loss: 0.248\n",
            "Mon Apr 25 11:59:05 2022: Epoch [6], Iteration [0/391/], Data(s): 0.053, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 91.406, Top5: 100.0000, Loss: 0.250\n",
            "Mon Apr 25 11:59:13 2022: Epoch [6], Iteration [100/391/], Data(s): 0.032, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.007, Top1: 91.932, Top5: 99.5900, Loss: 0.247\n",
            "Mon Apr 25 11:59:21 2022: Epoch [6], Iteration [200/391/], Data(s): 0.033, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.055, Top5: 99.5880, Loss: 0.238\n",
            "Mon Apr 25 11:59:29 2022: Epoch [6], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.007, Top1: 91.980, Top5: 99.6081, Loss: 0.240\n",
            "Mon Apr 25 11:59:36 2022: Epoch [7], Iteration [0/391/], Data(s): 0.055, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 97.656, Top5: 100.0000, Loss: 0.245\n",
            "Mon Apr 25 11:59:44 2022: Epoch [7], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.007, Top1: 91.963, Top5: 99.4972, Loss: 0.245\n",
            "Mon Apr 25 11:59:52 2022: Epoch [7], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.110, Top5: 99.5569, Loss: 0.237\n",
            "Mon Apr 25 12:00:00 2022: Epoch [7], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.151, Top5: 99.5795, Loss: 0.241\n",
            "Mon Apr 25 12:00:08 2022: Epoch [8], Iteration [0/391/], Data(s): 0.052, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.008, Top1: 89.844, Top5: 100.0000, Loss: 0.234\n",
            "Mon Apr 25 12:00:16 2022: Epoch [8], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.528, Top5: 99.6055, Loss: 0.234\n",
            "Mon Apr 25 12:00:24 2022: Epoch [8], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.502, Top5: 99.6191, Loss: 0.233\n",
            "Mon Apr 25 12:00:32 2022: Epoch [8], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.463, Top5: 99.6262, Loss: 0.233\n",
            "Mon Apr 25 12:00:39 2022: Epoch [9], Iteration [0/391/], Data(s): 0.055, Loss(s): 0.011, Forward(s): 0.004, Backward(s): 0.007, Top1: 92.188, Top5: 99.2188, Loss: 0.232\n",
            "Mon Apr 25 12:00:47 2022: Epoch [9], Iteration [100/391/], Data(s): 0.032, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.069, Top5: 99.6751, Loss: 0.214\n",
            "Mon Apr 25 12:00:55 2022: Epoch [9], Iteration [200/391/], Data(s): 0.033, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.708, Top5: 99.6152, Loss: 0.235\n",
            "Mon Apr 25 12:01:03 2022: Epoch [9], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.694, Top5: 99.6392, Loss: 0.221\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 12:01:13 2022: Test information, Data(s): 1.555, Forward(s): 0.210, Top1: 89.930, Top5: 99.260, \n",
            "\n",
            "Mon Apr 25 12:01:13 2022: conv5 Layer, 65 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 191, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(191, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(191, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]          73,856\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "             ReLU-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]         147,584\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15            [-1, 191, 8, 8]         220,223\n",
            "      BatchNorm2d-16            [-1, 191, 8, 8]             382\n",
            "             ReLU-17            [-1, 191, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         440,320\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]       1,180,160\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 14,767,111\n",
            "Trainable params: 14,767,111\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 6.48\n",
            "Params size (MB): 56.33\n",
            "Estimated Total Size (MB): 62.82\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 191, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(191, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(191, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 12:01:14 2022: Epoch [0], Iteration [0/391/], Data(s): 0.038, Loss(s): 0.003, Forward(s): 0.048, Backward(s): 0.093, Top1: 90.625, Top5: 100.0000, Loss: 0.239\n",
            "Mon Apr 25 12:01:22 2022: Epoch [0], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.008, Top1: 92.242, Top5: 99.6519, Loss: 0.232\n",
            "Mon Apr 25 12:01:30 2022: Epoch [0], Iteration [200/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.448, Top5: 99.6502, Loss: 0.224\n",
            "Mon Apr 25 12:01:38 2022: Epoch [0], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.398, Top5: 99.6392, Loss: 0.229\n",
            "Mon Apr 25 12:01:45 2022: Epoch [1], Iteration [0/391/], Data(s): 0.060, Loss(s): 0.009, Forward(s): 0.005, Backward(s): 0.008, Top1: 92.969, Top5: 97.6562, Loss: 0.224\n",
            "Mon Apr 25 12:01:53 2022: Epoch [1], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.953, Top5: 99.7061, Loss: 0.214\n",
            "Mon Apr 25 12:02:01 2022: Epoch [1], Iteration [200/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.879, Top5: 99.6502, Loss: 0.228\n",
            "Mon Apr 25 12:02:09 2022: Epoch [1], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.777, Top5: 99.6470, Loss: 0.225\n",
            "Mon Apr 25 12:02:16 2022: Epoch [2], Iteration [0/391/], Data(s): 0.076, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.008, Top1: 91.406, Top5: 100.0000, Loss: 0.227\n",
            "Mon Apr 25 12:02:24 2022: Epoch [2], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.551, Top5: 99.7679, Loss: 0.222\n",
            "Mon Apr 25 12:02:32 2022: Epoch [2], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.739, Top5: 99.7357, Loss: 0.217\n",
            "Mon Apr 25 12:02:40 2022: Epoch [2], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.808, Top5: 99.6808, Loss: 0.214\n",
            "Mon Apr 25 12:02:47 2022: Epoch [3], Iteration [0/391/], Data(s): 0.058, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 96.875, Top5: 100.0000, Loss: 0.212\n",
            "Mon Apr 25 12:02:55 2022: Epoch [3], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.907, Top5: 99.6751, Loss: 0.215\n",
            "Mon Apr 25 12:03:04 2022: Epoch [3], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.019, Top5: 99.6891, Loss: 0.216\n",
            "Mon Apr 25 12:03:12 2022: Epoch [3], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.021, Top5: 99.6963, Loss: 0.212\n",
            "Mon Apr 25 12:03:19 2022: Epoch [4], Iteration [0/391/], Data(s): 0.054, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.750, Top5: 100.0000, Loss: 0.213\n",
            "Mon Apr 25 12:03:27 2022: Epoch [4], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.884, Top5: 99.7061, Loss: 0.214\n",
            "Mon Apr 25 12:03:35 2022: Epoch [4], Iteration [200/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.159, Top5: 99.6735, Loss: 0.203\n",
            "Mon Apr 25 12:03:43 2022: Epoch [4], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.117, Top5: 99.6652, Loss: 0.212\n",
            "Mon Apr 25 12:03:50 2022: Epoch [5], Iteration [0/391/], Data(s): 0.060, Loss(s): 0.010, Forward(s): 0.004, Backward(s): 0.008, Top1: 94.531, Top5: 100.0000, Loss: 0.212\n",
            "Mon Apr 25 12:03:58 2022: Epoch [5], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.386, Top5: 99.6364, Loss: 0.209\n",
            "Mon Apr 25 12:04:06 2022: Epoch [5], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.287, Top5: 99.6696, Loss: 0.206\n",
            "Mon Apr 25 12:04:14 2022: Epoch [5], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.379, Top5: 99.6756, Loss: 0.200\n",
            "Mon Apr 25 12:04:21 2022: Epoch [6], Iteration [0/391/], Data(s): 0.060, Loss(s): 0.011, Forward(s): 0.004, Backward(s): 0.008, Top1: 92.969, Top5: 100.0000, Loss: 0.214\n",
            "Mon Apr 25 12:04:29 2022: Epoch [6], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.588, Top5: 99.7525, Loss: 0.192\n",
            "Mon Apr 25 12:04:37 2022: Epoch [6], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.260, Top5: 99.7396, Loss: 0.208\n",
            "Mon Apr 25 12:04:45 2022: Epoch [6], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.283, Top5: 99.7482, Loss: 0.204\n",
            "Mon Apr 25 12:04:53 2022: Epoch [7], Iteration [0/391/], Data(s): 0.054, Loss(s): 0.009, Forward(s): 0.005, Backward(s): 0.007, Top1: 90.625, Top5: 100.0000, Loss: 0.196\n",
            "Mon Apr 25 12:05:01 2022: Epoch [7], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.417, Top5: 99.7138, Loss: 0.194\n",
            "Mon Apr 25 12:05:09 2022: Epoch [7], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.198, Top5: 99.7085, Loss: 0.209\n",
            "Mon Apr 25 12:05:17 2022: Epoch [7], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.394, Top5: 99.7353, Loss: 0.190\n",
            "Mon Apr 25 12:05:24 2022: Epoch [8], Iteration [0/391/], Data(s): 0.054, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.531, Top5: 100.0000, Loss: 0.203\n",
            "Mon Apr 25 12:05:32 2022: Epoch [8], Iteration [100/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.518, Top5: 99.7370, Loss: 0.197\n",
            "Mon Apr 25 12:05:40 2022: Epoch [8], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.470, Top5: 99.7124, Loss: 0.202\n",
            "Mon Apr 25 12:05:48 2022: Epoch [8], Iteration [300/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.527, Top5: 99.7197, Loss: 0.193\n",
            "Mon Apr 25 12:05:56 2022: Epoch [9], Iteration [0/391/], Data(s): 0.052, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 95.312, Top5: 99.2188, Loss: 0.197\n",
            "Mon Apr 25 12:06:04 2022: Epoch [9], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.634, Top5: 99.6597, Loss: 0.192\n",
            "Mon Apr 25 12:06:12 2022: Epoch [9], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.668, Top5: 99.7201, Loss: 0.190\n",
            "Mon Apr 25 12:06:20 2022: Epoch [9], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.625, Top5: 99.7327, Loss: 0.195\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 12:06:30 2022: Test information, Data(s): 1.665, Forward(s): 0.217, Top1: 90.500, Top5: 99.300, \n",
            "\n",
            "Mon Apr 25 12:06:30 2022: conv5 Layer, 98 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 158, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(158, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(158, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]          73,856\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "             ReLU-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]         147,584\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15            [-1, 158, 8, 8]         182,174\n",
            "      BatchNorm2d-16            [-1, 158, 8, 8]             316\n",
            "             ReLU-17            [-1, 158, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         364,288\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]       1,180,160\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 14,652,964\n",
            "Trainable params: 14,652,964\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 6.43\n",
            "Params size (MB): 55.90\n",
            "Estimated Total Size (MB): 62.34\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 158, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(158, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(158, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 12:06:31 2022: Epoch [0], Iteration [0/391/], Data(s): 0.035, Loss(s): 0.003, Forward(s): 0.043, Backward(s): 0.080, Top1: 97.656, Top5: 100.0000, Loss: 0.137\n",
            "Mon Apr 25 12:06:39 2022: Epoch [0], Iteration [100/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.004, Backward(s): 0.008, Top1: 92.907, Top5: 99.6442, Loss: 0.211\n",
            "Mon Apr 25 12:06:47 2022: Epoch [0], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.008, Top1: 93.144, Top5: 99.6618, Loss: 0.202\n",
            "Mon Apr 25 12:06:55 2022: Epoch [0], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.093, Top5: 99.6782, Loss: 0.205\n",
            "Mon Apr 25 12:07:03 2022: Epoch [1], Iteration [0/391/], Data(s): 0.059, Loss(s): 0.009, Forward(s): 0.005, Backward(s): 0.008, Top1: 93.750, Top5: 100.0000, Loss: 0.199\n",
            "Mon Apr 25 12:07:11 2022: Epoch [1], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.889, Top5: 99.7215, Loss: 0.191\n",
            "Mon Apr 25 12:07:19 2022: Epoch [1], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.587, Top5: 99.7396, Loss: 0.201\n",
            "Mon Apr 25 12:07:26 2022: Epoch [1], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.532, Top5: 99.7093, Loss: 0.202\n",
            "Mon Apr 25 12:07:34 2022: Epoch [2], Iteration [0/391/], Data(s): 0.054, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.969, Top5: 99.2188, Loss: 0.200\n",
            "Mon Apr 25 12:07:42 2022: Epoch [2], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.727, Top5: 99.6597, Loss: 0.192\n",
            "Mon Apr 25 12:07:50 2022: Epoch [2], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.626, Top5: 99.7201, Loss: 0.190\n",
            "Mon Apr 25 12:07:57 2022: Epoch [2], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.529, Top5: 99.7093, Loss: 0.203\n",
            "Mon Apr 25 12:08:05 2022: Epoch [3], Iteration [0/391/], Data(s): 0.057, Loss(s): 0.011, Forward(s): 0.004, Backward(s): 0.007, Top1: 94.531, Top5: 100.0000, Loss: 0.189\n",
            "Mon Apr 25 12:08:13 2022: Epoch [3], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.232, Top5: 99.7293, Loss: 0.204\n",
            "Mon Apr 25 12:08:21 2022: Epoch [3], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.493, Top5: 99.7435, Loss: 0.187\n",
            "Mon Apr 25 12:08:29 2022: Epoch [3], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.568, Top5: 99.7560, Loss: 0.187\n",
            "Mon Apr 25 12:08:36 2022: Epoch [4], Iteration [0/391/], Data(s): 0.069, Loss(s): 0.010, Forward(s): 0.004, Backward(s): 0.008, Top1: 93.750, Top5: 99.2188, Loss: 0.196\n",
            "Mon Apr 25 12:08:44 2022: Epoch [4], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.951, Top5: 99.6751, Loss: 0.183\n",
            "Mon Apr 25 12:08:52 2022: Epoch [4], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.905, Top5: 99.7279, Loss: 0.187\n",
            "Mon Apr 25 12:09:00 2022: Epoch [4], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.841, Top5: 99.7586, Loss: 0.186\n",
            "Mon Apr 25 12:09:07 2022: Epoch [5], Iteration [0/391/], Data(s): 0.059, Loss(s): 0.009, Forward(s): 0.005, Backward(s): 0.007, Top1: 97.656, Top5: 100.0000, Loss: 0.183\n",
            "Mon Apr 25 12:09:15 2022: Epoch [5], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.920, Top5: 99.7989, Loss: 0.183\n",
            "Mon Apr 25 12:09:23 2022: Epoch [5], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.905, Top5: 99.7629, Loss: 0.182\n",
            "Mon Apr 25 12:09:31 2022: Epoch [5], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.924, Top5: 99.7404, Loss: 0.181\n",
            "Mon Apr 25 12:09:38 2022: Epoch [6], Iteration [0/391/], Data(s): 0.057, Loss(s): 0.010, Forward(s): 0.004, Backward(s): 0.007, Top1: 96.094, Top5: 100.0000, Loss: 0.177\n",
            "Mon Apr 25 12:09:46 2022: Epoch [6], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.090, Top5: 99.8840, Loss: 0.175\n",
            "Mon Apr 25 12:09:54 2022: Epoch [6], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.964, Top5: 99.8251, Loss: 0.183\n",
            "Mon Apr 25 12:10:02 2022: Epoch [6], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 93.877, Top5: 99.8105, Loss: 0.186\n",
            "Mon Apr 25 12:10:09 2022: Epoch [7], Iteration [0/391/], Data(s): 0.061, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 95.312, Top5: 100.0000, Loss: 0.184\n",
            "Mon Apr 25 12:10:17 2022: Epoch [7], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.152, Top5: 99.8221, Loss: 0.174\n",
            "Mon Apr 25 12:10:25 2022: Epoch [7], Iteration [200/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.228, Top5: 99.7668, Loss: 0.171\n",
            "Mon Apr 25 12:10:33 2022: Epoch [7], Iteration [300/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.072, Top5: 99.7456, Loss: 0.189\n",
            "Mon Apr 25 12:10:40 2022: Epoch [8], Iteration [0/391/], Data(s): 0.067, Loss(s): 0.009, Forward(s): 0.005, Backward(s): 0.010, Top1: 94.531, Top5: 100.0000, Loss: 0.182\n",
            "Mon Apr 25 12:10:48 2022: Epoch [8], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.191, Top5: 99.7602, Loss: 0.175\n",
            "Mon Apr 25 12:10:56 2022: Epoch [8], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.224, Top5: 99.7512, Loss: 0.180\n",
            "Mon Apr 25 12:11:04 2022: Epoch [8], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.170, Top5: 99.7560, Loss: 0.178\n",
            "Mon Apr 25 12:11:11 2022: Epoch [9], Iteration [0/391/], Data(s): 0.057, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 97.656, Top5: 100.0000, Loss: 0.174\n",
            "Mon Apr 25 12:11:19 2022: Epoch [9], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.307, Top5: 99.7757, Loss: 0.175\n",
            "Mon Apr 25 12:11:27 2022: Epoch [9], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.286, Top5: 99.8173, Loss: 0.170\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top1_accuracies = {}\n",
        "top5_accuracies = {}"
      ],
      "metadata": {
        "id": "vGkdZLA0_w08"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "7QR8ig_yrGHO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for conv, channel in zip(prune_layers[0:1], prune_channels[0:1]):    \n",
        "    top1_accuracies[conv] = []\n",
        "    top5_accuracies[conv] = []\n",
        "    \n",
        "    # load new network and check accuracy\n",
        "    network, _, _ = test_network(args, data_set=test_set)\n",
        "        \n",
        "    # remove 0 channels ~ M (max_channel_ratio) % of total channels\n",
        "    step = np.linspace(0, int(channel*max_channel_ratio), int(1/prune_step_ratio), dtype=np.int)\n",
        "    steps = (step[1:] - step[:-1]).tolist()\n",
        "    \n",
        "    for i in range(len(steps)):\n",
        "        print(\"\\n%s: %s Layer, %d Channels pruned\"%(time.ctime(), conv, sum(steps[:i+1])))\n",
        "        \n",
        "        # set prune information\n",
        "        args.prune_layers = [conv]\n",
        "        args.prune_channels =[steps[i]]\n",
        "\n",
        "        network = prune_network(args, network)\n",
        "        \n",
        "        network, _, (top1, top5) = test_network(args, network, test_set)\n",
        "            \n",
        "        top1_accuracies[conv].append(top1)\n",
        "        top5_accuracies[conv].append(top5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEy2I_G3_wv2",
        "outputId": "057fe09f-5c33-4b3d-98ee-c21cf6998a43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 18:48:28 2022: Test information, Data(s): 3.054, Forward(s): 0.520, Top1: 77.870, Top5: 97.560, \n",
            "\n",
            "Mon Apr 25 18:48:28 2022: conv1 Layer, 8 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 56, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(56, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 56, 32, 32]           1,568\n",
            "       BatchNorm2d-2           [-1, 56, 32, 32]             112\n",
            "              ReLU-3           [-1, 56, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          32,320\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]          73,856\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "             ReLU-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]         147,584\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         295,168\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]       1,180,160\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 14,987,098\n",
            "Trainable params: 14,987,098\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 6.39\n",
            "Params size (MB): 57.17\n",
            "Estimated Total Size (MB): 63.57\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 56, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(56, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  if __name__ == '__main__':\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 18:48:31 2022: Epoch [0], Iteration [0/391/], Data(s): 0.064, Loss(s): 0.008, Forward(s): 0.659, Backward(s): 1.390, Top1: 82.031, Top5: 98.4375, Loss: 0.491\n",
            "Mon Apr 25 18:48:49 2022: Epoch [0], Iteration [100/391/], Data(s): 0.063, Loss(s): 0.027, Forward(s): 0.013, Backward(s): 0.027, Top1: 87.570, Top5: 98.8707, Loss: 0.389\n",
            "Mon Apr 25 18:49:07 2022: Epoch [0], Iteration [200/391/], Data(s): 0.064, Loss(s): 0.027, Forward(s): 0.009, Backward(s): 0.020, Top1: 88.036, Top5: 99.0050, Loss: 0.355\n",
            "Mon Apr 25 18:49:25 2022: Epoch [0], Iteration [300/391/], Data(s): 0.065, Loss(s): 0.027, Forward(s): 0.008, Backward(s): 0.018, Top1: 88.455, Top5: 99.0397, Loss: 0.332\n",
            "Mon Apr 25 18:49:43 2022: Epoch [1], Iteration [0/391/], Data(s): 0.084, Loss(s): 0.030, Forward(s): 0.007, Backward(s): 0.013, Top1: 89.062, Top5: 99.2188, Loss: 0.326\n",
            "Mon Apr 25 18:50:00 2022: Epoch [1], Iteration [100/391/], Data(s): 0.065, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.014, Top1: 90.053, Top5: 99.3735, Loss: 0.308\n",
            "Mon Apr 25 18:50:18 2022: Epoch [1], Iteration [200/391/], Data(s): 0.064, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 90.116, Top5: 99.3548, Loss: 0.303\n",
            "Mon Apr 25 18:50:36 2022: Epoch [1], Iteration [300/391/], Data(s): 0.064, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 90.332, Top5: 99.4160, Loss: 0.291\n",
            "Mon Apr 25 18:50:52 2022: Epoch [2], Iteration [0/391/], Data(s): 0.093, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 92.969, Top5: 100.0000, Loss: 0.289\n",
            "Mon Apr 25 18:51:10 2022: Epoch [2], Iteration [100/391/], Data(s): 0.065, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 90.795, Top5: 99.4353, Loss: 0.290\n",
            "Mon Apr 25 18:51:27 2022: Epoch [2], Iteration [200/391/], Data(s): 0.064, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 90.823, Top5: 99.4403, Loss: 0.283\n",
            "Mon Apr 25 18:51:45 2022: Epoch [2], Iteration [300/391/], Data(s): 0.064, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 90.900, Top5: 99.4653, Loss: 0.276\n",
            "Mon Apr 25 18:52:01 2022: Epoch [3], Iteration [0/391/], Data(s): 0.093, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 93.750, Top5: 100.0000, Loss: 0.274\n",
            "Mon Apr 25 18:52:19 2022: Epoch [3], Iteration [100/391/], Data(s): 0.065, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.014, Top1: 91.313, Top5: 99.5127, Loss: 0.269\n",
            "Mon Apr 25 18:52:36 2022: Epoch [3], Iteration [200/391/], Data(s): 0.064, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 91.426, Top5: 99.5025, Loss: 0.261\n",
            "Mon Apr 25 18:52:54 2022: Epoch [3], Iteration [300/391/], Data(s): 0.063, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 91.406, Top5: 99.4913, Loss: 0.265\n",
            "Mon Apr 25 18:53:10 2022: Epoch [4], Iteration [0/391/], Data(s): 0.098, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.750, Top5: 98.4375, Loss: 0.253\n",
            "Mon Apr 25 18:53:27 2022: Epoch [4], Iteration [100/391/], Data(s): 0.065, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 91.708, Top5: 99.4972, Loss: 0.266\n",
            "Mon Apr 25 18:53:45 2022: Epoch [4], Iteration [200/391/], Data(s): 0.064, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 91.857, Top5: 99.5219, Loss: 0.252\n",
            "Mon Apr 25 18:54:02 2022: Epoch [4], Iteration [300/391/], Data(s): 0.063, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 91.775, Top5: 99.5172, Loss: 0.256\n",
            "Mon Apr 25 18:54:19 2022: Epoch [5], Iteration [0/391/], Data(s): 0.104, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 97.656, Top5: 100.0000, Loss: 0.260\n",
            "Mon Apr 25 18:54:36 2022: Epoch [5], Iteration [100/391/], Data(s): 0.066, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 91.700, Top5: 99.5668, Loss: 0.257\n",
            "Mon Apr 25 18:54:54 2022: Epoch [5], Iteration [200/391/], Data(s): 0.064, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 91.803, Top5: 99.5141, Loss: 0.252\n",
            "Mon Apr 25 18:55:11 2022: Epoch [5], Iteration [300/391/], Data(s): 0.063, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 91.936, Top5: 99.5302, Loss: 0.245\n",
            "Mon Apr 25 18:55:27 2022: Epoch [6], Iteration [0/391/], Data(s): 0.095, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.016, Top1: 89.844, Top5: 100.0000, Loss: 0.244\n",
            "Mon Apr 25 18:55:45 2022: Epoch [6], Iteration [100/391/], Data(s): 0.064, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.014, Top1: 91.747, Top5: 99.6364, Loss: 0.248\n",
            "Mon Apr 25 18:56:03 2022: Epoch [6], Iteration [200/391/], Data(s): 0.064, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 91.799, Top5: 99.5958, Loss: 0.246\n",
            "Mon Apr 25 18:56:20 2022: Epoch [6], Iteration [300/391/], Data(s): 0.063, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 92.042, Top5: 99.5951, Loss: 0.236\n",
            "Mon Apr 25 18:56:36 2022: Epoch [7], Iteration [0/391/], Data(s): 0.083, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 92.188, Top5: 99.2188, Loss: 0.246\n",
            "Mon Apr 25 18:56:54 2022: Epoch [7], Iteration [100/391/], Data(s): 0.065, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.014, Top1: 92.342, Top5: 99.5436, Loss: 0.237\n",
            "Mon Apr 25 18:57:11 2022: Epoch [7], Iteration [200/391/], Data(s): 0.064, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.014, Top1: 92.316, Top5: 99.5608, Loss: 0.240\n",
            "Mon Apr 25 18:57:29 2022: Epoch [7], Iteration [300/391/], Data(s): 0.063, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.014, Top1: 92.424, Top5: 99.5743, Loss: 0.225\n",
            "Mon Apr 25 18:57:45 2022: Epoch [8], Iteration [0/391/], Data(s): 0.084, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 93.750, Top5: 100.0000, Loss: 0.237\n",
            "Mon Apr 25 18:58:03 2022: Epoch [8], Iteration [100/391/], Data(s): 0.065, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.014, Top1: 92.505, Top5: 99.4895, Loss: 0.234\n",
            "Mon Apr 25 18:58:20 2022: Epoch [8], Iteration [200/391/], Data(s): 0.065, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 92.561, Top5: 99.5530, Loss: 0.228\n",
            "Mon Apr 25 18:58:38 2022: Epoch [8], Iteration [300/391/], Data(s): 0.064, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 92.489, Top5: 99.5665, Loss: 0.234\n",
            "Mon Apr 25 18:58:54 2022: Epoch [9], Iteration [0/391/], Data(s): 0.085, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.014, Top1: 93.750, Top5: 100.0000, Loss: 0.229\n",
            "Mon Apr 25 18:59:12 2022: Epoch [9], Iteration [100/391/], Data(s): 0.065, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.013, Top1: 92.605, Top5: 99.6519, Loss: 0.225\n",
            "Mon Apr 25 18:59:29 2022: Epoch [9], Iteration [200/391/], Data(s): 0.064, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 92.603, Top5: 99.6618, Loss: 0.224\n",
            "Mon Apr 25 18:59:47 2022: Epoch [9], Iteration [300/391/], Data(s): 0.064, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 92.569, Top5: 99.6392, Loss: 0.230\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 19:00:10 2022: Test information, Data(s): 2.998, Forward(s): 0.585, Top1: 90.000, Top5: 99.250, \n",
            "\n",
            "Mon Apr 25 19:00:10 2022: conv1 Layer, 16 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(48, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 48, 32, 32]           1,344\n",
            "       BatchNorm2d-2           [-1, 48, 32, 32]              96\n",
            "              ReLU-3           [-1, 48, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          27,712\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]          73,856\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "             ReLU-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]         147,584\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         295,168\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]       1,180,160\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 14,982,250\n",
            "Trainable params: 14,982,250\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 6.20\n",
            "Params size (MB): 57.15\n",
            "Estimated Total Size (MB): 63.36\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(48, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 19:00:11 2022: Epoch [0], Iteration [0/391/], Data(s): 0.064, Loss(s): 0.011, Forward(s): 0.094, Backward(s): 0.244, Top1: 96.875, Top5: 100.0000, Loss: 0.138\n",
            "Mon Apr 25 19:00:29 2022: Epoch [0], Iteration [100/391/], Data(s): 0.065, Loss(s): 0.026, Forward(s): 0.007, Backward(s): 0.015, Top1: 93.000, Top5: 99.6519, Loss: 0.216\n",
            "Mon Apr 25 19:00:46 2022: Epoch [0], Iteration [200/391/], Data(s): 0.064, Loss(s): 0.026, Forward(s): 0.007, Backward(s): 0.014, Top1: 92.848, Top5: 99.5958, Loss: 0.227\n",
            "Mon Apr 25 19:01:04 2022: Epoch [0], Iteration [300/391/], Data(s): 0.063, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.014, Top1: 92.888, Top5: 99.6314, Loss: 0.219\n",
            "Mon Apr 25 19:01:20 2022: Epoch [1], Iteration [0/391/], Data(s): 0.092, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.013, Top1: 90.625, Top5: 100.0000, Loss: 0.226\n",
            "Mon Apr 25 19:01:37 2022: Epoch [1], Iteration [100/391/], Data(s): 0.064, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.013, Top1: 92.427, Top5: 99.6364, Loss: 0.229\n",
            "Mon Apr 25 19:01:55 2022: Epoch [1], Iteration [200/391/], Data(s): 0.063, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.013, Top1: 92.673, Top5: 99.6463, Loss: 0.219\n",
            "Mon Apr 25 19:02:12 2022: Epoch [1], Iteration [300/391/], Data(s): 0.063, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.013, Top1: 92.800, Top5: 99.6574, Loss: 0.212\n",
            "Mon Apr 25 19:02:28 2022: Epoch [2], Iteration [0/391/], Data(s): 0.100, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.014, Top1: 92.188, Top5: 99.2188, Loss: 0.212\n",
            "Mon Apr 25 19:02:45 2022: Epoch [2], Iteration [100/391/], Data(s): 0.064, Loss(s): 0.026, Forward(s): 0.007, Backward(s): 0.014, Top1: 93.077, Top5: 99.6983, Loss: 0.209\n",
            "Mon Apr 25 19:03:03 2022: Epoch [2], Iteration [200/391/], Data(s): 0.063, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.014, Top1: 93.008, Top5: 99.7474, Loss: 0.210\n",
            "Mon Apr 25 19:03:20 2022: Epoch [2], Iteration [300/391/], Data(s): 0.063, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.013, Top1: 92.899, Top5: 99.6859, Loss: 0.226\n",
            "Mon Apr 25 19:03:36 2022: Epoch [3], Iteration [0/391/], Data(s): 0.093, Loss(s): 0.021, Forward(s): 0.011, Backward(s): 0.013, Top1: 90.625, Top5: 99.2188, Loss: 0.206\n",
            "Mon Apr 25 19:03:54 2022: Epoch [3], Iteration [100/391/], Data(s): 0.063, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.014, Top1: 93.270, Top5: 99.7061, Loss: 0.205\n",
            "Mon Apr 25 19:04:11 2022: Epoch [3], Iteration [200/391/], Data(s): 0.063, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.014, Top1: 93.268, Top5: 99.7396, Loss: 0.204\n",
            "Mon Apr 25 19:04:28 2022: Epoch [3], Iteration [300/391/], Data(s): 0.063, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.014, Top1: 93.226, Top5: 99.7119, Loss: 0.212\n",
            "Mon Apr 25 19:04:44 2022: Epoch [4], Iteration [0/391/], Data(s): 0.089, Loss(s): 0.023, Forward(s): 0.009, Backward(s): 0.016, Top1: 89.062, Top5: 100.0000, Loss: 0.212\n",
            "Mon Apr 25 19:05:02 2022: Epoch [4], Iteration [100/391/], Data(s): 0.064, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.014, Top1: 93.077, Top5: 99.7989, Loss: 0.210\n",
            "Mon Apr 25 19:05:19 2022: Epoch [4], Iteration [200/391/], Data(s): 0.063, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.014, Top1: 93.198, Top5: 99.7163, Loss: 0.206\n",
            "Mon Apr 25 19:05:36 2022: Epoch [4], Iteration [300/391/], Data(s): 0.063, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.014, Top1: 93.288, Top5: 99.7223, Loss: 0.199\n",
            "Mon Apr 25 19:05:52 2022: Epoch [5], Iteration [0/391/], Data(s): 0.084, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 92.969, Top5: 99.2188, Loss: 0.217\n",
            "Mon Apr 25 19:06:10 2022: Epoch [5], Iteration [100/391/], Data(s): 0.063, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.014, Top1: 93.247, Top5: 99.7912, Loss: 0.199\n",
            "Mon Apr 25 19:06:27 2022: Epoch [5], Iteration [200/391/], Data(s): 0.063, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.014, Top1: 93.431, Top5: 99.7512, Loss: 0.198\n",
            "Mon Apr 25 19:06:45 2022: Epoch [5], Iteration [300/391/], Data(s): 0.063, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.014, Top1: 93.381, Top5: 99.7275, Loss: 0.198\n",
            "Mon Apr 25 19:07:01 2022: Epoch [6], Iteration [0/391/], Data(s): 0.087, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 96.094, Top5: 100.0000, Loss: 0.202\n",
            "Mon Apr 25 19:07:18 2022: Epoch [6], Iteration [100/391/], Data(s): 0.064, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.014, Top1: 93.340, Top5: 99.6983, Loss: 0.201\n",
            "Mon Apr 25 19:07:35 2022: Epoch [6], Iteration [200/391/], Data(s): 0.063, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.014, Top1: 93.319, Top5: 99.7240, Loss: 0.204\n",
            "Mon Apr 25 19:07:53 2022: Epoch [6], Iteration [300/391/], Data(s): 0.063, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.013, Top1: 93.490, Top5: 99.7327, Loss: 0.191\n",
            "Mon Apr 25 19:08:09 2022: Epoch [7], Iteration [0/391/], Data(s): 0.087, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.188, Top5: 99.2188, Loss: 0.201\n",
            "Mon Apr 25 19:08:26 2022: Epoch [7], Iteration [100/391/], Data(s): 0.063, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.014, Top1: 93.688, Top5: 99.6751, Loss: 0.192\n",
            "Mon Apr 25 19:08:43 2022: Epoch [7], Iteration [200/391/], Data(s): 0.063, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.013, Top1: 93.614, Top5: 99.7163, Loss: 0.201\n",
            "Mon Apr 25 19:09:01 2022: Epoch [7], Iteration [300/391/], Data(s): 0.062, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.013, Top1: 93.488, Top5: 99.7015, Loss: 0.203\n",
            "Mon Apr 25 19:09:17 2022: Epoch [8], Iteration [0/391/], Data(s): 0.094, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 92.969, Top5: 100.0000, Loss: 0.194\n",
            "Mon Apr 25 19:09:34 2022: Epoch [8], Iteration [100/391/], Data(s): 0.064, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.013, Top1: 93.796, Top5: 99.7138, Loss: 0.193\n",
            "Mon Apr 25 19:09:52 2022: Epoch [8], Iteration [200/391/], Data(s): 0.063, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.013, Top1: 93.781, Top5: 99.7279, Loss: 0.193\n",
            "Mon Apr 25 19:10:09 2022: Epoch [8], Iteration [300/391/], Data(s): 0.062, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.014, Top1: 93.740, Top5: 99.7327, Loss: 0.194\n",
            "Mon Apr 25 19:10:25 2022: Epoch [9], Iteration [0/391/], Data(s): 0.095, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.013, Top1: 91.406, Top5: 99.2188, Loss: 0.199\n",
            "Mon Apr 25 19:10:42 2022: Epoch [9], Iteration [100/391/], Data(s): 0.065, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.014, Top1: 93.781, Top5: 99.6597, Loss: 0.185\n",
            "Mon Apr 25 19:10:59 2022: Epoch [9], Iteration [200/391/], Data(s): 0.063, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.013, Top1: 93.738, Top5: 99.7085, Loss: 0.186\n",
            "Mon Apr 25 19:11:17 2022: Epoch [9], Iteration [300/391/], Data(s): 0.063, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.013, Top1: 93.773, Top5: 99.7119, Loss: 0.185\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 19:11:39 2022: Test information, Data(s): 3.004, Forward(s): 0.656, Top1: 90.580, Top5: 99.300, \n",
            "\n",
            "Mon Apr 25 19:11:39 2022: conv1 Layer, 24 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(40, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 40, 32, 32]           1,120\n",
            "       BatchNorm2d-2           [-1, 40, 32, 32]              80\n",
            "              ReLU-3           [-1, 40, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          23,104\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]          73,856\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "             ReLU-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]         147,584\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         295,168\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]       1,180,160\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 14,977,402\n",
            "Trainable params: 14,977,402\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 6.01\n",
            "Params size (MB): 57.13\n",
            "Estimated Total Size (MB): 63.16\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(40, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 19:11:41 2022: Epoch [0], Iteration [0/391/], Data(s): 0.072, Loss(s): 0.023, Forward(s): 0.069, Backward(s): 0.226, Top1: 92.969, Top5: 100.0000, Loss: 0.178\n",
            "Mon Apr 25 19:11:58 2022: Epoch [0], Iteration [100/391/], Data(s): 0.064, Loss(s): 0.026, Forward(s): 0.007, Backward(s): 0.015, Top1: 93.959, Top5: 99.8530, Loss: 0.181\n",
            "Mon Apr 25 19:12:15 2022: Epoch [0], Iteration [200/391/], Data(s): 0.062, Loss(s): 0.026, Forward(s): 0.007, Backward(s): 0.014, Top1: 94.092, Top5: 99.8018, Loss: 0.180\n",
            "Mon Apr 25 19:12:33 2022: Epoch [0], Iteration [300/391/], Data(s): 0.062, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.014, Top1: 93.939, Top5: 99.7872, Loss: 0.191\n",
            "Mon Apr 25 19:12:49 2022: Epoch [1], Iteration [0/391/], Data(s): 0.096, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.019, Top1: 92.188, Top5: 98.4375, Loss: 0.204\n",
            "Mon Apr 25 19:13:06 2022: Epoch [1], Iteration [100/391/], Data(s): 0.063, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.014, Top1: 93.974, Top5: 99.7215, Loss: 0.187\n",
            "Mon Apr 25 19:13:23 2022: Epoch [1], Iteration [200/391/], Data(s): 0.062, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.013, Top1: 93.894, Top5: 99.7512, Loss: 0.185\n",
            "Mon Apr 25 19:13:40 2022: Epoch [1], Iteration [300/391/], Data(s): 0.062, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.013, Top1: 93.903, Top5: 99.7327, Loss: 0.189\n",
            "Mon Apr 25 19:13:56 2022: Epoch [2], Iteration [0/391/], Data(s): 0.083, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.312, Top5: 100.0000, Loss: 0.187\n",
            "Mon Apr 25 19:14:13 2022: Epoch [2], Iteration [100/391/], Data(s): 0.062, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.014, Top1: 94.214, Top5: 99.8530, Loss: 0.175\n",
            "Mon Apr 25 19:14:31 2022: Epoch [2], Iteration [200/391/], Data(s): 0.061, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.014, Top1: 94.154, Top5: 99.8018, Loss: 0.183\n",
            "Mon Apr 25 19:14:48 2022: Epoch [2], Iteration [300/391/], Data(s): 0.061, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.013, Top1: 94.093, Top5: 99.7898, Loss: 0.184\n",
            "Mon Apr 25 19:15:04 2022: Epoch [3], Iteration [0/391/], Data(s): 0.082, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 91.406, Top5: 99.2188, Loss: 0.184\n",
            "Mon Apr 25 19:15:21 2022: Epoch [3], Iteration [100/391/], Data(s): 0.063, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.013, Top1: 93.742, Top5: 99.6597, Loss: 0.191\n",
            "Mon Apr 25 19:15:38 2022: Epoch [3], Iteration [200/391/], Data(s): 0.062, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.013, Top1: 94.076, Top5: 99.7240, Loss: 0.171\n",
            "Mon Apr 25 19:15:55 2022: Epoch [3], Iteration [300/391/], Data(s): 0.062, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.013, Top1: 94.059, Top5: 99.7534, Loss: 0.183\n",
            "Mon Apr 25 19:16:11 2022: Epoch [4], Iteration [0/391/], Data(s): 0.083, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.014, Top1: 94.531, Top5: 100.0000, Loss: 0.175\n",
            "Mon Apr 25 19:16:29 2022: Epoch [4], Iteration [100/391/], Data(s): 0.064, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.014, Top1: 93.982, Top5: 99.7138, Loss: 0.178\n",
            "Mon Apr 25 19:16:46 2022: Epoch [4], Iteration [200/391/], Data(s): 0.063, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.013, Top1: 93.983, Top5: 99.7435, Loss: 0.180\n",
            "Mon Apr 25 19:17:03 2022: Epoch [4], Iteration [300/391/], Data(s): 0.062, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.013, Top1: 94.095, Top5: 99.7690, Loss: 0.173\n",
            "Mon Apr 25 19:17:19 2022: Epoch [5], Iteration [0/391/], Data(s): 0.086, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.013, Top1: 92.188, Top5: 100.0000, Loss: 0.180\n",
            "Mon Apr 25 19:17:37 2022: Epoch [5], Iteration [100/391/], Data(s): 0.063, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.014, Top1: 93.912, Top5: 99.7215, Loss: 0.179\n",
            "Mon Apr 25 19:17:54 2022: Epoch [5], Iteration [200/391/], Data(s): 0.062, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.014, Top1: 94.088, Top5: 99.7862, Loss: 0.171\n",
            "Mon Apr 25 19:18:11 2022: Epoch [5], Iteration [300/391/], Data(s): 0.062, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.013, Top1: 94.074, Top5: 99.7872, Loss: 0.179\n",
            "Mon Apr 25 19:18:27 2022: Epoch [6], Iteration [0/391/], Data(s): 0.087, Loss(s): 0.025, Forward(s): 0.007, Backward(s): 0.013, Top1: 93.750, Top5: 100.0000, Loss: 0.176\n",
            "Mon Apr 25 19:18:44 2022: Epoch [6], Iteration [100/391/], Data(s): 0.064, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.014, Top1: 94.485, Top5: 99.7293, Loss: 0.173\n",
            "Mon Apr 25 19:19:02 2022: Epoch [6], Iteration [200/391/], Data(s): 0.063, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.013, Top1: 94.224, Top5: 99.7396, Loss: 0.180\n",
            "Mon Apr 25 19:19:19 2022: Epoch [6], Iteration [300/391/], Data(s): 0.062, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.013, Top1: 94.311, Top5: 99.7482, Loss: 0.168\n",
            "Mon Apr 25 19:19:35 2022: Epoch [7], Iteration [0/391/], Data(s): 0.087, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.312, Top5: 100.0000, Loss: 0.172\n",
            "Mon Apr 25 19:19:52 2022: Epoch [7], Iteration [100/391/], Data(s): 0.063, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.013, Top1: 94.616, Top5: 99.8066, Loss: 0.167\n",
            "Mon Apr 25 19:20:09 2022: Epoch [7], Iteration [200/391/], Data(s): 0.062, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.013, Top1: 94.399, Top5: 99.7590, Loss: 0.178\n",
            "Mon Apr 25 19:20:27 2022: Epoch [7], Iteration [300/391/], Data(s): 0.062, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.013, Top1: 94.435, Top5: 99.7560, Loss: 0.168\n",
            "Mon Apr 25 19:20:42 2022: Epoch [8], Iteration [0/391/], Data(s): 0.086, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.312, Top5: 100.0000, Loss: 0.163\n",
            "Mon Apr 25 19:21:00 2022: Epoch [8], Iteration [100/391/], Data(s): 0.063, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.014, Top1: 94.493, Top5: 99.8066, Loss: 0.160\n",
            "Mon Apr 25 19:21:17 2022: Epoch [8], Iteration [200/391/], Data(s): 0.062, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.014, Top1: 94.465, Top5: 99.8212, Loss: 0.172\n",
            "Mon Apr 25 19:21:34 2022: Epoch [8], Iteration [300/391/], Data(s): 0.062, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.013, Top1: 94.409, Top5: 99.8001, Loss: 0.171\n",
            "Mon Apr 25 19:21:50 2022: Epoch [9], Iteration [0/391/], Data(s): 0.082, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.312, Top5: 100.0000, Loss: 0.170\n",
            "Mon Apr 25 19:22:08 2022: Epoch [9], Iteration [100/391/], Data(s): 0.063, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.013, Top1: 94.562, Top5: 99.8376, Loss: 0.160\n",
            "Mon Apr 25 19:22:25 2022: Epoch [9], Iteration [200/391/], Data(s): 0.062, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.013, Top1: 94.523, Top5: 99.8134, Loss: 0.166\n",
            "Mon Apr 25 19:22:42 2022: Epoch [9], Iteration [300/391/], Data(s): 0.062, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.013, Top1: 94.614, Top5: 99.8079, Loss: 0.166\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 19:23:05 2022: Test information, Data(s): 3.048, Forward(s): 0.619, Top1: 91.010, Top5: 99.320, \n",
            "\n",
            "Mon Apr 25 19:23:05 2022: conv1 Layer, 32 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 32, 32]             896\n",
            "       BatchNorm2d-2           [-1, 32, 32, 32]              64\n",
            "              ReLU-3           [-1, 32, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          18,496\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]          73,856\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "             ReLU-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]         147,584\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         295,168\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]       1,180,160\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 14,972,554\n",
            "Trainable params: 14,972,554\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 5.82\n",
            "Params size (MB): 57.12\n",
            "Estimated Total Size (MB): 62.95\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 19:23:06 2022: Epoch [0], Iteration [0/391/], Data(s): 0.064, Loss(s): 0.023, Forward(s): 0.060, Backward(s): 0.202, Top1: 95.312, Top5: 100.0000, Loss: 0.148\n",
            "Mon Apr 25 19:23:23 2022: Epoch [0], Iteration [100/391/], Data(s): 0.065, Loss(s): 0.025, Forward(s): 0.007, Backward(s): 0.015, Top1: 94.469, Top5: 99.7757, Loss: 0.168\n",
            "Mon Apr 25 19:23:40 2022: Epoch [0], Iteration [200/391/], Data(s): 0.064, Loss(s): 0.025, Forward(s): 0.007, Backward(s): 0.014, Top1: 94.625, Top5: 99.8134, Loss: 0.157\n",
            "Mon Apr 25 19:23:58 2022: Epoch [0], Iteration [300/391/], Data(s): 0.064, Loss(s): 0.025, Forward(s): 0.006, Backward(s): 0.014, Top1: 94.573, Top5: 99.8209, Loss: 0.167\n",
            "Mon Apr 25 19:24:13 2022: Epoch [1], Iteration [0/391/], Data(s): 0.088, Loss(s): 0.024, Forward(s): 0.007, Backward(s): 0.013, Top1: 93.750, Top5: 100.0000, Loss: 0.163\n",
            "Mon Apr 25 19:24:30 2022: Epoch [1], Iteration [100/391/], Data(s): 0.064, Loss(s): 0.025, Forward(s): 0.006, Backward(s): 0.013, Top1: 94.531, Top5: 99.7215, Loss: 0.166\n",
            "Mon Apr 25 19:24:47 2022: Epoch [1], Iteration [200/391/], Data(s): 0.062, Loss(s): 0.025, Forward(s): 0.006, Backward(s): 0.014, Top1: 94.640, Top5: 99.7979, Loss: 0.153\n",
            "Mon Apr 25 19:25:04 2022: Epoch [1], Iteration [300/391/], Data(s): 0.063, Loss(s): 0.025, Forward(s): 0.006, Backward(s): 0.013, Top1: 94.695, Top5: 99.8105, Loss: 0.158\n",
            "Mon Apr 25 19:25:20 2022: Epoch [2], Iteration [0/391/], Data(s): 0.083, Loss(s): 0.025, Forward(s): 0.006, Backward(s): 0.013, Top1: 96.094, Top5: 100.0000, Loss: 0.166\n",
            "Mon Apr 25 19:25:37 2022: Epoch [2], Iteration [100/391/], Data(s): 0.063, Loss(s): 0.025, Forward(s): 0.006, Backward(s): 0.014, Top1: 94.964, Top5: 99.7602, Loss: 0.150\n",
            "Mon Apr 25 19:25:54 2022: Epoch [2], Iteration [200/391/], Data(s): 0.063, Loss(s): 0.025, Forward(s): 0.006, Backward(s): 0.014, Top1: 94.784, Top5: 99.7629, Loss: 0.164\n",
            "Mon Apr 25 19:26:11 2022: Epoch [2], Iteration [300/391/], Data(s): 0.063, Loss(s): 0.025, Forward(s): 0.006, Backward(s): 0.013, Top1: 94.817, Top5: 99.7872, Loss: 0.153\n",
            "Mon Apr 25 19:26:27 2022: Epoch [3], Iteration [0/391/], Data(s): 0.097, Loss(s): 0.025, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.875, Top5: 100.0000, Loss: 0.158\n",
            "Mon Apr 25 19:26:44 2022: Epoch [3], Iteration [100/391/], Data(s): 0.064, Loss(s): 0.025, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.274, Top5: 99.8453, Loss: 0.150\n",
            "Mon Apr 25 19:27:01 2022: Epoch [3], Iteration [200/391/], Data(s): 0.063, Loss(s): 0.025, Forward(s): 0.006, Backward(s): 0.013, Top1: 94.897, Top5: 99.8251, Loss: 0.161\n",
            "Mon Apr 25 19:27:18 2022: Epoch [3], Iteration [300/391/], Data(s): 0.063, Loss(s): 0.025, Forward(s): 0.006, Backward(s): 0.013, Top1: 94.926, Top5: 99.8131, Loss: 0.157\n",
            "Mon Apr 25 19:27:34 2022: Epoch [4], Iteration [0/391/], Data(s): 0.086, Loss(s): 0.025, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.750, Top5: 99.2188, Loss: 0.157\n",
            "Mon Apr 25 19:27:51 2022: Epoch [4], Iteration [100/391/], Data(s): 0.063, Loss(s): 0.025, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.011, Top5: 99.8298, Loss: 0.150\n",
            "Mon Apr 25 19:28:08 2022: Epoch [4], Iteration [200/391/], Data(s): 0.063, Loss(s): 0.025, Forward(s): 0.006, Backward(s): 0.013, Top1: 94.959, Top5: 99.8329, Loss: 0.155\n",
            "Mon Apr 25 19:28:25 2022: Epoch [4], Iteration [300/391/], Data(s): 0.063, Loss(s): 0.025, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.011, Top5: 99.8183, Loss: 0.148\n",
            "Mon Apr 25 19:28:41 2022: Epoch [5], Iteration [0/391/], Data(s): 0.085, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.013, Top1: 92.969, Top5: 99.2188, Loss: 0.161\n",
            "Mon Apr 25 19:28:58 2022: Epoch [5], Iteration [100/391/], Data(s): 0.063, Loss(s): 0.025, Forward(s): 0.006, Backward(s): 0.014, Top1: 95.127, Top5: 99.8298, Loss: 0.143\n",
            "Mon Apr 25 19:29:15 2022: Epoch [5], Iteration [200/391/], Data(s): 0.063, Loss(s): 0.025, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.017, Top5: 99.7940, Loss: 0.153\n",
            "Mon Apr 25 19:29:32 2022: Epoch [5], Iteration [300/391/], Data(s): 0.062, Loss(s): 0.025, Forward(s): 0.006, Backward(s): 0.013, Top1: 94.998, Top5: 99.8131, Loss: 0.150\n",
            "Mon Apr 25 19:29:47 2022: Epoch [6], Iteration [0/391/], Data(s): 0.097, Loss(s): 0.025, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.094, Top5: 100.0000, Loss: 0.162\n",
            "Mon Apr 25 19:30:04 2022: Epoch [6], Iteration [100/391/], Data(s): 0.062, Loss(s): 0.025, Forward(s): 0.006, Backward(s): 0.014, Top1: 95.042, Top5: 99.8453, Loss: 0.149\n",
            "Mon Apr 25 19:30:21 2022: Epoch [6], Iteration [200/391/], Data(s): 0.063, Loss(s): 0.025, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.037, Top5: 99.8523, Loss: 0.150\n",
            "Mon Apr 25 19:30:38 2022: Epoch [6], Iteration [300/391/], Data(s): 0.063, Loss(s): 0.025, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.058, Top5: 99.8469, Loss: 0.151\n",
            "Mon Apr 25 19:30:54 2022: Epoch [7], Iteration [0/391/], Data(s): 0.105, Loss(s): 0.025, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.188, Top5: 100.0000, Loss: 0.158\n",
            "Mon Apr 25 19:31:11 2022: Epoch [7], Iteration [100/391/], Data(s): 0.064, Loss(s): 0.025, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.127, Top5: 99.8762, Loss: 0.144\n",
            "Mon Apr 25 19:31:28 2022: Epoch [7], Iteration [200/391/], Data(s): 0.063, Loss(s): 0.025, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.044, Top5: 99.8717, Loss: 0.148\n",
            "Mon Apr 25 19:31:45 2022: Epoch [7], Iteration [300/391/], Data(s): 0.063, Loss(s): 0.025, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.058, Top5: 99.8624, Loss: 0.148\n",
            "Mon Apr 25 19:32:01 2022: Epoch [8], Iteration [0/391/], Data(s): 0.089, Loss(s): 0.025, Forward(s): 0.006, Backward(s): 0.014, Top1: 97.656, Top5: 100.0000, Loss: 0.157\n",
            "Mon Apr 25 19:32:18 2022: Epoch [8], Iteration [100/391/], Data(s): 0.064, Loss(s): 0.025, Forward(s): 0.006, Backward(s): 0.014, Top1: 95.235, Top5: 99.8453, Loss: 0.143\n",
            "Mon Apr 25 19:32:35 2022: Epoch [8], Iteration [200/391/], Data(s): 0.063, Loss(s): 0.025, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.231, Top5: 99.8523, Loss: 0.143\n",
            "Mon Apr 25 19:32:52 2022: Epoch [8], Iteration [300/391/], Data(s): 0.062, Loss(s): 0.025, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.248, Top5: 99.8339, Loss: 0.148\n",
            "Mon Apr 25 19:33:08 2022: Epoch [9], Iteration [0/391/], Data(s): 0.095, Loss(s): 0.025, Forward(s): 0.006, Backward(s): 0.013, Top1: 97.656, Top5: 100.0000, Loss: 0.148\n",
            "Mon Apr 25 19:33:25 2022: Epoch [9], Iteration [100/391/], Data(s): 0.064, Loss(s): 0.025, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.158, Top5: 99.8453, Loss: 0.145\n",
            "Mon Apr 25 19:33:42 2022: Epoch [9], Iteration [200/391/], Data(s): 0.063, Loss(s): 0.025, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.289, Top5: 99.8562, Loss: 0.136\n",
            "Mon Apr 25 19:33:59 2022: Epoch [9], Iteration [300/391/], Data(s): 0.063, Loss(s): 0.025, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.242, Top5: 99.8495, Loss: 0.143\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 19:34:21 2022: Test information, Data(s): 2.980, Forward(s): 0.609, Top1: 91.200, Top5: 99.310, \n",
            "\n",
            "Mon Apr 25 19:34:21 2022: conv1 Layer, 40 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 24, 32, 32]             672\n",
            "       BatchNorm2d-2           [-1, 24, 32, 32]              48\n",
            "              ReLU-3           [-1, 24, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          13,888\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]          73,856\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "             ReLU-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]         147,584\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         295,168\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]       1,180,160\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 14,967,706\n",
            "Trainable params: 14,967,706\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 5.64\n",
            "Params size (MB): 57.10\n",
            "Estimated Total Size (MB): 62.75\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 19:34:23 2022: Epoch [0], Iteration [0/391/], Data(s): 0.064, Loss(s): 0.023, Forward(s): 0.052, Backward(s): 0.225, Top1: 94.531, Top5: 100.0000, Loss: 0.162\n",
            "Mon Apr 25 19:34:39 2022: Epoch [0], Iteration [100/391/], Data(s): 0.062, Loss(s): 0.025, Forward(s): 0.007, Backward(s): 0.015, Top1: 95.111, Top5: 99.8608, Loss: 0.143\n",
            "Mon Apr 25 19:34:57 2022: Epoch [0], Iteration [200/391/], Data(s): 0.062, Loss(s): 0.025, Forward(s): 0.006, Backward(s): 0.014, Top1: 95.056, Top5: 99.8368, Loss: 0.150\n",
            "Mon Apr 25 19:35:14 2022: Epoch [0], Iteration [300/391/], Data(s): 0.063, Loss(s): 0.025, Forward(s): 0.006, Backward(s): 0.014, Top1: 95.206, Top5: 99.8443, Loss: 0.135\n",
            "Mon Apr 25 19:35:29 2022: Epoch [1], Iteration [0/391/], Data(s): 0.100, Loss(s): 0.023, Forward(s): 0.008, Backward(s): 0.014, Top1: 91.406, Top5: 100.0000, Loss: 0.145\n",
            "Mon Apr 25 19:35:46 2022: Epoch [1], Iteration [100/391/], Data(s): 0.064, Loss(s): 0.025, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.429, Top5: 99.8530, Loss: 0.137\n",
            "Mon Apr 25 19:36:03 2022: Epoch [1], Iteration [200/391/], Data(s): 0.063, Loss(s): 0.025, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.503, Top5: 99.8445, Loss: 0.138\n",
            "Mon Apr 25 19:36:20 2022: Epoch [1], Iteration [300/391/], Data(s): 0.063, Loss(s): 0.025, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.336, Top5: 99.8547, Loss: 0.145\n",
            "Mon Apr 25 19:36:36 2022: Epoch [2], Iteration [0/391/], Data(s): 0.097, Loss(s): 0.025, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.312, Top5: 100.0000, Loss: 0.147\n",
            "Mon Apr 25 19:36:53 2022: Epoch [2], Iteration [100/391/], Data(s): 0.064, Loss(s): 0.025, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.769, Top5: 99.9226, Loss: 0.132\n",
            "Mon Apr 25 19:37:10 2022: Epoch [2], Iteration [200/391/], Data(s): 0.063, Loss(s): 0.025, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.530, Top5: 99.8912, Loss: 0.144\n",
            "Mon Apr 25 19:37:27 2022: Epoch [2], Iteration [300/391/], Data(s): 0.063, Loss(s): 0.025, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.627, Top5: 99.8806, Loss: 0.130\n",
            "Mon Apr 25 19:37:42 2022: Epoch [3], Iteration [0/391/], Data(s): 0.109, Loss(s): 0.025, Forward(s): 0.005, Backward(s): 0.012, Top1: 97.656, Top5: 100.0000, Loss: 0.142\n",
            "Mon Apr 25 19:37:59 2022: Epoch [3], Iteration [100/391/], Data(s): 0.064, Loss(s): 0.025, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.475, Top5: 99.9149, Loss: 0.134\n",
            "Mon Apr 25 19:38:16 2022: Epoch [3], Iteration [200/391/], Data(s): 0.064, Loss(s): 0.025, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.511, Top5: 99.8640, Loss: 0.143\n",
            "Mon Apr 25 19:38:33 2022: Epoch [3], Iteration [300/391/], Data(s): 0.064, Loss(s): 0.025, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.603, Top5: 99.8521, Loss: 0.130\n",
            "Mon Apr 25 19:38:49 2022: Epoch [4], Iteration [0/391/], Data(s): 0.098, Loss(s): 0.025, Forward(s): 0.006, Backward(s): 0.012, Top1: 97.656, Top5: 100.0000, Loss: 0.137\n",
            "Mon Apr 25 19:39:06 2022: Epoch [4], Iteration [100/391/], Data(s): 0.066, Loss(s): 0.025, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.777, Top5: 99.8762, Loss: 0.130\n",
            "Mon Apr 25 19:39:23 2022: Epoch [4], Iteration [200/391/], Data(s): 0.064, Loss(s): 0.025, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.515, Top5: 99.8756, Loss: 0.140\n",
            "Mon Apr 25 19:39:40 2022: Epoch [4], Iteration [300/391/], Data(s): 0.064, Loss(s): 0.025, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.528, Top5: 99.8780, Loss: 0.130\n",
            "Mon Apr 25 19:39:56 2022: Epoch [5], Iteration [0/391/], Data(s): 0.080, Loss(s): 0.025, Forward(s): 0.006, Backward(s): 0.012, Top1: 90.625, Top5: 100.0000, Loss: 0.134\n",
            "Mon Apr 25 19:40:13 2022: Epoch [5], Iteration [100/391/], Data(s): 0.065, Loss(s): 0.025, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.630, Top5: 99.8917, Loss: 0.129\n",
            "Mon Apr 25 19:40:30 2022: Epoch [5], Iteration [200/391/], Data(s): 0.063, Loss(s): 0.025, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.608, Top5: 99.8834, Loss: 0.132\n",
            "Mon Apr 25 19:40:47 2022: Epoch [5], Iteration [300/391/], Data(s): 0.063, Loss(s): 0.025, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.608, Top5: 99.8728, Loss: 0.130\n",
            "Mon Apr 25 19:41:02 2022: Epoch [6], Iteration [0/391/], Data(s): 0.085, Loss(s): 0.025, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.531, Top5: 100.0000, Loss: 0.134\n",
            "Mon Apr 25 19:41:20 2022: Epoch [6], Iteration [100/391/], Data(s): 0.064, Loss(s): 0.025, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.343, Top5: 99.8917, Loss: 0.141\n",
            "Mon Apr 25 19:41:37 2022: Epoch [6], Iteration [200/391/], Data(s): 0.064, Loss(s): 0.025, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.612, Top5: 99.8951, Loss: 0.121\n",
            "Mon Apr 25 19:41:54 2022: Epoch [6], Iteration [300/391/], Data(s): 0.063, Loss(s): 0.025, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.653, Top5: 99.8910, Loss: 0.129\n",
            "Mon Apr 25 19:42:09 2022: Epoch [7], Iteration [0/391/], Data(s): 0.093, Loss(s): 0.025, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.094, Top5: 100.0000, Loss: 0.130\n",
            "Mon Apr 25 19:42:26 2022: Epoch [7], Iteration [100/391/], Data(s): 0.064, Loss(s): 0.025, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.583, Top5: 99.8608, Loss: 0.133\n",
            "Mon Apr 25 19:42:43 2022: Epoch [7], Iteration [200/391/], Data(s): 0.063, Loss(s): 0.025, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.690, Top5: 99.8368, Loss: 0.128\n",
            "Mon Apr 25 19:43:00 2022: Epoch [7], Iteration [300/391/], Data(s): 0.063, Loss(s): 0.025, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.725, Top5: 99.8547, Loss: 0.129\n",
            "Mon Apr 25 19:43:16 2022: Epoch [8], Iteration [0/391/], Data(s): 0.086, Loss(s): 0.024, Forward(s): 0.007, Backward(s): 0.013, Top1: 96.094, Top5: 100.0000, Loss: 0.132\n",
            "Mon Apr 25 19:43:33 2022: Epoch [8], Iteration [100/391/], Data(s): 0.065, Loss(s): 0.025, Forward(s): 0.006, Backward(s): 0.014, Top1: 95.568, Top5: 99.9226, Loss: 0.132\n",
            "Mon Apr 25 19:43:50 2022: Epoch [8], Iteration [200/391/], Data(s): 0.063, Loss(s): 0.025, Forward(s): 0.006, Backward(s): 0.014, Top1: 95.662, Top5: 99.9067, Loss: 0.130\n",
            "Mon Apr 25 19:44:06 2022: Epoch [8], Iteration [300/391/], Data(s): 0.063, Loss(s): 0.025, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.738, Top5: 99.8910, Loss: 0.126\n",
            "Mon Apr 25 19:44:22 2022: Epoch [9], Iteration [0/391/], Data(s): 0.090, Loss(s): 0.025, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.531, Top5: 100.0000, Loss: 0.129\n",
            "Mon Apr 25 19:44:39 2022: Epoch [9], Iteration [100/391/], Data(s): 0.063, Loss(s): 0.025, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.955, Top5: 99.8917, Loss: 0.124\n",
            "Mon Apr 25 19:44:56 2022: Epoch [9], Iteration [200/391/], Data(s): 0.063, Loss(s): 0.025, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.981, Top5: 99.9067, Loss: 0.116\n",
            "Mon Apr 25 19:45:13 2022: Epoch [9], Iteration [300/391/], Data(s): 0.062, Loss(s): 0.025, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.977, Top5: 99.9040, Loss: 0.121\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 19:45:35 2022: Test information, Data(s): 2.947, Forward(s): 0.590, Top1: 91.330, Top5: 99.280, \n",
            "\n",
            "Mon Apr 25 19:45:35 2022: conv1 Layer, 48 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 16, 32, 32]             448\n",
            "       BatchNorm2d-2           [-1, 16, 32, 32]              32\n",
            "              ReLU-3           [-1, 16, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]           9,280\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]          73,856\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "             ReLU-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]         147,584\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         295,168\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]       1,180,160\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 14,962,858\n",
            "Trainable params: 14,962,858\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 5.45\n",
            "Params size (MB): 57.08\n",
            "Estimated Total Size (MB): 62.54\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 19:45:36 2022: Epoch [0], Iteration [0/391/], Data(s): 0.071, Loss(s): 0.022, Forward(s): 0.048, Backward(s): 0.187, Top1: 96.094, Top5: 99.2188, Loss: 0.117\n",
            "Mon Apr 25 19:45:53 2022: Epoch [0], Iteration [100/391/], Data(s): 0.063, Loss(s): 0.024, Forward(s): 0.007, Backward(s): 0.015, Top1: 95.258, Top5: 99.8840, Loss: 0.139\n",
            "Mon Apr 25 19:46:10 2022: Epoch [0], Iteration [200/391/], Data(s): 0.063, Loss(s): 0.024, Forward(s): 0.006, Backward(s): 0.014, Top1: 95.106, Top5: 99.8678, Loss: 0.147\n",
            "Mon Apr 25 19:46:27 2022: Epoch [0], Iteration [300/391/], Data(s): 0.062, Loss(s): 0.024, Forward(s): 0.006, Backward(s): 0.014, Top1: 95.271, Top5: 99.8676, Loss: 0.133\n",
            "Mon Apr 25 19:46:42 2022: Epoch [1], Iteration [0/391/], Data(s): 0.085, Loss(s): 0.023, Forward(s): 0.008, Backward(s): 0.014, Top1: 96.094, Top5: 99.2188, Loss: 0.130\n",
            "Mon Apr 25 19:46:59 2022: Epoch [1], Iteration [100/391/], Data(s): 0.064, Loss(s): 0.024, Forward(s): 0.006, Backward(s): 0.014, Top1: 95.738, Top5: 99.8608, Loss: 0.130\n",
            "Mon Apr 25 19:47:16 2022: Epoch [1], Iteration [200/391/], Data(s): 0.063, Loss(s): 0.024, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.841, Top5: 99.8989, Loss: 0.124\n",
            "Mon Apr 25 19:47:33 2022: Epoch [1], Iteration [300/391/], Data(s): 0.063, Loss(s): 0.024, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.819, Top5: 99.8910, Loss: 0.125\n",
            "Mon Apr 25 19:47:49 2022: Epoch [2], Iteration [0/391/], Data(s): 0.094, Loss(s): 0.024, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.094, Top5: 100.0000, Loss: 0.127\n",
            "Mon Apr 25 19:48:06 2022: Epoch [2], Iteration [100/391/], Data(s): 0.063, Loss(s): 0.024, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.808, Top5: 99.8840, Loss: 0.128\n",
            "Mon Apr 25 19:48:22 2022: Epoch [2], Iteration [200/391/], Data(s): 0.063, Loss(s): 0.024, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.826, Top5: 99.8756, Loss: 0.125\n",
            "Mon Apr 25 19:48:39 2022: Epoch [2], Iteration [300/391/], Data(s): 0.062, Loss(s): 0.024, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.767, Top5: 99.8936, Loss: 0.126\n",
            "Mon Apr 25 19:48:55 2022: Epoch [3], Iteration [0/391/], Data(s): 0.085, Loss(s): 0.023, Forward(s): 0.007, Backward(s): 0.013, Top1: 96.875, Top5: 100.0000, Loss: 0.123\n",
            "Mon Apr 25 19:49:12 2022: Epoch [3], Iteration [100/391/], Data(s): 0.064, Loss(s): 0.024, Forward(s): 0.006, Backward(s): 0.014, Top1: 95.746, Top5: 99.8917, Loss: 0.125\n",
            "Mon Apr 25 19:49:28 2022: Epoch [3], Iteration [200/391/], Data(s): 0.063, Loss(s): 0.024, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.837, Top5: 99.9028, Loss: 0.121\n",
            "Mon Apr 25 19:49:45 2022: Epoch [3], Iteration [300/391/], Data(s): 0.063, Loss(s): 0.024, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.847, Top5: 99.8962, Loss: 0.124\n",
            "Mon Apr 25 19:50:01 2022: Epoch [4], Iteration [0/391/], Data(s): 0.091, Loss(s): 0.024, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.312, Top5: 99.2188, Loss: 0.127\n",
            "Mon Apr 25 19:50:18 2022: Epoch [4], Iteration [100/391/], Data(s): 0.064, Loss(s): 0.025, Forward(s): 0.006, Backward(s): 0.013, Top1: 96.094, Top5: 99.8608, Loss: 0.121\n",
            "Mon Apr 25 19:50:35 2022: Epoch [4], Iteration [200/391/], Data(s): 0.064, Loss(s): 0.025, Forward(s): 0.006, Backward(s): 0.013, Top1: 96.109, Top5: 99.9067, Loss: 0.119\n",
            "Mon Apr 25 19:50:51 2022: Epoch [4], Iteration [300/391/], Data(s): 0.063, Loss(s): 0.025, Forward(s): 0.006, Backward(s): 0.013, Top1: 96.151, Top5: 99.9143, Loss: 0.117\n",
            "Mon Apr 25 19:51:07 2022: Epoch [5], Iteration [0/391/], Data(s): 0.084, Loss(s): 0.024, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.875, Top5: 99.2188, Loss: 0.117\n",
            "Mon Apr 25 19:51:24 2022: Epoch [5], Iteration [100/391/], Data(s): 0.065, Loss(s): 0.025, Forward(s): 0.006, Backward(s): 0.013, Top1: 96.287, Top5: 99.9072, Loss: 0.112\n",
            "Mon Apr 25 19:51:41 2022: Epoch [5], Iteration [200/391/], Data(s): 0.064, Loss(s): 0.025, Forward(s): 0.006, Backward(s): 0.013, Top1: 96.171, Top5: 99.9145, Loss: 0.117\n",
            "Mon Apr 25 19:51:58 2022: Epoch [5], Iteration [300/391/], Data(s): 0.063, Loss(s): 0.024, Forward(s): 0.006, Backward(s): 0.013, Top1: 96.063, Top5: 99.9118, Loss: 0.124\n",
            "Mon Apr 25 19:52:13 2022: Epoch [6], Iteration [0/391/], Data(s): 0.084, Loss(s): 0.025, Forward(s): 0.006, Backward(s): 0.013, Top1: 98.438, Top5: 100.0000, Loss: 0.116\n",
            "Mon Apr 25 19:52:30 2022: Epoch [6], Iteration [100/391/], Data(s): 0.063, Loss(s): 0.024, Forward(s): 0.006, Backward(s): 0.013, Top1: 96.473, Top5: 99.9304, Loss: 0.109\n",
            "Mon Apr 25 19:52:47 2022: Epoch [6], Iteration [200/391/], Data(s): 0.062, Loss(s): 0.025, Forward(s): 0.006, Backward(s): 0.013, Top1: 96.358, Top5: 99.9378, Loss: 0.116\n",
            "Mon Apr 25 19:53:03 2022: Epoch [6], Iteration [300/391/], Data(s): 0.062, Loss(s): 0.025, Forward(s): 0.006, Backward(s): 0.013, Top1: 96.275, Top5: 99.9377, Loss: 0.115\n",
            "Mon Apr 25 19:53:19 2022: Epoch [7], Iteration [0/391/], Data(s): 0.083, Loss(s): 0.024, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.312, Top5: 100.0000, Loss: 0.117\n",
            "Mon Apr 25 19:53:36 2022: Epoch [7], Iteration [100/391/], Data(s): 0.064, Loss(s): 0.024, Forward(s): 0.006, Backward(s): 0.013, Top1: 96.496, Top5: 99.9381, Loss: 0.107\n",
            "Mon Apr 25 19:53:53 2022: Epoch [7], Iteration [200/391/], Data(s): 0.063, Loss(s): 0.024, Forward(s): 0.006, Backward(s): 0.013, Top1: 96.436, Top5: 99.9378, Loss: 0.109\n",
            "Mon Apr 25 19:54:10 2022: Epoch [7], Iteration [300/391/], Data(s): 0.063, Loss(s): 0.024, Forward(s): 0.006, Backward(s): 0.013, Top1: 96.322, Top5: 99.9143, Loss: 0.120\n",
            "Mon Apr 25 19:54:25 2022: Epoch [8], Iteration [0/391/], Data(s): 0.090, Loss(s): 0.025, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.094, Top5: 100.0000, Loss: 0.121\n",
            "Mon Apr 25 19:54:42 2022: Epoch [8], Iteration [100/391/], Data(s): 0.064, Loss(s): 0.025, Forward(s): 0.006, Backward(s): 0.013, Top1: 96.256, Top5: 99.9459, Loss: 0.111\n",
            "Mon Apr 25 19:54:59 2022: Epoch [8], Iteration [200/391/], Data(s): 0.063, Loss(s): 0.025, Forward(s): 0.006, Backward(s): 0.013, Top1: 96.381, Top5: 99.9300, Loss: 0.108\n",
            "Mon Apr 25 19:55:16 2022: Epoch [8], Iteration [300/391/], Data(s): 0.063, Loss(s): 0.025, Forward(s): 0.006, Backward(s): 0.013, Top1: 96.195, Top5: 99.9299, Loss: 0.120\n",
            "Mon Apr 25 19:55:31 2022: Epoch [9], Iteration [0/391/], Data(s): 0.093, Loss(s): 0.024, Forward(s): 0.006, Backward(s): 0.013, Top1: 94.531, Top5: 100.0000, Loss: 0.109\n",
            "Mon Apr 25 19:55:48 2022: Epoch [9], Iteration [100/391/], Data(s): 0.064, Loss(s): 0.025, Forward(s): 0.006, Backward(s): 0.013, Top1: 96.303, Top5: 99.9149, Loss: 0.108\n",
            "Mon Apr 25 19:56:05 2022: Epoch [9], Iteration [200/391/], Data(s): 0.063, Loss(s): 0.025, Forward(s): 0.006, Backward(s): 0.013, Top1: 96.346, Top5: 99.9028, Loss: 0.113\n",
            "Mon Apr 25 19:56:22 2022: Epoch [9], Iteration [300/391/], Data(s): 0.063, Loss(s): 0.025, Forward(s): 0.006, Backward(s): 0.013, Top1: 96.333, Top5: 99.9092, Loss: 0.110\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 19:56:44 2022: Test information, Data(s): 3.027, Forward(s): 0.588, Top1: 91.320, Top5: 99.320, \n",
            "\n",
            "Mon Apr 25 19:56:44 2022: conv1 Layer, 57 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(7, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1            [-1, 7, 32, 32]             196\n",
            "       BatchNorm2d-2            [-1, 7, 32, 32]              14\n",
            "              ReLU-3            [-1, 7, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]           4,096\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]          73,856\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "             ReLU-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]         147,584\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         295,168\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]       1,180,160\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 14,957,404\n",
            "Trainable params: 14,957,404\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 5.24\n",
            "Params size (MB): 57.06\n",
            "Estimated Total Size (MB): 62.31\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(7, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 19:56:45 2022: Epoch [0], Iteration [0/391/], Data(s): 0.065, Loss(s): 0.022, Forward(s): 0.039, Backward(s): 0.174, Top1: 94.531, Top5: 99.2188, Loss: 0.277\n",
            "Mon Apr 25 19:57:02 2022: Epoch [0], Iteration [100/391/], Data(s): 0.064, Loss(s): 0.024, Forward(s): 0.006, Backward(s): 0.014, Top1: 93.062, Top5: 99.7679, Loss: 0.207\n",
            "Mon Apr 25 19:57:18 2022: Epoch [0], Iteration [200/391/], Data(s): 0.063, Loss(s): 0.024, Forward(s): 0.006, Backward(s): 0.013, Top1: 93.734, Top5: 99.7435, Loss: 0.169\n",
            "Mon Apr 25 19:57:34 2022: Epoch [0], Iteration [300/391/], Data(s): 0.062, Loss(s): 0.024, Forward(s): 0.006, Backward(s): 0.013, Top1: 94.199, Top5: 99.7768, Loss: 0.148\n",
            "Mon Apr 25 19:57:49 2022: Epoch [1], Iteration [0/391/], Data(s): 0.088, Loss(s): 0.022, Forward(s): 0.007, Backward(s): 0.013, Top1: 96.875, Top5: 99.2188, Loss: 0.149\n",
            "Mon Apr 25 19:58:06 2022: Epoch [1], Iteration [100/391/], Data(s): 0.064, Loss(s): 0.024, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.235, Top5: 99.8144, Loss: 0.141\n",
            "Mon Apr 25 19:58:22 2022: Epoch [1], Iteration [200/391/], Data(s): 0.063, Loss(s): 0.024, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.316, Top5: 99.8368, Loss: 0.134\n",
            "Mon Apr 25 19:58:38 2022: Epoch [1], Iteration [300/391/], Data(s): 0.062, Loss(s): 0.024, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.398, Top5: 99.8469, Loss: 0.132\n",
            "Mon Apr 25 19:58:54 2022: Epoch [2], Iteration [0/391/], Data(s): 0.084, Loss(s): 0.023, Forward(s): 0.006, Backward(s): 0.022, Top1: 94.531, Top5: 100.0000, Loss: 0.130\n",
            "Mon Apr 25 19:59:10 2022: Epoch [2], Iteration [100/391/], Data(s): 0.063, Loss(s): 0.024, Forward(s): 0.006, Backward(s): 0.013, Top1: 96.140, Top5: 99.9381, Loss: 0.116\n",
            "Mon Apr 25 19:59:26 2022: Epoch [2], Iteration [200/391/], Data(s): 0.062, Loss(s): 0.024, Forward(s): 0.006, Backward(s): 0.013, Top1: 96.125, Top5: 99.9300, Loss: 0.121\n",
            "Mon Apr 25 19:59:43 2022: Epoch [2], Iteration [300/391/], Data(s): 0.062, Loss(s): 0.024, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.954, Top5: 99.9429, Loss: 0.130\n",
            "Mon Apr 25 19:59:58 2022: Epoch [3], Iteration [0/391/], Data(s): 0.087, Loss(s): 0.023, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.094, Top5: 100.0000, Loss: 0.122\n",
            "Mon Apr 25 20:00:14 2022: Epoch [3], Iteration [100/391/], Data(s): 0.064, Loss(s): 0.024, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.947, Top5: 99.8840, Loss: 0.116\n",
            "Mon Apr 25 20:00:31 2022: Epoch [3], Iteration [200/391/], Data(s): 0.063, Loss(s): 0.024, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.965, Top5: 99.9028, Loss: 0.123\n",
            "Mon Apr 25 20:00:47 2022: Epoch [3], Iteration [300/391/], Data(s): 0.063, Loss(s): 0.024, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.977, Top5: 99.8910, Loss: 0.120\n",
            "Mon Apr 25 20:01:02 2022: Epoch [4], Iteration [0/391/], Data(s): 0.077, Loss(s): 0.024, Forward(s): 0.006, Backward(s): 0.012, Top1: 98.438, Top5: 100.0000, Loss: 0.116\n",
            "Mon Apr 25 20:01:18 2022: Epoch [4], Iteration [100/391/], Data(s): 0.063, Loss(s): 0.023, Forward(s): 0.006, Backward(s): 0.013, Top1: 96.241, Top5: 99.9072, Loss: 0.105\n",
            "Mon Apr 25 20:01:35 2022: Epoch [4], Iteration [200/391/], Data(s): 0.063, Loss(s): 0.024, Forward(s): 0.006, Backward(s): 0.013, Top1: 96.137, Top5: 99.9067, Loss: 0.115\n",
            "Mon Apr 25 20:01:51 2022: Epoch [4], Iteration [300/391/], Data(s): 0.063, Loss(s): 0.024, Forward(s): 0.006, Backward(s): 0.013, Top1: 96.203, Top5: 99.9092, Loss: 0.110\n",
            "Mon Apr 25 20:02:06 2022: Epoch [5], Iteration [0/391/], Data(s): 0.087, Loss(s): 0.023, Forward(s): 0.006, Backward(s): 0.013, Top1: 97.656, Top5: 100.0000, Loss: 0.114\n",
            "Mon Apr 25 20:02:23 2022: Epoch [5], Iteration [100/391/], Data(s): 0.064, Loss(s): 0.023, Forward(s): 0.006, Backward(s): 0.013, Top1: 96.450, Top5: 99.9149, Loss: 0.106\n",
            "Mon Apr 25 20:02:39 2022: Epoch [5], Iteration [200/391/], Data(s): 0.063, Loss(s): 0.024, Forward(s): 0.006, Backward(s): 0.013, Top1: 96.296, Top5: 99.9495, Loss: 0.112\n",
            "Mon Apr 25 20:02:55 2022: Epoch [5], Iteration [300/391/], Data(s): 0.062, Loss(s): 0.024, Forward(s): 0.006, Backward(s): 0.013, Top1: 96.320, Top5: 99.9247, Loss: 0.108\n",
            "Mon Apr 25 20:03:10 2022: Epoch [6], Iteration [0/391/], Data(s): 0.080, Loss(s): 0.024, Forward(s): 0.006, Backward(s): 0.022, Top1: 94.531, Top5: 100.0000, Loss: 0.110\n",
            "Mon Apr 25 20:03:27 2022: Epoch [6], Iteration [100/391/], Data(s): 0.063, Loss(s): 0.023, Forward(s): 0.006, Backward(s): 0.013, Top1: 96.264, Top5: 99.9072, Loss: 0.112\n",
            "Mon Apr 25 20:03:43 2022: Epoch [6], Iteration [200/391/], Data(s): 0.062, Loss(s): 0.024, Forward(s): 0.006, Backward(s): 0.013, Top1: 96.467, Top5: 99.9106, Loss: 0.104\n",
            "Mon Apr 25 20:03:59 2022: Epoch [6], Iteration [300/391/], Data(s): 0.062, Loss(s): 0.024, Forward(s): 0.006, Backward(s): 0.013, Top1: 96.436, Top5: 99.9092, Loss: 0.108\n",
            "Mon Apr 25 20:04:14 2022: Epoch [7], Iteration [0/391/], Data(s): 0.083, Loss(s): 0.024, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.312, Top5: 100.0000, Loss: 0.110\n",
            "Mon Apr 25 20:04:31 2022: Epoch [7], Iteration [100/391/], Data(s): 0.064, Loss(s): 0.024, Forward(s): 0.006, Backward(s): 0.013, Top1: 96.202, Top5: 99.9381, Loss: 0.108\n",
            "Mon Apr 25 20:04:47 2022: Epoch [7], Iteration [200/391/], Data(s): 0.063, Loss(s): 0.024, Forward(s): 0.006, Backward(s): 0.013, Top1: 96.276, Top5: 99.9223, Loss: 0.106\n",
            "Mon Apr 25 20:05:03 2022: Epoch [7], Iteration [300/391/], Data(s): 0.062, Loss(s): 0.024, Forward(s): 0.006, Backward(s): 0.013, Top1: 96.358, Top5: 99.9351, Loss: 0.101\n",
            "Mon Apr 25 20:05:18 2022: Epoch [8], Iteration [0/391/], Data(s): 0.088, Loss(s): 0.023, Forward(s): 0.006, Backward(s): 0.012, Top1: 97.656, Top5: 100.0000, Loss: 0.103\n",
            "Mon Apr 25 20:05:35 2022: Epoch [8], Iteration [100/391/], Data(s): 0.064, Loss(s): 0.024, Forward(s): 0.006, Backward(s): 0.013, Top1: 96.674, Top5: 99.9536, Loss: 0.100\n",
            "Mon Apr 25 20:05:51 2022: Epoch [8], Iteration [200/391/], Data(s): 0.063, Loss(s): 0.024, Forward(s): 0.006, Backward(s): 0.013, Top1: 96.692, Top5: 99.9456, Loss: 0.101\n",
            "Mon Apr 25 20:06:07 2022: Epoch [8], Iteration [300/391/], Data(s): 0.062, Loss(s): 0.024, Forward(s): 0.006, Backward(s): 0.013, Top1: 96.688, Top5: 99.9377, Loss: 0.102\n",
            "Mon Apr 25 20:06:22 2022: Epoch [9], Iteration [0/391/], Data(s): 0.082, Loss(s): 0.022, Forward(s): 0.008, Backward(s): 0.012, Top1: 96.094, Top5: 100.0000, Loss: 0.103\n",
            "Mon Apr 25 20:06:39 2022: Epoch [9], Iteration [100/391/], Data(s): 0.063, Loss(s): 0.024, Forward(s): 0.006, Backward(s): 0.013, Top1: 96.883, Top5: 99.9613, Loss: 0.095\n",
            "Mon Apr 25 20:06:55 2022: Epoch [9], Iteration [200/391/], Data(s): 0.062, Loss(s): 0.024, Forward(s): 0.006, Backward(s): 0.013, Top1: 96.836, Top5: 99.9650, Loss: 0.095\n",
            "Mon Apr 25 20:07:11 2022: Epoch [9], Iteration [300/391/], Data(s): 0.062, Loss(s): 0.024, Forward(s): 0.006, Backward(s): 0.013, Top1: 96.699, Top5: 99.9351, Loss: 0.105\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 20:07:32 2022: Test information, Data(s): 2.933, Forward(s): 0.583, Top1: 91.250, Top5: 99.290, \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top1_accuracies"
      ],
      "metadata": {
        "id": "tgadXIEP_wtk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c3e344f-e7ab-4219-86fc-f7aac281b9b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'conv1': [90.0, 90.58, 91.01, 91.2, 91.33, 91.32, 91.25]}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top5_accuracies"
      ],
      "metadata": {
        "id": "UjRdxImr_wrH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63ba4609-5dd3-4652-aaef-d7f85315ee8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'conv1': [99.25, 99.3, 99.32, 99.31, 99.28, 99.32, 99.29]}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top1_accuracies = {}\n",
        "top5_accuracies = {}"
      ],
      "metadata": {
        "id": "tJubP2tkrF6V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for conv, channel in zip(prune_layers[4:6], prune_channels[4:6]):    \n",
        "    top1_accuracies[conv] = []\n",
        "    top5_accuracies[conv] = []\n",
        "    \n",
        "    # load new network and check accuracy\n",
        "    network, _, _ = test_network(args, data_set=test_set)\n",
        "        \n",
        "    # remove 0 channels ~ M (max_channel_ratio) % of total channels\n",
        "    step = np.linspace(0, int(channel*max_channel_ratio), int(1/prune_step_ratio), dtype=np.int)\n",
        "    steps = (step[1:] - step[:-1]).tolist()\n",
        "    \n",
        "    for i in range(len(steps)):\n",
        "        print(\"\\n%s: %s Layer, %d Channels pruned\"%(time.ctime(), conv, sum(steps[:i+1])))\n",
        "        \n",
        "        # set prune information\n",
        "        args.prune_layers = [conv]\n",
        "        args.prune_channels =[steps[i]]\n",
        "\n",
        "        network = prune_network(args, network)\n",
        "        \n",
        "        network, _, (top1, top5) = test_network(args, network, test_set)\n",
        "            \n",
        "        top1_accuracies[conv].append(top1)\n",
        "        top5_accuracies[conv].append(top5)"
      ],
      "metadata": {
        "id": "Icm1wV98ADMS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3be038a-25d8-4989-86a9-1a11ce67c5c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 14:33:44 2022: Test information, Data(s): 2.768, Forward(s): 0.539, Top1: 77.870, Top5: 97.560, \n",
            "\n",
            "Mon Apr 25 14:33:44 2022: conv5 Layer, 32 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(224, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]          73,856\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "             ReLU-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]         147,584\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15            [-1, 224, 8, 8]         258,272\n",
            "      BatchNorm2d-16            [-1, 224, 8, 8]             448\n",
            "             ReLU-17            [-1, 224, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         516,352\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]       1,180,160\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 14,881,258\n",
            "Trainable params: 14,881,258\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 6.53\n",
            "Params size (MB): 56.77\n",
            "Estimated Total Size (MB): 63.31\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(224, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  if __name__ == '__main__':\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 14:33:48 2022: Epoch [0], Iteration [0/391/], Data(s): 0.071, Loss(s): 0.012, Forward(s): 0.912, Backward(s): 1.528, Top1: 83.594, Top5: 99.2188, Loss: 0.542\n",
            "Mon Apr 25 14:34:05 2022: Epoch [0], Iteration [100/391/], Data(s): 0.057, Loss(s): 0.028, Forward(s): 0.015, Backward(s): 0.029, Top1: 86.618, Top5: 98.8320, Loss: 0.414\n",
            "Mon Apr 25 14:34:22 2022: Epoch [0], Iteration [200/391/], Data(s): 0.056, Loss(s): 0.028, Forward(s): 0.011, Backward(s): 0.021, Top1: 87.554, Top5: 98.9817, Loss: 0.354\n",
            "Mon Apr 25 14:34:39 2022: Epoch [0], Iteration [300/391/], Data(s): 0.057, Loss(s): 0.028, Forward(s): 0.010, Backward(s): 0.019, Top1: 88.071, Top5: 99.0474, Loss: 0.337\n",
            "Mon Apr 25 14:34:56 2022: Epoch [1], Iteration [0/391/], Data(s): 0.062, Loss(s): 0.032, Forward(s): 0.007, Backward(s): 0.013, Top1: 89.844, Top5: 99.2188, Loss: 0.320\n",
            "Mon Apr 25 14:35:13 2022: Epoch [1], Iteration [100/391/], Data(s): 0.058, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.014, Top1: 89.751, Top5: 99.3502, Loss: 0.309\n",
            "Mon Apr 25 14:35:30 2022: Epoch [1], Iteration [200/391/], Data(s): 0.057, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.014, Top1: 90.015, Top5: 99.3159, Loss: 0.304\n",
            "Mon Apr 25 14:35:47 2022: Epoch [1], Iteration [300/391/], Data(s): 0.057, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.014, Top1: 90.160, Top5: 99.3355, Loss: 0.303\n",
            "Mon Apr 25 14:36:02 2022: Epoch [2], Iteration [0/391/], Data(s): 0.091, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.013, Top1: 91.406, Top5: 100.0000, Loss: 0.294\n",
            "Mon Apr 25 14:36:19 2022: Epoch [2], Iteration [100/391/], Data(s): 0.059, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.014, Top1: 90.981, Top5: 99.4199, Loss: 0.285\n",
            "Mon Apr 25 14:36:36 2022: Epoch [2], Iteration [200/391/], Data(s): 0.058, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.014, Top1: 90.808, Top5: 99.4403, Loss: 0.289\n",
            "Mon Apr 25 14:36:53 2022: Epoch [2], Iteration [300/391/], Data(s): 0.057, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.014, Top1: 90.918, Top5: 99.4731, Loss: 0.276\n",
            "Mon Apr 25 14:37:08 2022: Epoch [3], Iteration [0/391/], Data(s): 0.090, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.012, Top1: 90.625, Top5: 97.6562, Loss: 0.286\n",
            "Mon Apr 25 14:37:25 2022: Epoch [3], Iteration [100/391/], Data(s): 0.059, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.014, Top1: 91.306, Top5: 99.4276, Loss: 0.271\n",
            "Mon Apr 25 14:37:42 2022: Epoch [3], Iteration [200/391/], Data(s): 0.058, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.014, Top1: 91.344, Top5: 99.4675, Loss: 0.265\n",
            "Mon Apr 25 14:37:59 2022: Epoch [3], Iteration [300/391/], Data(s): 0.057, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.014, Top1: 91.328, Top5: 99.4835, Loss: 0.270\n",
            "Mon Apr 25 14:38:14 2022: Epoch [4], Iteration [0/391/], Data(s): 0.090, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.014, Top1: 89.844, Top5: 99.2188, Loss: 0.262\n",
            "Mon Apr 25 14:38:31 2022: Epoch [4], Iteration [100/391/], Data(s): 0.058, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.014, Top1: 91.422, Top5: 99.4817, Loss: 0.264\n",
            "Mon Apr 25 14:38:48 2022: Epoch [4], Iteration [200/391/], Data(s): 0.057, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.014, Top1: 91.546, Top5: 99.5103, Loss: 0.261\n",
            "Mon Apr 25 14:39:05 2022: Epoch [4], Iteration [300/391/], Data(s): 0.057, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.014, Top1: 91.650, Top5: 99.4991, Loss: 0.258\n",
            "Mon Apr 25 14:39:20 2022: Epoch [5], Iteration [0/391/], Data(s): 0.079, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.013, Top1: 92.969, Top5: 99.2188, Loss: 0.259\n",
            "Mon Apr 25 14:39:37 2022: Epoch [5], Iteration [100/391/], Data(s): 0.057, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.014, Top1: 92.025, Top5: 99.5668, Loss: 0.249\n",
            "Mon Apr 25 14:39:54 2022: Epoch [5], Iteration [200/391/], Data(s): 0.057, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.014, Top1: 92.048, Top5: 99.5802, Loss: 0.242\n",
            "Mon Apr 25 14:40:11 2022: Epoch [5], Iteration [300/391/], Data(s): 0.056, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.014, Top1: 92.097, Top5: 99.6029, Loss: 0.245\n",
            "Mon Apr 25 14:40:26 2022: Epoch [6], Iteration [0/391/], Data(s): 0.076, Loss(s): 0.029, Forward(s): 0.006, Backward(s): 0.013, Top1: 92.969, Top5: 98.4375, Loss: 0.244\n",
            "Mon Apr 25 14:40:43 2022: Epoch [6], Iteration [100/391/], Data(s): 0.057, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.014, Top1: 92.319, Top5: 99.5591, Loss: 0.244\n",
            "Mon Apr 25 14:41:00 2022: Epoch [6], Iteration [200/391/], Data(s): 0.057, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.014, Top1: 91.958, Top5: 99.5258, Loss: 0.256\n",
            "Mon Apr 25 14:41:17 2022: Epoch [6], Iteration [300/391/], Data(s): 0.056, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.014, Top1: 92.040, Top5: 99.5458, Loss: 0.244\n",
            "Mon Apr 25 14:41:32 2022: Epoch [7], Iteration [0/391/], Data(s): 0.076, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.013, Top1: 90.625, Top5: 100.0000, Loss: 0.241\n",
            "Mon Apr 25 14:41:49 2022: Epoch [7], Iteration [100/391/], Data(s): 0.057, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.014, Top1: 92.481, Top5: 99.5668, Loss: 0.229\n",
            "Mon Apr 25 14:42:06 2022: Epoch [7], Iteration [200/391/], Data(s): 0.057, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.014, Top1: 92.331, Top5: 99.5647, Loss: 0.240\n",
            "Mon Apr 25 14:42:22 2022: Epoch [7], Iteration [300/391/], Data(s): 0.056, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.014, Top1: 92.193, Top5: 99.5640, Loss: 0.246\n",
            "Mon Apr 25 14:42:38 2022: Epoch [8], Iteration [0/391/], Data(s): 0.089, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.013, Top1: 92.188, Top5: 99.2188, Loss: 0.233\n",
            "Mon Apr 25 14:42:55 2022: Epoch [8], Iteration [100/391/], Data(s): 0.057, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.014, Top1: 92.489, Top5: 99.6364, Loss: 0.229\n",
            "Mon Apr 25 14:43:12 2022: Epoch [8], Iteration [200/391/], Data(s): 0.057, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.014, Top1: 92.518, Top5: 99.6191, Loss: 0.234\n",
            "Mon Apr 25 14:43:28 2022: Epoch [8], Iteration [300/391/], Data(s): 0.056, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.014, Top1: 92.585, Top5: 99.6133, Loss: 0.229\n",
            "Mon Apr 25 14:43:44 2022: Epoch [9], Iteration [0/391/], Data(s): 0.091, Loss(s): 0.029, Forward(s): 0.006, Backward(s): 0.013, Top1: 91.406, Top5: 99.2188, Loss: 0.231\n",
            "Mon Apr 25 14:44:01 2022: Epoch [9], Iteration [100/391/], Data(s): 0.059, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.014, Top1: 92.551, Top5: 99.6055, Loss: 0.229\n",
            "Mon Apr 25 14:44:18 2022: Epoch [9], Iteration [200/391/], Data(s): 0.057, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.014, Top1: 92.448, Top5: 99.6385, Loss: 0.229\n",
            "Mon Apr 25 14:44:34 2022: Epoch [9], Iteration [300/391/], Data(s): 0.057, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.014, Top1: 92.668, Top5: 99.6133, Loss: 0.218\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 14:44:57 2022: Test information, Data(s): 2.778, Forward(s): 0.657, Top1: 89.720, Top5: 99.300, \n",
            "\n",
            "Mon Apr 25 14:44:57 2022: conv5 Layer, 65 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 191, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(191, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(191, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]          73,856\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "             ReLU-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]         147,584\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15            [-1, 191, 8, 8]         220,223\n",
            "      BatchNorm2d-16            [-1, 191, 8, 8]             382\n",
            "             ReLU-17            [-1, 191, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         440,320\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]       1,180,160\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 14,767,111\n",
            "Trainable params: 14,767,111\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 6.48\n",
            "Params size (MB): 56.33\n",
            "Estimated Total Size (MB): 62.82\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 191, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(191, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(191, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 14:44:59 2022: Epoch [0], Iteration [0/391/], Data(s): 0.072, Loss(s): 0.013, Forward(s): 0.099, Backward(s): 0.243, Top1: 90.625, Top5: 99.2188, Loss: 0.288\n",
            "Mon Apr 25 14:45:15 2022: Epoch [0], Iteration [100/391/], Data(s): 0.058, Loss(s): 0.028, Forward(s): 0.008, Backward(s): 0.016, Top1: 92.350, Top5: 99.6364, Loss: 0.232\n",
            "Mon Apr 25 14:45:32 2022: Epoch [0], Iteration [200/391/], Data(s): 0.057, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.015, Top1: 92.207, Top5: 99.6269, Loss: 0.233\n",
            "Mon Apr 25 14:45:49 2022: Epoch [0], Iteration [300/391/], Data(s): 0.057, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.014, Top1: 92.325, Top5: 99.6159, Loss: 0.230\n",
            "Mon Apr 25 14:46:04 2022: Epoch [1], Iteration [0/391/], Data(s): 0.075, Loss(s): 0.031, Forward(s): 0.007, Backward(s): 0.013, Top1: 97.656, Top5: 100.0000, Loss: 0.228\n",
            "Mon Apr 25 14:46:21 2022: Epoch [1], Iteration [100/391/], Data(s): 0.058, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.014, Top1: 92.783, Top5: 99.6519, Loss: 0.225\n",
            "Mon Apr 25 14:46:38 2022: Epoch [1], Iteration [200/391/], Data(s): 0.057, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.013, Top1: 92.681, Top5: 99.6463, Loss: 0.223\n",
            "Mon Apr 25 14:46:54 2022: Epoch [1], Iteration [300/391/], Data(s): 0.057, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.013, Top1: 92.764, Top5: 99.6522, Loss: 0.217\n",
            "Mon Apr 25 14:47:10 2022: Epoch [2], Iteration [0/391/], Data(s): 0.076, Loss(s): 0.029, Forward(s): 0.006, Backward(s): 0.012, Top1: 89.062, Top5: 99.2188, Loss: 0.223\n",
            "Mon Apr 25 14:47:26 2022: Epoch [2], Iteration [100/391/], Data(s): 0.058, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.014, Top1: 92.814, Top5: 99.6287, Loss: 0.218\n",
            "Mon Apr 25 14:47:43 2022: Epoch [2], Iteration [200/391/], Data(s): 0.057, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.014, Top1: 92.860, Top5: 99.6346, Loss: 0.215\n",
            "Mon Apr 25 14:48:00 2022: Epoch [2], Iteration [300/391/], Data(s): 0.056, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.014, Top1: 92.881, Top5: 99.6392, Loss: 0.216\n",
            "Mon Apr 25 14:48:15 2022: Epoch [3], Iteration [0/391/], Data(s): 0.101, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.013, Top1: 92.969, Top5: 100.0000, Loss: 0.229\n",
            "Mon Apr 25 14:48:32 2022: Epoch [3], Iteration [100/391/], Data(s): 0.057, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.014, Top1: 92.915, Top5: 99.7215, Loss: 0.206\n",
            "Mon Apr 25 14:48:48 2022: Epoch [3], Iteration [200/391/], Data(s): 0.056, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.014, Top1: 93.120, Top5: 99.7240, Loss: 0.209\n",
            "Mon Apr 25 14:49:05 2022: Epoch [3], Iteration [300/391/], Data(s): 0.056, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.013, Top1: 92.948, Top5: 99.6911, Loss: 0.225\n",
            "Mon Apr 25 14:49:20 2022: Epoch [4], Iteration [0/391/], Data(s): 0.080, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.014, Top1: 93.750, Top5: 100.0000, Loss: 0.211\n",
            "Mon Apr 25 14:49:37 2022: Epoch [4], Iteration [100/391/], Data(s): 0.056, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.014, Top1: 92.969, Top5: 99.6829, Loss: 0.213\n",
            "Mon Apr 25 14:49:53 2022: Epoch [4], Iteration [200/391/], Data(s): 0.056, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.014, Top1: 93.070, Top5: 99.6968, Loss: 0.210\n",
            "Mon Apr 25 14:50:10 2022: Epoch [4], Iteration [300/391/], Data(s): 0.056, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.014, Top1: 93.104, Top5: 99.7041, Loss: 0.208\n",
            "Mon Apr 25 14:50:25 2022: Epoch [5], Iteration [0/391/], Data(s): 0.087, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.014, Top1: 91.406, Top5: 100.0000, Loss: 0.205\n",
            "Mon Apr 25 14:50:42 2022: Epoch [5], Iteration [100/391/], Data(s): 0.058, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.014, Top1: 93.379, Top5: 99.7215, Loss: 0.195\n",
            "Mon Apr 25 14:50:58 2022: Epoch [5], Iteration [200/391/], Data(s): 0.057, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.013, Top1: 93.291, Top5: 99.6852, Loss: 0.206\n",
            "Mon Apr 25 14:51:15 2022: Epoch [5], Iteration [300/391/], Data(s): 0.056, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.013, Top1: 93.192, Top5: 99.6678, Loss: 0.214\n",
            "Mon Apr 25 14:51:30 2022: Epoch [6], Iteration [0/391/], Data(s): 0.087, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.013, Top1: 94.531, Top5: 100.0000, Loss: 0.203\n",
            "Mon Apr 25 14:51:47 2022: Epoch [6], Iteration [100/391/], Data(s): 0.057, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.014, Top1: 93.000, Top5: 99.7602, Loss: 0.208\n",
            "Mon Apr 25 14:52:03 2022: Epoch [6], Iteration [200/391/], Data(s): 0.056, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.014, Top1: 93.225, Top5: 99.7318, Loss: 0.201\n",
            "Mon Apr 25 14:52:20 2022: Epoch [6], Iteration [300/391/], Data(s): 0.055, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.013, Top1: 93.340, Top5: 99.7223, Loss: 0.195\n",
            "Mon Apr 25 14:52:35 2022: Epoch [7], Iteration [0/391/], Data(s): 0.078, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.020, Top1: 93.750, Top5: 100.0000, Loss: 0.197\n",
            "Mon Apr 25 14:52:52 2022: Epoch [7], Iteration [100/391/], Data(s): 0.057, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.014, Top1: 93.920, Top5: 99.7679, Loss: 0.190\n",
            "Mon Apr 25 14:53:08 2022: Epoch [7], Iteration [200/391/], Data(s): 0.056, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.013, Top1: 93.649, Top5: 99.7629, Loss: 0.198\n",
            "Mon Apr 25 14:53:25 2022: Epoch [7], Iteration [300/391/], Data(s): 0.056, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.013, Top1: 93.498, Top5: 99.7456, Loss: 0.204\n",
            "Mon Apr 25 14:53:40 2022: Epoch [8], Iteration [0/391/], Data(s): 0.080, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.018, Top1: 92.188, Top5: 100.0000, Loss: 0.200\n",
            "Mon Apr 25 14:53:57 2022: Epoch [8], Iteration [100/391/], Data(s): 0.057, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.014, Top1: 93.386, Top5: 99.7061, Loss: 0.202\n",
            "Mon Apr 25 14:54:13 2022: Epoch [8], Iteration [200/391/], Data(s): 0.056, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.014, Top1: 93.606, Top5: 99.7124, Loss: 0.191\n",
            "Mon Apr 25 14:54:30 2022: Epoch [8], Iteration [300/391/], Data(s): 0.056, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.013, Top1: 93.472, Top5: 99.7171, Loss: 0.205\n",
            "Mon Apr 25 14:54:45 2022: Epoch [9], Iteration [0/391/], Data(s): 0.077, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 92.969, Top5: 99.2188, Loss: 0.198\n",
            "Mon Apr 25 14:55:02 2022: Epoch [9], Iteration [100/391/], Data(s): 0.056, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.014, Top1: 93.727, Top5: 99.7679, Loss: 0.191\n",
            "Mon Apr 25 14:55:18 2022: Epoch [9], Iteration [200/391/], Data(s): 0.055, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.014, Top1: 93.742, Top5: 99.7707, Loss: 0.189\n",
            "Mon Apr 25 14:55:35 2022: Epoch [9], Iteration [300/391/], Data(s): 0.055, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.014, Top1: 93.755, Top5: 99.7690, Loss: 0.187\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 14:55:57 2022: Test information, Data(s): 2.701, Forward(s): 0.654, Top1: 90.540, Top5: 99.290, \n",
            "\n",
            "Mon Apr 25 14:55:57 2022: conv5 Layer, 98 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 158, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(158, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(158, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]          73,856\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "             ReLU-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]         147,584\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15            [-1, 158, 8, 8]         182,174\n",
            "      BatchNorm2d-16            [-1, 158, 8, 8]             316\n",
            "             ReLU-17            [-1, 158, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         364,288\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]       1,180,160\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 14,652,964\n",
            "Trainable params: 14,652,964\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 6.43\n",
            "Params size (MB): 55.90\n",
            "Estimated Total Size (MB): 62.34\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 158, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(158, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(158, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 14:55:58 2022: Epoch [0], Iteration [0/391/], Data(s): 0.058, Loss(s): 0.013, Forward(s): 0.121, Backward(s): 0.227, Top1: 92.969, Top5: 100.0000, Loss: 0.215\n",
            "Mon Apr 25 14:56:15 2022: Epoch [0], Iteration [100/391/], Data(s): 0.057, Loss(s): 0.027, Forward(s): 0.008, Backward(s): 0.016, Top1: 93.154, Top5: 99.7061, Loss: 0.204\n",
            "Mon Apr 25 14:56:31 2022: Epoch [0], Iteration [200/391/], Data(s): 0.056, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.015, Top1: 93.194, Top5: 99.6735, Loss: 0.211\n",
            "Mon Apr 25 14:56:48 2022: Epoch [0], Iteration [300/391/], Data(s): 0.056, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.014, Top1: 93.288, Top5: 99.7093, Loss: 0.197\n",
            "Mon Apr 25 14:57:03 2022: Epoch [1], Iteration [0/391/], Data(s): 0.077, Loss(s): 0.031, Forward(s): 0.007, Backward(s): 0.013, Top1: 96.875, Top5: 100.0000, Loss: 0.213\n",
            "Mon Apr 25 14:57:20 2022: Epoch [1], Iteration [100/391/], Data(s): 0.056, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.014, Top1: 93.278, Top5: 99.6210, Loss: 0.207\n",
            "Mon Apr 25 14:57:36 2022: Epoch [1], Iteration [200/391/], Data(s): 0.056, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.014, Top1: 93.497, Top5: 99.6774, Loss: 0.195\n",
            "Mon Apr 25 14:57:53 2022: Epoch [1], Iteration [300/391/], Data(s): 0.056, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.014, Top1: 93.519, Top5: 99.6911, Loss: 0.191\n",
            "Mon Apr 25 14:58:08 2022: Epoch [2], Iteration [0/391/], Data(s): 0.076, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 97.656, Top5: 100.0000, Loss: 0.193\n",
            "Mon Apr 25 14:58:24 2022: Epoch [2], Iteration [100/391/], Data(s): 0.056, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.013, Top1: 93.881, Top5: 99.7602, Loss: 0.187\n",
            "Mon Apr 25 14:58:41 2022: Epoch [2], Iteration [200/391/], Data(s): 0.055, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.013, Top1: 93.626, Top5: 99.7512, Loss: 0.196\n",
            "Mon Apr 25 14:58:57 2022: Epoch [2], Iteration [300/391/], Data(s): 0.055, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.013, Top1: 93.703, Top5: 99.7508, Loss: 0.188\n",
            "Mon Apr 25 14:59:13 2022: Epoch [3], Iteration [0/391/], Data(s): 0.083, Loss(s): 0.026, Forward(s): 0.007, Backward(s): 0.012, Top1: 97.656, Top5: 100.0000, Loss: 0.197\n",
            "Mon Apr 25 14:59:29 2022: Epoch [3], Iteration [100/391/], Data(s): 0.057, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.014, Top1: 93.626, Top5: 99.6597, Loss: 0.196\n",
            "Mon Apr 25 14:59:46 2022: Epoch [3], Iteration [200/391/], Data(s): 0.056, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.013, Top1: 93.649, Top5: 99.7046, Loss: 0.192\n",
            "Mon Apr 25 15:00:02 2022: Epoch [3], Iteration [300/391/], Data(s): 0.055, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.013, Top1: 93.729, Top5: 99.7327, Loss: 0.187\n",
            "Mon Apr 25 15:00:17 2022: Epoch [4], Iteration [0/391/], Data(s): 0.085, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.014, Top1: 94.531, Top5: 100.0000, Loss: 0.194\n",
            "Mon Apr 25 15:00:34 2022: Epoch [4], Iteration [100/391/], Data(s): 0.056, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.013, Top1: 93.967, Top5: 99.8221, Loss: 0.182\n",
            "Mon Apr 25 15:00:50 2022: Epoch [4], Iteration [200/391/], Data(s): 0.055, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.013, Top1: 93.983, Top5: 99.7823, Loss: 0.186\n",
            "Mon Apr 25 15:01:07 2022: Epoch [4], Iteration [300/391/], Data(s): 0.055, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.013, Top1: 93.885, Top5: 99.7690, Loss: 0.190\n",
            "Mon Apr 25 15:01:22 2022: Epoch [5], Iteration [0/391/], Data(s): 0.081, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.013, Top1: 96.094, Top5: 100.0000, Loss: 0.192\n",
            "Mon Apr 25 15:01:39 2022: Epoch [5], Iteration [100/391/], Data(s): 0.056, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.013, Top1: 94.028, Top5: 99.7757, Loss: 0.184\n",
            "Mon Apr 25 15:01:55 2022: Epoch [5], Iteration [200/391/], Data(s): 0.055, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.013, Top1: 94.131, Top5: 99.7629, Loss: 0.180\n",
            "Mon Apr 25 15:02:11 2022: Epoch [5], Iteration [300/391/], Data(s): 0.055, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.013, Top1: 94.043, Top5: 99.7638, Loss: 0.188\n",
            "Mon Apr 25 15:02:27 2022: Epoch [6], Iteration [0/391/], Data(s): 0.078, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 96.094, Top5: 99.2188, Loss: 0.182\n",
            "Mon Apr 25 15:02:43 2022: Epoch [6], Iteration [100/391/], Data(s): 0.056, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.014, Top1: 93.951, Top5: 99.7370, Loss: 0.187\n",
            "Mon Apr 25 15:03:00 2022: Epoch [6], Iteration [200/391/], Data(s): 0.055, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.013, Top1: 93.975, Top5: 99.7668, Loss: 0.180\n",
            "Mon Apr 25 15:03:16 2022: Epoch [6], Iteration [300/391/], Data(s): 0.055, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.013, Top1: 94.010, Top5: 99.7560, Loss: 0.183\n",
            "Mon Apr 25 15:03:31 2022: Epoch [7], Iteration [0/391/], Data(s): 0.082, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.013, Top1: 92.188, Top5: 99.2188, Loss: 0.189\n",
            "Mon Apr 25 15:03:48 2022: Epoch [7], Iteration [100/391/], Data(s): 0.056, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.014, Top1: 94.237, Top5: 99.7834, Loss: 0.173\n",
            "Mon Apr 25 15:04:04 2022: Epoch [7], Iteration [200/391/], Data(s): 0.056, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.014, Top1: 94.341, Top5: 99.7901, Loss: 0.171\n",
            "Mon Apr 25 15:04:21 2022: Epoch [7], Iteration [300/391/], Data(s): 0.055, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.014, Top1: 94.204, Top5: 99.7690, Loss: 0.178\n",
            "Mon Apr 25 15:04:36 2022: Epoch [8], Iteration [0/391/], Data(s): 0.079, Loss(s): 0.024, Forward(s): 0.010, Backward(s): 0.013, Top1: 95.312, Top5: 99.2188, Loss: 0.176\n",
            "Mon Apr 25 15:04:52 2022: Epoch [8], Iteration [100/391/], Data(s): 0.057, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.013, Top1: 94.384, Top5: 99.7525, Loss: 0.174\n",
            "Mon Apr 25 15:05:09 2022: Epoch [8], Iteration [200/391/], Data(s): 0.055, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.013, Top1: 94.216, Top5: 99.7474, Loss: 0.178\n",
            "Mon Apr 25 15:05:25 2022: Epoch [8], Iteration [300/391/], Data(s): 0.055, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.013, Top1: 94.183, Top5: 99.7508, Loss: 0.175\n",
            "Mon Apr 25 15:05:40 2022: Epoch [9], Iteration [0/391/], Data(s): 0.081, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.014, Top1: 92.188, Top5: 99.2188, Loss: 0.176\n",
            "Mon Apr 25 15:05:57 2022: Epoch [9], Iteration [100/391/], Data(s): 0.056, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.013, Top1: 94.284, Top5: 99.7370, Loss: 0.172\n",
            "Mon Apr 25 15:06:13 2022: Epoch [9], Iteration [200/391/], Data(s): 0.056, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.013, Top1: 94.279, Top5: 99.7512, Loss: 0.174\n",
            "Mon Apr 25 15:06:30 2022: Epoch [9], Iteration [300/391/], Data(s): 0.055, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.013, Top1: 94.279, Top5: 99.7872, Loss: 0.172\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 15:06:52 2022: Test information, Data(s): 2.715, Forward(s): 0.680, Top1: 90.850, Top5: 99.290, \n",
            "\n",
            "Mon Apr 25 15:06:52 2022: conv5 Layer, 131 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 125, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(125, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(125, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]          73,856\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "             ReLU-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]         147,584\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15            [-1, 125, 8, 8]         144,125\n",
            "      BatchNorm2d-16            [-1, 125, 8, 8]             250\n",
            "             ReLU-17            [-1, 125, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         288,256\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]       1,180,160\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 14,538,817\n",
            "Trainable params: 14,538,817\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 6.38\n",
            "Params size (MB): 55.46\n",
            "Estimated Total Size (MB): 61.86\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 125, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(125, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(125, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 15:06:53 2022: Epoch [0], Iteration [0/391/], Data(s): 0.059, Loss(s): 0.013, Forward(s): 0.081, Backward(s): 0.146, Top1: 91.406, Top5: 100.0000, Loss: 0.165\n",
            "Mon Apr 25 15:07:10 2022: Epoch [0], Iteration [100/391/], Data(s): 0.055, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.015, Top1: 93.649, Top5: 99.8066, Loss: 0.189\n",
            "Mon Apr 25 15:07:26 2022: Epoch [0], Iteration [200/391/], Data(s): 0.055, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.014, Top1: 93.567, Top5: 99.7590, Loss: 0.196\n",
            "Mon Apr 25 15:07:42 2022: Epoch [0], Iteration [300/391/], Data(s): 0.055, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.014, Top1: 93.589, Top5: 99.7690, Loss: 0.190\n",
            "Mon Apr 25 15:07:57 2022: Epoch [1], Iteration [0/391/], Data(s): 0.076, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.013, Top1: 92.188, Top5: 100.0000, Loss: 0.193\n",
            "Mon Apr 25 15:08:14 2022: Epoch [1], Iteration [100/391/], Data(s): 0.057, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.014, Top1: 93.696, Top5: 99.7447, Loss: 0.185\n",
            "Mon Apr 25 15:08:30 2022: Epoch [1], Iteration [200/391/], Data(s): 0.056, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.014, Top1: 93.933, Top5: 99.7435, Loss: 0.178\n",
            "Mon Apr 25 15:08:46 2022: Epoch [1], Iteration [300/391/], Data(s): 0.055, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 93.802, Top5: 99.7508, Loss: 0.193\n",
            "Mon Apr 25 15:09:01 2022: Epoch [2], Iteration [0/391/], Data(s): 0.083, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.969, Top5: 100.0000, Loss: 0.184\n",
            "Mon Apr 25 15:09:17 2022: Epoch [2], Iteration [100/391/], Data(s): 0.057, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.014, Top1: 94.144, Top5: 99.7602, Loss: 0.174\n",
            "Mon Apr 25 15:09:34 2022: Epoch [2], Iteration [200/391/], Data(s): 0.056, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.013, Top1: 94.007, Top5: 99.7707, Loss: 0.187\n",
            "Mon Apr 25 15:09:50 2022: Epoch [2], Iteration [300/391/], Data(s): 0.056, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 94.074, Top5: 99.7872, Loss: 0.172\n",
            "Mon Apr 25 15:10:05 2022: Epoch [3], Iteration [0/391/], Data(s): 0.081, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 91.406, Top5: 99.2188, Loss: 0.179\n",
            "Mon Apr 25 15:10:21 2022: Epoch [3], Iteration [100/391/], Data(s): 0.057, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.014, Top1: 93.711, Top5: 99.7061, Loss: 0.184\n",
            "Mon Apr 25 15:10:38 2022: Epoch [3], Iteration [200/391/], Data(s): 0.056, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.014, Top1: 94.123, Top5: 99.7551, Loss: 0.167\n",
            "Mon Apr 25 15:10:54 2022: Epoch [3], Iteration [300/391/], Data(s): 0.056, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.013, Top1: 94.181, Top5: 99.7534, Loss: 0.168\n",
            "Mon Apr 25 15:11:09 2022: Epoch [4], Iteration [0/391/], Data(s): 0.080, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 92.188, Top5: 100.0000, Loss: 0.173\n",
            "Mon Apr 25 15:11:25 2022: Epoch [4], Iteration [100/391/], Data(s): 0.057, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.014, Top1: 94.601, Top5: 99.7912, Loss: 0.164\n",
            "Mon Apr 25 15:11:42 2022: Epoch [4], Iteration [200/391/], Data(s): 0.056, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.014, Top1: 94.442, Top5: 99.8095, Loss: 0.174\n",
            "Mon Apr 25 15:11:58 2022: Epoch [4], Iteration [300/391/], Data(s): 0.056, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.014, Top1: 94.425, Top5: 99.7898, Loss: 0.176\n",
            "Mon Apr 25 15:12:13 2022: Epoch [5], Iteration [0/391/], Data(s): 0.083, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.013, Top1: 94.531, Top5: 100.0000, Loss: 0.173\n",
            "Mon Apr 25 15:12:29 2022: Epoch [5], Iteration [100/391/], Data(s): 0.057, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.013, Top1: 94.670, Top5: 99.8685, Loss: 0.157\n",
            "Mon Apr 25 15:12:45 2022: Epoch [5], Iteration [200/391/], Data(s): 0.056, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 94.325, Top5: 99.8290, Loss: 0.179\n",
            "Mon Apr 25 15:13:02 2022: Epoch [5], Iteration [300/391/], Data(s): 0.055, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 94.404, Top5: 99.8417, Loss: 0.166\n",
            "Mon Apr 25 15:13:17 2022: Epoch [6], Iteration [0/391/], Data(s): 0.076, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.013, Top1: 92.969, Top5: 100.0000, Loss: 0.180\n",
            "Mon Apr 25 15:13:33 2022: Epoch [6], Iteration [100/391/], Data(s): 0.056, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.014, Top1: 94.168, Top5: 99.8144, Loss: 0.170\n",
            "Mon Apr 25 15:13:49 2022: Epoch [6], Iteration [200/391/], Data(s): 0.055, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 94.419, Top5: 99.7901, Loss: 0.164\n",
            "Mon Apr 25 15:14:06 2022: Epoch [6], Iteration [300/391/], Data(s): 0.055, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 94.552, Top5: 99.8105, Loss: 0.156\n",
            "Mon Apr 25 15:14:21 2022: Epoch [7], Iteration [0/391/], Data(s): 0.082, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 92.969, Top5: 100.0000, Loss: 0.168\n",
            "Mon Apr 25 15:14:37 2022: Epoch [7], Iteration [100/391/], Data(s): 0.056, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.014, Top1: 94.732, Top5: 99.8298, Loss: 0.157\n",
            "Mon Apr 25 15:14:53 2022: Epoch [7], Iteration [200/391/], Data(s): 0.055, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.014, Top1: 94.663, Top5: 99.8212, Loss: 0.161\n",
            "Mon Apr 25 15:15:09 2022: Epoch [7], Iteration [300/391/], Data(s): 0.055, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 94.560, Top5: 99.8287, Loss: 0.164\n",
            "Mon Apr 25 15:15:24 2022: Epoch [8], Iteration [0/391/], Data(s): 0.079, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.013, Top1: 96.875, Top5: 100.0000, Loss: 0.170\n",
            "Mon Apr 25 15:15:41 2022: Epoch [8], Iteration [100/391/], Data(s): 0.057, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.014, Top1: 94.686, Top5: 99.8221, Loss: 0.159\n",
            "Mon Apr 25 15:15:57 2022: Epoch [8], Iteration [200/391/], Data(s): 0.055, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.013, Top1: 94.605, Top5: 99.7940, Loss: 0.164\n",
            "Mon Apr 25 15:16:13 2022: Epoch [8], Iteration [300/391/], Data(s): 0.055, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.013, Top1: 94.716, Top5: 99.8131, Loss: 0.153\n",
            "Mon Apr 25 15:16:28 2022: Epoch [9], Iteration [0/391/], Data(s): 0.075, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.013, Top1: 95.312, Top5: 100.0000, Loss: 0.157\n",
            "Mon Apr 25 15:16:45 2022: Epoch [9], Iteration [100/391/], Data(s): 0.057, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.014, Top1: 94.980, Top5: 99.8144, Loss: 0.155\n",
            "Mon Apr 25 15:17:01 2022: Epoch [9], Iteration [200/391/], Data(s): 0.056, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 94.924, Top5: 99.8173, Loss: 0.157\n",
            "Mon Apr 25 15:17:17 2022: Epoch [9], Iteration [300/391/], Data(s): 0.055, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 94.757, Top5: 99.8157, Loss: 0.163\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 15:17:39 2022: Test information, Data(s): 2.721, Forward(s): 0.617, Top1: 91.050, Top5: 99.340, \n",
            "\n",
            "Mon Apr 25 15:17:39 2022: conv5 Layer, 164 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 92, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(92, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(92, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]          73,856\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "             ReLU-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]         147,584\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15             [-1, 92, 8, 8]         106,076\n",
            "      BatchNorm2d-16             [-1, 92, 8, 8]             184\n",
            "             ReLU-17             [-1, 92, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         212,224\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]       1,180,160\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 14,424,670\n",
            "Trainable params: 14,424,670\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 6.33\n",
            "Params size (MB): 55.03\n",
            "Estimated Total Size (MB): 61.37\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 92, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(92, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(92, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 15:17:40 2022: Epoch [0], Iteration [0/391/], Data(s): 0.059, Loss(s): 0.003, Forward(s): 0.086, Backward(s): 0.129, Top1: 92.969, Top5: 100.0000, Loss: 0.231\n",
            "Mon Apr 25 15:17:57 2022: Epoch [0], Iteration [100/391/], Data(s): 0.056, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.015, Top1: 93.170, Top5: 99.7370, Loss: 0.201\n",
            "Mon Apr 25 15:18:13 2022: Epoch [0], Iteration [200/391/], Data(s): 0.056, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.014, Top1: 93.361, Top5: 99.7007, Loss: 0.197\n",
            "Mon Apr 25 15:18:29 2022: Epoch [0], Iteration [300/391/], Data(s): 0.055, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.014, Top1: 93.368, Top5: 99.6937, Loss: 0.198\n",
            "Mon Apr 25 15:18:44 2022: Epoch [1], Iteration [0/391/], Data(s): 0.078, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.014, Top1: 95.312, Top5: 100.0000, Loss: 0.181\n",
            "Mon Apr 25 15:19:01 2022: Epoch [1], Iteration [100/391/], Data(s): 0.056, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.013, Top1: 93.325, Top5: 99.7602, Loss: 0.194\n",
            "Mon Apr 25 15:19:17 2022: Epoch [1], Iteration [200/391/], Data(s): 0.056, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.013, Top1: 93.653, Top5: 99.7357, Loss: 0.180\n",
            "Mon Apr 25 15:19:33 2022: Epoch [1], Iteration [300/391/], Data(s): 0.055, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 93.732, Top5: 99.7560, Loss: 0.180\n",
            "Mon Apr 25 15:19:48 2022: Epoch [2], Iteration [0/391/], Data(s): 0.075, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.312, Top5: 100.0000, Loss: 0.175\n",
            "Mon Apr 25 15:20:04 2022: Epoch [2], Iteration [100/391/], Data(s): 0.056, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.014, Top1: 93.928, Top5: 99.7215, Loss: 0.178\n",
            "Mon Apr 25 15:20:20 2022: Epoch [2], Iteration [200/391/], Data(s): 0.055, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.014, Top1: 93.940, Top5: 99.7512, Loss: 0.175\n",
            "Mon Apr 25 15:20:36 2022: Epoch [2], Iteration [300/391/], Data(s): 0.055, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.013, Top1: 94.069, Top5: 99.7846, Loss: 0.169\n",
            "Mon Apr 25 15:20:51 2022: Epoch [3], Iteration [0/391/], Data(s): 0.076, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.014, Top1: 92.969, Top5: 100.0000, Loss: 0.169\n",
            "Mon Apr 25 15:21:08 2022: Epoch [3], Iteration [100/391/], Data(s): 0.056, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.014, Top1: 94.214, Top5: 99.7834, Loss: 0.173\n",
            "Mon Apr 25 15:21:24 2022: Epoch [3], Iteration [200/391/], Data(s): 0.055, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.013, Top1: 94.178, Top5: 99.7590, Loss: 0.173\n",
            "Mon Apr 25 15:21:40 2022: Epoch [3], Iteration [300/391/], Data(s): 0.055, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.013, Top1: 94.238, Top5: 99.7768, Loss: 0.165\n",
            "Mon Apr 25 15:21:55 2022: Epoch [4], Iteration [0/391/], Data(s): 0.076, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.013, Top1: 92.188, Top5: 99.2188, Loss: 0.180\n",
            "Mon Apr 25 15:22:11 2022: Epoch [4], Iteration [100/391/], Data(s): 0.056, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.014, Top1: 94.152, Top5: 99.8221, Loss: 0.169\n",
            "Mon Apr 25 15:22:27 2022: Epoch [4], Iteration [200/391/], Data(s): 0.055, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.014, Top1: 94.213, Top5: 99.8368, Loss: 0.172\n",
            "Mon Apr 25 15:22:44 2022: Epoch [4], Iteration [300/391/], Data(s): 0.055, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 94.373, Top5: 99.8313, Loss: 0.157\n",
            "Mon Apr 25 15:22:58 2022: Epoch [5], Iteration [0/391/], Data(s): 0.080, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.014, Top1: 97.656, Top5: 100.0000, Loss: 0.168\n",
            "Mon Apr 25 15:23:15 2022: Epoch [5], Iteration [100/391/], Data(s): 0.056, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.014, Top1: 94.794, Top5: 99.8221, Loss: 0.162\n",
            "Mon Apr 25 15:23:31 2022: Epoch [5], Iteration [200/391/], Data(s): 0.055, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.013, Top1: 94.846, Top5: 99.8018, Loss: 0.155\n",
            "Mon Apr 25 15:23:47 2022: Epoch [5], Iteration [300/391/], Data(s): 0.055, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 94.661, Top5: 99.7975, Loss: 0.167\n",
            "Mon Apr 25 15:24:02 2022: Epoch [6], Iteration [0/391/], Data(s): 0.075, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.013, Top1: 94.531, Top5: 99.2188, Loss: 0.166\n",
            "Mon Apr 25 15:24:18 2022: Epoch [6], Iteration [100/391/], Data(s): 0.056, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.014, Top1: 94.694, Top5: 99.7989, Loss: 0.157\n",
            "Mon Apr 25 15:24:34 2022: Epoch [6], Iteration [200/391/], Data(s): 0.055, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.014, Top1: 94.660, Top5: 99.8134, Loss: 0.159\n",
            "Mon Apr 25 15:24:51 2022: Epoch [6], Iteration [300/391/], Data(s): 0.056, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.014, Top1: 94.832, Top5: 99.8183, Loss: 0.152\n",
            "Mon Apr 25 15:25:06 2022: Epoch [7], Iteration [0/391/], Data(s): 0.076, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.013, Top1: 92.969, Top5: 100.0000, Loss: 0.158\n",
            "Mon Apr 25 15:25:22 2022: Epoch [7], Iteration [100/391/], Data(s): 0.056, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.014, Top1: 95.026, Top5: 99.8530, Loss: 0.149\n",
            "Mon Apr 25 15:25:38 2022: Epoch [7], Iteration [200/391/], Data(s): 0.055, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 94.807, Top5: 99.8678, Loss: 0.161\n",
            "Mon Apr 25 15:25:54 2022: Epoch [7], Iteration [300/391/], Data(s): 0.055, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.014, Top1: 94.770, Top5: 99.8624, Loss: 0.157\n",
            "Mon Apr 25 15:26:09 2022: Epoch [8], Iteration [0/391/], Data(s): 0.077, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 93.750, Top5: 100.0000, Loss: 0.153\n",
            "Mon Apr 25 15:26:26 2022: Epoch [8], Iteration [100/391/], Data(s): 0.056, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.014, Top1: 95.135, Top5: 99.8376, Loss: 0.150\n",
            "Mon Apr 25 15:26:42 2022: Epoch [8], Iteration [200/391/], Data(s): 0.055, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 94.963, Top5: 99.8057, Loss: 0.154\n",
            "Mon Apr 25 15:26:58 2022: Epoch [8], Iteration [300/391/], Data(s): 0.055, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 94.952, Top5: 99.8235, Loss: 0.153\n",
            "Mon Apr 25 15:27:13 2022: Epoch [9], Iteration [0/391/], Data(s): 0.079, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.013, Top1: 94.531, Top5: 100.0000, Loss: 0.155\n",
            "Mon Apr 25 15:27:29 2022: Epoch [9], Iteration [100/391/], Data(s): 0.057, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.014, Top1: 94.980, Top5: 99.8994, Loss: 0.153\n",
            "Mon Apr 25 15:27:45 2022: Epoch [9], Iteration [200/391/], Data(s): 0.055, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.013, Top1: 95.184, Top5: 99.8445, Loss: 0.145\n",
            "Mon Apr 25 15:28:02 2022: Epoch [9], Iteration [300/391/], Data(s): 0.055, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.115, Top5: 99.8365, Loss: 0.153\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 15:28:23 2022: Test information, Data(s): 2.828, Forward(s): 0.644, Top1: 91.140, Top5: 99.290, \n",
            "\n",
            "Mon Apr 25 15:28:23 2022: conv5 Layer, 197 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 59, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(59, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(59, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]          73,856\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "             ReLU-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]         147,584\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15             [-1, 59, 8, 8]          68,027\n",
            "      BatchNorm2d-16             [-1, 59, 8, 8]             118\n",
            "             ReLU-17             [-1, 59, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         136,192\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]       1,180,160\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 14,310,523\n",
            "Trainable params: 14,310,523\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 6.29\n",
            "Params size (MB): 54.59\n",
            "Estimated Total Size (MB): 60.89\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 59, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(59, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(59, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 15:28:25 2022: Epoch [0], Iteration [0/391/], Data(s): 0.056, Loss(s): 0.013, Forward(s): 0.060, Backward(s): 0.104, Top1: 90.625, Top5: 99.2188, Loss: 0.286\n",
            "Mon Apr 25 15:28:41 2022: Epoch [0], Iteration [100/391/], Data(s): 0.054, Loss(s): 0.026, Forward(s): 0.007, Backward(s): 0.014, Top1: 91.337, Top5: 99.5127, Loss: 0.264\n",
            "Mon Apr 25 15:28:57 2022: Epoch [0], Iteration [200/391/], Data(s): 0.054, Loss(s): 0.026, Forward(s): 0.007, Backward(s): 0.014, Top1: 91.768, Top5: 99.5841, Loss: 0.234\n",
            "Mon Apr 25 15:29:13 2022: Epoch [0], Iteration [300/391/], Data(s): 0.054, Loss(s): 0.026, Forward(s): 0.007, Backward(s): 0.014, Top1: 91.967, Top5: 99.6340, Loss: 0.228\n",
            "Mon Apr 25 15:29:28 2022: Epoch [1], Iteration [0/391/], Data(s): 0.086, Loss(s): 0.023, Forward(s): 0.009, Backward(s): 0.014, Top1: 95.312, Top5: 100.0000, Loss: 0.214\n",
            "Mon Apr 25 15:29:44 2022: Epoch [1], Iteration [100/391/], Data(s): 0.056, Loss(s): 0.026, Forward(s): 0.007, Backward(s): 0.014, Top1: 93.325, Top5: 99.7061, Loss: 0.204\n",
            "Mon Apr 25 15:30:00 2022: Epoch [1], Iteration [200/391/], Data(s): 0.055, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.014, Top1: 93.284, Top5: 99.7201, Loss: 0.202\n",
            "Mon Apr 25 15:30:16 2022: Epoch [1], Iteration [300/391/], Data(s): 0.055, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.013, Top1: 93.244, Top5: 99.7586, Loss: 0.200\n",
            "Mon Apr 25 15:30:31 2022: Epoch [2], Iteration [0/391/], Data(s): 0.080, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.312, Top5: 100.0000, Loss: 0.195\n",
            "Mon Apr 25 15:30:47 2022: Epoch [2], Iteration [100/391/], Data(s): 0.057, Loss(s): 0.026, Forward(s): 0.007, Backward(s): 0.014, Top1: 93.325, Top5: 99.7912, Loss: 0.190\n",
            "Mon Apr 25 15:31:03 2022: Epoch [2], Iteration [200/391/], Data(s): 0.056, Loss(s): 0.026, Forward(s): 0.007, Backward(s): 0.014, Top1: 93.482, Top5: 99.7940, Loss: 0.188\n",
            "Mon Apr 25 15:31:19 2022: Epoch [2], Iteration [300/391/], Data(s): 0.055, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.014, Top1: 93.493, Top5: 99.7768, Loss: 0.190\n",
            "Mon Apr 25 15:31:34 2022: Epoch [3], Iteration [0/391/], Data(s): 0.071, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.013, Top1: 93.750, Top5: 100.0000, Loss: 0.188\n",
            "Mon Apr 25 15:31:50 2022: Epoch [3], Iteration [100/391/], Data(s): 0.055, Loss(s): 0.026, Forward(s): 0.007, Backward(s): 0.014, Top1: 93.982, Top5: 99.7989, Loss: 0.174\n",
            "Mon Apr 25 15:32:06 2022: Epoch [3], Iteration [200/391/], Data(s): 0.055, Loss(s): 0.026, Forward(s): 0.007, Backward(s): 0.013, Top1: 93.909, Top5: 99.7940, Loss: 0.186\n",
            "Mon Apr 25 15:32:22 2022: Epoch [3], Iteration [300/391/], Data(s): 0.055, Loss(s): 0.026, Forward(s): 0.007, Backward(s): 0.013, Top1: 93.825, Top5: 99.7456, Loss: 0.192\n",
            "Mon Apr 25 15:32:37 2022: Epoch [4], Iteration [0/391/], Data(s): 0.076, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 89.844, Top5: 100.0000, Loss: 0.190\n",
            "Mon Apr 25 15:32:53 2022: Epoch [4], Iteration [100/391/], Data(s): 0.056, Loss(s): 0.026, Forward(s): 0.007, Backward(s): 0.014, Top1: 94.090, Top5: 99.8144, Loss: 0.176\n",
            "Mon Apr 25 15:33:09 2022: Epoch [4], Iteration [200/391/], Data(s): 0.055, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.013, Top1: 94.010, Top5: 99.8018, Loss: 0.181\n",
            "Mon Apr 25 15:33:25 2022: Epoch [4], Iteration [300/391/], Data(s): 0.055, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.013, Top1: 93.950, Top5: 99.8027, Loss: 0.176\n",
            "Mon Apr 25 15:33:40 2022: Epoch [5], Iteration [0/391/], Data(s): 0.076, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 96.094, Top5: 100.0000, Loss: 0.172\n",
            "Mon Apr 25 15:33:56 2022: Epoch [5], Iteration [100/391/], Data(s): 0.056, Loss(s): 0.026, Forward(s): 0.007, Backward(s): 0.014, Top1: 94.709, Top5: 99.8840, Loss: 0.158\n",
            "Mon Apr 25 15:34:12 2022: Epoch [5], Iteration [200/391/], Data(s): 0.055, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.014, Top1: 94.434, Top5: 99.8290, Loss: 0.169\n",
            "Mon Apr 25 15:34:28 2022: Epoch [5], Iteration [300/391/], Data(s): 0.055, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.014, Top1: 94.342, Top5: 99.8079, Loss: 0.173\n",
            "Mon Apr 25 15:34:43 2022: Epoch [6], Iteration [0/391/], Data(s): 0.079, Loss(s): 0.026, Forward(s): 0.007, Backward(s): 0.013, Top1: 89.062, Top5: 100.0000, Loss: 0.180\n",
            "Mon Apr 25 15:34:59 2022: Epoch [6], Iteration [100/391/], Data(s): 0.055, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.014, Top1: 94.524, Top5: 99.9149, Loss: 0.162\n",
            "Mon Apr 25 15:35:15 2022: Epoch [6], Iteration [200/391/], Data(s): 0.055, Loss(s): 0.026, Forward(s): 0.007, Backward(s): 0.014, Top1: 94.403, Top5: 99.8717, Loss: 0.166\n",
            "Mon Apr 25 15:35:31 2022: Epoch [6], Iteration [300/391/], Data(s): 0.055, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.014, Top1: 94.417, Top5: 99.8495, Loss: 0.164\n",
            "Mon Apr 25 15:35:46 2022: Epoch [7], Iteration [0/391/], Data(s): 0.075, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 96.094, Top5: 100.0000, Loss: 0.166\n",
            "Mon Apr 25 15:36:02 2022: Epoch [7], Iteration [100/391/], Data(s): 0.056, Loss(s): 0.026, Forward(s): 0.007, Backward(s): 0.014, Top1: 94.616, Top5: 99.8298, Loss: 0.163\n",
            "Mon Apr 25 15:36:18 2022: Epoch [7], Iteration [200/391/], Data(s): 0.055, Loss(s): 0.026, Forward(s): 0.007, Backward(s): 0.014, Top1: 94.683, Top5: 99.8640, Loss: 0.157\n",
            "Mon Apr 25 15:36:34 2022: Epoch [7], Iteration [300/391/], Data(s): 0.055, Loss(s): 0.026, Forward(s): 0.007, Backward(s): 0.014, Top1: 94.630, Top5: 99.8443, Loss: 0.160\n",
            "Mon Apr 25 15:36:49 2022: Epoch [8], Iteration [0/391/], Data(s): 0.075, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 97.656, Top5: 100.0000, Loss: 0.161\n",
            "Mon Apr 25 15:37:05 2022: Epoch [8], Iteration [100/391/], Data(s): 0.057, Loss(s): 0.026, Forward(s): 0.007, Backward(s): 0.013, Top1: 94.616, Top5: 99.8221, Loss: 0.159\n",
            "Mon Apr 25 15:37:21 2022: Epoch [8], Iteration [200/391/], Data(s): 0.056, Loss(s): 0.026, Forward(s): 0.007, Backward(s): 0.013, Top1: 94.784, Top5: 99.7862, Loss: 0.152\n",
            "Mon Apr 25 15:37:37 2022: Epoch [8], Iteration [300/391/], Data(s): 0.055, Loss(s): 0.026, Forward(s): 0.007, Backward(s): 0.013, Top1: 94.749, Top5: 99.8183, Loss: 0.156\n",
            "Mon Apr 25 15:37:52 2022: Epoch [9], Iteration [0/391/], Data(s): 0.074, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.750, Top5: 100.0000, Loss: 0.159\n",
            "Mon Apr 25 15:38:08 2022: Epoch [9], Iteration [100/391/], Data(s): 0.055, Loss(s): 0.026, Forward(s): 0.007, Backward(s): 0.014, Top1: 94.740, Top5: 99.8994, Loss: 0.154\n",
            "Mon Apr 25 15:38:24 2022: Epoch [9], Iteration [200/391/], Data(s): 0.055, Loss(s): 0.026, Forward(s): 0.007, Backward(s): 0.014, Top1: 94.706, Top5: 99.8795, Loss: 0.155\n",
            "Mon Apr 25 15:38:40 2022: Epoch [9], Iteration [300/391/], Data(s): 0.055, Loss(s): 0.026, Forward(s): 0.007, Backward(s): 0.013, Top1: 94.723, Top5: 99.8650, Loss: 0.153\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 15:39:01 2022: Test information, Data(s): 2.684, Forward(s): 0.630, Top1: 90.720, Top5: 99.370, \n",
            "\n",
            "Mon Apr 25 15:39:01 2022: conv5 Layer, 230 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 26, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(26, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]          73,856\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "             ReLU-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]         147,584\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15             [-1, 26, 8, 8]          29,978\n",
            "      BatchNorm2d-16             [-1, 26, 8, 8]              52\n",
            "             ReLU-17             [-1, 26, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]          60,160\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]       1,180,160\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 14,196,376\n",
            "Trainable params: 14,196,376\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 6.24\n",
            "Params size (MB): 54.15\n",
            "Estimated Total Size (MB): 60.40\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 26, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(26, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 15:39:03 2022: Epoch [0], Iteration [0/391/], Data(s): 0.055, Loss(s): 0.013, Forward(s): 0.046, Backward(s): 0.110, Top1: 75.781, Top5: 96.0938, Loss: 0.974\n",
            "Mon Apr 25 15:39:19 2022: Epoch [0], Iteration [100/391/], Data(s): 0.056, Loss(s): 0.026, Forward(s): 0.007, Backward(s): 0.014, Top1: 84.700, Top5: 98.6773, Loss: 0.506\n",
            "Mon Apr 25 15:39:35 2022: Epoch [0], Iteration [200/391/], Data(s): 0.055, Loss(s): 0.026, Forward(s): 0.007, Backward(s): 0.014, Top1: 86.427, Top5: 98.9544, Loss: 0.374\n",
            "Mon Apr 25 15:39:51 2022: Epoch [0], Iteration [300/391/], Data(s): 0.055, Loss(s): 0.026, Forward(s): 0.007, Backward(s): 0.014, Top1: 87.181, Top5: 99.0890, Loss: 0.341\n",
            "Mon Apr 25 15:40:05 2022: Epoch [1], Iteration [0/391/], Data(s): 0.073, Loss(s): 0.026, Forward(s): 0.007, Backward(s): 0.013, Top1: 85.938, Top5: 100.0000, Loss: 0.319\n",
            "Mon Apr 25 15:40:22 2022: Epoch [1], Iteration [100/391/], Data(s): 0.056, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.014, Top1: 90.362, Top5: 99.4276, Loss: 0.286\n",
            "Mon Apr 25 15:40:38 2022: Epoch [1], Iteration [200/391/], Data(s): 0.055, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.014, Top1: 90.388, Top5: 99.4908, Loss: 0.282\n",
            "Mon Apr 25 15:40:53 2022: Epoch [1], Iteration [300/391/], Data(s): 0.055, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.014, Top1: 90.277, Top5: 99.4757, Loss: 0.295\n",
            "Mon Apr 25 15:41:08 2022: Epoch [2], Iteration [0/391/], Data(s): 0.076, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 91.406, Top5: 100.0000, Loss: 0.291\n",
            "Mon Apr 25 15:41:24 2022: Epoch [2], Iteration [100/391/], Data(s): 0.055, Loss(s): 0.026, Forward(s): 0.007, Backward(s): 0.014, Top1: 90.996, Top5: 99.6597, Loss: 0.266\n",
            "Mon Apr 25 15:41:40 2022: Epoch [2], Iteration [200/391/], Data(s): 0.055, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.013, Top1: 91.181, Top5: 99.6035, Loss: 0.258\n",
            "Mon Apr 25 15:41:56 2022: Epoch [2], Iteration [300/391/], Data(s): 0.055, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.013, Top1: 91.139, Top5: 99.6288, Loss: 0.266\n",
            "Mon Apr 25 15:42:11 2022: Epoch [3], Iteration [0/391/], Data(s): 0.076, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.013, Top1: 91.406, Top5: 100.0000, Loss: 0.249\n",
            "Mon Apr 25 15:42:27 2022: Epoch [3], Iteration [100/391/], Data(s): 0.056, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.014, Top1: 91.940, Top5: 99.5436, Loss: 0.246\n",
            "Mon Apr 25 15:42:43 2022: Epoch [3], Iteration [200/391/], Data(s): 0.055, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.014, Top1: 91.713, Top5: 99.6308, Loss: 0.247\n",
            "Mon Apr 25 15:42:59 2022: Epoch [3], Iteration [300/391/], Data(s): 0.055, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.013, Top1: 91.715, Top5: 99.6029, Loss: 0.253\n",
            "Mon Apr 25 15:43:14 2022: Epoch [4], Iteration [0/391/], Data(s): 0.075, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.969, Top5: 99.2188, Loss: 0.242\n",
            "Mon Apr 25 15:43:30 2022: Epoch [4], Iteration [100/391/], Data(s): 0.056, Loss(s): 0.026, Forward(s): 0.007, Backward(s): 0.014, Top1: 92.265, Top5: 99.7215, Loss: 0.229\n",
            "Mon Apr 25 15:43:46 2022: Epoch [4], Iteration [200/391/], Data(s): 0.055, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.014, Top1: 92.226, Top5: 99.7318, Loss: 0.226\n",
            "Mon Apr 25 15:44:02 2022: Epoch [4], Iteration [300/391/], Data(s): 0.055, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.014, Top1: 92.195, Top5: 99.6963, Loss: 0.236\n",
            "Mon Apr 25 15:44:16 2022: Epoch [5], Iteration [0/391/], Data(s): 0.074, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 88.281, Top5: 97.6562, Loss: 0.244\n",
            "Mon Apr 25 15:44:33 2022: Epoch [5], Iteration [100/391/], Data(s): 0.056, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.013, Top1: 92.574, Top5: 99.6906, Loss: 0.220\n",
            "Mon Apr 25 15:44:49 2022: Epoch [5], Iteration [200/391/], Data(s): 0.055, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.013, Top1: 92.615, Top5: 99.7279, Loss: 0.218\n",
            "Mon Apr 25 15:45:05 2022: Epoch [5], Iteration [300/391/], Data(s): 0.055, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.013, Top1: 92.566, Top5: 99.7404, Loss: 0.222\n",
            "Mon Apr 25 15:45:19 2022: Epoch [6], Iteration [0/391/], Data(s): 0.073, Loss(s): 0.029, Forward(s): 0.006, Backward(s): 0.028, Top1: 92.969, Top5: 100.0000, Loss: 0.220\n",
            "Mon Apr 25 15:45:35 2022: Epoch [6], Iteration [100/391/], Data(s): 0.056, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.014, Top1: 92.783, Top5: 99.7138, Loss: 0.211\n",
            "Mon Apr 25 15:45:51 2022: Epoch [6], Iteration [200/391/], Data(s): 0.055, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.014, Top1: 92.899, Top5: 99.7590, Loss: 0.213\n",
            "Mon Apr 25 15:46:07 2022: Epoch [6], Iteration [300/391/], Data(s): 0.055, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.013, Top1: 92.826, Top5: 99.7353, Loss: 0.214\n",
            "Mon Apr 25 15:46:22 2022: Epoch [7], Iteration [0/391/], Data(s): 0.074, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.013, Top1: 96.094, Top5: 100.0000, Loss: 0.209\n",
            "Mon Apr 25 15:46:38 2022: Epoch [7], Iteration [100/391/], Data(s): 0.056, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.014, Top1: 92.891, Top5: 99.7061, Loss: 0.212\n",
            "Mon Apr 25 15:46:54 2022: Epoch [7], Iteration [200/391/], Data(s): 0.055, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.014, Top1: 93.074, Top5: 99.7279, Loss: 0.198\n",
            "Mon Apr 25 15:47:10 2022: Epoch [7], Iteration [300/391/], Data(s): 0.055, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.013, Top1: 93.028, Top5: 99.7275, Loss: 0.208\n",
            "Mon Apr 25 15:47:25 2022: Epoch [8], Iteration [0/391/], Data(s): 0.076, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.312, Top5: 100.0000, Loss: 0.211\n",
            "Mon Apr 25 15:47:41 2022: Epoch [8], Iteration [100/391/], Data(s): 0.056, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.014, Top1: 93.325, Top5: 99.7138, Loss: 0.201\n",
            "Mon Apr 25 15:47:57 2022: Epoch [8], Iteration [200/391/], Data(s): 0.055, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.014, Top1: 93.241, Top5: 99.7474, Loss: 0.197\n",
            "Mon Apr 25 15:48:13 2022: Epoch [8], Iteration [300/391/], Data(s): 0.055, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.014, Top1: 93.265, Top5: 99.7508, Loss: 0.200\n",
            "Mon Apr 25 15:48:27 2022: Epoch [9], Iteration [0/391/], Data(s): 0.076, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.013, Top1: 92.188, Top5: 100.0000, Loss: 0.197\n",
            "Mon Apr 25 15:48:44 2022: Epoch [9], Iteration [100/391/], Data(s): 0.056, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.014, Top1: 93.456, Top5: 99.7757, Loss: 0.197\n",
            "Mon Apr 25 15:49:00 2022: Epoch [9], Iteration [200/391/], Data(s): 0.055, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.014, Top1: 93.404, Top5: 99.7435, Loss: 0.202\n",
            "Mon Apr 25 15:49:16 2022: Epoch [9], Iteration [300/391/], Data(s): 0.055, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.013, Top1: 93.550, Top5: 99.7586, Loss: 0.184\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 15:49:37 2022: Test information, Data(s): 2.669, Forward(s): 0.585, Top1: 89.350, Top5: 99.150, \n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 15:49:47 2022: Test information, Data(s): 2.829, Forward(s): 0.569, Top1: 77.870, Top5: 97.560, \n",
            "\n",
            "Mon Apr 25 15:49:47 2022: conv6 Layer, 32 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(224, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]          73,856\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "             ReLU-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]         147,584\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         295,168\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 224, 8, 8]         516,320\n",
            "      BatchNorm2d-19            [-1, 224, 8, 8]             448\n",
            "             ReLU-20            [-1, 224, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         516,352\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]       1,180,160\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 14,844,394\n",
            "Trainable params: 14,844,394\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 6.53\n",
            "Params size (MB): 56.63\n",
            "Estimated Total Size (MB): 63.17\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(224, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 15:49:48 2022: Epoch [0], Iteration [0/391/], Data(s): 0.054, Loss(s): 0.002, Forward(s): 0.128, Backward(s): 0.189, Top1: 82.031, Top5: 96.8750, Loss: 0.491\n",
            "Mon Apr 25 15:50:05 2022: Epoch [0], Iteration [100/391/], Data(s): 0.055, Loss(s): 0.028, Forward(s): 0.008, Backward(s): 0.015, Top1: 87.500, Top5: 98.9325, Loss: 0.392\n",
            "Mon Apr 25 15:50:22 2022: Epoch [0], Iteration [200/391/], Data(s): 0.055, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.014, Top1: 87.998, Top5: 99.0322, Loss: 0.354\n",
            "Mon Apr 25 15:50:38 2022: Epoch [0], Iteration [300/391/], Data(s): 0.055, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.014, Top1: 88.419, Top5: 99.1201, Loss: 0.328\n",
            "Mon Apr 25 15:50:54 2022: Epoch [1], Iteration [0/391/], Data(s): 0.081, Loss(s): 0.031, Forward(s): 0.008, Backward(s): 0.013, Top1: 88.281, Top5: 99.2188, Loss: 0.331\n",
            "Mon Apr 25 15:51:11 2022: Epoch [1], Iteration [100/391/], Data(s): 0.057, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.014, Top1: 89.805, Top5: 99.4121, Loss: 0.309\n",
            "Mon Apr 25 15:51:27 2022: Epoch [1], Iteration [200/391/], Data(s): 0.056, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.013, Top1: 89.953, Top5: 99.4014, Loss: 0.301\n",
            "Mon Apr 25 15:51:44 2022: Epoch [1], Iteration [300/391/], Data(s): 0.055, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.013, Top1: 90.121, Top5: 99.4134, Loss: 0.290\n",
            "Mon Apr 25 15:51:59 2022: Epoch [2], Iteration [0/391/], Data(s): 0.081, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.013, Top1: 87.500, Top5: 99.2188, Loss: 0.300\n",
            "Mon Apr 25 15:52:16 2022: Epoch [2], Iteration [100/391/], Data(s): 0.056, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.014, Top1: 90.625, Top5: 99.3502, Loss: 0.291\n",
            "Mon Apr 25 15:52:33 2022: Epoch [2], Iteration [200/391/], Data(s): 0.055, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.013, Top1: 90.847, Top5: 99.4209, Loss: 0.278\n",
            "Mon Apr 25 15:52:49 2022: Epoch [2], Iteration [300/391/], Data(s): 0.055, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.013, Top1: 90.978, Top5: 99.4394, Loss: 0.271\n",
            "Mon Apr 25 15:53:05 2022: Epoch [3], Iteration [0/391/], Data(s): 0.077, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.013, Top1: 93.750, Top5: 100.0000, Loss: 0.279\n",
            "Mon Apr 25 15:53:22 2022: Epoch [3], Iteration [100/391/], Data(s): 0.056, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.014, Top1: 91.344, Top5: 99.4817, Loss: 0.273\n",
            "Mon Apr 25 15:53:38 2022: Epoch [3], Iteration [200/391/], Data(s): 0.056, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.014, Top1: 91.344, Top5: 99.4792, Loss: 0.273\n",
            "Mon Apr 25 15:53:55 2022: Epoch [3], Iteration [300/391/], Data(s): 0.055, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.013, Top1: 91.318, Top5: 99.5043, Loss: 0.264\n",
            "Mon Apr 25 15:54:10 2022: Epoch [4], Iteration [0/391/], Data(s): 0.077, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.013, Top1: 97.656, Top5: 100.0000, Loss: 0.266\n",
            "Mon Apr 25 15:54:27 2022: Epoch [4], Iteration [100/391/], Data(s): 0.056, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.014, Top1: 91.414, Top5: 99.5050, Loss: 0.263\n",
            "Mon Apr 25 15:54:44 2022: Epoch [4], Iteration [200/391/], Data(s): 0.056, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.013, Top1: 91.639, Top5: 99.5375, Loss: 0.250\n",
            "Mon Apr 25 15:55:01 2022: Epoch [4], Iteration [300/391/], Data(s): 0.055, Loss(s): 0.029, Forward(s): 0.006, Backward(s): 0.013, Top1: 91.832, Top5: 99.5562, Loss: 0.242\n",
            "Mon Apr 25 15:55:16 2022: Epoch [5], Iteration [0/391/], Data(s): 0.075, Loss(s): 0.029, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.750, Top5: 100.0000, Loss: 0.252\n",
            "Mon Apr 25 15:55:33 2022: Epoch [5], Iteration [100/391/], Data(s): 0.057, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.013, Top1: 91.662, Top5: 99.5282, Loss: 0.261\n",
            "Mon Apr 25 15:55:50 2022: Epoch [5], Iteration [200/391/], Data(s): 0.056, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.013, Top1: 91.950, Top5: 99.5569, Loss: 0.243\n",
            "Mon Apr 25 15:56:06 2022: Epoch [5], Iteration [300/391/], Data(s): 0.056, Loss(s): 0.029, Forward(s): 0.007, Backward(s): 0.013, Top1: 92.094, Top5: 99.6029, Loss: 0.235\n",
            "Mon Apr 25 15:56:22 2022: Epoch [6], Iteration [0/391/], Data(s): 0.076, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.015, Top1: 92.969, Top5: 99.2188, Loss: 0.249\n",
            "Mon Apr 25 15:56:38 2022: Epoch [6], Iteration [100/391/], Data(s): 0.056, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.013, Top1: 92.559, Top5: 99.6442, Loss: 0.232\n",
            "Mon Apr 25 15:56:55 2022: Epoch [6], Iteration [200/391/], Data(s): 0.056, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.013, Top1: 92.269, Top5: 99.6113, Loss: 0.251\n",
            "Mon Apr 25 15:57:12 2022: Epoch [6], Iteration [300/391/], Data(s): 0.055, Loss(s): 0.029, Forward(s): 0.007, Backward(s): 0.013, Top1: 92.188, Top5: 99.5951, Loss: 0.242\n",
            "Mon Apr 25 15:57:27 2022: Epoch [7], Iteration [0/391/], Data(s): 0.076, Loss(s): 0.029, Forward(s): 0.006, Backward(s): 0.013, Top1: 94.531, Top5: 100.0000, Loss: 0.232\n",
            "Mon Apr 25 15:57:44 2022: Epoch [7], Iteration [100/391/], Data(s): 0.056, Loss(s): 0.029, Forward(s): 0.006, Backward(s): 0.013, Top1: 92.234, Top5: 99.5900, Loss: 0.237\n",
            "Mon Apr 25 15:58:01 2022: Epoch [7], Iteration [200/391/], Data(s): 0.056, Loss(s): 0.029, Forward(s): 0.006, Backward(s): 0.013, Top1: 92.269, Top5: 99.5841, Loss: 0.234\n",
            "Mon Apr 25 15:58:18 2022: Epoch [7], Iteration [300/391/], Data(s): 0.056, Loss(s): 0.029, Forward(s): 0.006, Backward(s): 0.013, Top1: 92.354, Top5: 99.5769, Loss: 0.232\n",
            "Mon Apr 25 15:58:33 2022: Epoch [8], Iteration [0/391/], Data(s): 0.074, Loss(s): 0.029, Forward(s): 0.006, Backward(s): 0.013, Top1: 93.750, Top5: 100.0000, Loss: 0.232\n",
            "Mon Apr 25 15:58:50 2022: Epoch [8], Iteration [100/391/], Data(s): 0.057, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.013, Top1: 92.567, Top5: 99.6519, Loss: 0.229\n",
            "Mon Apr 25 15:59:07 2022: Epoch [8], Iteration [200/391/], Data(s): 0.055, Loss(s): 0.029, Forward(s): 0.006, Backward(s): 0.013, Top1: 92.728, Top5: 99.6813, Loss: 0.221\n",
            "Mon Apr 25 15:59:23 2022: Epoch [8], Iteration [300/391/], Data(s): 0.055, Loss(s): 0.029, Forward(s): 0.006, Backward(s): 0.013, Top1: 92.553, Top5: 99.6496, Loss: 0.237\n",
            "Mon Apr 25 15:59:39 2022: Epoch [9], Iteration [0/391/], Data(s): 0.078, Loss(s): 0.029, Forward(s): 0.006, Backward(s): 0.013, Top1: 92.188, Top5: 99.2188, Loss: 0.220\n",
            "Mon Apr 25 15:59:55 2022: Epoch [9], Iteration [100/391/], Data(s): 0.056, Loss(s): 0.029, Forward(s): 0.006, Backward(s): 0.014, Top1: 92.412, Top5: 99.5978, Loss: 0.230\n",
            "Mon Apr 25 16:00:12 2022: Epoch [9], Iteration [200/391/], Data(s): 0.056, Loss(s): 0.029, Forward(s): 0.006, Backward(s): 0.013, Top1: 92.502, Top5: 99.6346, Loss: 0.223\n",
            "Mon Apr 25 16:00:29 2022: Epoch [9], Iteration [300/391/], Data(s): 0.055, Loss(s): 0.029, Forward(s): 0.006, Backward(s): 0.013, Top1: 92.551, Top5: 99.6262, Loss: 0.226\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 16:00:51 2022: Test information, Data(s): 2.691, Forward(s): 0.603, Top1: 89.970, Top5: 99.250, \n",
            "\n",
            "Mon Apr 25 16:00:51 2022: conv6 Layer, 65 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 191, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(191, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(191, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]          73,856\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "             ReLU-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]         147,584\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         295,168\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 191, 8, 8]         440,255\n",
            "      BatchNorm2d-19            [-1, 191, 8, 8]             382\n",
            "             ReLU-20            [-1, 191, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         440,320\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]       1,180,160\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 14,692,231\n",
            "Trainable params: 14,692,231\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 6.48\n",
            "Params size (MB): 56.05\n",
            "Estimated Total Size (MB): 62.54\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 191, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(191, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(191, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 16:00:53 2022: Epoch [0], Iteration [0/391/], Data(s): 0.152, Loss(s): 0.009, Forward(s): 0.072, Backward(s): 0.119, Top1: 89.844, Top5: 98.4375, Loss: 0.273\n",
            "Mon Apr 25 16:01:09 2022: Epoch [0], Iteration [100/391/], Data(s): 0.056, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.014, Top1: 92.907, Top5: 99.6442, Loss: 0.218\n",
            "Mon Apr 25 16:01:26 2022: Epoch [0], Iteration [200/391/], Data(s): 0.055, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.014, Top1: 92.716, Top5: 99.6346, Loss: 0.229\n",
            "Mon Apr 25 16:01:42 2022: Epoch [0], Iteration [300/391/], Data(s): 0.055, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.013, Top1: 92.681, Top5: 99.6288, Loss: 0.224\n",
            "Mon Apr 25 16:01:57 2022: Epoch [1], Iteration [0/391/], Data(s): 0.080, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.013, Top1: 92.188, Top5: 100.0000, Loss: 0.219\n",
            "Mon Apr 25 16:02:14 2022: Epoch [1], Iteration [100/391/], Data(s): 0.056, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.014, Top1: 92.744, Top5: 99.6364, Loss: 0.222\n",
            "Mon Apr 25 16:02:30 2022: Epoch [1], Iteration [200/391/], Data(s): 0.056, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.014, Top1: 92.786, Top5: 99.6813, Loss: 0.216\n",
            "Mon Apr 25 16:02:47 2022: Epoch [1], Iteration [300/391/], Data(s): 0.055, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.013, Top1: 92.803, Top5: 99.6626, Loss: 0.215\n",
            "Mon Apr 25 16:03:02 2022: Epoch [2], Iteration [0/391/], Data(s): 0.076, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 92.969, Top5: 99.2188, Loss: 0.216\n",
            "Mon Apr 25 16:03:18 2022: Epoch [2], Iteration [100/391/], Data(s): 0.056, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.013, Top1: 92.574, Top5: 99.6597, Loss: 0.227\n",
            "Mon Apr 25 16:03:35 2022: Epoch [2], Iteration [200/391/], Data(s): 0.055, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.013, Top1: 92.973, Top5: 99.6852, Loss: 0.204\n",
            "Mon Apr 25 16:03:51 2022: Epoch [2], Iteration [300/391/], Data(s): 0.055, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.013, Top1: 92.925, Top5: 99.6730, Loss: 0.216\n",
            "Mon Apr 25 16:04:06 2022: Epoch [3], Iteration [0/391/], Data(s): 0.076, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.013, Top1: 90.625, Top5: 99.2188, Loss: 0.217\n",
            "Mon Apr 25 16:04:23 2022: Epoch [3], Iteration [100/391/], Data(s): 0.056, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.013, Top1: 92.582, Top5: 99.6983, Loss: 0.216\n",
            "Mon Apr 25 16:04:39 2022: Epoch [3], Iteration [200/391/], Data(s): 0.055, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.013, Top1: 92.798, Top5: 99.6929, Loss: 0.208\n",
            "Mon Apr 25 16:04:56 2022: Epoch [3], Iteration [300/391/], Data(s): 0.055, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.013, Top1: 92.842, Top5: 99.6522, Loss: 0.217\n",
            "Mon Apr 25 16:05:11 2022: Epoch [4], Iteration [0/391/], Data(s): 0.081, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.013, Top1: 90.625, Top5: 100.0000, Loss: 0.210\n",
            "Mon Apr 25 16:05:27 2022: Epoch [4], Iteration [100/391/], Data(s): 0.056, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.014, Top1: 92.969, Top5: 99.6829, Loss: 0.209\n",
            "Mon Apr 25 16:05:44 2022: Epoch [4], Iteration [200/391/], Data(s): 0.055, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.013, Top1: 93.128, Top5: 99.7046, Loss: 0.204\n",
            "Mon Apr 25 16:06:00 2022: Epoch [4], Iteration [300/391/], Data(s): 0.055, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.013, Top1: 93.145, Top5: 99.7171, Loss: 0.211\n",
            "Mon Apr 25 16:06:15 2022: Epoch [5], Iteration [0/391/], Data(s): 0.079, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.013, Top1: 93.750, Top5: 100.0000, Loss: 0.200\n",
            "Mon Apr 25 16:06:32 2022: Epoch [5], Iteration [100/391/], Data(s): 0.056, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.014, Top1: 93.526, Top5: 99.7061, Loss: 0.196\n",
            "Mon Apr 25 16:06:48 2022: Epoch [5], Iteration [200/391/], Data(s): 0.055, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.013, Top1: 93.501, Top5: 99.6891, Loss: 0.203\n",
            "Mon Apr 25 16:07:05 2022: Epoch [5], Iteration [300/391/], Data(s): 0.055, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.013, Top1: 93.340, Top5: 99.6782, Loss: 0.215\n",
            "Mon Apr 25 16:07:20 2022: Epoch [6], Iteration [0/391/], Data(s): 0.077, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 91.406, Top5: 100.0000, Loss: 0.205\n",
            "Mon Apr 25 16:07:36 2022: Epoch [6], Iteration [100/391/], Data(s): 0.056, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.014, Top1: 93.541, Top5: 99.6751, Loss: 0.202\n",
            "Mon Apr 25 16:07:53 2022: Epoch [6], Iteration [200/391/], Data(s): 0.055, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.013, Top1: 93.563, Top5: 99.6891, Loss: 0.199\n",
            "Mon Apr 25 16:08:09 2022: Epoch [6], Iteration [300/391/], Data(s): 0.055, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.013, Top1: 93.566, Top5: 99.6808, Loss: 0.197\n",
            "Mon Apr 25 16:08:24 2022: Epoch [7], Iteration [0/391/], Data(s): 0.077, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 92.188, Top5: 98.4375, Loss: 0.201\n",
            "Mon Apr 25 16:08:41 2022: Epoch [7], Iteration [100/391/], Data(s): 0.056, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.014, Top1: 93.642, Top5: 99.7834, Loss: 0.194\n",
            "Mon Apr 25 16:08:57 2022: Epoch [7], Iteration [200/391/], Data(s): 0.055, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.013, Top1: 93.528, Top5: 99.6891, Loss: 0.206\n",
            "Mon Apr 25 16:09:14 2022: Epoch [7], Iteration [300/391/], Data(s): 0.055, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.013, Top1: 93.550, Top5: 99.6756, Loss: 0.201\n",
            "Mon Apr 25 16:09:29 2022: Epoch [8], Iteration [0/391/], Data(s): 0.086, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.013, Top1: 94.531, Top5: 99.2188, Loss: 0.201\n",
            "Mon Apr 25 16:09:45 2022: Epoch [8], Iteration [100/391/], Data(s): 0.056, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.013, Top1: 93.325, Top5: 99.7138, Loss: 0.201\n",
            "Mon Apr 25 16:10:02 2022: Epoch [8], Iteration [200/391/], Data(s): 0.055, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.013, Top1: 93.486, Top5: 99.7124, Loss: 0.194\n",
            "Mon Apr 25 16:10:18 2022: Epoch [8], Iteration [300/391/], Data(s): 0.055, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.013, Top1: 93.519, Top5: 99.7067, Loss: 0.195\n",
            "Mon Apr 25 16:10:33 2022: Epoch [9], Iteration [0/391/], Data(s): 0.080, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.312, Top5: 98.4375, Loss: 0.191\n",
            "Mon Apr 25 16:10:50 2022: Epoch [9], Iteration [100/391/], Data(s): 0.056, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.014, Top1: 93.557, Top5: 99.6906, Loss: 0.196\n",
            "Mon Apr 25 16:11:06 2022: Epoch [9], Iteration [200/391/], Data(s): 0.055, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.014, Top1: 93.785, Top5: 99.7007, Loss: 0.189\n",
            "Mon Apr 25 16:11:23 2022: Epoch [9], Iteration [300/391/], Data(s): 0.055, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.014, Top1: 93.846, Top5: 99.7041, Loss: 0.183\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 16:11:45 2022: Test information, Data(s): 2.722, Forward(s): 0.618, Top1: 90.500, Top5: 99.340, \n",
            "\n",
            "Mon Apr 25 16:11:45 2022: conv6 Layer, 98 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 158, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(158, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(158, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]          73,856\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "             ReLU-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]         147,584\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         295,168\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 158, 8, 8]         364,190\n",
            "      BatchNorm2d-19            [-1, 158, 8, 8]             316\n",
            "             ReLU-20            [-1, 158, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         364,288\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]       1,180,160\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 14,540,068\n",
            "Trainable params: 14,540,068\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 6.43\n",
            "Params size (MB): 55.47\n",
            "Estimated Total Size (MB): 61.91\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 158, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(158, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(158, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 16:11:47 2022: Epoch [0], Iteration [0/391/], Data(s): 0.059, Loss(s): 0.013, Forward(s): 0.066, Backward(s): 0.142, Top1: 94.531, Top5: 100.0000, Loss: 0.166\n",
            "Mon Apr 25 16:12:03 2022: Epoch [0], Iteration [100/391/], Data(s): 0.056, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.015, Top1: 93.472, Top5: 99.6674, Loss: 0.199\n",
            "Mon Apr 25 16:12:19 2022: Epoch [0], Iteration [200/391/], Data(s): 0.055, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.014, Top1: 93.556, Top5: 99.6774, Loss: 0.202\n",
            "Mon Apr 25 16:12:36 2022: Epoch [0], Iteration [300/391/], Data(s): 0.055, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.014, Top1: 93.657, Top5: 99.7041, Loss: 0.189\n",
            "Mon Apr 25 16:12:51 2022: Epoch [1], Iteration [0/391/], Data(s): 0.075, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.013, Top1: 92.969, Top5: 100.0000, Loss: 0.189\n",
            "Mon Apr 25 16:13:07 2022: Epoch [1], Iteration [100/391/], Data(s): 0.056, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.013, Top1: 93.278, Top5: 99.7447, Loss: 0.201\n",
            "Mon Apr 25 16:13:24 2022: Epoch [1], Iteration [200/391/], Data(s): 0.055, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.013, Top1: 93.633, Top5: 99.7357, Loss: 0.185\n",
            "Mon Apr 25 16:13:40 2022: Epoch [1], Iteration [300/391/], Data(s): 0.055, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.013, Top1: 93.703, Top5: 99.7560, Loss: 0.183\n",
            "Mon Apr 25 16:13:55 2022: Epoch [2], Iteration [0/391/], Data(s): 0.079, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.013, Top1: 98.438, Top5: 100.0000, Loss: 0.195\n",
            "Mon Apr 25 16:14:11 2022: Epoch [2], Iteration [100/391/], Data(s): 0.056, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.014, Top1: 93.874, Top5: 99.7293, Loss: 0.189\n",
            "Mon Apr 25 16:14:28 2022: Epoch [2], Iteration [200/391/], Data(s): 0.055, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.014, Top1: 93.960, Top5: 99.7474, Loss: 0.190\n",
            "Mon Apr 25 16:14:44 2022: Epoch [2], Iteration [300/391/], Data(s): 0.055, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 94.030, Top5: 99.7379, Loss: 0.182\n",
            "Mon Apr 25 16:14:59 2022: Epoch [3], Iteration [0/391/], Data(s): 0.087, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.013, Top1: 94.531, Top5: 100.0000, Loss: 0.197\n",
            "Mon Apr 25 16:15:16 2022: Epoch [3], Iteration [100/391/], Data(s): 0.056, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.013, Top1: 93.827, Top5: 99.7370, Loss: 0.187\n",
            "Mon Apr 25 16:15:32 2022: Epoch [3], Iteration [200/391/], Data(s): 0.055, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 93.944, Top5: 99.7668, Loss: 0.182\n",
            "Mon Apr 25 16:15:48 2022: Epoch [3], Iteration [300/391/], Data(s): 0.055, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 93.851, Top5: 99.7586, Loss: 0.186\n",
            "Mon Apr 25 16:16:04 2022: Epoch [4], Iteration [0/391/], Data(s): 0.078, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 94.531, Top5: 99.2188, Loss: 0.193\n",
            "Mon Apr 25 16:16:20 2022: Epoch [4], Iteration [100/391/], Data(s): 0.056, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.014, Top1: 94.152, Top5: 99.7912, Loss: 0.177\n",
            "Mon Apr 25 16:16:36 2022: Epoch [4], Iteration [200/391/], Data(s): 0.055, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.014, Top1: 94.174, Top5: 99.7474, Loss: 0.180\n",
            "Mon Apr 25 16:16:53 2022: Epoch [4], Iteration [300/391/], Data(s): 0.055, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.014, Top1: 94.137, Top5: 99.7534, Loss: 0.182\n",
            "Mon Apr 25 16:17:08 2022: Epoch [5], Iteration [0/391/], Data(s): 0.078, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.013, Top1: 93.750, Top5: 100.0000, Loss: 0.181\n",
            "Mon Apr 25 16:17:24 2022: Epoch [5], Iteration [100/391/], Data(s): 0.057, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.014, Top1: 93.998, Top5: 99.7989, Loss: 0.175\n",
            "Mon Apr 25 16:17:41 2022: Epoch [5], Iteration [200/391/], Data(s): 0.056, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.014, Top1: 94.003, Top5: 99.7979, Loss: 0.179\n",
            "Mon Apr 25 16:17:57 2022: Epoch [5], Iteration [300/391/], Data(s): 0.056, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 93.989, Top5: 99.7742, Loss: 0.181\n",
            "Mon Apr 25 16:18:12 2022: Epoch [6], Iteration [0/391/], Data(s): 0.079, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.312, Top5: 100.0000, Loss: 0.175\n",
            "Mon Apr 25 16:18:29 2022: Epoch [6], Iteration [100/391/], Data(s): 0.057, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.014, Top1: 93.881, Top5: 99.7447, Loss: 0.182\n",
            "Mon Apr 25 16:18:45 2022: Epoch [6], Iteration [200/391/], Data(s): 0.056, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.014, Top1: 94.042, Top5: 99.7823, Loss: 0.171\n",
            "Mon Apr 25 16:19:02 2022: Epoch [6], Iteration [300/391/], Data(s): 0.056, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.014, Top1: 94.248, Top5: 99.7820, Loss: 0.167\n",
            "Mon Apr 25 16:19:17 2022: Epoch [7], Iteration [0/391/], Data(s): 0.081, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.014, Top1: 91.406, Top5: 99.2188, Loss: 0.178\n",
            "Mon Apr 25 16:19:33 2022: Epoch [7], Iteration [100/391/], Data(s): 0.057, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.014, Top1: 94.346, Top5: 99.7989, Loss: 0.170\n",
            "Mon Apr 25 16:19:50 2022: Epoch [7], Iteration [200/391/], Data(s): 0.056, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.014, Top1: 94.193, Top5: 99.7318, Loss: 0.177\n",
            "Mon Apr 25 16:20:06 2022: Epoch [7], Iteration [300/391/], Data(s): 0.055, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.014, Top1: 94.134, Top5: 99.7404, Loss: 0.185\n",
            "Mon Apr 25 16:20:21 2022: Epoch [8], Iteration [0/391/], Data(s): 0.078, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.014, Top1: 95.312, Top5: 99.2188, Loss: 0.164\n",
            "Mon Apr 25 16:20:37 2022: Epoch [8], Iteration [100/391/], Data(s): 0.056, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.014, Top1: 94.431, Top5: 99.8221, Loss: 0.166\n",
            "Mon Apr 25 16:20:54 2022: Epoch [8], Iteration [200/391/], Data(s): 0.056, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.014, Top1: 94.380, Top5: 99.8095, Loss: 0.172\n",
            "Mon Apr 25 16:21:10 2022: Epoch [8], Iteration [300/391/], Data(s): 0.056, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.014, Top1: 94.383, Top5: 99.8027, Loss: 0.172\n",
            "Mon Apr 25 16:21:25 2022: Epoch [9], Iteration [0/391/], Data(s): 0.076, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.013, Top1: 90.625, Top5: 99.2188, Loss: 0.172\n",
            "Mon Apr 25 16:21:42 2022: Epoch [9], Iteration [100/391/], Data(s): 0.056, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.014, Top1: 94.732, Top5: 99.7447, Loss: 0.166\n",
            "Mon Apr 25 16:21:58 2022: Epoch [9], Iteration [200/391/], Data(s): 0.056, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.014, Top1: 94.827, Top5: 99.7901, Loss: 0.161\n",
            "Mon Apr 25 16:22:14 2022: Epoch [9], Iteration [300/391/], Data(s): 0.055, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.014, Top1: 94.656, Top5: 99.7794, Loss: 0.169\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 16:22:37 2022: Test information, Data(s): 2.715, Forward(s): 0.596, Top1: 91.080, Top5: 99.320, \n",
            "\n",
            "Mon Apr 25 16:22:37 2022: conv6 Layer, 131 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 125, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(125, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(125, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]          73,856\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "             ReLU-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]         147,584\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         295,168\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 125, 8, 8]         288,125\n",
            "      BatchNorm2d-19            [-1, 125, 8, 8]             250\n",
            "             ReLU-20            [-1, 125, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         288,256\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]       1,180,160\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 14,387,905\n",
            "Trainable params: 14,387,905\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 6.38\n",
            "Params size (MB): 54.89\n",
            "Estimated Total Size (MB): 61.28\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 125, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(125, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(125, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 16:22:38 2022: Epoch [0], Iteration [0/391/], Data(s): 0.058, Loss(s): 0.011, Forward(s): 0.056, Backward(s): 0.125, Top1: 92.188, Top5: 99.2188, Loss: 0.219\n",
            "Mon Apr 25 16:22:54 2022: Epoch [0], Iteration [100/391/], Data(s): 0.056, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.015, Top1: 93.874, Top5: 99.6983, Loss: 0.181\n",
            "Mon Apr 25 16:23:11 2022: Epoch [0], Iteration [200/391/], Data(s): 0.055, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.014, Top1: 93.975, Top5: 99.7435, Loss: 0.179\n",
            "Mon Apr 25 16:23:27 2022: Epoch [0], Iteration [300/391/], Data(s): 0.055, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.014, Top1: 94.056, Top5: 99.7560, Loss: 0.174\n",
            "Mon Apr 25 16:23:42 2022: Epoch [1], Iteration [0/391/], Data(s): 0.076, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.013, Top1: 95.312, Top5: 100.0000, Loss: 0.175\n",
            "Mon Apr 25 16:23:58 2022: Epoch [1], Iteration [100/391/], Data(s): 0.056, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.014, Top1: 94.338, Top5: 99.7370, Loss: 0.173\n",
            "Mon Apr 25 16:24:14 2022: Epoch [1], Iteration [200/391/], Data(s): 0.055, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.014, Top1: 94.209, Top5: 99.7823, Loss: 0.173\n",
            "Mon Apr 25 16:24:30 2022: Epoch [1], Iteration [300/391/], Data(s): 0.055, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.014, Top1: 94.196, Top5: 99.7872, Loss: 0.170\n",
            "Mon Apr 25 16:24:45 2022: Epoch [2], Iteration [0/391/], Data(s): 0.092, Loss(s): 0.026, Forward(s): 0.007, Backward(s): 0.014, Top1: 96.094, Top5: 99.2188, Loss: 0.169\n",
            "Mon Apr 25 16:25:01 2022: Epoch [2], Iteration [100/391/], Data(s): 0.056, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.014, Top1: 94.268, Top5: 99.7138, Loss: 0.177\n",
            "Mon Apr 25 16:25:17 2022: Epoch [2], Iteration [200/391/], Data(s): 0.055, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.014, Top1: 94.205, Top5: 99.7435, Loss: 0.177\n",
            "Mon Apr 25 16:25:33 2022: Epoch [2], Iteration [300/391/], Data(s): 0.055, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.014, Top1: 94.378, Top5: 99.7456, Loss: 0.159\n",
            "Mon Apr 25 16:25:48 2022: Epoch [3], Iteration [0/391/], Data(s): 0.077, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.013, Top1: 95.312, Top5: 100.0000, Loss: 0.159\n",
            "Mon Apr 25 16:26:05 2022: Epoch [3], Iteration [100/391/], Data(s): 0.056, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.014, Top1: 94.833, Top5: 99.8762, Loss: 0.163\n",
            "Mon Apr 25 16:26:21 2022: Epoch [3], Iteration [200/391/], Data(s): 0.055, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.014, Top1: 94.889, Top5: 99.8601, Loss: 0.152\n",
            "Mon Apr 25 16:26:37 2022: Epoch [3], Iteration [300/391/], Data(s): 0.055, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.014, Top1: 94.773, Top5: 99.8313, Loss: 0.167\n",
            "Mon Apr 25 16:26:52 2022: Epoch [4], Iteration [0/391/], Data(s): 0.075, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.013, Top1: 94.531, Top5: 100.0000, Loss: 0.173\n",
            "Mon Apr 25 16:27:08 2022: Epoch [4], Iteration [100/391/], Data(s): 0.056, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.014, Top1: 94.508, Top5: 99.8221, Loss: 0.166\n",
            "Mon Apr 25 16:27:24 2022: Epoch [4], Iteration [200/391/], Data(s): 0.055, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.014, Top1: 94.508, Top5: 99.7785, Loss: 0.167\n",
            "Mon Apr 25 16:27:40 2022: Epoch [4], Iteration [300/391/], Data(s): 0.055, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.014, Top1: 94.661, Top5: 99.8053, Loss: 0.159\n",
            "Mon Apr 25 16:27:55 2022: Epoch [5], Iteration [0/391/], Data(s): 0.077, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.013, Top1: 94.531, Top5: 100.0000, Loss: 0.155\n",
            "Mon Apr 25 16:28:12 2022: Epoch [5], Iteration [100/391/], Data(s): 0.056, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.014, Top1: 94.686, Top5: 99.8994, Loss: 0.156\n",
            "Mon Apr 25 16:28:28 2022: Epoch [5], Iteration [200/391/], Data(s): 0.056, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.014, Top1: 94.753, Top5: 99.8368, Loss: 0.158\n",
            "Mon Apr 25 16:28:44 2022: Epoch [5], Iteration [300/391/], Data(s): 0.055, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 94.747, Top5: 99.8131, Loss: 0.159\n",
            "Mon Apr 25 16:28:59 2022: Epoch [6], Iteration [0/391/], Data(s): 0.080, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.312, Top5: 100.0000, Loss: 0.168\n",
            "Mon Apr 25 16:29:15 2022: Epoch [6], Iteration [100/391/], Data(s): 0.056, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.014, Top1: 94.895, Top5: 99.7989, Loss: 0.155\n",
            "Mon Apr 25 16:29:31 2022: Epoch [6], Iteration [200/391/], Data(s): 0.056, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.014, Top1: 94.796, Top5: 99.8095, Loss: 0.157\n",
            "Mon Apr 25 16:29:47 2022: Epoch [6], Iteration [300/391/], Data(s): 0.055, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.013, Top1: 94.692, Top5: 99.8261, Loss: 0.165\n",
            "Mon Apr 25 16:30:02 2022: Epoch [7], Iteration [0/391/], Data(s): 0.076, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.014, Top1: 94.531, Top5: 100.0000, Loss: 0.159\n",
            "Mon Apr 25 16:30:19 2022: Epoch [7], Iteration [100/391/], Data(s): 0.056, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.014, Top1: 94.740, Top5: 99.8144, Loss: 0.157\n",
            "Mon Apr 25 16:30:35 2022: Epoch [7], Iteration [200/391/], Data(s): 0.055, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.014, Top1: 94.951, Top5: 99.8173, Loss: 0.151\n",
            "Mon Apr 25 16:30:51 2022: Epoch [7], Iteration [300/391/], Data(s): 0.055, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.014, Top1: 94.949, Top5: 99.8313, Loss: 0.150\n",
            "Mon Apr 25 16:31:06 2022: Epoch [8], Iteration [0/391/], Data(s): 0.089, Loss(s): 0.026, Forward(s): 0.007, Backward(s): 0.014, Top1: 92.969, Top5: 100.0000, Loss: 0.160\n",
            "Mon Apr 25 16:31:22 2022: Epoch [8], Iteration [100/391/], Data(s): 0.056, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.014, Top1: 94.624, Top5: 99.8066, Loss: 0.156\n",
            "Mon Apr 25 16:31:38 2022: Epoch [8], Iteration [200/391/], Data(s): 0.055, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.014, Top1: 94.959, Top5: 99.8406, Loss: 0.145\n",
            "Mon Apr 25 16:31:54 2022: Epoch [8], Iteration [300/391/], Data(s): 0.055, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.014, Top1: 94.944, Top5: 99.8365, Loss: 0.156\n",
            "Mon Apr 25 16:32:09 2022: Epoch [9], Iteration [0/391/], Data(s): 0.090, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.312, Top5: 99.2188, Loss: 0.154\n",
            "Mon Apr 25 16:32:26 2022: Epoch [9], Iteration [100/391/], Data(s): 0.056, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.014, Top1: 95.065, Top5: 99.8840, Loss: 0.145\n",
            "Mon Apr 25 16:32:42 2022: Epoch [9], Iteration [200/391/], Data(s): 0.055, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.014, Top1: 95.048, Top5: 99.8795, Loss: 0.148\n",
            "Mon Apr 25 16:32:58 2022: Epoch [9], Iteration [300/391/], Data(s): 0.055, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.045, Top5: 99.8598, Loss: 0.154\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 16:33:20 2022: Test information, Data(s): 2.705, Forward(s): 0.593, Top1: 90.980, Top5: 99.320, \n",
            "\n",
            "Mon Apr 25 16:33:20 2022: conv6 Layer, 164 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 92, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(92, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(92, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]          73,856\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "             ReLU-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]         147,584\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         295,168\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18             [-1, 92, 8, 8]         212,060\n",
            "      BatchNorm2d-19             [-1, 92, 8, 8]             184\n",
            "             ReLU-20             [-1, 92, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         212,224\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]       1,180,160\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 14,235,742\n",
            "Trainable params: 14,235,742\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 6.33\n",
            "Params size (MB): 54.31\n",
            "Estimated Total Size (MB): 60.65\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 92, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(92, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(92, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 16:33:21 2022: Epoch [0], Iteration [0/391/], Data(s): 0.055, Loss(s): 0.012, Forward(s): 0.055, Backward(s): 0.098, Top1: 96.094, Top5: 100.0000, Loss: 0.158\n",
            "Mon Apr 25 16:33:37 2022: Epoch [0], Iteration [100/391/], Data(s): 0.056, Loss(s): 0.026, Forward(s): 0.007, Backward(s): 0.014, Top1: 93.874, Top5: 99.7989, Loss: 0.182\n",
            "Mon Apr 25 16:33:53 2022: Epoch [0], Iteration [200/391/], Data(s): 0.055, Loss(s): 0.026, Forward(s): 0.007, Backward(s): 0.014, Top1: 94.178, Top5: 99.7785, Loss: 0.166\n",
            "Mon Apr 25 16:34:09 2022: Epoch [0], Iteration [300/391/], Data(s): 0.055, Loss(s): 0.026, Forward(s): 0.007, Backward(s): 0.014, Top1: 94.204, Top5: 99.7768, Loss: 0.175\n",
            "Mon Apr 25 16:34:24 2022: Epoch [1], Iteration [0/391/], Data(s): 0.075, Loss(s): 0.026, Forward(s): 0.007, Backward(s): 0.014, Top1: 94.531, Top5: 100.0000, Loss: 0.171\n",
            "Mon Apr 25 16:34:41 2022: Epoch [1], Iteration [100/391/], Data(s): 0.057, Loss(s): 0.026, Forward(s): 0.007, Backward(s): 0.014, Top1: 94.446, Top5: 99.8376, Loss: 0.166\n",
            "Mon Apr 25 16:34:57 2022: Epoch [1], Iteration [200/391/], Data(s): 0.055, Loss(s): 0.026, Forward(s): 0.007, Backward(s): 0.014, Top1: 94.737, Top5: 99.8290, Loss: 0.151\n",
            "Mon Apr 25 16:35:13 2022: Epoch [1], Iteration [300/391/], Data(s): 0.055, Loss(s): 0.026, Forward(s): 0.007, Backward(s): 0.013, Top1: 94.671, Top5: 99.8365, Loss: 0.163\n",
            "Mon Apr 25 16:35:28 2022: Epoch [2], Iteration [0/391/], Data(s): 0.079, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.312, Top5: 99.2188, Loss: 0.164\n",
            "Mon Apr 25 16:35:44 2022: Epoch [2], Iteration [100/391/], Data(s): 0.056, Loss(s): 0.026, Forward(s): 0.007, Backward(s): 0.014, Top1: 94.616, Top5: 99.8376, Loss: 0.163\n",
            "Mon Apr 25 16:36:00 2022: Epoch [2], Iteration [200/391/], Data(s): 0.055, Loss(s): 0.026, Forward(s): 0.007, Backward(s): 0.013, Top1: 94.691, Top5: 99.8484, Loss: 0.157\n",
            "Mon Apr 25 16:36:16 2022: Epoch [2], Iteration [300/391/], Data(s): 0.055, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 94.666, Top5: 99.8261, Loss: 0.157\n",
            "Mon Apr 25 16:36:31 2022: Epoch [3], Iteration [0/391/], Data(s): 0.076, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 96.875, Top5: 100.0000, Loss: 0.157\n",
            "Mon Apr 25 16:36:47 2022: Epoch [3], Iteration [100/391/], Data(s): 0.056, Loss(s): 0.026, Forward(s): 0.007, Backward(s): 0.014, Top1: 94.732, Top5: 99.8066, Loss: 0.161\n",
            "Mon Apr 25 16:37:03 2022: Epoch [3], Iteration [200/391/], Data(s): 0.055, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.014, Top1: 94.900, Top5: 99.8095, Loss: 0.151\n",
            "Mon Apr 25 16:37:19 2022: Epoch [3], Iteration [300/391/], Data(s): 0.055, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.014, Top1: 94.843, Top5: 99.8209, Loss: 0.158\n",
            "Mon Apr 25 16:37:34 2022: Epoch [4], Iteration [0/391/], Data(s): 0.080, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.312, Top5: 100.0000, Loss: 0.154\n",
            "Mon Apr 25 16:37:50 2022: Epoch [4], Iteration [100/391/], Data(s): 0.057, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.014, Top1: 95.119, Top5: 99.8762, Loss: 0.144\n",
            "Mon Apr 25 16:38:06 2022: Epoch [4], Iteration [200/391/], Data(s): 0.056, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.014, Top1: 94.955, Top5: 99.8445, Loss: 0.154\n",
            "Mon Apr 25 16:38:22 2022: Epoch [4], Iteration [300/391/], Data(s): 0.055, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.014, Top1: 94.952, Top5: 99.8521, Loss: 0.150\n",
            "Mon Apr 25 16:38:37 2022: Epoch [5], Iteration [0/391/], Data(s): 0.075, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.014, Top1: 96.875, Top5: 99.2188, Loss: 0.157\n",
            "Mon Apr 25 16:38:53 2022: Epoch [5], Iteration [100/391/], Data(s): 0.056, Loss(s): 0.026, Forward(s): 0.007, Backward(s): 0.014, Top1: 95.251, Top5: 99.7989, Loss: 0.148\n",
            "Mon Apr 25 16:39:09 2022: Epoch [5], Iteration [200/391/], Data(s): 0.056, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.014, Top1: 95.204, Top5: 99.8134, Loss: 0.150\n",
            "Mon Apr 25 16:39:26 2022: Epoch [5], Iteration [300/391/], Data(s): 0.056, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.014, Top1: 95.216, Top5: 99.8391, Loss: 0.145\n",
            "Mon Apr 25 16:39:40 2022: Epoch [6], Iteration [0/391/], Data(s): 0.082, Loss(s): 0.026, Forward(s): 0.007, Backward(s): 0.013, Top1: 98.438, Top5: 100.0000, Loss: 0.143\n",
            "Mon Apr 25 16:39:57 2022: Epoch [6], Iteration [100/391/], Data(s): 0.056, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.014, Top1: 95.220, Top5: 99.8530, Loss: 0.142\n",
            "Mon Apr 25 16:40:13 2022: Epoch [6], Iteration [200/391/], Data(s): 0.056, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.250, Top5: 99.8368, Loss: 0.142\n",
            "Mon Apr 25 16:40:29 2022: Epoch [6], Iteration [300/391/], Data(s): 0.055, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.229, Top5: 99.8287, Loss: 0.142\n",
            "Mon Apr 25 16:40:44 2022: Epoch [7], Iteration [0/391/], Data(s): 0.088, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.013, Top1: 92.969, Top5: 100.0000, Loss: 0.144\n",
            "Mon Apr 25 16:41:00 2022: Epoch [7], Iteration [100/391/], Data(s): 0.056, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.014, Top1: 95.459, Top5: 99.8376, Loss: 0.139\n",
            "Mon Apr 25 16:41:16 2022: Epoch [7], Iteration [200/391/], Data(s): 0.056, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.014, Top1: 95.305, Top5: 99.8290, Loss: 0.151\n",
            "Mon Apr 25 16:41:32 2022: Epoch [7], Iteration [300/391/], Data(s): 0.056, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.014, Top1: 95.258, Top5: 99.8339, Loss: 0.141\n",
            "Mon Apr 25 16:41:47 2022: Epoch [8], Iteration [0/391/], Data(s): 0.078, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.312, Top5: 100.0000, Loss: 0.142\n",
            "Mon Apr 25 16:42:03 2022: Epoch [8], Iteration [100/391/], Data(s): 0.057, Loss(s): 0.026, Forward(s): 0.007, Backward(s): 0.014, Top1: 95.846, Top5: 99.8221, Loss: 0.131\n",
            "Mon Apr 25 16:42:19 2022: Epoch [8], Iteration [200/391/], Data(s): 0.056, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.487, Top5: 99.8756, Loss: 0.144\n",
            "Mon Apr 25 16:42:36 2022: Epoch [8], Iteration [300/391/], Data(s): 0.056, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.450, Top5: 99.8832, Loss: 0.130\n",
            "Mon Apr 25 16:42:50 2022: Epoch [9], Iteration [0/391/], Data(s): 0.077, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.013, Top1: 97.656, Top5: 100.0000, Loss: 0.137\n",
            "Mon Apr 25 16:43:07 2022: Epoch [9], Iteration [100/391/], Data(s): 0.057, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.014, Top1: 95.823, Top5: 99.8530, Loss: 0.129\n",
            "Mon Apr 25 16:43:23 2022: Epoch [9], Iteration [200/391/], Data(s): 0.056, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.014, Top1: 95.658, Top5: 99.8484, Loss: 0.136\n",
            "Mon Apr 25 16:43:39 2022: Epoch [9], Iteration [300/391/], Data(s): 0.056, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.014, Top1: 95.658, Top5: 99.8521, Loss: 0.131\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 16:44:00 2022: Test information, Data(s): 2.706, Forward(s): 0.582, Top1: 91.080, Top5: 99.380, \n",
            "\n",
            "Mon Apr 25 16:44:00 2022: conv6 Layer, 197 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 59, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(59, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(59, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]          73,856\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "             ReLU-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]         147,584\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         295,168\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18             [-1, 59, 8, 8]         135,995\n",
            "      BatchNorm2d-19             [-1, 59, 8, 8]             118\n",
            "             ReLU-20             [-1, 59, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         136,192\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]       1,180,160\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 14,083,579\n",
            "Trainable params: 14,083,579\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 6.29\n",
            "Params size (MB): 53.72\n",
            "Estimated Total Size (MB): 60.02\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 59, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(59, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(59, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 16:44:02 2022: Epoch [0], Iteration [0/391/], Data(s): 0.057, Loss(s): 0.011, Forward(s): 0.069, Backward(s): 0.088, Top1: 91.406, Top5: 98.4375, Loss: 0.248\n",
            "Mon Apr 25 16:44:18 2022: Epoch [0], Iteration [100/391/], Data(s): 0.056, Loss(s): 0.026, Forward(s): 0.007, Backward(s): 0.015, Top1: 93.201, Top5: 99.6210, Loss: 0.199\n",
            "Mon Apr 25 16:44:34 2022: Epoch [0], Iteration [200/391/], Data(s): 0.055, Loss(s): 0.026, Forward(s): 0.007, Backward(s): 0.014, Top1: 93.439, Top5: 99.6774, Loss: 0.190\n",
            "Mon Apr 25 16:44:50 2022: Epoch [0], Iteration [300/391/], Data(s): 0.055, Loss(s): 0.026, Forward(s): 0.007, Backward(s): 0.014, Top1: 93.680, Top5: 99.7171, Loss: 0.175\n",
            "Mon Apr 25 16:45:04 2022: Epoch [1], Iteration [0/391/], Data(s): 0.082, Loss(s): 0.024, Forward(s): 0.008, Backward(s): 0.013, Top1: 96.094, Top5: 100.0000, Loss: 0.178\n",
            "Mon Apr 25 16:45:20 2022: Epoch [1], Iteration [100/391/], Data(s): 0.056, Loss(s): 0.026, Forward(s): 0.007, Backward(s): 0.014, Top1: 94.075, Top5: 99.7525, Loss: 0.177\n",
            "Mon Apr 25 16:45:36 2022: Epoch [1], Iteration [200/391/], Data(s): 0.055, Loss(s): 0.026, Forward(s): 0.007, Backward(s): 0.014, Top1: 94.438, Top5: 99.7396, Loss: 0.164\n",
            "Mon Apr 25 16:45:52 2022: Epoch [1], Iteration [300/391/], Data(s): 0.055, Loss(s): 0.026, Forward(s): 0.007, Backward(s): 0.014, Top1: 94.529, Top5: 99.7690, Loss: 0.158\n",
            "Mon Apr 25 16:46:06 2022: Epoch [2], Iteration [0/391/], Data(s): 0.074, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.013, Top1: 93.750, Top5: 100.0000, Loss: 0.164\n",
            "Mon Apr 25 16:46:22 2022: Epoch [2], Iteration [100/391/], Data(s): 0.056, Loss(s): 0.025, Forward(s): 0.007, Backward(s): 0.014, Top1: 95.011, Top5: 99.8221, Loss: 0.154\n",
            "Mon Apr 25 16:46:38 2022: Epoch [2], Iteration [200/391/], Data(s): 0.056, Loss(s): 0.026, Forward(s): 0.007, Backward(s): 0.014, Top1: 94.897, Top5: 99.8329, Loss: 0.153\n",
            "Mon Apr 25 16:46:54 2022: Epoch [2], Iteration [300/391/], Data(s): 0.055, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.014, Top1: 94.726, Top5: 99.8131, Loss: 0.175\n",
            "Mon Apr 25 16:47:09 2022: Epoch [3], Iteration [0/391/], Data(s): 0.079, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.013, Top1: 93.750, Top5: 100.0000, Loss: 0.158\n",
            "Mon Apr 25 16:47:25 2022: Epoch [3], Iteration [100/391/], Data(s): 0.057, Loss(s): 0.026, Forward(s): 0.007, Backward(s): 0.014, Top1: 94.910, Top5: 99.8453, Loss: 0.155\n",
            "Mon Apr 25 16:47:41 2022: Epoch [3], Iteration [200/391/], Data(s): 0.056, Loss(s): 0.026, Forward(s): 0.007, Backward(s): 0.014, Top1: 95.091, Top5: 99.8368, Loss: 0.145\n",
            "Mon Apr 25 16:47:56 2022: Epoch [3], Iteration [300/391/], Data(s): 0.056, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.014, Top1: 94.936, Top5: 99.8495, Loss: 0.156\n",
            "Mon Apr 25 16:48:11 2022: Epoch [4], Iteration [0/391/], Data(s): 0.078, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.014, Top1: 94.531, Top5: 99.2188, Loss: 0.153\n",
            "Mon Apr 25 16:48:27 2022: Epoch [4], Iteration [100/391/], Data(s): 0.056, Loss(s): 0.026, Forward(s): 0.007, Backward(s): 0.014, Top1: 95.057, Top5: 99.8453, Loss: 0.147\n",
            "Mon Apr 25 16:48:43 2022: Epoch [4], Iteration [200/391/], Data(s): 0.055, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.014, Top1: 94.974, Top5: 99.8406, Loss: 0.150\n",
            "Mon Apr 25 16:48:59 2022: Epoch [4], Iteration [300/391/], Data(s): 0.055, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.014, Top1: 95.009, Top5: 99.8339, Loss: 0.148\n",
            "Mon Apr 25 16:49:13 2022: Epoch [5], Iteration [0/391/], Data(s): 0.075, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.013, Top1: 94.531, Top5: 100.0000, Loss: 0.149\n",
            "Mon Apr 25 16:49:29 2022: Epoch [5], Iteration [100/391/], Data(s): 0.057, Loss(s): 0.026, Forward(s): 0.007, Backward(s): 0.014, Top1: 95.583, Top5: 99.8530, Loss: 0.133\n",
            "Mon Apr 25 16:49:45 2022: Epoch [5], Iteration [200/391/], Data(s): 0.056, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.014, Top1: 95.452, Top5: 99.8484, Loss: 0.138\n",
            "Mon Apr 25 16:50:01 2022: Epoch [5], Iteration [300/391/], Data(s): 0.055, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.014, Top1: 95.307, Top5: 99.8391, Loss: 0.149\n",
            "Mon Apr 25 16:50:15 2022: Epoch [6], Iteration [0/391/], Data(s): 0.078, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.013, Top1: 92.969, Top5: 100.0000, Loss: 0.147\n",
            "Mon Apr 25 16:50:31 2022: Epoch [6], Iteration [100/391/], Data(s): 0.056, Loss(s): 0.026, Forward(s): 0.007, Backward(s): 0.014, Top1: 95.421, Top5: 99.8762, Loss: 0.136\n",
            "Mon Apr 25 16:50:47 2022: Epoch [6], Iteration [200/391/], Data(s): 0.055, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.014, Top1: 95.328, Top5: 99.8601, Loss: 0.142\n",
            "Mon Apr 25 16:51:03 2022: Epoch [6], Iteration [300/391/], Data(s): 0.055, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.014, Top1: 95.271, Top5: 99.8521, Loss: 0.146\n",
            "Mon Apr 25 16:51:18 2022: Epoch [7], Iteration [0/391/], Data(s): 0.075, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.013, Top1: 93.750, Top5: 99.2188, Loss: 0.133\n",
            "Mon Apr 25 16:51:34 2022: Epoch [7], Iteration [100/391/], Data(s): 0.056, Loss(s): 0.026, Forward(s): 0.007, Backward(s): 0.014, Top1: 95.614, Top5: 99.8917, Loss: 0.134\n",
            "Mon Apr 25 16:51:50 2022: Epoch [7], Iteration [200/391/], Data(s): 0.055, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.014, Top1: 95.519, Top5: 99.9067, Loss: 0.136\n",
            "Mon Apr 25 16:52:05 2022: Epoch [7], Iteration [300/391/], Data(s): 0.055, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.014, Top1: 95.536, Top5: 99.8910, Loss: 0.135\n",
            "Mon Apr 25 16:52:20 2022: Epoch [8], Iteration [0/391/], Data(s): 0.078, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.013, Top1: 97.656, Top5: 100.0000, Loss: 0.139\n",
            "Mon Apr 25 16:52:36 2022: Epoch [8], Iteration [100/391/], Data(s): 0.056, Loss(s): 0.026, Forward(s): 0.007, Backward(s): 0.014, Top1: 95.630, Top5: 99.8685, Loss: 0.135\n",
            "Mon Apr 25 16:52:52 2022: Epoch [8], Iteration [200/391/], Data(s): 0.055, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.014, Top1: 95.690, Top5: 99.8795, Loss: 0.131\n",
            "Mon Apr 25 16:53:08 2022: Epoch [8], Iteration [300/391/], Data(s): 0.055, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.014, Top1: 95.691, Top5: 99.8754, Loss: 0.131\n",
            "Mon Apr 25 16:53:22 2022: Epoch [9], Iteration [0/391/], Data(s): 0.076, Loss(s): 0.026, Forward(s): 0.007, Backward(s): 0.014, Top1: 95.312, Top5: 100.0000, Loss: 0.138\n",
            "Mon Apr 25 16:53:38 2022: Epoch [9], Iteration [100/391/], Data(s): 0.056, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.722, Top5: 99.8530, Loss: 0.129\n",
            "Mon Apr 25 16:53:54 2022: Epoch [9], Iteration [200/391/], Data(s): 0.055, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.888, Top5: 99.8989, Loss: 0.120\n",
            "Mon Apr 25 16:54:10 2022: Epoch [9], Iteration [300/391/], Data(s): 0.055, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.746, Top5: 99.8988, Loss: 0.132\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 16:54:32 2022: Test information, Data(s): 2.711, Forward(s): 0.621, Top1: 90.890, Top5: 99.370, \n",
            "\n",
            "Mon Apr 25 16:54:32 2022: conv6 Layer, 230 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 26, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(26, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]          73,856\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "             ReLU-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]         147,584\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         295,168\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18             [-1, 26, 8, 8]          59,930\n",
            "      BatchNorm2d-19             [-1, 26, 8, 8]              52\n",
            "             ReLU-20             [-1, 26, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]          60,160\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]       1,180,160\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 13,931,416\n",
            "Trainable params: 13,931,416\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 6.24\n",
            "Params size (MB): 53.14\n",
            "Estimated Total Size (MB): 59.39\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 26, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(26, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 16:54:33 2022: Epoch [0], Iteration [0/391/], Data(s): 0.056, Loss(s): 0.011, Forward(s): 0.053, Backward(s): 0.068, Top1: 82.812, Top5: 98.4375, Loss: 0.543\n",
            "Mon Apr 25 16:54:49 2022: Epoch [0], Iteration [100/391/], Data(s): 0.056, Loss(s): 0.025, Forward(s): 0.007, Backward(s): 0.015, Top1: 88.707, Top5: 99.2961, Loss: 0.355\n",
            "Mon Apr 25 16:55:05 2022: Epoch [0], Iteration [200/391/], Data(s): 0.055, Loss(s): 0.025, Forward(s): 0.007, Backward(s): 0.014, Top1: 89.712, Top5: 99.3742, Loss: 0.278\n",
            "Mon Apr 25 16:55:20 2022: Epoch [0], Iteration [300/391/], Data(s): 0.055, Loss(s): 0.026, Forward(s): 0.007, Backward(s): 0.014, Top1: 90.262, Top5: 99.4238, Loss: 0.260\n",
            "Mon Apr 25 16:55:35 2022: Epoch [1], Iteration [0/391/], Data(s): 0.075, Loss(s): 0.024, Forward(s): 0.008, Backward(s): 0.013, Top1: 95.312, Top5: 100.0000, Loss: 0.247\n",
            "Mon Apr 25 16:55:51 2022: Epoch [1], Iteration [100/391/], Data(s): 0.057, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.014, Top1: 92.218, Top5: 99.6829, Loss: 0.228\n",
            "Mon Apr 25 16:56:07 2022: Epoch [1], Iteration [200/391/], Data(s): 0.056, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.014, Top1: 92.467, Top5: 99.7085, Loss: 0.214\n",
            "Mon Apr 25 16:56:23 2022: Epoch [1], Iteration [300/391/], Data(s): 0.055, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.014, Top1: 92.520, Top5: 99.6885, Loss: 0.214\n",
            "Mon Apr 25 16:56:37 2022: Epoch [2], Iteration [0/391/], Data(s): 0.078, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.013, Top1: 92.969, Top5: 100.0000, Loss: 0.216\n",
            "Mon Apr 25 16:56:53 2022: Epoch [2], Iteration [100/391/], Data(s): 0.057, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.014, Top1: 92.946, Top5: 99.7525, Loss: 0.202\n",
            "Mon Apr 25 16:57:09 2022: Epoch [2], Iteration [200/391/], Data(s): 0.055, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.013, Top1: 93.039, Top5: 99.7396, Loss: 0.201\n",
            "Mon Apr 25 16:57:25 2022: Epoch [2], Iteration [300/391/], Data(s): 0.055, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.013, Top1: 93.169, Top5: 99.7430, Loss: 0.193\n",
            "Mon Apr 25 16:57:39 2022: Epoch [3], Iteration [0/391/], Data(s): 0.076, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.013, Top1: 91.406, Top5: 100.0000, Loss: 0.189\n",
            "Mon Apr 25 16:57:55 2022: Epoch [3], Iteration [100/391/], Data(s): 0.057, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.014, Top1: 93.247, Top5: 99.7757, Loss: 0.198\n",
            "Mon Apr 25 16:58:11 2022: Epoch [3], Iteration [200/391/], Data(s): 0.056, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.014, Top1: 93.361, Top5: 99.7901, Loss: 0.193\n",
            "Mon Apr 25 16:58:27 2022: Epoch [3], Iteration [300/391/], Data(s): 0.056, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.014, Top1: 93.490, Top5: 99.7846, Loss: 0.187\n",
            "Mon Apr 25 16:58:42 2022: Epoch [4], Iteration [0/391/], Data(s): 0.075, Loss(s): 0.025, Forward(s): 0.006, Backward(s): 0.013, Top1: 96.875, Top5: 100.0000, Loss: 0.188\n",
            "Mon Apr 25 16:58:57 2022: Epoch [4], Iteration [100/391/], Data(s): 0.056, Loss(s): 0.025, Forward(s): 0.006, Backward(s): 0.014, Top1: 94.361, Top5: 99.8221, Loss: 0.168\n",
            "Mon Apr 25 16:59:13 2022: Epoch [4], Iteration [200/391/], Data(s): 0.055, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.014, Top1: 94.236, Top5: 99.8057, Loss: 0.181\n",
            "Mon Apr 25 16:59:29 2022: Epoch [4], Iteration [300/391/], Data(s): 0.055, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.014, Top1: 94.147, Top5: 99.7950, Loss: 0.180\n",
            "Mon Apr 25 16:59:44 2022: Epoch [5], Iteration [0/391/], Data(s): 0.079, Loss(s): 0.025, Forward(s): 0.006, Backward(s): 0.013, Top1: 92.188, Top5: 100.0000, Loss: 0.183\n",
            "Mon Apr 25 16:59:59 2022: Epoch [5], Iteration [100/391/], Data(s): 0.056, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.014, Top1: 94.175, Top5: 99.7989, Loss: 0.174\n",
            "Mon Apr 25 17:00:15 2022: Epoch [5], Iteration [200/391/], Data(s): 0.056, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.014, Top1: 94.259, Top5: 99.8406, Loss: 0.167\n",
            "Mon Apr 25 17:00:31 2022: Epoch [5], Iteration [300/391/], Data(s): 0.055, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.014, Top1: 94.152, Top5: 99.8365, Loss: 0.176\n",
            "Mon Apr 25 17:00:46 2022: Epoch [6], Iteration [0/391/], Data(s): 0.073, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.013, Top1: 97.656, Top5: 100.0000, Loss: 0.177\n",
            "Mon Apr 25 17:01:02 2022: Epoch [6], Iteration [100/391/], Data(s): 0.057, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.014, Top1: 94.709, Top5: 99.8376, Loss: 0.162\n",
            "Mon Apr 25 17:01:17 2022: Epoch [6], Iteration [200/391/], Data(s): 0.056, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.014, Top1: 94.656, Top5: 99.8251, Loss: 0.165\n",
            "Mon Apr 25 17:01:33 2022: Epoch [6], Iteration [300/391/], Data(s): 0.055, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.014, Top1: 94.518, Top5: 99.8079, Loss: 0.172\n",
            "Mon Apr 25 17:01:48 2022: Epoch [7], Iteration [0/391/], Data(s): 0.075, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.013, Top1: 94.531, Top5: 100.0000, Loss: 0.173\n",
            "Mon Apr 25 17:02:04 2022: Epoch [7], Iteration [100/391/], Data(s): 0.056, Loss(s): 0.025, Forward(s): 0.006, Backward(s): 0.014, Top1: 94.585, Top5: 99.8298, Loss: 0.158\n",
            "Mon Apr 25 17:02:19 2022: Epoch [7], Iteration [200/391/], Data(s): 0.055, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.014, Top1: 94.745, Top5: 99.8601, Loss: 0.152\n",
            "Mon Apr 25 17:02:35 2022: Epoch [7], Iteration [300/391/], Data(s): 0.055, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.014, Top1: 94.638, Top5: 99.8469, Loss: 0.161\n",
            "Mon Apr 25 17:02:50 2022: Epoch [8], Iteration [0/391/], Data(s): 0.076, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.013, Top1: 92.969, Top5: 99.2188, Loss: 0.164\n",
            "Mon Apr 25 17:03:06 2022: Epoch [8], Iteration [100/391/], Data(s): 0.057, Loss(s): 0.025, Forward(s): 0.006, Backward(s): 0.014, Top1: 94.817, Top5: 99.7679, Loss: 0.155\n",
            "Mon Apr 25 17:03:21 2022: Epoch [8], Iteration [200/391/], Data(s): 0.056, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.014, Top1: 94.846, Top5: 99.8251, Loss: 0.155\n",
            "Mon Apr 25 17:03:37 2022: Epoch [8], Iteration [300/391/], Data(s): 0.056, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.014, Top1: 94.640, Top5: 99.8261, Loss: 0.170\n",
            "Mon Apr 25 17:03:52 2022: Epoch [9], Iteration [0/391/], Data(s): 0.080, Loss(s): 0.025, Forward(s): 0.007, Backward(s): 0.013, Top1: 91.406, Top5: 99.2188, Loss: 0.159\n",
            "Mon Apr 25 17:04:08 2022: Epoch [9], Iteration [100/391/], Data(s): 0.056, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.014, Top1: 95.034, Top5: 99.8530, Loss: 0.145\n",
            "Mon Apr 25 17:04:24 2022: Epoch [9], Iteration [200/391/], Data(s): 0.056, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.014, Top1: 94.862, Top5: 99.8018, Loss: 0.159\n",
            "Mon Apr 25 17:04:39 2022: Epoch [9], Iteration [300/391/], Data(s): 0.055, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.014, Top1: 94.949, Top5: 99.8261, Loss: 0.149\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 17:05:01 2022: Test information, Data(s): 2.722, Forward(s): 0.581, Top1: 90.370, Top5: 99.270, \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top1_accuracies"
      ],
      "metadata": {
        "id": "Hf_miwmVAG4K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee1e1056-dc8b-4cf0-fe1a-bbe527b62a59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'conv5': [89.72, 90.54, 90.85, 91.05, 91.14, 90.72, 89.35],\n",
              " 'conv6': [89.97, 90.5, 91.08, 90.98, 91.08, 90.89, 90.37]}"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top5_accuracies"
      ],
      "metadata": {
        "id": "XtOQ6DuAAG4L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e670c321-a15e-4512-abf5-b89449f1437d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'conv5': [99.3, 99.29, 99.29, 99.34, 99.29, 99.37, 99.15],\n",
              " 'conv6': [99.25, 99.34, 99.32, 99.32, 99.38, 99.37, 99.27]}"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "1ygFkPv5rL9Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "JkcQSWj2rL64"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top1_accuracies = {}\n",
        "top5_accuracies = {}"
      ],
      "metadata": {
        "id": "hmGEDIvGrL4F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for conv, channel in zip(prune_layers[3:4], prune_channels[3:4]):    \n",
        "    top1_accuracies[conv] = []\n",
        "    top5_accuracies[conv] = []\n",
        "    \n",
        "    # load new network and check accuracy\n",
        "    network, _, _ = test_network(args, data_set=test_set)\n",
        "        \n",
        "    # remove 0 channels ~ M (max_channel_ratio) % of total channels\n",
        "    step = np.linspace(0, int(channel*max_channel_ratio), int(1/prune_step_ratio), dtype=np.int)\n",
        "    steps = (step[1:] - step[:-1]).tolist()\n",
        "    \n",
        "    for i in range(len(steps)):\n",
        "        print(\"\\n%s: %s Layer, %d Channels pruned\"%(time.ctime(), conv, sum(steps[:i+1])))\n",
        "        \n",
        "        # set prune information\n",
        "        args.prune_layers = [conv]\n",
        "        args.prune_channels =[steps[i]]\n",
        "\n",
        "        network = prune_network(args, network)\n",
        "        \n",
        "        network, _, (top1, top5) = test_network(args, network, test_set)\n",
        "            \n",
        "        top1_accuracies[conv].append(top1)\n",
        "        top5_accuracies[conv].append(top5)"
      ],
      "metadata": {
        "id": "DHx2tp-iBY-y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4516f340-edfb-4c33-9ca0-6d7b1f545502"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 18:25:25 2022: Test information, Data(s): 1.676, Forward(s): 0.210, Top1: 77.870, Top5: 97.560, \n",
            "\n",
            "Mon Apr 25 18:25:25 2022: conv4 Layer, 16 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 112, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(112, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]          73,856\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "             ReLU-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11          [-1, 112, 16, 16]         129,136\n",
            "      BatchNorm2d-12          [-1, 112, 16, 16]             224\n",
            "             ReLU-13          [-1, 112, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 112, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         258,304\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]       1,180,160\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 14,936,602\n",
            "Trainable params: 14,936,602\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 6.47\n",
            "Params size (MB): 56.98\n",
            "Estimated Total Size (MB): 63.46\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 112, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(112, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  if __name__ == '__main__':\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 18:25:26 2022: Epoch [0], Iteration [0/391/], Data(s): 0.040, Loss(s): 0.007, Forward(s): 0.041, Backward(s): 0.092, Top1: 89.062, Top5: 97.6562, Loss: 0.435\n",
            "Mon Apr 25 18:25:34 2022: Epoch [0], Iteration [100/391/], Data(s): 0.036, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 86.904, Top5: 98.8320, Loss: 0.405\n",
            "Mon Apr 25 18:25:42 2022: Epoch [0], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 87.702, Top5: 98.9817, Loss: 0.354\n",
            "Mon Apr 25 18:25:50 2022: Epoch [0], Iteration [300/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 88.201, Top5: 99.0942, Loss: 0.336\n",
            "Mon Apr 25 18:25:58 2022: Epoch [1], Iteration [0/391/], Data(s): 0.059, Loss(s): 0.009, Forward(s): 0.005, Backward(s): 0.006, Top1: 90.625, Top5: 100.0000, Loss: 0.322\n",
            "Mon Apr 25 18:26:06 2022: Epoch [1], Iteration [100/391/], Data(s): 0.036, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 90.207, Top5: 99.4353, Loss: 0.301\n",
            "Mon Apr 25 18:26:15 2022: Epoch [1], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 90.372, Top5: 99.4131, Loss: 0.301\n",
            "Mon Apr 25 18:26:23 2022: Epoch [1], Iteration [300/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 90.402, Top5: 99.3901, Loss: 0.304\n",
            "Mon Apr 25 18:26:30 2022: Epoch [2], Iteration [0/391/], Data(s): 0.058, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.531, Top5: 99.2188, Loss: 0.295\n",
            "Mon Apr 25 18:26:38 2022: Epoch [2], Iteration [100/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 90.648, Top5: 99.5127, Loss: 0.289\n",
            "Mon Apr 25 18:26:47 2022: Epoch [2], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 90.676, Top5: 99.3859, Loss: 0.291\n",
            "Mon Apr 25 18:26:55 2022: Epoch [2], Iteration [300/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 90.744, Top5: 99.4186, Loss: 0.279\n",
            "Mon Apr 25 18:27:03 2022: Epoch [3], Iteration [0/391/], Data(s): 0.069, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 91.406, Top5: 100.0000, Loss: 0.274\n",
            "Mon Apr 25 18:27:11 2022: Epoch [3], Iteration [100/391/], Data(s): 0.036, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 91.267, Top5: 99.5436, Loss: 0.267\n",
            "Mon Apr 25 18:27:19 2022: Epoch [3], Iteration [200/391/], Data(s): 0.037, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 91.142, Top5: 99.5336, Loss: 0.275\n",
            "Mon Apr 25 18:27:27 2022: Epoch [3], Iteration [300/391/], Data(s): 0.036, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 91.191, Top5: 99.5484, Loss: 0.263\n",
            "Mon Apr 25 18:27:35 2022: Epoch [4], Iteration [0/391/], Data(s): 0.063, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.531, Top5: 99.2188, Loss: 0.259\n",
            "Mon Apr 25 18:27:43 2022: Epoch [4], Iteration [100/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 91.646, Top5: 99.5282, Loss: 0.260\n",
            "Mon Apr 25 18:27:52 2022: Epoch [4], Iteration [200/391/], Data(s): 0.036, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 91.659, Top5: 99.5025, Loss: 0.259\n",
            "Mon Apr 25 18:28:00 2022: Epoch [4], Iteration [300/391/], Data(s): 0.036, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 91.463, Top5: 99.5146, Loss: 0.267\n",
            "Mon Apr 25 18:28:07 2022: Epoch [5], Iteration [0/391/], Data(s): 0.064, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.188, Top5: 100.0000, Loss: 0.246\n",
            "Mon Apr 25 18:28:16 2022: Epoch [5], Iteration [100/391/], Data(s): 0.036, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 91.994, Top5: 99.5514, Loss: 0.249\n",
            "Mon Apr 25 18:28:24 2022: Epoch [5], Iteration [200/391/], Data(s): 0.037, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.051, Top5: 99.5491, Loss: 0.239\n",
            "Mon Apr 25 18:28:33 2022: Epoch [5], Iteration [300/391/], Data(s): 0.037, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 91.980, Top5: 99.5717, Loss: 0.253\n",
            "Mon Apr 25 18:28:40 2022: Epoch [6], Iteration [0/391/], Data(s): 0.065, Loss(s): 0.010, Forward(s): 0.004, Backward(s): 0.006, Top1: 89.844, Top5: 100.0000, Loss: 0.247\n",
            "Mon Apr 25 18:28:49 2022: Epoch [6], Iteration [100/391/], Data(s): 0.039, Loss(s): 0.011, Forward(s): 0.004, Backward(s): 0.006, Top1: 91.932, Top5: 99.4817, Loss: 0.250\n",
            "Mon Apr 25 18:28:57 2022: Epoch [6], Iteration [200/391/], Data(s): 0.038, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.083, Top5: 99.5219, Loss: 0.244\n",
            "Mon Apr 25 18:29:05 2022: Epoch [6], Iteration [300/391/], Data(s): 0.036, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 91.988, Top5: 99.5536, Loss: 0.247\n",
            "Mon Apr 25 18:29:13 2022: Epoch [7], Iteration [0/391/], Data(s): 0.063, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 89.844, Top5: 98.4375, Loss: 0.232\n",
            "Mon Apr 25 18:29:21 2022: Epoch [7], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.211, Top5: 99.5359, Loss: 0.241\n",
            "Mon Apr 25 18:29:29 2022: Epoch [7], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.242, Top5: 99.5180, Loss: 0.241\n",
            "Mon Apr 25 18:29:37 2022: Epoch [7], Iteration [300/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.198, Top5: 99.5406, Loss: 0.236\n",
            "Mon Apr 25 18:29:45 2022: Epoch [8], Iteration [0/391/], Data(s): 0.060, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.969, Top5: 100.0000, Loss: 0.239\n",
            "Mon Apr 25 18:29:53 2022: Epoch [8], Iteration [100/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.350, Top5: 99.6597, Loss: 0.233\n",
            "Mon Apr 25 18:30:01 2022: Epoch [8], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.320, Top5: 99.5997, Loss: 0.240\n",
            "Mon Apr 25 18:30:09 2022: Epoch [8], Iteration [300/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.470, Top5: 99.5977, Loss: 0.226\n",
            "Mon Apr 25 18:30:17 2022: Epoch [9], Iteration [0/391/], Data(s): 0.055, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.750, Top5: 100.0000, Loss: 0.226\n",
            "Mon Apr 25 18:30:25 2022: Epoch [9], Iteration [100/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.675, Top5: 99.5050, Loss: 0.230\n",
            "Mon Apr 25 18:30:33 2022: Epoch [9], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.697, Top5: 99.5336, Loss: 0.232\n",
            "Mon Apr 25 18:30:41 2022: Epoch [9], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.631, Top5: 99.5795, Loss: 0.232\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 18:30:52 2022: Test information, Data(s): 1.690, Forward(s): 0.251, Top1: 90.060, Top5: 99.230, \n",
            "\n",
            "Mon Apr 25 18:30:52 2022: conv4 Layer, 32 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(96, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]          73,856\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "             ReLU-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11           [-1, 96, 16, 16]         110,688\n",
            "      BatchNorm2d-12           [-1, 96, 16, 16]             192\n",
            "             ReLU-13           [-1, 96, 16, 16]               0\n",
            "        MaxPool2d-14             [-1, 96, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         221,440\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]       1,180,160\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 14,881,258\n",
            "Trainable params: 14,881,258\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 6.37\n",
            "Params size (MB): 56.77\n",
            "Estimated Total Size (MB): 63.15\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(96, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 18:30:53 2022: Epoch [0], Iteration [0/391/], Data(s): 0.041, Loss(s): 0.005, Forward(s): 0.040, Backward(s): 0.089, Top1: 96.094, Top5: 99.2188, Loss: 0.181\n",
            "Mon Apr 25 18:31:01 2022: Epoch [0], Iteration [100/391/], Data(s): 0.037, Loss(s): 0.011, Forward(s): 0.004, Backward(s): 0.007, Top1: 92.079, Top5: 99.5668, Loss: 0.241\n",
            "Mon Apr 25 18:31:09 2022: Epoch [0], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.051, Top5: 99.5958, Loss: 0.236\n",
            "Mon Apr 25 18:31:17 2022: Epoch [0], Iteration [300/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.226, Top5: 99.6237, Loss: 0.226\n",
            "Mon Apr 25 18:31:25 2022: Epoch [1], Iteration [0/391/], Data(s): 0.054, Loss(s): 0.010, Forward(s): 0.004, Backward(s): 0.006, Top1: 91.406, Top5: 100.0000, Loss: 0.228\n",
            "Mon Apr 25 18:31:33 2022: Epoch [1], Iteration [100/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.512, Top5: 99.6829, Loss: 0.224\n",
            "Mon Apr 25 18:31:41 2022: Epoch [1], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.596, Top5: 99.6346, Loss: 0.225\n",
            "Mon Apr 25 18:31:49 2022: Epoch [1], Iteration [300/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.621, Top5: 99.6081, Loss: 0.225\n",
            "Mon Apr 25 18:31:57 2022: Epoch [2], Iteration [0/391/], Data(s): 0.073, Loss(s): 0.009, Forward(s): 0.005, Backward(s): 0.007, Top1: 92.969, Top5: 100.0000, Loss: 0.219\n",
            "Mon Apr 25 18:32:05 2022: Epoch [2], Iteration [100/391/], Data(s): 0.037, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.031, Top5: 99.7679, Loss: 0.212\n",
            "Mon Apr 25 18:32:13 2022: Epoch [2], Iteration [200/391/], Data(s): 0.037, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.860, Top5: 99.7512, Loss: 0.216\n",
            "Mon Apr 25 18:32:22 2022: Epoch [2], Iteration [300/391/], Data(s): 0.038, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.844, Top5: 99.6963, Loss: 0.223\n",
            "Mon Apr 25 18:32:30 2022: Epoch [3], Iteration [0/391/], Data(s): 0.054, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 91.406, Top5: 98.4375, Loss: 0.224\n",
            "Mon Apr 25 18:32:38 2022: Epoch [3], Iteration [100/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.791, Top5: 99.6906, Loss: 0.218\n",
            "Mon Apr 25 18:32:46 2022: Epoch [3], Iteration [200/391/], Data(s): 0.036, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.821, Top5: 99.6813, Loss: 0.215\n",
            "Mon Apr 25 18:32:54 2022: Epoch [3], Iteration [300/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.803, Top5: 99.6885, Loss: 0.216\n",
            "Mon Apr 25 18:33:02 2022: Epoch [4], Iteration [0/391/], Data(s): 0.056, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 89.844, Top5: 100.0000, Loss: 0.213\n",
            "Mon Apr 25 18:33:10 2022: Epoch [4], Iteration [100/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.791, Top5: 99.7293, Loss: 0.213\n",
            "Mon Apr 25 18:33:18 2022: Epoch [4], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.008, Top5: 99.6385, Loss: 0.213\n",
            "Mon Apr 25 18:33:26 2022: Epoch [4], Iteration [300/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.930, Top5: 99.6704, Loss: 0.214\n",
            "Mon Apr 25 18:33:34 2022: Epoch [5], Iteration [0/391/], Data(s): 0.059, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 97.656, Top5: 100.0000, Loss: 0.205\n",
            "Mon Apr 25 18:33:42 2022: Epoch [5], Iteration [100/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.123, Top5: 99.6983, Loss: 0.205\n",
            "Mon Apr 25 18:33:50 2022: Epoch [5], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.054, Top5: 99.7046, Loss: 0.212\n",
            "Mon Apr 25 18:33:58 2022: Epoch [5], Iteration [300/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.044, Top5: 99.7015, Loss: 0.204\n",
            "Mon Apr 25 18:34:06 2022: Epoch [6], Iteration [0/391/], Data(s): 0.055, Loss(s): 0.010, Forward(s): 0.004, Backward(s): 0.006, Top1: 89.844, Top5: 99.2188, Loss: 0.212\n",
            "Mon Apr 25 18:34:14 2022: Epoch [6], Iteration [100/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.255, Top5: 99.6597, Loss: 0.209\n",
            "Mon Apr 25 18:34:22 2022: Epoch [6], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.334, Top5: 99.6735, Loss: 0.202\n",
            "Mon Apr 25 18:34:30 2022: Epoch [6], Iteration [300/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.317, Top5: 99.6522, Loss: 0.204\n",
            "Mon Apr 25 18:34:37 2022: Epoch [7], Iteration [0/391/], Data(s): 0.056, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.750, Top5: 100.0000, Loss: 0.207\n",
            "Mon Apr 25 18:34:46 2022: Epoch [7], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.356, Top5: 99.7061, Loss: 0.207\n",
            "Mon Apr 25 18:34:54 2022: Epoch [7], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.295, Top5: 99.6152, Loss: 0.211\n",
            "Mon Apr 25 18:35:02 2022: Epoch [7], Iteration [300/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.314, Top5: 99.6730, Loss: 0.205\n",
            "Mon Apr 25 18:35:09 2022: Epoch [8], Iteration [0/391/], Data(s): 0.056, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.969, Top5: 100.0000, Loss: 0.200\n",
            "Mon Apr 25 18:35:17 2022: Epoch [8], Iteration [100/391/], Data(s): 0.036, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.495, Top5: 99.7447, Loss: 0.198\n",
            "Mon Apr 25 18:35:25 2022: Epoch [8], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.389, Top5: 99.7201, Loss: 0.202\n",
            "Mon Apr 25 18:35:33 2022: Epoch [8], Iteration [300/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.480, Top5: 99.6963, Loss: 0.198\n",
            "Mon Apr 25 18:35:41 2022: Epoch [9], Iteration [0/391/], Data(s): 0.054, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.750, Top5: 100.0000, Loss: 0.203\n",
            "Mon Apr 25 18:35:49 2022: Epoch [9], Iteration [100/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.642, Top5: 99.7138, Loss: 0.193\n",
            "Mon Apr 25 18:35:57 2022: Epoch [9], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.711, Top5: 99.7240, Loss: 0.196\n",
            "Mon Apr 25 18:36:05 2022: Epoch [9], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.576, Top5: 99.7093, Loss: 0.198\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 18:36:15 2022: Test information, Data(s): 1.648, Forward(s): 0.252, Top1: 90.460, Top5: 99.290, \n",
            "\n",
            "Mon Apr 25 18:36:15 2022: conv4 Layer, 49 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 79, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(79, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(79, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]          73,856\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "             ReLU-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11           [-1, 79, 16, 16]          91,087\n",
            "      BatchNorm2d-12           [-1, 79, 16, 16]             158\n",
            "             ReLU-13           [-1, 79, 16, 16]               0\n",
            "        MaxPool2d-14             [-1, 79, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         182,272\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]       1,180,160\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 14,822,455\n",
            "Trainable params: 14,822,455\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 6.26\n",
            "Params size (MB): 56.54\n",
            "Estimated Total Size (MB): 62.82\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 79, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(79, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(79, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 18:36:17 2022: Epoch [0], Iteration [0/391/], Data(s): 0.038, Loss(s): 0.004, Forward(s): 0.039, Backward(s): 0.083, Top1: 92.188, Top5: 100.0000, Loss: 0.255\n",
            "Mon Apr 25 18:36:25 2022: Epoch [0], Iteration [100/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.721, Top5: 99.7138, Loss: 0.218\n",
            "Mon Apr 25 18:36:33 2022: Epoch [0], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.957, Top5: 99.7046, Loss: 0.206\n",
            "Mon Apr 25 18:36:41 2022: Epoch [0], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.883, Top5: 99.6652, Loss: 0.221\n",
            "Mon Apr 25 18:36:48 2022: Epoch [1], Iteration [0/391/], Data(s): 0.057, Loss(s): 0.010, Forward(s): 0.004, Backward(s): 0.006, Top1: 92.188, Top5: 100.0000, Loss: 0.212\n",
            "Mon Apr 25 18:36:56 2022: Epoch [1], Iteration [100/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.201, Top5: 99.6519, Loss: 0.209\n",
            "Mon Apr 25 18:37:04 2022: Epoch [1], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.186, Top5: 99.6463, Loss: 0.211\n",
            "Mon Apr 25 18:37:12 2022: Epoch [1], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.192, Top5: 99.6782, Loss: 0.209\n",
            "Mon Apr 25 18:37:20 2022: Epoch [2], Iteration [0/391/], Data(s): 0.065, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 90.625, Top5: 100.0000, Loss: 0.208\n",
            "Mon Apr 25 18:37:28 2022: Epoch [2], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.922, Top5: 99.6364, Loss: 0.204\n",
            "Mon Apr 25 18:37:36 2022: Epoch [2], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.000, Top5: 99.6813, Loss: 0.202\n",
            "Mon Apr 25 18:37:44 2022: Epoch [2], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.195, Top5: 99.6885, Loss: 0.200\n",
            "Mon Apr 25 18:37:51 2022: Epoch [3], Iteration [0/391/], Data(s): 0.055, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.188, Top5: 100.0000, Loss: 0.196\n",
            "Mon Apr 25 18:37:59 2022: Epoch [3], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.162, Top5: 99.6906, Loss: 0.206\n",
            "Mon Apr 25 18:38:07 2022: Epoch [3], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.389, Top5: 99.7085, Loss: 0.193\n",
            "Mon Apr 25 18:38:15 2022: Epoch [3], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.330, Top5: 99.7119, Loss: 0.203\n",
            "Mon Apr 25 18:38:23 2022: Epoch [4], Iteration [0/391/], Data(s): 0.057, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.094, Top5: 100.0000, Loss: 0.200\n",
            "Mon Apr 25 18:38:31 2022: Epoch [4], Iteration [100/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.680, Top5: 99.7370, Loss: 0.189\n",
            "Mon Apr 25 18:38:39 2022: Epoch [4], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.618, Top5: 99.7163, Loss: 0.195\n",
            "Mon Apr 25 18:38:47 2022: Epoch [4], Iteration [300/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.683, Top5: 99.7275, Loss: 0.192\n",
            "Mon Apr 25 18:38:54 2022: Epoch [5], Iteration [0/391/], Data(s): 0.057, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.531, Top5: 100.0000, Loss: 0.191\n",
            "Mon Apr 25 18:39:02 2022: Epoch [5], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.881, Top5: 99.7293, Loss: 0.190\n",
            "Mon Apr 25 18:39:10 2022: Epoch [5], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.801, Top5: 99.7357, Loss: 0.189\n",
            "Mon Apr 25 18:39:18 2022: Epoch [5], Iteration [300/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.745, Top5: 99.7171, Loss: 0.193\n",
            "Mon Apr 25 18:39:26 2022: Epoch [6], Iteration [0/391/], Data(s): 0.056, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.531, Top5: 100.0000, Loss: 0.191\n",
            "Mon Apr 25 18:39:34 2022: Epoch [6], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.928, Top5: 99.7834, Loss: 0.186\n",
            "Mon Apr 25 18:39:42 2022: Epoch [6], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.762, Top5: 99.7474, Loss: 0.185\n",
            "Mon Apr 25 18:39:50 2022: Epoch [6], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.773, Top5: 99.7353, Loss: 0.186\n",
            "Mon Apr 25 18:39:57 2022: Epoch [7], Iteration [0/391/], Data(s): 0.056, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.969, Top5: 100.0000, Loss: 0.194\n",
            "Mon Apr 25 18:40:05 2022: Epoch [7], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.866, Top5: 99.7834, Loss: 0.186\n",
            "Mon Apr 25 18:40:13 2022: Epoch [7], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.933, Top5: 99.7163, Loss: 0.181\n",
            "Mon Apr 25 18:40:21 2022: Epoch [7], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.939, Top5: 99.7249, Loss: 0.183\n",
            "Mon Apr 25 18:40:29 2022: Epoch [8], Iteration [0/391/], Data(s): 0.056, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.094, Top5: 99.2188, Loss: 0.182\n",
            "Mon Apr 25 18:40:37 2022: Epoch [8], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.353, Top5: 99.8144, Loss: 0.172\n",
            "Mon Apr 25 18:40:45 2022: Epoch [8], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.209, Top5: 99.7551, Loss: 0.185\n",
            "Mon Apr 25 18:40:53 2022: Epoch [8], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.080, Top5: 99.7508, Loss: 0.187\n",
            "Mon Apr 25 18:41:00 2022: Epoch [9], Iteration [0/391/], Data(s): 0.057, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.312, Top5: 100.0000, Loss: 0.194\n",
            "Mon Apr 25 18:41:08 2022: Epoch [9], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.044, Top5: 99.7679, Loss: 0.177\n",
            "Mon Apr 25 18:41:16 2022: Epoch [9], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.108, Top5: 99.7629, Loss: 0.177\n",
            "Mon Apr 25 18:41:24 2022: Epoch [9], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.176, Top5: 99.7664, Loss: 0.175\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 18:41:34 2022: Test information, Data(s): 1.661, Forward(s): 0.246, Top1: 90.860, Top5: 99.320, \n",
            "\n",
            "Mon Apr 25 18:41:34 2022: conv4 Layer, 65 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 63, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(63, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(63, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]          73,856\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "             ReLU-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11           [-1, 63, 16, 16]          72,639\n",
            "      BatchNorm2d-12           [-1, 63, 16, 16]             126\n",
            "             ReLU-13           [-1, 63, 16, 16]               0\n",
            "        MaxPool2d-14             [-1, 63, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         145,408\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]       1,180,160\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 14,767,111\n",
            "Trainable params: 14,767,111\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 6.16\n",
            "Params size (MB): 56.33\n",
            "Estimated Total Size (MB): 62.51\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 63, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(63, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(63, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 18:41:36 2022: Epoch [0], Iteration [0/391/], Data(s): 0.039, Loss(s): 0.003, Forward(s): 0.037, Backward(s): 0.071, Top1: 91.406, Top5: 99.2188, Loss: 0.253\n",
            "Mon Apr 25 18:41:44 2022: Epoch [0], Iteration [100/391/], Data(s): 0.036, Loss(s): 0.010, Forward(s): 0.004, Backward(s): 0.007, Top1: 92.899, Top5: 99.5746, Loss: 0.217\n",
            "Mon Apr 25 18:41:51 2022: Epoch [0], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.860, Top5: 99.6502, Loss: 0.212\n",
            "Mon Apr 25 18:41:59 2022: Epoch [0], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.000, Top5: 99.6470, Loss: 0.202\n",
            "Mon Apr 25 18:42:07 2022: Epoch [1], Iteration [0/391/], Data(s): 0.056, Loss(s): 0.009, Forward(s): 0.004, Backward(s): 0.006, Top1: 94.531, Top5: 100.0000, Loss: 0.192\n",
            "Mon Apr 25 18:42:15 2022: Epoch [1], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.255, Top5: 99.7061, Loss: 0.197\n",
            "Mon Apr 25 18:42:23 2022: Epoch [1], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.190, Top5: 99.7007, Loss: 0.203\n",
            "Mon Apr 25 18:42:30 2022: Epoch [1], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.319, Top5: 99.6833, Loss: 0.198\n",
            "Mon Apr 25 18:42:38 2022: Epoch [2], Iteration [0/391/], Data(s): 0.058, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.531, Top5: 100.0000, Loss: 0.196\n",
            "Mon Apr 25 18:42:46 2022: Epoch [2], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.098, Top5: 99.7525, Loss: 0.177\n",
            "Mon Apr 25 18:42:53 2022: Epoch [2], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.773, Top5: 99.7668, Loss: 0.191\n",
            "Mon Apr 25 18:43:01 2022: Epoch [2], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.867, Top5: 99.7430, Loss: 0.185\n",
            "Mon Apr 25 18:43:09 2022: Epoch [3], Iteration [0/391/], Data(s): 0.056, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 89.062, Top5: 100.0000, Loss: 0.197\n",
            "Mon Apr 25 18:43:16 2022: Epoch [3], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.781, Top5: 99.7679, Loss: 0.190\n",
            "Mon Apr 25 18:43:25 2022: Epoch [3], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.878, Top5: 99.7862, Loss: 0.180\n",
            "Mon Apr 25 18:43:32 2022: Epoch [3], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.924, Top5: 99.7768, Loss: 0.179\n",
            "Mon Apr 25 18:43:40 2022: Epoch [4], Iteration [0/391/], Data(s): 0.055, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.094, Top5: 99.2188, Loss: 0.180\n",
            "Mon Apr 25 18:43:48 2022: Epoch [4], Iteration [100/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.044, Top5: 99.7757, Loss: 0.185\n",
            "Mon Apr 25 18:43:56 2022: Epoch [4], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.909, Top5: 99.7629, Loss: 0.185\n",
            "Mon Apr 25 18:44:03 2022: Epoch [4], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.942, Top5: 99.7794, Loss: 0.178\n",
            "Mon Apr 25 18:44:11 2022: Epoch [5], Iteration [0/391/], Data(s): 0.057, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.188, Top5: 100.0000, Loss: 0.174\n",
            "Mon Apr 25 18:44:19 2022: Epoch [5], Iteration [100/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.307, Top5: 99.7834, Loss: 0.177\n",
            "Mon Apr 25 18:44:27 2022: Epoch [5], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.352, Top5: 99.7823, Loss: 0.175\n",
            "Mon Apr 25 18:44:34 2022: Epoch [5], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.267, Top5: 99.7664, Loss: 0.177\n",
            "Mon Apr 25 18:44:42 2022: Epoch [6], Iteration [0/391/], Data(s): 0.060, Loss(s): 0.009, Forward(s): 0.004, Backward(s): 0.006, Top1: 97.656, Top5: 99.2188, Loss: 0.174\n",
            "Mon Apr 25 18:44:50 2022: Epoch [6], Iteration [100/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.477, Top5: 99.8840, Loss: 0.164\n",
            "Mon Apr 25 18:44:58 2022: Epoch [6], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.205, Top5: 99.8717, Loss: 0.178\n",
            "Mon Apr 25 18:45:05 2022: Epoch [6], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.334, Top5: 99.8521, Loss: 0.167\n",
            "Mon Apr 25 18:45:13 2022: Epoch [7], Iteration [0/391/], Data(s): 0.056, Loss(s): 0.010, Forward(s): 0.004, Backward(s): 0.006, Top1: 96.875, Top5: 100.0000, Loss: 0.176\n",
            "Mon Apr 25 18:45:21 2022: Epoch [7], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.585, Top5: 99.8066, Loss: 0.166\n",
            "Mon Apr 25 18:45:29 2022: Epoch [7], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.644, Top5: 99.8290, Loss: 0.161\n",
            "Mon Apr 25 18:45:36 2022: Epoch [7], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.422, Top5: 99.8105, Loss: 0.172\n",
            "Mon Apr 25 18:45:44 2022: Epoch [8], Iteration [0/391/], Data(s): 0.053, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.875, Top5: 100.0000, Loss: 0.175\n",
            "Mon Apr 25 18:45:52 2022: Epoch [8], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.531, Top5: 99.8144, Loss: 0.167\n",
            "Mon Apr 25 18:46:00 2022: Epoch [8], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.430, Top5: 99.8290, Loss: 0.168\n",
            "Mon Apr 25 18:46:07 2022: Epoch [8], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.443, Top5: 99.8235, Loss: 0.164\n",
            "Mon Apr 25 18:46:15 2022: Epoch [9], Iteration [0/391/], Data(s): 0.059, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.188, Top5: 100.0000, Loss: 0.171\n",
            "Mon Apr 25 18:46:23 2022: Epoch [9], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.879, Top5: 99.8608, Loss: 0.158\n",
            "Mon Apr 25 18:46:31 2022: Epoch [9], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.815, Top5: 99.8601, Loss: 0.157\n",
            "Mon Apr 25 18:46:39 2022: Epoch [9], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.687, Top5: 99.8339, Loss: 0.163\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 18:46:49 2022: Test information, Data(s): 1.628, Forward(s): 0.253, Top1: 90.610, Top5: 99.330, \n",
            "\n",
            "Mon Apr 25 18:46:49 2022: conv4 Layer, 82 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 46, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(46, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(46, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]          73,856\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "             ReLU-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11           [-1, 46, 16, 16]          53,038\n",
            "      BatchNorm2d-12           [-1, 46, 16, 16]              92\n",
            "             ReLU-13           [-1, 46, 16, 16]               0\n",
            "        MaxPool2d-14             [-1, 46, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         106,240\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]       1,180,160\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 14,708,308\n",
            "Trainable params: 14,708,308\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 6.05\n",
            "Params size (MB): 56.11\n",
            "Estimated Total Size (MB): 62.17\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 46, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(46, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(46, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 18:46:50 2022: Epoch [0], Iteration [0/391/], Data(s): 0.041, Loss(s): 0.004, Forward(s): 0.036, Backward(s): 0.064, Top1: 96.875, Top5: 100.0000, Loss: 0.161\n",
            "Mon Apr 25 18:46:58 2022: Epoch [0], Iteration [100/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 91.847, Top5: 99.6132, Loss: 0.243\n",
            "Mon Apr 25 18:47:06 2022: Epoch [0], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.281, Top5: 99.5880, Loss: 0.225\n",
            "Mon Apr 25 18:47:13 2022: Epoch [0], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.359, Top5: 99.6003, Loss: 0.226\n",
            "Mon Apr 25 18:47:21 2022: Epoch [1], Iteration [0/391/], Data(s): 0.054, Loss(s): 0.009, Forward(s): 0.004, Backward(s): 0.006, Top1: 95.312, Top5: 99.2188, Loss: 0.214\n",
            "Mon Apr 25 18:47:29 2022: Epoch [1], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.332, Top5: 99.7215, Loss: 0.201\n",
            "Mon Apr 25 18:47:37 2022: Epoch [1], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.210, Top5: 99.7163, Loss: 0.209\n",
            "Mon Apr 25 18:47:44 2022: Epoch [1], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.179, Top5: 99.7301, Loss: 0.201\n",
            "Mon Apr 25 18:47:52 2022: Epoch [2], Iteration [0/391/], Data(s): 0.074, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 89.062, Top5: 97.6562, Loss: 0.209\n",
            "Mon Apr 25 18:47:59 2022: Epoch [2], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.858, Top5: 99.7061, Loss: 0.188\n",
            "Mon Apr 25 18:48:07 2022: Epoch [2], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.661, Top5: 99.7512, Loss: 0.195\n",
            "Mon Apr 25 18:48:15 2022: Epoch [2], Iteration [300/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.581, Top5: 99.7586, Loss: 0.198\n",
            "Mon Apr 25 18:48:23 2022: Epoch [3], Iteration [0/391/], Data(s): 0.061, Loss(s): 0.009, Forward(s): 0.004, Backward(s): 0.006, Top1: 94.531, Top5: 99.2188, Loss: 0.197\n",
            "Mon Apr 25 18:48:30 2022: Epoch [3], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.425, Top5: 99.7293, Loss: 0.194\n",
            "Mon Apr 25 18:48:38 2022: Epoch [3], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.668, Top5: 99.7551, Loss: 0.183\n",
            "Mon Apr 25 18:48:46 2022: Epoch [3], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.610, Top5: 99.7560, Loss: 0.190\n",
            "Mon Apr 25 18:48:54 2022: Epoch [4], Iteration [0/391/], Data(s): 0.064, Loss(s): 0.009, Forward(s): 0.004, Backward(s): 0.007, Top1: 87.500, Top5: 99.2188, Loss: 0.193\n",
            "Mon Apr 25 18:49:01 2022: Epoch [4], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.843, Top5: 99.7989, Loss: 0.183\n",
            "Mon Apr 25 18:49:09 2022: Epoch [4], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.839, Top5: 99.7901, Loss: 0.181\n",
            "Mon Apr 25 18:49:17 2022: Epoch [4], Iteration [300/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.960, Top5: 99.8001, Loss: 0.177\n",
            "Mon Apr 25 18:49:25 2022: Epoch [5], Iteration [0/391/], Data(s): 0.055, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 91.406, Top5: 100.0000, Loss: 0.192\n",
            "Mon Apr 25 18:49:32 2022: Epoch [5], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.827, Top5: 99.7447, Loss: 0.186\n",
            "Mon Apr 25 18:49:40 2022: Epoch [5], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.824, Top5: 99.7785, Loss: 0.183\n",
            "Mon Apr 25 18:49:48 2022: Epoch [5], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.916, Top5: 99.7846, Loss: 0.179\n",
            "Mon Apr 25 18:49:56 2022: Epoch [6], Iteration [0/391/], Data(s): 0.055, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.188, Top5: 99.2188, Loss: 0.176\n",
            "Mon Apr 25 18:50:03 2022: Epoch [6], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.230, Top5: 99.7757, Loss: 0.170\n",
            "Mon Apr 25 18:50:11 2022: Epoch [6], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.294, Top5: 99.7746, Loss: 0.170\n",
            "Mon Apr 25 18:50:19 2022: Epoch [6], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.285, Top5: 99.7872, Loss: 0.172\n",
            "Mon Apr 25 18:50:27 2022: Epoch [7], Iteration [0/391/], Data(s): 0.062, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.009, Top1: 93.750, Top5: 99.2188, Loss: 0.167\n",
            "Mon Apr 25 18:50:34 2022: Epoch [7], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.477, Top5: 99.7370, Loss: 0.169\n",
            "Mon Apr 25 18:50:42 2022: Epoch [7], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.481, Top5: 99.7551, Loss: 0.167\n",
            "Mon Apr 25 18:50:50 2022: Epoch [7], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.430, Top5: 99.7716, Loss: 0.170\n",
            "Mon Apr 25 18:50:57 2022: Epoch [8], Iteration [0/391/], Data(s): 0.057, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.750, Top5: 100.0000, Loss: 0.169\n",
            "Mon Apr 25 18:51:05 2022: Epoch [8], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.593, Top5: 99.8994, Loss: 0.160\n",
            "Mon Apr 25 18:51:13 2022: Epoch [8], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.403, Top5: 99.8601, Loss: 0.170\n",
            "Mon Apr 25 18:51:21 2022: Epoch [8], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.409, Top5: 99.8235, Loss: 0.170\n",
            "Mon Apr 25 18:51:28 2022: Epoch [9], Iteration [0/391/], Data(s): 0.057, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.312, Top5: 99.2188, Loss: 0.161\n",
            "Mon Apr 25 18:51:36 2022: Epoch [9], Iteration [100/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.632, Top5: 99.7525, Loss: 0.162\n",
            "Mon Apr 25 18:51:44 2022: Epoch [9], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.792, Top5: 99.7668, Loss: 0.156\n",
            "Mon Apr 25 18:51:52 2022: Epoch [9], Iteration [300/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.630, Top5: 99.7638, Loss: 0.171\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 18:52:02 2022: Test information, Data(s): 1.680, Forward(s): 0.242, Top1: 90.410, Top5: 99.260, \n",
            "\n",
            "Mon Apr 25 18:52:02 2022: conv4 Layer, 98 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(30, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]          73,856\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "             ReLU-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11           [-1, 30, 16, 16]          34,590\n",
            "      BatchNorm2d-12           [-1, 30, 16, 16]              60\n",
            "             ReLU-13           [-1, 30, 16, 16]               0\n",
            "        MaxPool2d-14             [-1, 30, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]          69,376\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]       1,180,160\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 14,652,964\n",
            "Trainable params: 14,652,964\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 5.95\n",
            "Params size (MB): 55.90\n",
            "Estimated Total Size (MB): 61.86\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(30, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 18:52:03 2022: Epoch [0], Iteration [0/391/], Data(s): 0.037, Loss(s): 0.004, Forward(s): 0.031, Backward(s): 0.058, Top1: 89.062, Top5: 99.2188, Loss: 0.299\n",
            "Mon Apr 25 18:52:11 2022: Epoch [0], Iteration [100/391/], Data(s): 0.035, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 89.968, Top5: 99.4663, Loss: 0.306\n",
            "Mon Apr 25 18:52:19 2022: Epoch [0], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 90.543, Top5: 99.4675, Loss: 0.275\n",
            "Mon Apr 25 18:52:27 2022: Epoch [0], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 90.846, Top5: 99.5043, Loss: 0.258\n",
            "Mon Apr 25 18:52:34 2022: Epoch [1], Iteration [0/391/], Data(s): 0.060, Loss(s): 0.009, Forward(s): 0.004, Backward(s): 0.006, Top1: 91.406, Top5: 100.0000, Loss: 0.256\n",
            "Mon Apr 25 18:52:42 2022: Epoch [1], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.273, Top5: 99.6442, Loss: 0.229\n",
            "Mon Apr 25 18:52:50 2022: Epoch [1], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.467, Top5: 99.6191, Loss: 0.223\n",
            "Mon Apr 25 18:52:57 2022: Epoch [1], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.426, Top5: 99.6211, Loss: 0.227\n",
            "Mon Apr 25 18:53:05 2022: Epoch [2], Iteration [0/391/], Data(s): 0.062, Loss(s): 0.009, Forward(s): 0.004, Backward(s): 0.006, Top1: 94.531, Top5: 99.2188, Loss: 0.227\n",
            "Mon Apr 25 18:53:12 2022: Epoch [2], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.806, Top5: 99.6597, Loss: 0.216\n",
            "Mon Apr 25 18:53:20 2022: Epoch [2], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.681, Top5: 99.6463, Loss: 0.222\n",
            "Mon Apr 25 18:53:28 2022: Epoch [2], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.792, Top5: 99.6678, Loss: 0.208\n",
            "Mon Apr 25 18:53:35 2022: Epoch [3], Iteration [0/391/], Data(s): 0.053, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 97.656, Top5: 100.0000, Loss: 0.215\n",
            "Mon Apr 25 18:53:43 2022: Epoch [3], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.425, Top5: 99.7447, Loss: 0.201\n",
            "Mon Apr 25 18:53:51 2022: Epoch [3], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.369, Top5: 99.7474, Loss: 0.203\n",
            "Mon Apr 25 18:53:59 2022: Epoch [3], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.319, Top5: 99.7119, Loss: 0.207\n",
            "Mon Apr 25 18:54:06 2022: Epoch [4], Iteration [0/391/], Data(s): 0.057, Loss(s): 0.009, Forward(s): 0.003, Backward(s): 0.006, Top1: 90.625, Top5: 100.0000, Loss: 0.204\n",
            "Mon Apr 25 18:54:14 2022: Epoch [4], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.139, Top5: 99.7602, Loss: 0.197\n",
            "Mon Apr 25 18:54:21 2022: Epoch [4], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.338, Top5: 99.7862, Loss: 0.196\n",
            "Mon Apr 25 18:54:29 2022: Epoch [4], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.376, Top5: 99.7794, Loss: 0.193\n",
            "Mon Apr 25 18:54:36 2022: Epoch [5], Iteration [0/391/], Data(s): 0.057, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.750, Top5: 100.0000, Loss: 0.209\n",
            "Mon Apr 25 18:54:44 2022: Epoch [5], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.765, Top5: 99.7757, Loss: 0.186\n",
            "Mon Apr 25 18:54:52 2022: Epoch [5], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.758, Top5: 99.7785, Loss: 0.186\n",
            "Mon Apr 25 18:55:00 2022: Epoch [5], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.846, Top5: 99.8001, Loss: 0.185\n",
            "Mon Apr 25 18:55:07 2022: Epoch [6], Iteration [0/391/], Data(s): 0.057, Loss(s): 0.008, Forward(s): 0.005, Backward(s): 0.007, Top1: 98.438, Top5: 100.0000, Loss: 0.195\n",
            "Mon Apr 25 18:55:14 2022: Epoch [6], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.943, Top5: 99.8298, Loss: 0.184\n",
            "Mon Apr 25 18:55:22 2022: Epoch [6], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.042, Top5: 99.7979, Loss: 0.177\n",
            "Mon Apr 25 18:55:30 2022: Epoch [6], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.862, Top5: 99.7742, Loss: 0.197\n",
            "Mon Apr 25 18:55:37 2022: Epoch [7], Iteration [0/391/], Data(s): 0.048, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 91.406, Top5: 99.2188, Loss: 0.189\n",
            "Mon Apr 25 18:55:45 2022: Epoch [7], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.144, Top5: 99.8453, Loss: 0.179\n",
            "Mon Apr 25 18:55:53 2022: Epoch [7], Iteration [200/391/], Data(s): 0.036, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.100, Top5: 99.8329, Loss: 0.180\n",
            "Mon Apr 25 18:56:01 2022: Epoch [7], Iteration [300/391/], Data(s): 0.036, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.984, Top5: 99.8079, Loss: 0.181\n",
            "Mon Apr 25 18:56:09 2022: Epoch [8], Iteration [0/391/], Data(s): 0.060, Loss(s): 0.009, Forward(s): 0.004, Backward(s): 0.007, Top1: 91.406, Top5: 100.0000, Loss: 0.176\n",
            "Mon Apr 25 18:56:18 2022: Epoch [8], Iteration [100/391/], Data(s): 0.043, Loss(s): 0.010, Forward(s): 0.004, Backward(s): 0.007, Top1: 94.222, Top5: 99.8066, Loss: 0.176\n",
            "Mon Apr 25 18:56:26 2022: Epoch [8], Iteration [200/391/], Data(s): 0.041, Loss(s): 0.010, Forward(s): 0.004, Backward(s): 0.007, Top1: 94.178, Top5: 99.7862, Loss: 0.177\n",
            "Mon Apr 25 18:56:34 2022: Epoch [8], Iteration [300/391/], Data(s): 0.040, Loss(s): 0.010, Forward(s): 0.004, Backward(s): 0.007, Top1: 94.163, Top5: 99.7846, Loss: 0.175\n",
            "Mon Apr 25 18:56:42 2022: Epoch [9], Iteration [0/391/], Data(s): 0.057, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.008, Top1: 92.188, Top5: 100.0000, Loss: 0.176\n",
            "Mon Apr 25 18:56:50 2022: Epoch [9], Iteration [100/391/], Data(s): 0.037, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.647, Top5: 99.8066, Loss: 0.164\n",
            "Mon Apr 25 18:56:58 2022: Epoch [9], Iteration [200/391/], Data(s): 0.036, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.419, Top5: 99.8251, Loss: 0.170\n",
            "Mon Apr 25 18:57:06 2022: Epoch [9], Iteration [300/391/], Data(s): 0.036, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.443, Top5: 99.8235, Loss: 0.167\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 18:57:16 2022: Test information, Data(s): 1.672, Forward(s): 0.247, Top1: 90.210, Top5: 99.380, \n",
            "\n",
            "Mon Apr 25 18:57:16 2022: conv4 Layer, 115 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 13, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(13, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]          73,856\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "             ReLU-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11           [-1, 13, 16, 16]          14,989\n",
            "      BatchNorm2d-12           [-1, 13, 16, 16]              26\n",
            "             ReLU-13           [-1, 13, 16, 16]               0\n",
            "        MaxPool2d-14             [-1, 13, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]          30,208\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]       1,180,160\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 14,594,161\n",
            "Trainable params: 14,594,161\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 5.84\n",
            "Params size (MB): 55.67\n",
            "Estimated Total Size (MB): 61.53\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 13, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(13, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 18:57:17 2022: Epoch [0], Iteration [0/391/], Data(s): 0.042, Loss(s): 0.003, Forward(s): 0.030, Backward(s): 0.051, Top1: 72.656, Top5: 97.6562, Loss: 1.143\n",
            "Mon Apr 25 18:57:25 2022: Epoch [0], Iteration [100/391/], Data(s): 0.037, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 81.459, Top5: 98.3834, Loss: 0.621\n",
            "Mon Apr 25 18:57:33 2022: Epoch [0], Iteration [200/391/], Data(s): 0.036, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 83.392, Top5: 98.5813, Loss: 0.460\n",
            "Mon Apr 25 18:57:41 2022: Epoch [0], Iteration [300/391/], Data(s): 0.036, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 84.167, Top5: 98.6789, Loss: 0.446\n",
            "Mon Apr 25 18:57:48 2022: Epoch [1], Iteration [0/391/], Data(s): 0.055, Loss(s): 0.008, Forward(s): 0.005, Backward(s): 0.006, Top1: 84.375, Top5: 100.0000, Loss: 0.426\n",
            "Mon Apr 25 18:57:56 2022: Epoch [1], Iteration [100/391/], Data(s): 0.036, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 87.090, Top5: 99.3580, Loss: 0.376\n",
            "Mon Apr 25 18:58:04 2022: Epoch [1], Iteration [200/391/], Data(s): 0.037, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 87.566, Top5: 99.2226, Loss: 0.368\n",
            "Mon Apr 25 18:58:12 2022: Epoch [1], Iteration [300/391/], Data(s): 0.036, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 87.555, Top5: 99.2603, Loss: 0.363\n",
            "Mon Apr 25 18:58:19 2022: Epoch [2], Iteration [0/391/], Data(s): 0.060, Loss(s): 0.009, Forward(s): 0.004, Backward(s): 0.007, Top1: 85.156, Top5: 99.2188, Loss: 0.359\n",
            "Mon Apr 25 18:58:27 2022: Epoch [2], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 88.614, Top5: 99.2574, Loss: 0.343\n",
            "Mon Apr 25 18:58:34 2022: Epoch [2], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 88.888, Top5: 99.3781, Loss: 0.328\n",
            "Mon Apr 25 18:58:42 2022: Epoch [2], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 89.101, Top5: 99.3875, Loss: 0.315\n",
            "Mon Apr 25 18:58:49 2022: Epoch [3], Iteration [0/391/], Data(s): 0.068, Loss(s): 0.009, Forward(s): 0.003, Backward(s): 0.006, Top1: 85.938, Top5: 98.4375, Loss: 0.324\n",
            "Mon Apr 25 18:58:57 2022: Epoch [3], Iteration [100/391/], Data(s): 0.035, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 89.225, Top5: 99.4044, Loss: 0.319\n",
            "Mon Apr 25 18:59:05 2022: Epoch [3], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 89.801, Top5: 99.4947, Loss: 0.291\n",
            "Mon Apr 25 18:59:12 2022: Epoch [3], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 89.719, Top5: 99.4965, Loss: 0.306\n",
            "Mon Apr 25 18:59:20 2022: Epoch [4], Iteration [0/391/], Data(s): 0.053, Loss(s): 0.009, Forward(s): 0.003, Backward(s): 0.006, Top1: 89.844, Top5: 100.0000, Loss: 0.308\n",
            "Mon Apr 25 18:59:27 2022: Epoch [4], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 90.494, Top5: 99.5436, Loss: 0.285\n",
            "Mon Apr 25 18:59:35 2022: Epoch [4], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 90.221, Top5: 99.5025, Loss: 0.297\n",
            "Mon Apr 25 18:59:43 2022: Epoch [4], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 90.327, Top5: 99.5302, Loss: 0.282\n",
            "Mon Apr 25 18:59:50 2022: Epoch [5], Iteration [0/391/], Data(s): 0.060, Loss(s): 0.009, Forward(s): 0.003, Backward(s): 0.006, Top1: 89.844, Top5: 100.0000, Loss: 0.285\n",
            "Mon Apr 25 18:59:57 2022: Epoch [5], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 90.656, Top5: 99.5823, Loss: 0.273\n",
            "Mon Apr 25 19:00:05 2022: Epoch [5], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 90.796, Top5: 99.5958, Loss: 0.273\n",
            "Mon Apr 25 19:00:13 2022: Epoch [5], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 90.687, Top5: 99.6081, Loss: 0.281\n",
            "Mon Apr 25 19:00:20 2022: Epoch [6], Iteration [0/391/], Data(s): 0.058, Loss(s): 0.009, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.531, Top5: 100.0000, Loss: 0.276\n",
            "Mon Apr 25 19:00:28 2022: Epoch [6], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 91.043, Top5: 99.5514, Loss: 0.268\n",
            "Mon Apr 25 19:00:36 2022: Epoch [6], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 91.014, Top5: 99.5569, Loss: 0.265\n",
            "Mon Apr 25 19:00:43 2022: Epoch [6], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 91.017, Top5: 99.5821, Loss: 0.260\n",
            "Mon Apr 25 19:00:50 2022: Epoch [7], Iteration [0/391/], Data(s): 0.054, Loss(s): 0.009, Forward(s): 0.003, Backward(s): 0.006, Top1: 91.406, Top5: 99.2188, Loss: 0.258\n",
            "Mon Apr 25 19:00:58 2022: Epoch [7], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 91.886, Top5: 99.6132, Loss: 0.246\n",
            "Mon Apr 25 19:01:06 2022: Epoch [7], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 91.558, Top5: 99.5919, Loss: 0.256\n",
            "Mon Apr 25 19:01:13 2022: Epoch [7], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 91.445, Top5: 99.5977, Loss: 0.259\n",
            "Mon Apr 25 19:01:21 2022: Epoch [8], Iteration [0/391/], Data(s): 0.054, Loss(s): 0.009, Forward(s): 0.003, Backward(s): 0.006, Top1: 89.844, Top5: 99.2188, Loss: 0.255\n",
            "Mon Apr 25 19:01:28 2022: Epoch [8], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 91.576, Top5: 99.5746, Loss: 0.248\n",
            "Mon Apr 25 19:01:36 2022: Epoch [8], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 91.717, Top5: 99.5997, Loss: 0.243\n",
            "Mon Apr 25 19:01:44 2022: Epoch [8], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 91.593, Top5: 99.5743, Loss: 0.256\n",
            "Mon Apr 25 19:01:51 2022: Epoch [9], Iteration [0/391/], Data(s): 0.056, Loss(s): 0.009, Forward(s): 0.004, Backward(s): 0.006, Top1: 93.750, Top5: 100.0000, Loss: 0.236\n",
            "Mon Apr 25 19:01:59 2022: Epoch [9], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 91.963, Top5: 99.6751, Loss: 0.238\n",
            "Mon Apr 25 19:02:06 2022: Epoch [9], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 91.853, Top5: 99.6346, Loss: 0.247\n",
            "Mon Apr 25 19:02:14 2022: Epoch [9], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.037, Top5: 99.6496, Loss: 0.237\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 19:02:24 2022: Test information, Data(s): 1.636, Forward(s): 0.242, Top1: 88.370, Top5: 99.320, \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "gustN4fzogHt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for conv, channel in zip(prune_layers[10:11], prune_channels[10:11]):    \n",
        "    top1_accuracies[conv] = []\n",
        "    top5_accuracies[conv] = []\n",
        "    \n",
        "    # load new network and check accuracy\n",
        "    network, _, _ = test_network(args, data_set=test_set)\n",
        "        \n",
        "    # remove 0 channels ~ M (max_channel_ratio) % of total channels\n",
        "    step = np.linspace(0, int(channel*max_channel_ratio), int(1/prune_step_ratio), dtype=np.int)\n",
        "    steps = (step[1:] - step[:-1]).tolist()\n",
        "    \n",
        "    for i in range(len(steps)):\n",
        "        print(\"\\n%s: %s Layer, %d Channels pruned\"%(time.ctime(), conv, sum(steps[:i+1])))\n",
        "        \n",
        "        # set prune information\n",
        "        args.prune_layers = [conv]\n",
        "        args.prune_channels =[steps[i]]\n",
        "\n",
        "        network = prune_network(args, network)\n",
        "        \n",
        "        network, _, (top1, top5) = test_network(args, network, test_set)\n",
        "            \n",
        "        top1_accuracies[conv].append(top1)\n",
        "        top5_accuracies[conv].append(top5)"
      ],
      "metadata": {
        "id": "LgJxve8yBtZx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60ba3374-78a8-44b0-a67b-6d89c5515fed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 17:47:11 2022: Test information, Data(s): 1.616, Forward(s): 0.210, Top1: 77.870, Top5: 97.560, \n",
            "\n",
            "Mon Apr 25 17:47:11 2022: conv11 Layer, 65 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 447, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(447, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(447, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]          73,856\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "             ReLU-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]         147,584\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         295,168\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]       1,180,160\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 447, 2, 2]       2,060,223\n",
            "      BatchNorm2d-36            [-1, 447, 2, 2]             894\n",
            "             ReLU-37            [-1, 447, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       2,060,288\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 14,392,711\n",
            "Trainable params: 14,392,711\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 6.57\n",
            "Params size (MB): 54.90\n",
            "Estimated Total Size (MB): 61.48\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 447, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(447, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(447, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  if __name__ == '__main__':\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 17:47:12 2022: Epoch [0], Iteration [0/391/], Data(s): 0.038, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 89.062, Top5: 98.4375, Loss: 0.439\n",
            "Mon Apr 25 17:47:20 2022: Epoch [0], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 87.214, Top5: 99.0408, Loss: 0.398\n",
            "Mon Apr 25 17:47:28 2022: Epoch [0], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 87.838, Top5: 99.1177, Loss: 0.354\n",
            "Mon Apr 25 17:47:36 2022: Epoch [0], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 88.203, Top5: 99.1435, Loss: 0.342\n",
            "Mon Apr 25 17:47:43 2022: Epoch [1], Iteration [0/391/], Data(s): 0.052, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.531, Top5: 100.0000, Loss: 0.327\n",
            "Mon Apr 25 17:47:51 2022: Epoch [1], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 89.411, Top5: 99.3425, Loss: 0.325\n",
            "Mon Apr 25 17:48:00 2022: Epoch [1], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 89.960, Top5: 99.3431, Loss: 0.301\n",
            "Mon Apr 25 17:48:08 2022: Epoch [1], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 90.070, Top5: 99.3745, Loss: 0.298\n",
            "Mon Apr 25 17:48:15 2022: Epoch [2], Iteration [0/391/], Data(s): 0.054, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.188, Top5: 100.0000, Loss: 0.287\n",
            "Mon Apr 25 17:48:23 2022: Epoch [2], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 90.811, Top5: 99.4044, Loss: 0.286\n",
            "Mon Apr 25 17:48:31 2022: Epoch [2], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 90.777, Top5: 99.4325, Loss: 0.288\n",
            "Mon Apr 25 17:48:39 2022: Epoch [2], Iteration [300/391/], Data(s): 0.035, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 90.952, Top5: 99.4627, Loss: 0.272\n",
            "Mon Apr 25 17:48:47 2022: Epoch [3], Iteration [0/391/], Data(s): 0.064, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 89.844, Top5: 100.0000, Loss: 0.281\n",
            "Mon Apr 25 17:48:55 2022: Epoch [3], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 91.375, Top5: 99.5823, Loss: 0.263\n",
            "Mon Apr 25 17:49:03 2022: Epoch [3], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 91.461, Top5: 99.5375, Loss: 0.266\n",
            "Mon Apr 25 17:49:11 2022: Epoch [3], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 91.365, Top5: 99.5146, Loss: 0.272\n",
            "Mon Apr 25 17:49:19 2022: Epoch [4], Iteration [0/391/], Data(s): 0.053, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 89.062, Top5: 99.2188, Loss: 0.259\n",
            "Mon Apr 25 17:49:27 2022: Epoch [4], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 91.785, Top5: 99.6364, Loss: 0.253\n",
            "Mon Apr 25 17:49:35 2022: Epoch [4], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 91.748, Top5: 99.6152, Loss: 0.261\n",
            "Mon Apr 25 17:49:43 2022: Epoch [4], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 91.764, Top5: 99.5951, Loss: 0.251\n",
            "Mon Apr 25 17:49:50 2022: Epoch [5], Iteration [0/391/], Data(s): 0.065, Loss(s): 0.010, Forward(s): 0.004, Backward(s): 0.007, Top1: 89.062, Top5: 99.2188, Loss: 0.254\n",
            "Mon Apr 25 17:49:58 2022: Epoch [5], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 91.576, Top5: 99.4895, Loss: 0.257\n",
            "Mon Apr 25 17:50:06 2022: Epoch [5], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 91.842, Top5: 99.5608, Loss: 0.241\n",
            "Mon Apr 25 17:50:14 2022: Epoch [5], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 91.775, Top5: 99.5354, Loss: 0.255\n",
            "Mon Apr 25 17:50:22 2022: Epoch [6], Iteration [0/391/], Data(s): 0.057, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 91.406, Top5: 100.0000, Loss: 0.239\n",
            "Mon Apr 25 17:50:30 2022: Epoch [6], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 91.839, Top5: 99.5204, Loss: 0.247\n",
            "Mon Apr 25 17:50:38 2022: Epoch [6], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.110, Top5: 99.5919, Loss: 0.234\n",
            "Mon Apr 25 17:50:46 2022: Epoch [6], Iteration [300/391/], Data(s): 0.035, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.167, Top5: 99.5691, Loss: 0.245\n",
            "Mon Apr 25 17:50:54 2022: Epoch [7], Iteration [0/391/], Data(s): 0.053, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.969, Top5: 98.4375, Loss: 0.246\n",
            "Mon Apr 25 17:51:02 2022: Epoch [7], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.280, Top5: 99.6364, Loss: 0.236\n",
            "Mon Apr 25 17:51:10 2022: Epoch [7], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.413, Top5: 99.6230, Loss: 0.231\n",
            "Mon Apr 25 17:51:18 2022: Epoch [7], Iteration [300/391/], Data(s): 0.035, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.312, Top5: 99.5899, Loss: 0.241\n",
            "Mon Apr 25 17:51:25 2022: Epoch [8], Iteration [0/391/], Data(s): 0.056, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 96.094, Top5: 100.0000, Loss: 0.232\n",
            "Mon Apr 25 17:51:33 2022: Epoch [8], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.234, Top5: 99.5978, Loss: 0.237\n",
            "Mon Apr 25 17:51:42 2022: Epoch [8], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.448, Top5: 99.6113, Loss: 0.224\n",
            "Mon Apr 25 17:51:50 2022: Epoch [8], Iteration [300/391/], Data(s): 0.035, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.476, Top5: 99.6314, Loss: 0.231\n",
            "Mon Apr 25 17:51:57 2022: Epoch [9], Iteration [0/391/], Data(s): 0.069, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.531, Top5: 100.0000, Loss: 0.224\n",
            "Mon Apr 25 17:52:05 2022: Epoch [9], Iteration [100/391/], Data(s): 0.035, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.574, Top5: 99.6674, Loss: 0.228\n",
            "Mon Apr 25 17:52:14 2022: Epoch [9], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.545, Top5: 99.6152, Loss: 0.230\n",
            "Mon Apr 25 17:52:22 2022: Epoch [9], Iteration [300/391/], Data(s): 0.035, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.769, Top5: 99.6340, Loss: 0.211\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 17:52:32 2022: Test information, Data(s): 1.616, Forward(s): 0.234, Top1: 89.840, Top5: 99.270, \n",
            "\n",
            "Mon Apr 25 17:52:32 2022: conv11 Layer, 131 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 381, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(381, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(381, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]          73,856\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "             ReLU-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]         147,584\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         295,168\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]       1,180,160\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 381, 2, 2]       1,756,029\n",
            "      BatchNorm2d-36            [-1, 381, 2, 2]             762\n",
            "             ReLU-37            [-1, 381, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       1,756,160\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 13,784,257\n",
            "Trainable params: 13,784,257\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 6.56\n",
            "Params size (MB): 52.58\n",
            "Estimated Total Size (MB): 59.16\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 381, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(381, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(381, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 17:52:33 2022: Epoch [0], Iteration [0/391/], Data(s): 0.039, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 91.406, Top5: 100.0000, Loss: 0.247\n",
            "Mon Apr 25 17:52:41 2022: Epoch [0], Iteration [100/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.930, Top5: 99.6829, Loss: 0.214\n",
            "Mon Apr 25 17:52:49 2022: Epoch [0], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.883, Top5: 99.6696, Loss: 0.224\n",
            "Mon Apr 25 17:52:57 2022: Epoch [0], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.748, Top5: 99.6574, Loss: 0.228\n",
            "Mon Apr 25 17:53:04 2022: Epoch [1], Iteration [0/391/], Data(s): 0.052, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.094, Top5: 100.0000, Loss: 0.218\n",
            "Mon Apr 25 17:53:12 2022: Epoch [1], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.845, Top5: 99.6364, Loss: 0.221\n",
            "Mon Apr 25 17:53:21 2022: Epoch [1], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.829, Top5: 99.6657, Loss: 0.220\n",
            "Mon Apr 25 17:53:29 2022: Epoch [1], Iteration [300/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.891, Top5: 99.6782, Loss: 0.214\n",
            "Mon Apr 25 17:53:36 2022: Epoch [2], Iteration [0/391/], Data(s): 0.054, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 91.406, Top5: 100.0000, Loss: 0.223\n",
            "Mon Apr 25 17:53:44 2022: Epoch [2], Iteration [100/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.301, Top5: 99.6983, Loss: 0.209\n",
            "Mon Apr 25 17:53:52 2022: Epoch [2], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.206, Top5: 99.6968, Loss: 0.211\n",
            "Mon Apr 25 17:54:00 2022: Epoch [2], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.086, Top5: 99.6652, Loss: 0.220\n",
            "Mon Apr 25 17:54:07 2022: Epoch [3], Iteration [0/391/], Data(s): 0.054, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.531, Top5: 100.0000, Loss: 0.213\n",
            "Mon Apr 25 17:54:16 2022: Epoch [3], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.301, Top5: 99.6442, Loss: 0.206\n",
            "Mon Apr 25 17:54:24 2022: Epoch [3], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.338, Top5: 99.6929, Loss: 0.204\n",
            "Mon Apr 25 17:54:32 2022: Epoch [3], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.192, Top5: 99.6885, Loss: 0.218\n",
            "Mon Apr 25 17:54:39 2022: Epoch [4], Iteration [0/391/], Data(s): 0.055, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.969, Top5: 100.0000, Loss: 0.206\n",
            "Mon Apr 25 17:54:47 2022: Epoch [4], Iteration [100/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.417, Top5: 99.7525, Loss: 0.201\n",
            "Mon Apr 25 17:54:55 2022: Epoch [4], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.186, Top5: 99.7085, Loss: 0.211\n",
            "Mon Apr 25 17:55:03 2022: Epoch [4], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.018, Top5: 99.6885, Loss: 0.221\n",
            "Mon Apr 25 17:55:10 2022: Epoch [5], Iteration [0/391/], Data(s): 0.054, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.750, Top5: 99.2188, Loss: 0.205\n",
            "Mon Apr 25 17:55:19 2022: Epoch [5], Iteration [100/391/], Data(s): 0.036, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.611, Top5: 99.6674, Loss: 0.199\n",
            "Mon Apr 25 17:55:27 2022: Epoch [5], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.439, Top5: 99.7124, Loss: 0.201\n",
            "Mon Apr 25 17:55:35 2022: Epoch [5], Iteration [300/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.400, Top5: 99.6704, Loss: 0.205\n",
            "Mon Apr 25 17:55:42 2022: Epoch [6], Iteration [0/391/], Data(s): 0.056, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.875, Top5: 100.0000, Loss: 0.210\n",
            "Mon Apr 25 17:55:50 2022: Epoch [6], Iteration [100/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.379, Top5: 99.7215, Loss: 0.199\n",
            "Mon Apr 25 17:55:58 2022: Epoch [6], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.427, Top5: 99.7435, Loss: 0.201\n",
            "Mon Apr 25 17:56:06 2022: Epoch [6], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.459, Top5: 99.7275, Loss: 0.200\n",
            "Mon Apr 25 17:56:13 2022: Epoch [7], Iteration [0/391/], Data(s): 0.056, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.531, Top5: 100.0000, Loss: 0.198\n",
            "Mon Apr 25 17:56:21 2022: Epoch [7], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.317, Top5: 99.6364, Loss: 0.205\n",
            "Mon Apr 25 17:56:29 2022: Epoch [7], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.462, Top5: 99.7163, Loss: 0.193\n",
            "Mon Apr 25 17:56:37 2022: Epoch [7], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.413, Top5: 99.7145, Loss: 0.197\n",
            "Mon Apr 25 17:56:45 2022: Epoch [8], Iteration [0/391/], Data(s): 0.054, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.188, Top5: 99.2188, Loss: 0.188\n",
            "Mon Apr 25 17:56:53 2022: Epoch [8], Iteration [100/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.036, Top5: 99.7293, Loss: 0.189\n",
            "Mon Apr 25 17:57:01 2022: Epoch [8], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.894, Top5: 99.7124, Loss: 0.192\n",
            "Mon Apr 25 17:57:09 2022: Epoch [8], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.755, Top5: 99.7145, Loss: 0.200\n",
            "Mon Apr 25 17:57:16 2022: Epoch [9], Iteration [0/391/], Data(s): 0.063, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.531, Top5: 99.2188, Loss: 0.194\n",
            "Mon Apr 25 17:57:24 2022: Epoch [9], Iteration [100/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.075, Top5: 99.7370, Loss: 0.186\n",
            "Mon Apr 25 17:57:32 2022: Epoch [9], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.886, Top5: 99.7163, Loss: 0.193\n",
            "Mon Apr 25 17:57:40 2022: Epoch [9], Iteration [300/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.862, Top5: 99.7223, Loss: 0.192\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 17:57:50 2022: Test information, Data(s): 1.655, Forward(s): 0.244, Top1: 90.730, Top5: 99.310, \n",
            "\n",
            "Mon Apr 25 17:57:50 2022: conv11 Layer, 197 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 315, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(315, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(315, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]          73,856\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "             ReLU-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]         147,584\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         295,168\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]       1,180,160\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 315, 2, 2]       1,451,835\n",
            "      BatchNorm2d-36            [-1, 315, 2, 2]             630\n",
            "             ReLU-37            [-1, 315, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       1,452,032\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 13,175,803\n",
            "Trainable params: 13,175,803\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 6.56\n",
            "Params size (MB): 50.26\n",
            "Estimated Total Size (MB): 56.83\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 315, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(315, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(315, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 17:57:52 2022: Epoch [0], Iteration [0/391/], Data(s): 0.038, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 97.656, Top5: 100.0000, Loss: 0.114\n",
            "Mon Apr 25 17:58:00 2022: Epoch [0], Iteration [100/391/], Data(s): 0.036, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.727, Top5: 99.7757, Loss: 0.189\n",
            "Mon Apr 25 17:58:08 2022: Epoch [0], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.738, Top5: 99.7707, Loss: 0.188\n",
            "Mon Apr 25 17:58:15 2022: Epoch [0], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.747, Top5: 99.7586, Loss: 0.189\n",
            "Mon Apr 25 17:58:23 2022: Epoch [1], Iteration [0/391/], Data(s): 0.062, Loss(s): 0.010, Forward(s): 0.004, Backward(s): 0.006, Top1: 95.312, Top5: 100.0000, Loss: 0.186\n",
            "Mon Apr 25 17:58:31 2022: Epoch [1], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.541, Top5: 99.7061, Loss: 0.199\n",
            "Mon Apr 25 17:58:38 2022: Epoch [1], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.839, Top5: 99.7279, Loss: 0.179\n",
            "Mon Apr 25 17:58:46 2022: Epoch [1], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.807, Top5: 99.7301, Loss: 0.186\n",
            "Mon Apr 25 17:58:54 2022: Epoch [2], Iteration [0/391/], Data(s): 0.054, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.188, Top5: 100.0000, Loss: 0.183\n",
            "Mon Apr 25 17:59:02 2022: Epoch [2], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.075, Top5: 99.7215, Loss: 0.182\n",
            "Mon Apr 25 17:59:09 2022: Epoch [2], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.014, Top5: 99.7474, Loss: 0.188\n",
            "Mon Apr 25 17:59:17 2022: Epoch [2], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.978, Top5: 99.7742, Loss: 0.188\n",
            "Mon Apr 25 17:59:25 2022: Epoch [3], Iteration [0/391/], Data(s): 0.056, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 89.844, Top5: 99.2188, Loss: 0.181\n",
            "Mon Apr 25 17:59:32 2022: Epoch [3], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.152, Top5: 99.8376, Loss: 0.180\n",
            "Mon Apr 25 17:59:40 2022: Epoch [3], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.259, Top5: 99.8134, Loss: 0.175\n",
            "Mon Apr 25 17:59:48 2022: Epoch [3], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.093, Top5: 99.7898, Loss: 0.186\n",
            "Mon Apr 25 17:59:56 2022: Epoch [4], Iteration [0/391/], Data(s): 0.054, Loss(s): 0.010, Forward(s): 0.004, Backward(s): 0.006, Top1: 95.312, Top5: 100.0000, Loss: 0.177\n",
            "Mon Apr 25 18:00:04 2022: Epoch [4], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.353, Top5: 99.8144, Loss: 0.170\n",
            "Mon Apr 25 18:00:12 2022: Epoch [4], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.279, Top5: 99.7512, Loss: 0.180\n",
            "Mon Apr 25 18:00:19 2022: Epoch [4], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.217, Top5: 99.7898, Loss: 0.178\n",
            "Mon Apr 25 18:00:27 2022: Epoch [5], Iteration [0/391/], Data(s): 0.055, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.531, Top5: 100.0000, Loss: 0.179\n",
            "Mon Apr 25 18:00:35 2022: Epoch [5], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.144, Top5: 99.8221, Loss: 0.172\n",
            "Mon Apr 25 18:00:43 2022: Epoch [5], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.220, Top5: 99.8212, Loss: 0.175\n",
            "Mon Apr 25 18:00:51 2022: Epoch [5], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.212, Top5: 99.8183, Loss: 0.173\n",
            "Mon Apr 25 18:00:58 2022: Epoch [6], Iteration [0/391/], Data(s): 0.052, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.094, Top5: 100.0000, Loss: 0.179\n",
            "Mon Apr 25 18:01:06 2022: Epoch [6], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.322, Top5: 99.8144, Loss: 0.172\n",
            "Mon Apr 25 18:01:14 2022: Epoch [6], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.314, Top5: 99.8212, Loss: 0.170\n",
            "Mon Apr 25 18:01:22 2022: Epoch [6], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.241, Top5: 99.7950, Loss: 0.179\n",
            "Mon Apr 25 18:01:29 2022: Epoch [7], Iteration [0/391/], Data(s): 0.059, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.531, Top5: 100.0000, Loss: 0.177\n",
            "Mon Apr 25 18:01:37 2022: Epoch [7], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.616, Top5: 99.8221, Loss: 0.163\n",
            "Mon Apr 25 18:01:45 2022: Epoch [7], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.523, Top5: 99.7940, Loss: 0.168\n",
            "Mon Apr 25 18:01:53 2022: Epoch [7], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.370, Top5: 99.7975, Loss: 0.175\n",
            "Mon Apr 25 18:02:00 2022: Epoch [8], Iteration [0/391/], Data(s): 0.052, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.531, Top5: 100.0000, Loss: 0.168\n",
            "Mon Apr 25 18:02:08 2022: Epoch [8], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.585, Top5: 99.7757, Loss: 0.166\n",
            "Mon Apr 25 18:02:16 2022: Epoch [8], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.465, Top5: 99.7668, Loss: 0.171\n",
            "Mon Apr 25 18:02:24 2022: Epoch [8], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.396, Top5: 99.7742, Loss: 0.168\n",
            "Mon Apr 25 18:02:31 2022: Epoch [9], Iteration [0/391/], Data(s): 0.052, Loss(s): 0.009, Forward(s): 0.005, Backward(s): 0.006, Top1: 96.875, Top5: 100.0000, Loss: 0.173\n",
            "Mon Apr 25 18:02:39 2022: Epoch [9], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.516, Top5: 99.8530, Loss: 0.165\n",
            "Mon Apr 25 18:02:47 2022: Epoch [9], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.527, Top5: 99.7862, Loss: 0.168\n",
            "Mon Apr 25 18:02:55 2022: Epoch [9], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.523, Top5: 99.7716, Loss: 0.171\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 18:03:05 2022: Test information, Data(s): 1.636, Forward(s): 0.207, Top1: 91.100, Top5: 99.270, \n",
            "\n",
            "Mon Apr 25 18:03:05 2022: conv11 Layer, 262 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 250, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(250, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(250, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]          73,856\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "             ReLU-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]         147,584\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         295,168\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]       1,180,160\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 250, 2, 2]       1,152,250\n",
            "      BatchNorm2d-36            [-1, 250, 2, 2]             500\n",
            "             ReLU-37            [-1, 250, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       1,152,512\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 12,576,568\n",
            "Trainable params: 12,576,568\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 6.55\n",
            "Params size (MB): 47.98\n",
            "Estimated Total Size (MB): 54.54\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 250, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(250, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(250, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 18:03:06 2022: Epoch [0], Iteration [0/391/], Data(s): 0.036, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.188, Top5: 100.0000, Loss: 0.174\n",
            "Mon Apr 25 18:03:14 2022: Epoch [0], Iteration [100/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.392, Top5: 99.7912, Loss: 0.167\n",
            "Mon Apr 25 18:03:22 2022: Epoch [0], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.422, Top5: 99.7979, Loss: 0.165\n",
            "Mon Apr 25 18:03:29 2022: Epoch [0], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.594, Top5: 99.8001, Loss: 0.158\n",
            "Mon Apr 25 18:03:37 2022: Epoch [1], Iteration [0/391/], Data(s): 0.055, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.531, Top5: 100.0000, Loss: 0.163\n",
            "Mon Apr 25 18:03:45 2022: Epoch [1], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.539, Top5: 99.8144, Loss: 0.165\n",
            "Mon Apr 25 18:03:52 2022: Epoch [1], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.733, Top5: 99.8173, Loss: 0.156\n",
            "Mon Apr 25 18:04:00 2022: Epoch [1], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.656, Top5: 99.8183, Loss: 0.163\n",
            "Mon Apr 25 18:04:07 2022: Epoch [2], Iteration [0/391/], Data(s): 0.051, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.969, Top5: 100.0000, Loss: 0.159\n",
            "Mon Apr 25 18:04:15 2022: Epoch [2], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.104, Top5: 99.9072, Loss: 0.149\n",
            "Mon Apr 25 18:04:23 2022: Epoch [2], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.959, Top5: 99.8640, Loss: 0.159\n",
            "Mon Apr 25 18:04:31 2022: Epoch [2], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.817, Top5: 99.8624, Loss: 0.162\n",
            "Mon Apr 25 18:04:38 2022: Epoch [3], Iteration [0/391/], Data(s): 0.054, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 89.844, Top5: 100.0000, Loss: 0.154\n",
            "Mon Apr 25 18:04:46 2022: Epoch [3], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.026, Top5: 99.7989, Loss: 0.148\n",
            "Mon Apr 25 18:04:54 2022: Epoch [3], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.842, Top5: 99.8212, Loss: 0.158\n",
            "Mon Apr 25 18:05:02 2022: Epoch [3], Iteration [300/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.791, Top5: 99.8339, Loss: 0.157\n",
            "Mon Apr 25 18:05:09 2022: Epoch [4], Iteration [0/391/], Data(s): 0.065, Loss(s): 0.010, Forward(s): 0.004, Backward(s): 0.006, Top1: 91.406, Top5: 98.4375, Loss: 0.154\n",
            "Mon Apr 25 18:05:17 2022: Epoch [4], Iteration [100/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.307, Top5: 99.8221, Loss: 0.165\n",
            "Mon Apr 25 18:05:25 2022: Epoch [4], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.729, Top5: 99.8212, Loss: 0.151\n",
            "Mon Apr 25 18:05:33 2022: Epoch [4], Iteration [300/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.822, Top5: 99.8235, Loss: 0.156\n",
            "Mon Apr 25 18:05:40 2022: Epoch [5], Iteration [0/391/], Data(s): 0.054, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.531, Top5: 99.2188, Loss: 0.147\n",
            "Mon Apr 25 18:05:48 2022: Epoch [5], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.166, Top5: 99.8608, Loss: 0.147\n",
            "Mon Apr 25 18:05:56 2022: Epoch [5], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.040, Top5: 99.8484, Loss: 0.155\n",
            "Mon Apr 25 18:06:03 2022: Epoch [5], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.980, Top5: 99.8469, Loss: 0.156\n",
            "Mon Apr 25 18:06:11 2022: Epoch [6], Iteration [0/391/], Data(s): 0.053, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 98.438, Top5: 100.0000, Loss: 0.153\n",
            "Mon Apr 25 18:06:19 2022: Epoch [6], Iteration [100/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.142, Top5: 99.8376, Loss: 0.146\n",
            "Mon Apr 25 18:06:26 2022: Epoch [6], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.091, Top5: 99.8173, Loss: 0.150\n",
            "Mon Apr 25 18:06:34 2022: Epoch [6], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.063, Top5: 99.8261, Loss: 0.149\n",
            "Mon Apr 25 18:06:41 2022: Epoch [7], Iteration [0/391/], Data(s): 0.053, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 97.656, Top5: 100.0000, Loss: 0.146\n",
            "Mon Apr 25 18:06:49 2022: Epoch [7], Iteration [100/391/], Data(s): 0.036, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.957, Top5: 99.8298, Loss: 0.150\n",
            "Mon Apr 25 18:06:57 2022: Epoch [7], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.122, Top5: 99.8368, Loss: 0.142\n",
            "Mon Apr 25 18:07:05 2022: Epoch [7], Iteration [300/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.175, Top5: 99.8183, Loss: 0.151\n",
            "Mon Apr 25 18:07:12 2022: Epoch [8], Iteration [0/391/], Data(s): 0.059, Loss(s): 0.010, Forward(s): 0.004, Backward(s): 0.006, Top1: 96.875, Top5: 100.0000, Loss: 0.147\n",
            "Mon Apr 25 18:07:20 2022: Epoch [8], Iteration [100/391/], Data(s): 0.036, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.297, Top5: 99.8453, Loss: 0.143\n",
            "Mon Apr 25 18:07:28 2022: Epoch [8], Iteration [200/391/], Data(s): 0.037, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.293, Top5: 99.8290, Loss: 0.146\n",
            "Mon Apr 25 18:07:37 2022: Epoch [8], Iteration [300/391/], Data(s): 0.037, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.201, Top5: 99.8391, Loss: 0.150\n",
            "Mon Apr 25 18:07:44 2022: Epoch [9], Iteration [0/391/], Data(s): 0.053, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.312, Top5: 99.2188, Loss: 0.149\n",
            "Mon Apr 25 18:07:52 2022: Epoch [9], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.142, Top5: 99.8840, Loss: 0.148\n",
            "Mon Apr 25 18:08:00 2022: Epoch [9], Iteration [200/391/], Data(s): 0.036, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.297, Top5: 99.8912, Loss: 0.137\n",
            "Mon Apr 25 18:08:08 2022: Epoch [9], Iteration [300/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.287, Top5: 99.8936, Loss: 0.142\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 18:08:18 2022: Test information, Data(s): 1.668, Forward(s): 0.210, Top1: 91.270, Top5: 99.300, \n",
            "\n",
            "Mon Apr 25 18:08:18 2022: conv11 Layer, 328 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(184, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]          73,856\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "             ReLU-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]         147,584\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         295,168\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]       1,180,160\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 184, 2, 2]         848,056\n",
            "      BatchNorm2d-36            [-1, 184, 2, 2]             368\n",
            "             ReLU-37            [-1, 184, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]         848,384\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 11,968,114\n",
            "Trainable params: 11,968,114\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 6.54\n",
            "Params size (MB): 45.65\n",
            "Estimated Total Size (MB): 52.21\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(184, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 18:08:19 2022: Epoch [0], Iteration [0/391/], Data(s): 0.039, Loss(s): 0.009, Forward(s): 0.004, Backward(s): 0.006, Top1: 94.531, Top5: 100.0000, Loss: 0.196\n",
            "Mon Apr 25 18:08:27 2022: Epoch [0], Iteration [100/391/], Data(s): 0.035, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.483, Top5: 99.8762, Loss: 0.139\n",
            "Mon Apr 25 18:08:34 2022: Epoch [0], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.449, Top5: 99.8484, Loss: 0.141\n",
            "Mon Apr 25 18:08:42 2022: Epoch [0], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.305, Top5: 99.8261, Loss: 0.152\n",
            "Mon Apr 25 18:08:49 2022: Epoch [1], Iteration [0/391/], Data(s): 0.053, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.875, Top5: 99.2188, Loss: 0.140\n",
            "Mon Apr 25 18:08:57 2022: Epoch [1], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.320, Top5: 99.8608, Loss: 0.141\n",
            "Mon Apr 25 18:09:05 2022: Epoch [1], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.367, Top5: 99.8640, Loss: 0.134\n",
            "Mon Apr 25 18:09:13 2022: Epoch [1], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.323, Top5: 99.8598, Loss: 0.140\n",
            "Mon Apr 25 18:09:20 2022: Epoch [2], Iteration [0/391/], Data(s): 0.049, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.531, Top5: 100.0000, Loss: 0.141\n",
            "Mon Apr 25 18:09:27 2022: Epoch [2], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.173, Top5: 99.8608, Loss: 0.141\n",
            "Mon Apr 25 18:09:35 2022: Epoch [2], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.359, Top5: 99.8562, Loss: 0.134\n",
            "Mon Apr 25 18:09:43 2022: Epoch [2], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.442, Top5: 99.8547, Loss: 0.134\n",
            "Mon Apr 25 18:09:50 2022: Epoch [3], Iteration [0/391/], Data(s): 0.049, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 98.438, Top5: 100.0000, Loss: 0.135\n",
            "Mon Apr 25 18:09:58 2022: Epoch [3], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.583, Top5: 99.8685, Loss: 0.135\n",
            "Mon Apr 25 18:10:06 2022: Epoch [3], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.542, Top5: 99.8756, Loss: 0.137\n",
            "Mon Apr 25 18:10:14 2022: Epoch [3], Iteration [300/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.665, Top5: 99.8806, Loss: 0.128\n",
            "Mon Apr 25 18:10:21 2022: Epoch [4], Iteration [0/391/], Data(s): 0.050, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.094, Top5: 100.0000, Loss: 0.143\n",
            "Mon Apr 25 18:10:29 2022: Epoch [4], Iteration [100/391/], Data(s): 0.035, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.343, Top5: 99.8376, Loss: 0.139\n",
            "Mon Apr 25 18:10:36 2022: Epoch [4], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.491, Top5: 99.8795, Loss: 0.124\n",
            "Mon Apr 25 18:10:44 2022: Epoch [4], Iteration [300/391/], Data(s): 0.035, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.460, Top5: 99.8832, Loss: 0.137\n",
            "Mon Apr 25 18:10:51 2022: Epoch [5], Iteration [0/391/], Data(s): 0.050, Loss(s): 0.010, Forward(s): 0.004, Backward(s): 0.006, Top1: 96.094, Top5: 100.0000, Loss: 0.131\n",
            "Mon Apr 25 18:10:59 2022: Epoch [5], Iteration [100/391/], Data(s): 0.035, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.351, Top5: 99.8453, Loss: 0.139\n",
            "Mon Apr 25 18:11:07 2022: Epoch [5], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.581, Top5: 99.8756, Loss: 0.129\n",
            "Mon Apr 25 18:11:15 2022: Epoch [5], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.595, Top5: 99.8858, Loss: 0.132\n",
            "Mon Apr 25 18:11:22 2022: Epoch [6], Iteration [0/391/], Data(s): 0.051, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.094, Top5: 99.2188, Loss: 0.134\n",
            "Mon Apr 25 18:11:29 2022: Epoch [6], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.707, Top5: 99.9072, Loss: 0.128\n",
            "Mon Apr 25 18:11:37 2022: Epoch [6], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.693, Top5: 99.8640, Loss: 0.128\n",
            "Mon Apr 25 18:11:45 2022: Epoch [6], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.694, Top5: 99.8676, Loss: 0.131\n",
            "Mon Apr 25 18:11:52 2022: Epoch [7], Iteration [0/391/], Data(s): 0.051, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.094, Top5: 100.0000, Loss: 0.128\n",
            "Mon Apr 25 18:12:00 2022: Epoch [7], Iteration [100/391/], Data(s): 0.036, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.668, Top5: 99.8994, Loss: 0.127\n",
            "Mon Apr 25 18:12:08 2022: Epoch [7], Iteration [200/391/], Data(s): 0.036, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.759, Top5: 99.8717, Loss: 0.129\n",
            "Mon Apr 25 18:12:16 2022: Epoch [7], Iteration [300/391/], Data(s): 0.037, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.725, Top5: 99.8754, Loss: 0.130\n",
            "Mon Apr 25 18:12:24 2022: Epoch [8], Iteration [0/391/], Data(s): 0.059, Loss(s): 0.009, Forward(s): 0.004, Backward(s): 0.006, Top1: 91.406, Top5: 100.0000, Loss: 0.128\n",
            "Mon Apr 25 18:12:32 2022: Epoch [8], Iteration [100/391/], Data(s): 0.039, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.630, Top5: 99.8685, Loss: 0.129\n",
            "Mon Apr 25 18:12:41 2022: Epoch [8], Iteration [200/391/], Data(s): 0.039, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.736, Top5: 99.8795, Loss: 0.122\n",
            "Mon Apr 25 18:12:49 2022: Epoch [8], Iteration [300/391/], Data(s): 0.038, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.754, Top5: 99.8728, Loss: 0.123\n",
            "Mon Apr 25 18:12:56 2022: Epoch [9], Iteration [0/391/], Data(s): 0.051, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.875, Top5: 100.0000, Loss: 0.128\n",
            "Mon Apr 25 18:13:03 2022: Epoch [9], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.885, Top5: 99.8762, Loss: 0.126\n",
            "Mon Apr 25 18:13:11 2022: Epoch [9], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.818, Top5: 99.8640, Loss: 0.128\n",
            "Mon Apr 25 18:13:19 2022: Epoch [9], Iteration [300/391/], Data(s): 0.035, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.824, Top5: 99.8780, Loss: 0.124\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 18:13:29 2022: Test information, Data(s): 1.691, Forward(s): 0.215, Top1: 91.170, Top5: 99.260, \n",
            "\n",
            "Mon Apr 25 18:13:29 2022: conv11 Layer, 394 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 118, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(118, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(118, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]          73,856\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "             ReLU-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]         147,584\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         295,168\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]       1,180,160\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 118, 2, 2]         543,862\n",
            "      BatchNorm2d-36            [-1, 118, 2, 2]             236\n",
            "             ReLU-37            [-1, 118, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]         544,256\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 11,359,660\n",
            "Trainable params: 11,359,660\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 6.54\n",
            "Params size (MB): 43.33\n",
            "Estimated Total Size (MB): 49.88\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 118, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(118, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(118, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 18:13:30 2022: Epoch [0], Iteration [0/391/], Data(s): 0.037, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.875, Top5: 100.0000, Loss: 0.110\n",
            "Mon Apr 25 18:13:38 2022: Epoch [0], Iteration [100/391/], Data(s): 0.037, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.900, Top5: 99.9149, Loss: 0.121\n",
            "Mon Apr 25 18:13:46 2022: Epoch [0], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.876, Top5: 99.9067, Loss: 0.124\n",
            "Mon Apr 25 18:13:54 2022: Epoch [0], Iteration [300/391/], Data(s): 0.035, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.871, Top5: 99.9040, Loss: 0.124\n",
            "Mon Apr 25 18:14:01 2022: Epoch [1], Iteration [0/391/], Data(s): 0.061, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.875, Top5: 100.0000, Loss: 0.126\n",
            "Mon Apr 25 18:14:08 2022: Epoch [1], Iteration [100/391/], Data(s): 0.035, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.746, Top5: 99.8994, Loss: 0.125\n",
            "Mon Apr 25 18:14:16 2022: Epoch [1], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.907, Top5: 99.8912, Loss: 0.120\n",
            "Mon Apr 25 18:14:24 2022: Epoch [1], Iteration [300/391/], Data(s): 0.035, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.972, Top5: 99.9040, Loss: 0.119\n",
            "Mon Apr 25 18:14:31 2022: Epoch [2], Iteration [0/391/], Data(s): 0.053, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 97.656, Top5: 99.2188, Loss: 0.117\n",
            "Mon Apr 25 18:14:39 2022: Epoch [2], Iteration [100/391/], Data(s): 0.035, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.955, Top5: 99.8994, Loss: 0.119\n",
            "Mon Apr 25 18:14:47 2022: Epoch [2], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.175, Top5: 99.8951, Loss: 0.110\n",
            "Mon Apr 25 18:14:54 2022: Epoch [2], Iteration [300/391/], Data(s): 0.035, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.102, Top5: 99.8702, Loss: 0.125\n",
            "Mon Apr 25 18:15:02 2022: Epoch [3], Iteration [0/391/], Data(s): 0.056, Loss(s): 0.009, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.094, Top5: 100.0000, Loss: 0.120\n",
            "Mon Apr 25 18:15:09 2022: Epoch [3], Iteration [100/391/], Data(s): 0.035, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.908, Top5: 99.8762, Loss: 0.117\n",
            "Mon Apr 25 18:15:17 2022: Epoch [3], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.989, Top5: 99.8834, Loss: 0.120\n",
            "Mon Apr 25 18:15:25 2022: Epoch [3], Iteration [300/391/], Data(s): 0.035, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.987, Top5: 99.9014, Loss: 0.119\n",
            "Mon Apr 25 18:15:32 2022: Epoch [4], Iteration [0/391/], Data(s): 0.054, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.094, Top5: 100.0000, Loss: 0.117\n",
            "Mon Apr 25 18:15:41 2022: Epoch [4], Iteration [100/391/], Data(s): 0.040, Loss(s): 0.010, Forward(s): 0.004, Backward(s): 0.007, Top1: 96.024, Top5: 99.8298, Loss: 0.118\n",
            "Mon Apr 25 18:15:49 2022: Epoch [4], Iteration [200/391/], Data(s): 0.040, Loss(s): 0.010, Forward(s): 0.004, Backward(s): 0.007, Top1: 96.109, Top5: 99.8562, Loss: 0.117\n",
            "Mon Apr 25 18:15:57 2022: Epoch [4], Iteration [300/391/], Data(s): 0.039, Loss(s): 0.010, Forward(s): 0.004, Backward(s): 0.007, Top1: 96.135, Top5: 99.8728, Loss: 0.115\n",
            "Mon Apr 25 18:16:04 2022: Epoch [5], Iteration [0/391/], Data(s): 0.057, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.531, Top5: 100.0000, Loss: 0.119\n",
            "Mon Apr 25 18:16:12 2022: Epoch [5], Iteration [100/391/], Data(s): 0.038, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.978, Top5: 99.8994, Loss: 0.119\n",
            "Mon Apr 25 18:16:20 2022: Epoch [5], Iteration [200/391/], Data(s): 0.038, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.059, Top5: 99.9067, Loss: 0.117\n",
            "Mon Apr 25 18:16:28 2022: Epoch [5], Iteration [300/391/], Data(s): 0.037, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.182, Top5: 99.9195, Loss: 0.109\n",
            "Mon Apr 25 18:16:36 2022: Epoch [6], Iteration [0/391/], Data(s): 0.069, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 98.438, Top5: 100.0000, Loss: 0.114\n",
            "Mon Apr 25 18:16:43 2022: Epoch [6], Iteration [100/391/], Data(s): 0.036, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.279, Top5: 99.9304, Loss: 0.111\n",
            "Mon Apr 25 18:16:51 2022: Epoch [6], Iteration [200/391/], Data(s): 0.036, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.183, Top5: 99.9300, Loss: 0.116\n",
            "Mon Apr 25 18:16:59 2022: Epoch [6], Iteration [300/391/], Data(s): 0.036, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.182, Top5: 99.9143, Loss: 0.113\n",
            "Mon Apr 25 18:17:06 2022: Epoch [7], Iteration [0/391/], Data(s): 0.052, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.531, Top5: 99.2188, Loss: 0.105\n",
            "Mon Apr 25 18:17:15 2022: Epoch [7], Iteration [100/391/], Data(s): 0.038, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.279, Top5: 99.9304, Loss: 0.111\n",
            "Mon Apr 25 18:17:23 2022: Epoch [7], Iteration [200/391/], Data(s): 0.040, Loss(s): 0.010, Forward(s): 0.004, Backward(s): 0.007, Top1: 96.346, Top5: 99.9262, Loss: 0.107\n",
            "Mon Apr 25 18:17:31 2022: Epoch [7], Iteration [300/391/], Data(s): 0.040, Loss(s): 0.010, Forward(s): 0.004, Backward(s): 0.007, Top1: 96.335, Top5: 99.9195, Loss: 0.104\n",
            "Mon Apr 25 18:17:39 2022: Epoch [8], Iteration [0/391/], Data(s): 0.053, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.312, Top5: 100.0000, Loss: 0.114\n",
            "Mon Apr 25 18:17:47 2022: Epoch [8], Iteration [100/391/], Data(s): 0.036, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.705, Top5: 99.8917, Loss: 0.100\n",
            "Mon Apr 25 18:17:55 2022: Epoch [8], Iteration [200/391/], Data(s): 0.037, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.514, Top5: 99.9106, Loss: 0.110\n",
            "Mon Apr 25 18:18:03 2022: Epoch [8], Iteration [300/391/], Data(s): 0.037, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.465, Top5: 99.9066, Loss: 0.108\n",
            "Mon Apr 25 18:18:10 2022: Epoch [9], Iteration [0/391/], Data(s): 0.053, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.875, Top5: 100.0000, Loss: 0.105\n",
            "Mon Apr 25 18:18:18 2022: Epoch [9], Iteration [100/391/], Data(s): 0.037, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.395, Top5: 99.9226, Loss: 0.103\n",
            "Mon Apr 25 18:18:26 2022: Epoch [9], Iteration [200/391/], Data(s): 0.036, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.451, Top5: 99.9223, Loss: 0.102\n",
            "Mon Apr 25 18:18:33 2022: Epoch [9], Iteration [300/391/], Data(s): 0.036, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.416, Top5: 99.9247, Loss: 0.108\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 18:18:44 2022: Test information, Data(s): 1.717, Forward(s): 0.220, Top1: 91.280, Top5: 99.230, \n",
            "\n",
            "Mon Apr 25 18:18:44 2022: conv11 Layer, 460 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 52, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(52, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]          73,856\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "             ReLU-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]         147,584\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         295,168\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]       1,180,160\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35             [-1, 52, 2, 2]         239,668\n",
            "      BatchNorm2d-36             [-1, 52, 2, 2]             104\n",
            "             ReLU-37             [-1, 52, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]         240,128\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 10,751,206\n",
            "Trainable params: 10,751,206\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 6.53\n",
            "Params size (MB): 41.01\n",
            "Estimated Total Size (MB): 47.56\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 52, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(52, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 18:18:45 2022: Epoch [0], Iteration [0/391/], Data(s): 0.039, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 97.656, Top5: 100.0000, Loss: 0.069\n",
            "Mon Apr 25 18:18:53 2022: Epoch [0], Iteration [100/391/], Data(s): 0.037, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.883, Top5: 99.9459, Loss: 0.096\n",
            "Mon Apr 25 18:19:00 2022: Epoch [0], Iteration [200/391/], Data(s): 0.037, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.723, Top5: 99.9534, Loss: 0.106\n",
            "Mon Apr 25 18:19:08 2022: Epoch [0], Iteration [300/391/], Data(s): 0.036, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.587, Top5: 99.9507, Loss: 0.106\n",
            "Mon Apr 25 18:19:15 2022: Epoch [1], Iteration [0/391/], Data(s): 0.053, Loss(s): 0.009, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.312, Top5: 100.0000, Loss: 0.104\n",
            "Mon Apr 25 18:19:23 2022: Epoch [1], Iteration [100/391/], Data(s): 0.037, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.705, Top5: 99.9304, Loss: 0.100\n",
            "Mon Apr 25 18:19:31 2022: Epoch [1], Iteration [200/391/], Data(s): 0.037, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.580, Top5: 99.9262, Loss: 0.104\n",
            "Mon Apr 25 18:19:39 2022: Epoch [1], Iteration [300/391/], Data(s): 0.037, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.618, Top5: 99.9351, Loss: 0.100\n",
            "Mon Apr 25 18:19:46 2022: Epoch [2], Iteration [0/391/], Data(s): 0.055, Loss(s): 0.009, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.312, Top5: 100.0000, Loss: 0.109\n",
            "Mon Apr 25 18:19:54 2022: Epoch [2], Iteration [100/391/], Data(s): 0.038, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.767, Top5: 99.9536, Loss: 0.095\n",
            "Mon Apr 25 18:20:02 2022: Epoch [2], Iteration [200/391/], Data(s): 0.038, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.766, Top5: 99.9534, Loss: 0.098\n",
            "Mon Apr 25 18:20:10 2022: Epoch [2], Iteration [300/391/], Data(s): 0.039, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.737, Top5: 99.9507, Loss: 0.103\n",
            "Mon Apr 25 18:20:18 2022: Epoch [3], Iteration [0/391/], Data(s): 0.052, Loss(s): 0.009, Forward(s): 0.003, Backward(s): 0.006, Top1: 98.438, Top5: 99.2188, Loss: 0.099\n",
            "Mon Apr 25 18:20:26 2022: Epoch [3], Iteration [100/391/], Data(s): 0.039, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.767, Top5: 99.9536, Loss: 0.097\n",
            "Mon Apr 25 18:20:34 2022: Epoch [3], Iteration [200/391/], Data(s): 0.040, Loss(s): 0.010, Forward(s): 0.004, Backward(s): 0.007, Top1: 96.836, Top5: 99.9417, Loss: 0.093\n",
            "Mon Apr 25 18:20:42 2022: Epoch [3], Iteration [300/391/], Data(s): 0.039, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.771, Top5: 99.9325, Loss: 0.098\n",
            "Mon Apr 25 18:20:50 2022: Epoch [4], Iteration [0/391/], Data(s): 0.058, Loss(s): 0.009, Forward(s): 0.003, Backward(s): 0.009, Top1: 96.875, Top5: 100.0000, Loss: 0.098\n",
            "Mon Apr 25 18:20:58 2022: Epoch [4], Iteration [100/391/], Data(s): 0.038, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.844, Top5: 99.9459, Loss: 0.097\n",
            "Mon Apr 25 18:21:05 2022: Epoch [4], Iteration [200/391/], Data(s): 0.038, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.824, Top5: 99.9106, Loss: 0.098\n",
            "Mon Apr 25 18:21:13 2022: Epoch [4], Iteration [300/391/], Data(s): 0.037, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.865, Top5: 99.9221, Loss: 0.089\n",
            "Mon Apr 25 18:21:20 2022: Epoch [5], Iteration [0/391/], Data(s): 0.052, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 99.219, Top5: 100.0000, Loss: 0.101\n",
            "Mon Apr 25 18:21:28 2022: Epoch [5], Iteration [100/391/], Data(s): 0.035, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.883, Top5: 99.9381, Loss: 0.096\n",
            "Mon Apr 25 18:21:36 2022: Epoch [5], Iteration [200/391/], Data(s): 0.036, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.968, Top5: 99.9495, Loss: 0.088\n",
            "Mon Apr 25 18:21:44 2022: Epoch [5], Iteration [300/391/], Data(s): 0.036, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.927, Top5: 99.9455, Loss: 0.097\n",
            "Mon Apr 25 18:21:51 2022: Epoch [6], Iteration [0/391/], Data(s): 0.051, Loss(s): 0.009, Forward(s): 0.004, Backward(s): 0.006, Top1: 97.656, Top5: 100.0000, Loss: 0.090\n",
            "Mon Apr 25 18:21:58 2022: Epoch [6], Iteration [100/391/], Data(s): 0.036, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 97.061, Top5: 99.9613, Loss: 0.092\n",
            "Mon Apr 25 18:22:06 2022: Epoch [6], Iteration [200/391/], Data(s): 0.036, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 97.128, Top5: 99.9495, Loss: 0.089\n",
            "Mon Apr 25 18:22:14 2022: Epoch [6], Iteration [300/391/], Data(s): 0.036, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 97.046, Top5: 99.9481, Loss: 0.094\n",
            "Mon Apr 25 18:22:21 2022: Epoch [7], Iteration [0/391/], Data(s): 0.052, Loss(s): 0.009, Forward(s): 0.003, Backward(s): 0.006, Top1: 97.656, Top5: 100.0000, Loss: 0.093\n",
            "Mon Apr 25 18:22:29 2022: Epoch [7], Iteration [100/391/], Data(s): 0.036, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 97.053, Top5: 99.9536, Loss: 0.089\n",
            "Mon Apr 25 18:22:37 2022: Epoch [7], Iteration [200/391/], Data(s): 0.036, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.995, Top5: 99.9611, Loss: 0.092\n",
            "Mon Apr 25 18:22:45 2022: Epoch [7], Iteration [300/391/], Data(s): 0.036, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.971, Top5: 99.9481, Loss: 0.092\n",
            "Mon Apr 25 18:22:52 2022: Epoch [8], Iteration [0/391/], Data(s): 0.051, Loss(s): 0.009, Forward(s): 0.004, Backward(s): 0.006, Top1: 97.656, Top5: 100.0000, Loss: 0.093\n",
            "Mon Apr 25 18:22:59 2022: Epoch [8], Iteration [100/391/], Data(s): 0.035, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 97.177, Top5: 99.9459, Loss: 0.086\n",
            "Mon Apr 25 18:23:07 2022: Epoch [8], Iteration [200/391/], Data(s): 0.036, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 97.236, Top5: 99.9456, Loss: 0.085\n",
            "Mon Apr 25 18:23:15 2022: Epoch [8], Iteration [300/391/], Data(s): 0.036, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 97.166, Top5: 99.9585, Loss: 0.089\n",
            "Mon Apr 25 18:23:22 2022: Epoch [9], Iteration [0/391/], Data(s): 0.050, Loss(s): 0.009, Forward(s): 0.003, Backward(s): 0.006, Top1: 98.438, Top5: 100.0000, Loss: 0.097\n",
            "Mon Apr 25 18:23:30 2022: Epoch [9], Iteration [100/391/], Data(s): 0.035, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 97.099, Top5: 99.9226, Loss: 0.087\n",
            "Mon Apr 25 18:23:38 2022: Epoch [9], Iteration [200/391/], Data(s): 0.036, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 97.213, Top5: 99.9262, Loss: 0.082\n",
            "Mon Apr 25 18:23:45 2022: Epoch [9], Iteration [300/391/], Data(s): 0.036, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 97.215, Top5: 99.9247, Loss: 0.083\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 18:23:56 2022: Test information, Data(s): 1.774, Forward(s): 0.222, Top1: 91.140, Top5: 99.240, \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for conv, channel in zip(prune_layers[11:12], prune_channels[11:12]):    \n",
        "    top1_accuracies[conv] = []\n",
        "    top5_accuracies[conv] = []\n",
        "    \n",
        "    # load new network and check accuracy\n",
        "    network, _, _ = test_network(args, data_set=test_set)\n",
        "        \n",
        "    # remove 0 channels ~ M (max_channel_ratio) % of total channels\n",
        "    step = np.linspace(0, int(channel*max_channel_ratio), int(1/prune_step_ratio), dtype=np.int)\n",
        "    steps = (step[1:] - step[:-1]).tolist()\n",
        "    \n",
        "    for i in range(len(steps)):\n",
        "        print(\"\\n%s: %s Layer, %d Channels pruned\"%(time.ctime(), conv, sum(steps[:i+1])))\n",
        "        \n",
        "        # set prune information\n",
        "        args.prune_layers = [conv]\n",
        "        args.prune_channels =[steps[i]]\n",
        "\n",
        "        network = prune_network(args, network)\n",
        "        \n",
        "        network, _, (top1, top5) = test_network(args, network, test_set)\n",
        "            \n",
        "        top1_accuracies[conv].append(top1)\n",
        "        top5_accuracies[conv].append(top5)"
      ],
      "metadata": {
        "id": "YwwGBWqmBzqi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f6d44a7-0a6e-4b35-aa43-a9ddfc85b033"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 17:10:02 2022: Test information, Data(s): 1.691, Forward(s): 0.217, Top1: 77.870, Top5: 97.560, \n",
            "\n",
            "Mon Apr 25 17:10:02 2022: conv12 Layer, 65 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 447, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(447, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(447, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]          73,856\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "             ReLU-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]         147,584\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         295,168\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]       1,180,160\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 447, 2, 2]       2,060,223\n",
            "      BatchNorm2d-39            [-1, 447, 2, 2]             894\n",
            "             ReLU-40            [-1, 447, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       2,060,288\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 14,392,711\n",
            "Trainable params: 14,392,711\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 6.57\n",
            "Params size (MB): 54.90\n",
            "Estimated Total Size (MB): 61.48\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 447, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(447, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(447, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  if __name__ == '__main__':\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 17:10:03 2022: Epoch [0], Iteration [0/391/], Data(s): 0.039, Loss(s): 0.001, Forward(s): 0.067, Backward(s): 0.135, Top1: 82.031, Top5: 96.8750, Loss: 0.584\n",
            "Mon Apr 25 17:10:11 2022: Epoch [0], Iteration [100/391/], Data(s): 0.036, Loss(s): 0.011, Forward(s): 0.004, Backward(s): 0.008, Top1: 87.020, Top5: 98.8707, Loss: 0.403\n",
            "Mon Apr 25 17:10:19 2022: Epoch [0], Iteration [200/391/], Data(s): 0.036, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 87.924, Top5: 99.0322, Loss: 0.353\n",
            "Mon Apr 25 17:10:28 2022: Epoch [0], Iteration [300/391/], Data(s): 0.036, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 88.390, Top5: 99.0812, Loss: 0.335\n",
            "Mon Apr 25 17:10:35 2022: Epoch [1], Iteration [0/391/], Data(s): 0.065, Loss(s): 0.010, Forward(s): 0.004, Backward(s): 0.008, Top1: 89.844, Top5: 100.0000, Loss: 0.324\n",
            "Mon Apr 25 17:10:44 2022: Epoch [1], Iteration [100/391/], Data(s): 0.036, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.007, Top1: 90.076, Top5: 99.3967, Loss: 0.310\n",
            "Mon Apr 25 17:10:52 2022: Epoch [1], Iteration [200/391/], Data(s): 0.036, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.007, Top1: 90.345, Top5: 99.3664, Loss: 0.292\n",
            "Mon Apr 25 17:11:00 2022: Epoch [1], Iteration [300/391/], Data(s): 0.036, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 90.498, Top5: 99.4186, Loss: 0.291\n",
            "Mon Apr 25 17:11:08 2022: Epoch [2], Iteration [0/391/], Data(s): 0.070, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 90.625, Top5: 99.2188, Loss: 0.294\n",
            "Mon Apr 25 17:11:16 2022: Epoch [2], Iteration [100/391/], Data(s): 0.036, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 90.339, Top5: 99.4431, Loss: 0.295\n",
            "Mon Apr 25 17:11:24 2022: Epoch [2], Iteration [200/391/], Data(s): 0.036, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 90.893, Top5: 99.4597, Loss: 0.273\n",
            "Mon Apr 25 17:11:32 2022: Epoch [2], Iteration [300/391/], Data(s): 0.035, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 90.934, Top5: 99.4887, Loss: 0.276\n",
            "Mon Apr 25 17:11:40 2022: Epoch [3], Iteration [0/391/], Data(s): 0.058, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 91.406, Top5: 100.0000, Loss: 0.269\n",
            "Mon Apr 25 17:11:48 2022: Epoch [3], Iteration [100/391/], Data(s): 0.037, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 91.259, Top5: 99.6055, Loss: 0.271\n",
            "Mon Apr 25 17:11:56 2022: Epoch [3], Iteration [200/391/], Data(s): 0.037, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 91.290, Top5: 99.5802, Loss: 0.267\n",
            "Mon Apr 25 17:12:04 2022: Epoch [3], Iteration [300/391/], Data(s): 0.036, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 91.362, Top5: 99.5276, Loss: 0.263\n",
            "Mon Apr 25 17:12:12 2022: Epoch [4], Iteration [0/391/], Data(s): 0.054, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.969, Top5: 99.2188, Loss: 0.253\n",
            "Mon Apr 25 17:12:20 2022: Epoch [4], Iteration [100/391/], Data(s): 0.035, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 91.429, Top5: 99.5746, Loss: 0.265\n",
            "Mon Apr 25 17:12:29 2022: Epoch [4], Iteration [200/391/], Data(s): 0.036, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 91.799, Top5: 99.5763, Loss: 0.243\n",
            "Mon Apr 25 17:12:37 2022: Epoch [4], Iteration [300/391/], Data(s): 0.036, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 91.793, Top5: 99.5899, Loss: 0.249\n",
            "Mon Apr 25 17:12:44 2022: Epoch [5], Iteration [0/391/], Data(s): 0.059, Loss(s): 0.010, Forward(s): 0.005, Backward(s): 0.007, Top1: 89.844, Top5: 100.0000, Loss: 0.259\n",
            "Mon Apr 25 17:12:53 2022: Epoch [5], Iteration [100/391/], Data(s): 0.036, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 91.971, Top5: 99.6287, Loss: 0.242\n",
            "Mon Apr 25 17:13:01 2022: Epoch [5], Iteration [200/391/], Data(s): 0.036, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.044, Top5: 99.6191, Loss: 0.245\n",
            "Mon Apr 25 17:13:09 2022: Epoch [5], Iteration [300/391/], Data(s): 0.036, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 91.920, Top5: 99.5847, Loss: 0.254\n",
            "Mon Apr 25 17:13:17 2022: Epoch [6], Iteration [0/391/], Data(s): 0.061, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 90.625, Top5: 99.2188, Loss: 0.249\n",
            "Mon Apr 25 17:13:25 2022: Epoch [6], Iteration [100/391/], Data(s): 0.037, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.226, Top5: 99.5514, Loss: 0.239\n",
            "Mon Apr 25 17:13:34 2022: Epoch [6], Iteration [200/391/], Data(s): 0.037, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.129, Top5: 99.5647, Loss: 0.246\n",
            "Mon Apr 25 17:13:42 2022: Epoch [6], Iteration [300/391/], Data(s): 0.036, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.149, Top5: 99.5977, Loss: 0.238\n",
            "Mon Apr 25 17:13:49 2022: Epoch [7], Iteration [0/391/], Data(s): 0.063, Loss(s): 0.010, Forward(s): 0.004, Backward(s): 0.008, Top1: 92.969, Top5: 99.2188, Loss: 0.236\n",
            "Mon Apr 25 17:13:58 2022: Epoch [7], Iteration [100/391/], Data(s): 0.036, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.296, Top5: 99.6210, Loss: 0.234\n",
            "Mon Apr 25 17:14:06 2022: Epoch [7], Iteration [200/391/], Data(s): 0.036, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.215, Top5: 99.5919, Loss: 0.245\n",
            "Mon Apr 25 17:14:14 2022: Epoch [7], Iteration [300/391/], Data(s): 0.036, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.206, Top5: 99.5795, Loss: 0.239\n",
            "Mon Apr 25 17:14:22 2022: Epoch [8], Iteration [0/391/], Data(s): 0.057, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.312, Top5: 98.4375, Loss: 0.231\n",
            "Mon Apr 25 17:14:30 2022: Epoch [8], Iteration [100/391/], Data(s): 0.036, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.814, Top5: 99.5900, Loss: 0.225\n",
            "Mon Apr 25 17:14:38 2022: Epoch [8], Iteration [200/391/], Data(s): 0.036, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.697, Top5: 99.5841, Loss: 0.230\n",
            "Mon Apr 25 17:14:46 2022: Epoch [8], Iteration [300/391/], Data(s): 0.036, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.590, Top5: 99.6081, Loss: 0.231\n",
            "Mon Apr 25 17:14:54 2022: Epoch [9], Iteration [0/391/], Data(s): 0.058, Loss(s): 0.011, Forward(s): 0.004, Backward(s): 0.006, Top1: 91.406, Top5: 100.0000, Loss: 0.227\n",
            "Mon Apr 25 17:15:02 2022: Epoch [9], Iteration [100/391/], Data(s): 0.036, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.257, Top5: 99.7138, Loss: 0.229\n",
            "Mon Apr 25 17:15:11 2022: Epoch [9], Iteration [200/391/], Data(s): 0.036, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.537, Top5: 99.7163, Loss: 0.221\n",
            "Mon Apr 25 17:15:19 2022: Epoch [9], Iteration [300/391/], Data(s): 0.036, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 92.611, Top5: 99.6782, Loss: 0.223\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 17:15:29 2022: Test information, Data(s): 1.725, Forward(s): 0.307, Top1: 89.880, Top5: 99.330, \n",
            "\n",
            "Mon Apr 25 17:15:29 2022: conv12 Layer, 131 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 381, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(381, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(381, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]          73,856\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "             ReLU-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]         147,584\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         295,168\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]       1,180,160\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 381, 2, 2]       1,756,029\n",
            "      BatchNorm2d-39            [-1, 381, 2, 2]             762\n",
            "             ReLU-40            [-1, 381, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       1,756,160\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 13,784,257\n",
            "Trainable params: 13,784,257\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 6.56\n",
            "Params size (MB): 52.58\n",
            "Estimated Total Size (MB): 59.16\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 381, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(381, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(381, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 17:15:31 2022: Epoch [0], Iteration [0/391/], Data(s): 0.036, Loss(s): 0.000, Forward(s): 0.060, Backward(s): 0.121, Top1: 90.625, Top5: 100.0000, Loss: 0.254\n",
            "Mon Apr 25 17:15:39 2022: Epoch [0], Iteration [100/391/], Data(s): 0.036, Loss(s): 0.011, Forward(s): 0.004, Backward(s): 0.007, Top1: 92.466, Top5: 99.7138, Loss: 0.228\n",
            "Mon Apr 25 17:15:47 2022: Epoch [0], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.638, Top5: 99.6891, Loss: 0.218\n",
            "Mon Apr 25 17:15:55 2022: Epoch [0], Iteration [300/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.717, Top5: 99.6911, Loss: 0.211\n",
            "Mon Apr 25 17:16:02 2022: Epoch [1], Iteration [0/391/], Data(s): 0.058, Loss(s): 0.009, Forward(s): 0.004, Backward(s): 0.006, Top1: 89.844, Top5: 100.0000, Loss: 0.215\n",
            "Mon Apr 25 17:16:11 2022: Epoch [1], Iteration [100/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.690, Top5: 99.6906, Loss: 0.223\n",
            "Mon Apr 25 17:16:19 2022: Epoch [1], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.743, Top5: 99.6696, Loss: 0.216\n",
            "Mon Apr 25 17:16:27 2022: Epoch [1], Iteration [300/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.787, Top5: 99.6470, Loss: 0.211\n",
            "Mon Apr 25 17:16:34 2022: Epoch [2], Iteration [0/391/], Data(s): 0.052, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.094, Top5: 100.0000, Loss: 0.216\n",
            "Mon Apr 25 17:16:42 2022: Epoch [2], Iteration [100/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.984, Top5: 99.6983, Loss: 0.212\n",
            "Mon Apr 25 17:16:50 2022: Epoch [2], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.015, Top5: 99.6891, Loss: 0.214\n",
            "Mon Apr 25 17:16:59 2022: Epoch [2], Iteration [300/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.984, Top5: 99.7041, Loss: 0.213\n",
            "Mon Apr 25 17:17:06 2022: Epoch [3], Iteration [0/391/], Data(s): 0.057, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.750, Top5: 100.0000, Loss: 0.209\n",
            "Mon Apr 25 17:17:14 2022: Epoch [3], Iteration [100/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.100, Top5: 99.6210, Loss: 0.213\n",
            "Mon Apr 25 17:17:22 2022: Epoch [3], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.163, Top5: 99.6152, Loss: 0.207\n",
            "Mon Apr 25 17:17:30 2022: Epoch [3], Iteration [300/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.101, Top5: 99.6418, Loss: 0.213\n",
            "Mon Apr 25 17:17:38 2022: Epoch [4], Iteration [0/391/], Data(s): 0.053, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.312, Top5: 100.0000, Loss: 0.215\n",
            "Mon Apr 25 17:17:46 2022: Epoch [4], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.541, Top5: 99.7061, Loss: 0.202\n",
            "Mon Apr 25 17:17:54 2022: Epoch [4], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.186, Top5: 99.7046, Loss: 0.222\n",
            "Mon Apr 25 17:18:02 2022: Epoch [4], Iteration [300/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.174, Top5: 99.7041, Loss: 0.208\n",
            "Mon Apr 25 17:18:09 2022: Epoch [5], Iteration [0/391/], Data(s): 0.052, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.531, Top5: 100.0000, Loss: 0.203\n",
            "Mon Apr 25 17:18:18 2022: Epoch [5], Iteration [100/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.804, Top5: 99.7447, Loss: 0.191\n",
            "Mon Apr 25 17:18:26 2022: Epoch [5], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.552, Top5: 99.7474, Loss: 0.204\n",
            "Mon Apr 25 17:18:34 2022: Epoch [5], Iteration [300/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.457, Top5: 99.7041, Loss: 0.206\n",
            "Mon Apr 25 17:18:41 2022: Epoch [6], Iteration [0/391/], Data(s): 0.055, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.750, Top5: 99.2188, Loss: 0.202\n",
            "Mon Apr 25 17:18:50 2022: Epoch [6], Iteration [100/391/], Data(s): 0.036, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.642, Top5: 99.7293, Loss: 0.196\n",
            "Mon Apr 25 17:18:58 2022: Epoch [6], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.517, Top5: 99.7046, Loss: 0.198\n",
            "Mon Apr 25 17:19:06 2022: Epoch [6], Iteration [300/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.511, Top5: 99.7015, Loss: 0.198\n",
            "Mon Apr 25 17:19:13 2022: Epoch [7], Iteration [0/391/], Data(s): 0.054, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.312, Top5: 100.0000, Loss: 0.203\n",
            "Mon Apr 25 17:19:21 2022: Epoch [7], Iteration [100/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.495, Top5: 99.7525, Loss: 0.197\n",
            "Mon Apr 25 17:19:29 2022: Epoch [7], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.389, Top5: 99.7590, Loss: 0.201\n",
            "Mon Apr 25 17:19:37 2022: Epoch [7], Iteration [300/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.477, Top5: 99.7197, Loss: 0.194\n",
            "Mon Apr 25 17:19:45 2022: Epoch [8], Iteration [0/391/], Data(s): 0.054, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.312, Top5: 100.0000, Loss: 0.191\n",
            "Mon Apr 25 17:19:53 2022: Epoch [8], Iteration [100/391/], Data(s): 0.036, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.595, Top5: 99.6829, Loss: 0.198\n",
            "Mon Apr 25 17:20:01 2022: Epoch [8], Iteration [200/391/], Data(s): 0.036, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.630, Top5: 99.6929, Loss: 0.186\n",
            "Mon Apr 25 17:20:09 2022: Epoch [8], Iteration [300/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.581, Top5: 99.7145, Loss: 0.196\n",
            "Mon Apr 25 17:20:17 2022: Epoch [9], Iteration [0/391/], Data(s): 0.054, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.750, Top5: 100.0000, Loss: 0.196\n",
            "Mon Apr 25 17:20:25 2022: Epoch [9], Iteration [100/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.827, Top5: 99.6829, Loss: 0.196\n",
            "Mon Apr 25 17:20:33 2022: Epoch [9], Iteration [200/391/], Data(s): 0.036, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.781, Top5: 99.6774, Loss: 0.190\n",
            "Mon Apr 25 17:20:41 2022: Epoch [9], Iteration [300/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.797, Top5: 99.6808, Loss: 0.191\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 17:20:51 2022: Test information, Data(s): 1.651, Forward(s): 0.293, Top1: 90.670, Top5: 99.310, \n",
            "\n",
            "Mon Apr 25 17:20:51 2022: conv12 Layer, 197 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 315, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(315, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(315, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]          73,856\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "             ReLU-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]         147,584\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         295,168\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]       1,180,160\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 315, 2, 2]       1,451,835\n",
            "      BatchNorm2d-39            [-1, 315, 2, 2]             630\n",
            "             ReLU-40            [-1, 315, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       1,452,032\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 13,175,803\n",
            "Trainable params: 13,175,803\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 6.56\n",
            "Params size (MB): 50.26\n",
            "Estimated Total Size (MB): 56.83\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 315, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(315, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(315, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 17:20:53 2022: Epoch [0], Iteration [0/391/], Data(s): 0.036, Loss(s): 0.000, Forward(s): 0.052, Backward(s): 0.103, Top1: 96.094, Top5: 100.0000, Loss: 0.156\n",
            "Mon Apr 25 17:21:01 2022: Epoch [0], Iteration [100/391/], Data(s): 0.036, Loss(s): 0.011, Forward(s): 0.004, Backward(s): 0.007, Top1: 93.851, Top5: 99.7525, Loss: 0.187\n",
            "Mon Apr 25 17:21:09 2022: Epoch [0], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.653, Top5: 99.7551, Loss: 0.198\n",
            "Mon Apr 25 17:21:17 2022: Epoch [0], Iteration [300/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.830, Top5: 99.7560, Loss: 0.177\n",
            "Mon Apr 25 17:21:24 2022: Epoch [1], Iteration [0/391/], Data(s): 0.051, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.531, Top5: 99.2188, Loss: 0.194\n",
            "Mon Apr 25 17:21:32 2022: Epoch [1], Iteration [100/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.936, Top5: 99.7447, Loss: 0.184\n",
            "Mon Apr 25 17:21:40 2022: Epoch [1], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.073, Top5: 99.7435, Loss: 0.179\n",
            "Mon Apr 25 17:21:48 2022: Epoch [1], Iteration [300/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.895, Top5: 99.7301, Loss: 0.196\n",
            "Mon Apr 25 17:21:55 2022: Epoch [2], Iteration [0/391/], Data(s): 0.053, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.969, Top5: 100.0000, Loss: 0.184\n",
            "Mon Apr 25 17:22:03 2022: Epoch [2], Iteration [100/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.688, Top5: 99.7447, Loss: 0.189\n",
            "Mon Apr 25 17:22:12 2022: Epoch [2], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.738, Top5: 99.7551, Loss: 0.184\n",
            "Mon Apr 25 17:22:19 2022: Epoch [2], Iteration [300/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.893, Top5: 99.7612, Loss: 0.177\n",
            "Mon Apr 25 17:22:27 2022: Epoch [3], Iteration [0/391/], Data(s): 0.053, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.531, Top5: 100.0000, Loss: 0.176\n",
            "Mon Apr 25 17:22:35 2022: Epoch [3], Iteration [100/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.943, Top5: 99.8066, Loss: 0.184\n",
            "Mon Apr 25 17:22:43 2022: Epoch [3], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.956, Top5: 99.7551, Loss: 0.185\n",
            "Mon Apr 25 17:22:51 2022: Epoch [3], Iteration [300/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.036, Top5: 99.7560, Loss: 0.174\n",
            "Mon Apr 25 17:22:58 2022: Epoch [4], Iteration [0/391/], Data(s): 0.052, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.969, Top5: 100.0000, Loss: 0.171\n",
            "Mon Apr 25 17:23:06 2022: Epoch [4], Iteration [100/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.152, Top5: 99.7138, Loss: 0.181\n",
            "Mon Apr 25 17:23:14 2022: Epoch [4], Iteration [200/391/], Data(s): 0.036, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.999, Top5: 99.7862, Loss: 0.179\n",
            "Mon Apr 25 17:23:22 2022: Epoch [4], Iteration [300/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.080, Top5: 99.7898, Loss: 0.171\n",
            "Mon Apr 25 17:23:30 2022: Epoch [5], Iteration [0/391/], Data(s): 0.054, Loss(s): 0.010, Forward(s): 0.004, Backward(s): 0.006, Top1: 92.188, Top5: 99.2188, Loss: 0.171\n",
            "Mon Apr 25 17:23:38 2022: Epoch [5], Iteration [100/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.338, Top5: 99.8066, Loss: 0.170\n",
            "Mon Apr 25 17:23:46 2022: Epoch [5], Iteration [200/391/], Data(s): 0.036, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.154, Top5: 99.7901, Loss: 0.180\n",
            "Mon Apr 25 17:23:54 2022: Epoch [5], Iteration [300/391/], Data(s): 0.036, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.163, Top5: 99.7794, Loss: 0.181\n",
            "Mon Apr 25 17:24:01 2022: Epoch [6], Iteration [0/391/], Data(s): 0.053, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 89.844, Top5: 99.2188, Loss: 0.171\n",
            "Mon Apr 25 17:24:09 2022: Epoch [6], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.585, Top5: 99.8221, Loss: 0.165\n",
            "Mon Apr 25 17:24:18 2022: Epoch [6], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.384, Top5: 99.7785, Loss: 0.173\n",
            "Mon Apr 25 17:24:26 2022: Epoch [6], Iteration [300/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.228, Top5: 99.7638, Loss: 0.181\n",
            "Mon Apr 25 17:24:33 2022: Epoch [7], Iteration [0/391/], Data(s): 0.060, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.312, Top5: 100.0000, Loss: 0.175\n",
            "Mon Apr 25 17:24:41 2022: Epoch [7], Iteration [100/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.168, Top5: 99.7602, Loss: 0.180\n",
            "Mon Apr 25 17:24:49 2022: Epoch [7], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.069, Top5: 99.7862, Loss: 0.175\n",
            "Mon Apr 25 17:24:57 2022: Epoch [7], Iteration [300/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.290, Top5: 99.7898, Loss: 0.160\n",
            "Mon Apr 25 17:25:04 2022: Epoch [8], Iteration [0/391/], Data(s): 0.053, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 90.625, Top5: 100.0000, Loss: 0.166\n",
            "Mon Apr 25 17:25:12 2022: Epoch [8], Iteration [100/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.276, Top5: 99.8221, Loss: 0.169\n",
            "Mon Apr 25 17:25:20 2022: Epoch [8], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.399, Top5: 99.7823, Loss: 0.170\n",
            "Mon Apr 25 17:25:28 2022: Epoch [8], Iteration [300/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.342, Top5: 99.7846, Loss: 0.172\n",
            "Mon Apr 25 17:25:35 2022: Epoch [9], Iteration [0/391/], Data(s): 0.051, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.531, Top5: 99.2188, Loss: 0.168\n",
            "Mon Apr 25 17:25:43 2022: Epoch [9], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.848, Top5: 99.7602, Loss: 0.157\n",
            "Mon Apr 25 17:25:51 2022: Epoch [9], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.520, Top5: 99.7629, Loss: 0.170\n",
            "Mon Apr 25 17:25:59 2022: Epoch [9], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.518, Top5: 99.7820, Loss: 0.161\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 17:26:09 2022: Test information, Data(s): 1.616, Forward(s): 0.251, Top1: 91.070, Top5: 99.320, \n",
            "\n",
            "Mon Apr 25 17:26:09 2022: conv12 Layer, 262 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 250, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(250, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(250, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]          73,856\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "             ReLU-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]         147,584\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         295,168\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]       1,180,160\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 250, 2, 2]       1,152,250\n",
            "      BatchNorm2d-39            [-1, 250, 2, 2]             500\n",
            "             ReLU-40            [-1, 250, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       1,152,512\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 12,576,568\n",
            "Trainable params: 12,576,568\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 6.55\n",
            "Params size (MB): 47.98\n",
            "Estimated Total Size (MB): 54.54\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 250, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(250, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(250, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 17:26:10 2022: Epoch [0], Iteration [0/391/], Data(s): 0.041, Loss(s): 0.000, Forward(s): 0.046, Backward(s): 0.088, Top1: 95.312, Top5: 99.2188, Loss: 0.161\n",
            "Mon Apr 25 17:26:18 2022: Epoch [0], Iteration [100/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.524, Top5: 99.8066, Loss: 0.166\n",
            "Mon Apr 25 17:26:26 2022: Epoch [0], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.496, Top5: 99.8251, Loss: 0.161\n",
            "Mon Apr 25 17:26:34 2022: Epoch [0], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.632, Top5: 99.8261, Loss: 0.160\n",
            "Mon Apr 25 17:26:41 2022: Epoch [1], Iteration [0/391/], Data(s): 0.050, Loss(s): 0.009, Forward(s): 0.004, Backward(s): 0.006, Top1: 92.969, Top5: 100.0000, Loss: 0.154\n",
            "Mon Apr 25 17:26:49 2022: Epoch [1], Iteration [100/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.810, Top5: 99.8144, Loss: 0.155\n",
            "Mon Apr 25 17:26:57 2022: Epoch [1], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.558, Top5: 99.8173, Loss: 0.169\n",
            "Mon Apr 25 17:27:05 2022: Epoch [1], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.677, Top5: 99.7820, Loss: 0.159\n",
            "Mon Apr 25 17:27:12 2022: Epoch [2], Iteration [0/391/], Data(s): 0.058, Loss(s): 0.010, Forward(s): 0.004, Backward(s): 0.006, Top1: 93.750, Top5: 98.4375, Loss: 0.161\n",
            "Mon Apr 25 17:27:20 2022: Epoch [2], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.957, Top5: 99.8453, Loss: 0.156\n",
            "Mon Apr 25 17:27:28 2022: Epoch [2], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.819, Top5: 99.8290, Loss: 0.160\n",
            "Mon Apr 25 17:27:36 2022: Epoch [2], Iteration [300/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.736, Top5: 99.8027, Loss: 0.162\n",
            "Mon Apr 25 17:27:43 2022: Epoch [3], Iteration [0/391/], Data(s): 0.049, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.531, Top5: 99.2188, Loss: 0.152\n",
            "Mon Apr 25 17:27:51 2022: Epoch [3], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.988, Top5: 99.8530, Loss: 0.150\n",
            "Mon Apr 25 17:27:59 2022: Epoch [3], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.687, Top5: 99.8523, Loss: 0.165\n",
            "Mon Apr 25 17:28:06 2022: Epoch [3], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.838, Top5: 99.8547, Loss: 0.149\n",
            "Mon Apr 25 17:28:14 2022: Epoch [4], Iteration [0/391/], Data(s): 0.050, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.011, Top1: 97.656, Top5: 100.0000, Loss: 0.159\n",
            "Mon Apr 25 17:28:22 2022: Epoch [4], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.531, Top5: 99.7525, Loss: 0.164\n",
            "Mon Apr 25 17:28:29 2022: Epoch [4], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.854, Top5: 99.7901, Loss: 0.150\n",
            "Mon Apr 25 17:28:37 2022: Epoch [4], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.910, Top5: 99.8209, Loss: 0.151\n",
            "Mon Apr 25 17:28:44 2022: Epoch [5], Iteration [0/391/], Data(s): 0.053, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.188, Top5: 100.0000, Loss: 0.157\n",
            "Mon Apr 25 17:28:52 2022: Epoch [5], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.196, Top5: 99.7602, Loss: 0.151\n",
            "Mon Apr 25 17:29:00 2022: Epoch [5], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.025, Top5: 99.8290, Loss: 0.151\n",
            "Mon Apr 25 17:29:08 2022: Epoch [5], Iteration [300/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.962, Top5: 99.8261, Loss: 0.153\n",
            "Mon Apr 25 17:29:15 2022: Epoch [6], Iteration [0/391/], Data(s): 0.053, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.008, Top1: 95.312, Top5: 100.0000, Loss: 0.153\n",
            "Mon Apr 25 17:29:23 2022: Epoch [6], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.748, Top5: 99.8144, Loss: 0.156\n",
            "Mon Apr 25 17:29:31 2022: Epoch [6], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.784, Top5: 99.8290, Loss: 0.156\n",
            "Mon Apr 25 17:29:39 2022: Epoch [6], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.832, Top5: 99.8183, Loss: 0.151\n",
            "Mon Apr 25 17:29:46 2022: Epoch [7], Iteration [0/391/], Data(s): 0.052, Loss(s): 0.009, Forward(s): 0.004, Backward(s): 0.006, Top1: 97.656, Top5: 100.0000, Loss: 0.150\n",
            "Mon Apr 25 17:29:54 2022: Epoch [7], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.374, Top5: 99.8298, Loss: 0.144\n",
            "Mon Apr 25 17:30:02 2022: Epoch [7], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.200, Top5: 99.8290, Loss: 0.150\n",
            "Mon Apr 25 17:30:10 2022: Epoch [7], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.167, Top5: 99.8157, Loss: 0.150\n",
            "Mon Apr 25 17:30:17 2022: Epoch [8], Iteration [0/391/], Data(s): 0.057, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.750, Top5: 100.0000, Loss: 0.145\n",
            "Mon Apr 25 17:30:25 2022: Epoch [8], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.529, Top5: 99.8685, Loss: 0.137\n",
            "Mon Apr 25 17:30:33 2022: Epoch [8], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.250, Top5: 99.8678, Loss: 0.148\n",
            "Mon Apr 25 17:30:41 2022: Epoch [8], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.191, Top5: 99.8469, Loss: 0.151\n",
            "Mon Apr 25 17:30:48 2022: Epoch [9], Iteration [0/391/], Data(s): 0.055, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.312, Top5: 100.0000, Loss: 0.146\n",
            "Mon Apr 25 17:30:56 2022: Epoch [9], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.282, Top5: 99.8840, Loss: 0.145\n",
            "Mon Apr 25 17:31:03 2022: Epoch [9], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.215, Top5: 99.8717, Loss: 0.142\n",
            "Mon Apr 25 17:31:11 2022: Epoch [9], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.216, Top5: 99.8469, Loss: 0.144\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 17:31:21 2022: Test information, Data(s): 1.629, Forward(s): 0.245, Top1: 91.280, Top5: 99.340, \n",
            "\n",
            "Mon Apr 25 17:31:21 2022: conv12 Layer, 328 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(184, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]          73,856\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "             ReLU-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]         147,584\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         295,168\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]       1,180,160\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 184, 2, 2]         848,056\n",
            "      BatchNorm2d-39            [-1, 184, 2, 2]             368\n",
            "             ReLU-40            [-1, 184, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]         848,384\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 11,968,114\n",
            "Trainable params: 11,968,114\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 6.54\n",
            "Params size (MB): 45.65\n",
            "Estimated Total Size (MB): 52.21\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(184, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 17:31:23 2022: Epoch [0], Iteration [0/391/], Data(s): 0.040, Loss(s): 0.000, Forward(s): 0.036, Backward(s): 0.068, Top1: 92.969, Top5: 99.2188, Loss: 0.199\n",
            "Mon Apr 25 17:31:30 2022: Epoch [0], Iteration [100/391/], Data(s): 0.035, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.343, Top5: 99.8762, Loss: 0.141\n",
            "Mon Apr 25 17:31:38 2022: Epoch [0], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.328, Top5: 99.8640, Loss: 0.140\n",
            "Mon Apr 25 17:31:46 2022: Epoch [0], Iteration [300/391/], Data(s): 0.035, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.310, Top5: 99.8495, Loss: 0.143\n",
            "Mon Apr 25 17:31:53 2022: Epoch [1], Iteration [0/391/], Data(s): 0.049, Loss(s): 0.009, Forward(s): 0.004, Backward(s): 0.006, Top1: 92.188, Top5: 100.0000, Loss: 0.146\n",
            "Mon Apr 25 17:32:01 2022: Epoch [1], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.537, Top5: 99.8144, Loss: 0.140\n",
            "Mon Apr 25 17:32:09 2022: Epoch [1], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.604, Top5: 99.8601, Loss: 0.132\n",
            "Mon Apr 25 17:32:16 2022: Epoch [1], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.479, Top5: 99.8754, Loss: 0.141\n",
            "Mon Apr 25 17:32:24 2022: Epoch [2], Iteration [0/391/], Data(s): 0.055, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.969, Top5: 99.2188, Loss: 0.146\n",
            "Mon Apr 25 17:32:31 2022: Epoch [2], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.490, Top5: 99.8221, Loss: 0.135\n",
            "Mon Apr 25 17:32:39 2022: Epoch [2], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.495, Top5: 99.8640, Loss: 0.137\n",
            "Mon Apr 25 17:32:47 2022: Epoch [2], Iteration [300/391/], Data(s): 0.035, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.473, Top5: 99.8572, Loss: 0.138\n",
            "Mon Apr 25 17:32:54 2022: Epoch [3], Iteration [0/391/], Data(s): 0.049, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.009, Top1: 96.875, Top5: 100.0000, Loss: 0.147\n",
            "Mon Apr 25 17:33:02 2022: Epoch [3], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.514, Top5: 99.8762, Loss: 0.136\n",
            "Mon Apr 25 17:33:10 2022: Epoch [3], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.359, Top5: 99.8756, Loss: 0.141\n",
            "Mon Apr 25 17:33:17 2022: Epoch [3], Iteration [300/391/], Data(s): 0.035, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.375, Top5: 99.8806, Loss: 0.134\n",
            "Mon Apr 25 17:33:25 2022: Epoch [4], Iteration [0/391/], Data(s): 0.049, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.531, Top5: 100.0000, Loss: 0.128\n",
            "Mon Apr 25 17:33:32 2022: Epoch [4], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.568, Top5: 99.8221, Loss: 0.134\n",
            "Mon Apr 25 17:33:40 2022: Epoch [4], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.433, Top5: 99.8329, Loss: 0.140\n",
            "Mon Apr 25 17:33:48 2022: Epoch [4], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.528, Top5: 99.8365, Loss: 0.131\n",
            "Mon Apr 25 17:33:55 2022: Epoch [5], Iteration [0/391/], Data(s): 0.055, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.750, Top5: 99.2188, Loss: 0.140\n",
            "Mon Apr 25 17:34:03 2022: Epoch [5], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.661, Top5: 99.8840, Loss: 0.131\n",
            "Mon Apr 25 17:34:10 2022: Epoch [5], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.713, Top5: 99.8834, Loss: 0.132\n",
            "Mon Apr 25 17:34:18 2022: Epoch [5], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.678, Top5: 99.8936, Loss: 0.131\n",
            "Mon Apr 25 17:34:25 2022: Epoch [6], Iteration [0/391/], Data(s): 0.052, Loss(s): 0.010, Forward(s): 0.004, Backward(s): 0.006, Top1: 96.094, Top5: 99.2188, Loss: 0.134\n",
            "Mon Apr 25 17:34:33 2022: Epoch [6], Iteration [100/391/], Data(s): 0.035, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.846, Top5: 99.8376, Loss: 0.128\n",
            "Mon Apr 25 17:34:41 2022: Epoch [6], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.833, Top5: 99.8756, Loss: 0.125\n",
            "Mon Apr 25 17:34:48 2022: Epoch [6], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.813, Top5: 99.8858, Loss: 0.128\n",
            "Mon Apr 25 17:34:56 2022: Epoch [7], Iteration [0/391/], Data(s): 0.051, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.969, Top5: 100.0000, Loss: 0.130\n",
            "Mon Apr 25 17:35:03 2022: Epoch [7], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.575, Top5: 99.9304, Loss: 0.128\n",
            "Mon Apr 25 17:35:11 2022: Epoch [7], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.658, Top5: 99.9067, Loss: 0.125\n",
            "Mon Apr 25 17:35:19 2022: Epoch [7], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.710, Top5: 99.9014, Loss: 0.127\n",
            "Mon Apr 25 17:35:26 2022: Epoch [8], Iteration [0/391/], Data(s): 0.054, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.008, Top1: 96.094, Top5: 100.0000, Loss: 0.123\n",
            "Mon Apr 25 17:35:34 2022: Epoch [8], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.792, Top5: 99.8453, Loss: 0.125\n",
            "Mon Apr 25 17:35:42 2022: Epoch [8], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.732, Top5: 99.8523, Loss: 0.132\n",
            "Mon Apr 25 17:35:49 2022: Epoch [8], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.738, Top5: 99.8650, Loss: 0.129\n",
            "Mon Apr 25 17:35:56 2022: Epoch [9], Iteration [0/391/], Data(s): 0.058, Loss(s): 0.010, Forward(s): 0.004, Backward(s): 0.008, Top1: 92.188, Top5: 100.0000, Loss: 0.128\n",
            "Mon Apr 25 17:36:04 2022: Epoch [9], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.947, Top5: 99.9536, Loss: 0.118\n",
            "Mon Apr 25 17:36:12 2022: Epoch [9], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.977, Top5: 99.9106, Loss: 0.120\n",
            "Mon Apr 25 17:36:20 2022: Epoch [9], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.894, Top5: 99.8910, Loss: 0.127\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 17:36:30 2022: Test information, Data(s): 1.615, Forward(s): 0.236, Top1: 91.410, Top5: 99.250, \n",
            "\n",
            "Mon Apr 25 17:36:30 2022: conv12 Layer, 394 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 118, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(118, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(118, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]          73,856\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "             ReLU-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]         147,584\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         295,168\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]       1,180,160\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 118, 2, 2]         543,862\n",
            "      BatchNorm2d-39            [-1, 118, 2, 2]             236\n",
            "             ReLU-40            [-1, 118, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]         544,256\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 11,359,660\n",
            "Trainable params: 11,359,660\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 6.54\n",
            "Params size (MB): 43.33\n",
            "Estimated Total Size (MB): 49.88\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 118, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(118, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(118, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 17:36:31 2022: Epoch [0], Iteration [0/391/], Data(s): 0.037, Loss(s): 0.000, Forward(s): 0.030, Backward(s): 0.041, Top1: 96.094, Top5: 100.0000, Loss: 0.134\n",
            "Mon Apr 25 17:36:38 2022: Epoch [0], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.955, Top5: 99.9149, Loss: 0.119\n",
            "Mon Apr 25 17:36:46 2022: Epoch [0], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.105, Top5: 99.9067, Loss: 0.118\n",
            "Mon Apr 25 17:36:54 2022: Epoch [0], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.974, Top5: 99.8988, Loss: 0.124\n",
            "Mon Apr 25 17:37:01 2022: Epoch [1], Iteration [0/391/], Data(s): 0.048, Loss(s): 0.009, Forward(s): 0.004, Backward(s): 0.006, Top1: 92.188, Top5: 100.0000, Loss: 0.124\n",
            "Mon Apr 25 17:37:08 2022: Epoch [1], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.692, Top5: 99.9304, Loss: 0.126\n",
            "Mon Apr 25 17:37:16 2022: Epoch [1], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.911, Top5: 99.9145, Loss: 0.118\n",
            "Mon Apr 25 17:37:24 2022: Epoch [1], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.993, Top5: 99.9066, Loss: 0.116\n",
            "Mon Apr 25 17:37:31 2022: Epoch [2], Iteration [0/391/], Data(s): 0.051, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.094, Top5: 100.0000, Loss: 0.120\n",
            "Mon Apr 25 17:37:38 2022: Epoch [2], Iteration [100/391/], Data(s): 0.035, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.248, Top5: 99.9459, Loss: 0.114\n",
            "Mon Apr 25 17:37:46 2022: Epoch [2], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.938, Top5: 99.9184, Loss: 0.129\n",
            "Mon Apr 25 17:37:54 2022: Epoch [2], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.039, Top5: 99.9169, Loss: 0.118\n",
            "Mon Apr 25 17:38:01 2022: Epoch [3], Iteration [0/391/], Data(s): 0.050, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.094, Top5: 100.0000, Loss: 0.117\n",
            "Mon Apr 25 17:38:09 2022: Epoch [3], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.962, Top5: 99.8608, Loss: 0.121\n",
            "Mon Apr 25 17:38:16 2022: Epoch [3], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.012, Top5: 99.8912, Loss: 0.120\n",
            "Mon Apr 25 17:38:24 2022: Epoch [3], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.969, Top5: 99.8910, Loss: 0.121\n",
            "Mon Apr 25 17:38:31 2022: Epoch [4], Iteration [0/391/], Data(s): 0.048, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.531, Top5: 100.0000, Loss: 0.116\n",
            "Mon Apr 25 17:38:39 2022: Epoch [4], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.869, Top5: 99.9072, Loss: 0.117\n",
            "Mon Apr 25 17:38:46 2022: Epoch [4], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.012, Top5: 99.8951, Loss: 0.112\n",
            "Mon Apr 25 17:38:54 2022: Epoch [4], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.065, Top5: 99.8806, Loss: 0.115\n",
            "Mon Apr 25 17:39:01 2022: Epoch [5], Iteration [0/391/], Data(s): 0.050, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 97.656, Top5: 100.0000, Loss: 0.114\n",
            "Mon Apr 25 17:39:09 2022: Epoch [5], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.187, Top5: 99.8994, Loss: 0.114\n",
            "Mon Apr 25 17:39:16 2022: Epoch [5], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.284, Top5: 99.8989, Loss: 0.108\n",
            "Mon Apr 25 17:39:24 2022: Epoch [5], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.257, Top5: 99.9195, Loss: 0.111\n",
            "Mon Apr 25 17:39:31 2022: Epoch [6], Iteration [0/391/], Data(s): 0.048, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.531, Top5: 100.0000, Loss: 0.117\n",
            "Mon Apr 25 17:39:39 2022: Epoch [6], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.310, Top5: 99.9149, Loss: 0.113\n",
            "Mon Apr 25 17:39:46 2022: Epoch [6], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.331, Top5: 99.9456, Loss: 0.109\n",
            "Mon Apr 25 17:39:54 2022: Epoch [6], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.317, Top5: 99.9247, Loss: 0.114\n",
            "Mon Apr 25 17:40:01 2022: Epoch [7], Iteration [0/391/], Data(s): 0.048, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 99.219, Top5: 100.0000, Loss: 0.107\n",
            "Mon Apr 25 17:40:09 2022: Epoch [7], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.666, Top5: 99.9304, Loss: 0.099\n",
            "Mon Apr 25 17:40:16 2022: Epoch [7], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.436, Top5: 99.9339, Loss: 0.112\n",
            "Mon Apr 25 17:40:24 2022: Epoch [7], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.410, Top5: 99.9351, Loss: 0.109\n",
            "Mon Apr 25 17:40:31 2022: Epoch [8], Iteration [0/391/], Data(s): 0.054, Loss(s): 0.009, Forward(s): 0.004, Backward(s): 0.006, Top1: 96.094, Top5: 100.0000, Loss: 0.109\n",
            "Mon Apr 25 17:40:39 2022: Epoch [8], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.566, Top5: 99.8917, Loss: 0.109\n",
            "Mon Apr 25 17:40:46 2022: Epoch [8], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.576, Top5: 99.9145, Loss: 0.104\n",
            "Mon Apr 25 17:40:54 2022: Epoch [8], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.499, Top5: 99.9118, Loss: 0.107\n",
            "Mon Apr 25 17:41:01 2022: Epoch [9], Iteration [0/391/], Data(s): 0.055, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.750, Top5: 100.0000, Loss: 0.102\n",
            "Mon Apr 25 17:41:09 2022: Epoch [9], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.295, Top5: 99.8840, Loss: 0.112\n",
            "Mon Apr 25 17:41:17 2022: Epoch [9], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.498, Top5: 99.9067, Loss: 0.098\n",
            "Mon Apr 25 17:41:24 2022: Epoch [9], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.410, Top5: 99.9169, Loss: 0.109\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 17:41:34 2022: Test information, Data(s): 1.602, Forward(s): 0.234, Top1: 91.370, Top5: 99.260, \n",
            "\n",
            "Mon Apr 25 17:41:34 2022: conv12 Layer, 460 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 52, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(52, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]          73,856\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "             ReLU-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]         147,584\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         295,168\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]       1,180,160\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38             [-1, 52, 2, 2]         239,668\n",
            "      BatchNorm2d-39             [-1, 52, 2, 2]             104\n",
            "             ReLU-40             [-1, 52, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]         240,128\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 10,751,206\n",
            "Trainable params: 10,751,206\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 6.53\n",
            "Params size (MB): 41.01\n",
            "Estimated Total Size (MB): 47.56\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 52, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(52, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 17:41:35 2022: Epoch [0], Iteration [0/391/], Data(s): 0.036, Loss(s): 0.000, Forward(s): 0.023, Backward(s): 0.029, Top1: 96.875, Top5: 100.0000, Loss: 0.103\n",
            "Mon Apr 25 17:41:43 2022: Epoch [0], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.643, Top5: 99.9226, Loss: 0.102\n",
            "Mon Apr 25 17:41:50 2022: Epoch [0], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.700, Top5: 99.9184, Loss: 0.106\n",
            "Mon Apr 25 17:41:58 2022: Epoch [0], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.665, Top5: 99.9247, Loss: 0.103\n",
            "Mon Apr 25 17:42:05 2022: Epoch [1], Iteration [0/391/], Data(s): 0.050, Loss(s): 0.009, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.094, Top5: 100.0000, Loss: 0.113\n",
            "Mon Apr 25 17:42:12 2022: Epoch [1], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.643, Top5: 99.9381, Loss: 0.099\n",
            "Mon Apr 25 17:42:20 2022: Epoch [1], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.583, Top5: 99.9378, Loss: 0.104\n",
            "Mon Apr 25 17:42:27 2022: Epoch [1], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.587, Top5: 99.9377, Loss: 0.103\n",
            "Mon Apr 25 17:42:34 2022: Epoch [2], Iteration [0/391/], Data(s): 0.048, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.312, Top5: 100.0000, Loss: 0.097\n",
            "Mon Apr 25 17:42:42 2022: Epoch [2], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.960, Top5: 99.9304, Loss: 0.094\n",
            "Mon Apr 25 17:42:49 2022: Epoch [2], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.786, Top5: 99.9456, Loss: 0.100\n",
            "Mon Apr 25 17:42:57 2022: Epoch [2], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.792, Top5: 99.9377, Loss: 0.096\n",
            "Mon Apr 25 17:43:04 2022: Epoch [3], Iteration [0/391/], Data(s): 0.055, Loss(s): 0.008, Forward(s): 0.005, Backward(s): 0.006, Top1: 91.406, Top5: 99.2188, Loss: 0.108\n",
            "Mon Apr 25 17:43:11 2022: Epoch [3], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.689, Top5: 99.9613, Loss: 0.098\n",
            "Mon Apr 25 17:43:19 2022: Epoch [3], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.832, Top5: 99.9572, Loss: 0.090\n",
            "Mon Apr 25 17:43:27 2022: Epoch [3], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.820, Top5: 99.9533, Loss: 0.097\n",
            "Mon Apr 25 17:43:34 2022: Epoch [4], Iteration [0/391/], Data(s): 0.048, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 98.438, Top5: 100.0000, Loss: 0.095\n",
            "Mon Apr 25 17:43:41 2022: Epoch [4], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 97.076, Top5: 99.9613, Loss: 0.094\n",
            "Mon Apr 25 17:43:49 2022: Epoch [4], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.910, Top5: 99.9417, Loss: 0.098\n",
            "Mon Apr 25 17:43:56 2022: Epoch [4], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.935, Top5: 99.9455, Loss: 0.092\n",
            "Mon Apr 25 17:44:03 2022: Epoch [5], Iteration [0/391/], Data(s): 0.049, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 97.656, Top5: 100.0000, Loss: 0.096\n",
            "Mon Apr 25 17:44:11 2022: Epoch [5], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.867, Top5: 99.9536, Loss: 0.093\n",
            "Mon Apr 25 17:44:19 2022: Epoch [5], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.906, Top5: 99.9534, Loss: 0.091\n",
            "Mon Apr 25 17:44:26 2022: Epoch [5], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.849, Top5: 99.9403, Loss: 0.098\n",
            "Mon Apr 25 17:44:33 2022: Epoch [6], Iteration [0/391/], Data(s): 0.052, Loss(s): 0.009, Forward(s): 0.003, Backward(s): 0.006, Top1: 97.656, Top5: 100.0000, Loss: 0.095\n",
            "Mon Apr 25 17:44:41 2022: Epoch [6], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.929, Top5: 99.9226, Loss: 0.096\n",
            "Mon Apr 25 17:44:48 2022: Epoch [6], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.964, Top5: 99.9300, Loss: 0.092\n",
            "Mon Apr 25 17:44:56 2022: Epoch [6], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.984, Top5: 99.9429, Loss: 0.089\n",
            "Mon Apr 25 17:45:03 2022: Epoch [7], Iteration [0/391/], Data(s): 0.053, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.009, Top1: 98.438, Top5: 100.0000, Loss: 0.093\n",
            "Mon Apr 25 17:45:10 2022: Epoch [7], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 97.208, Top5: 99.9381, Loss: 0.085\n",
            "Mon Apr 25 17:45:18 2022: Epoch [7], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 97.217, Top5: 99.9262, Loss: 0.087\n",
            "Mon Apr 25 17:45:26 2022: Epoch [7], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 97.171, Top5: 99.9299, Loss: 0.088\n",
            "Mon Apr 25 17:45:33 2022: Epoch [8], Iteration [0/391/], Data(s): 0.054, Loss(s): 0.009, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.094, Top5: 100.0000, Loss: 0.099\n",
            "Mon Apr 25 17:45:40 2022: Epoch [8], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 97.107, Top5: 99.9613, Loss: 0.084\n",
            "Mon Apr 25 17:45:48 2022: Epoch [8], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 97.132, Top5: 99.9378, Loss: 0.088\n",
            "Mon Apr 25 17:45:55 2022: Epoch [8], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 97.090, Top5: 99.9403, Loss: 0.092\n",
            "Mon Apr 25 17:46:02 2022: Epoch [9], Iteration [0/391/], Data(s): 0.046, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 98.438, Top5: 100.0000, Loss: 0.084\n",
            "Mon Apr 25 17:46:10 2022: Epoch [9], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 97.324, Top5: 99.9613, Loss: 0.082\n",
            "Mon Apr 25 17:46:18 2022: Epoch [9], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 97.182, Top5: 99.9572, Loss: 0.086\n",
            "Mon Apr 25 17:46:25 2022: Epoch [9], Iteration [300/391/], Data(s): 0.035, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 97.179, Top5: 99.9507, Loss: 0.086\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 17:46:35 2022: Test information, Data(s): 1.645, Forward(s): 0.232, Top1: 91.200, Top5: 99.320, \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for conv, channel in zip(prune_layers[12:], prune_channels[12:]):    \n",
        "    top1_accuracies[conv] = []\n",
        "    top5_accuracies[conv] = []\n",
        "    \n",
        "    # load new network and check accuracy\n",
        "    network, _, _ = test_network(args, data_set=test_set)\n",
        "        \n",
        "    # remove 0 channels ~ M (max_channel_ratio) % of total channels\n",
        "    step = np.linspace(0, int(channel*max_channel_ratio), int(1/prune_step_ratio), dtype=np.int)\n",
        "    steps = (step[1:] - step[:-1]).tolist()\n",
        "    \n",
        "    for i in range(len(steps)):\n",
        "        print(\"\\n%s: %s Layer, %d Channels pruned\"%(time.ctime(), conv, sum(steps[:i+1])))\n",
        "        \n",
        "        # set prune information\n",
        "        args.prune_layers = [conv]\n",
        "        args.prune_channels =[steps[i]]\n",
        "\n",
        "        network = prune_network(args, network)\n",
        "        \n",
        "        network, _, (top1, top5) = test_network(args, network, test_set)\n",
        "            \n",
        "        top1_accuracies[conv].append(top1)\n",
        "        top5_accuracies[conv].append(top5)"
      ],
      "metadata": {
        "id": "4E4KmrIZEm_F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b561c03b-5f73-4583-c13c-926d05993ade"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 16:24:15 2022: Test information, Data(s): 1.657, Forward(s): 0.213, Top1: 77.870, Top5: 97.560, \n",
            "\n",
            "Mon Apr 25 16:24:15 2022: conv13 Layer, 65 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 447, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(447, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=447, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]          73,856\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "             ReLU-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]         147,584\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         295,168\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]       1,180,160\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 447, 2, 2]       2,060,223\n",
            "      BatchNorm2d-42            [-1, 447, 2, 2]             894\n",
            "             ReLU-43            [-1, 447, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 447, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         229,376\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 14,658,951\n",
            "Trainable params: 14,658,951\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 6.57\n",
            "Params size (MB): 55.92\n",
            "Estimated Total Size (MB): 62.50\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 447, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(447, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=447, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  if __name__ == '__main__':\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 16:24:17 2022: Epoch [0], Iteration [0/391/], Data(s): 0.042, Loss(s): 0.006, Forward(s): 0.373, Backward(s): 0.697, Top1: 81.250, Top5: 97.6562, Loss: 0.533\n",
            "Mon Apr 25 16:24:25 2022: Epoch [0], Iteration [100/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.007, Backward(s): 0.013, Top1: 86.603, Top5: 98.9403, Loss: 0.403\n",
            "Mon Apr 25 16:24:33 2022: Epoch [0], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.005, Backward(s): 0.010, Top1: 87.749, Top5: 99.0944, Loss: 0.345\n",
            "Mon Apr 25 16:24:41 2022: Epoch [0], Iteration [300/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.004, Backward(s): 0.009, Top1: 88.289, Top5: 99.0994, Loss: 0.334\n",
            "Mon Apr 25 16:24:49 2022: Epoch [1], Iteration [0/391/], Data(s): 0.041, Loss(s): 0.010, Forward(s): 0.004, Backward(s): 0.006, Top1: 91.406, Top5: 100.0000, Loss: 0.319\n",
            "Mon Apr 25 16:24:57 2022: Epoch [1], Iteration [100/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 89.937, Top5: 99.3116, Loss: 0.313\n",
            "Mon Apr 25 16:25:06 2022: Epoch [1], Iteration [200/391/], Data(s): 0.036, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 90.174, Top5: 99.3664, Loss: 0.299\n",
            "Mon Apr 25 16:25:14 2022: Epoch [1], Iteration [300/391/], Data(s): 0.036, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 90.329, Top5: 99.3641, Loss: 0.295\n",
            "Mon Apr 25 16:25:21 2022: Epoch [2], Iteration [0/391/], Data(s): 0.070, Loss(s): 0.011, Forward(s): 0.004, Backward(s): 0.006, Top1: 91.406, Top5: 100.0000, Loss: 0.285\n",
            "Mon Apr 25 16:25:29 2022: Epoch [2], Iteration [100/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 90.865, Top5: 99.4276, Loss: 0.287\n",
            "Mon Apr 25 16:25:37 2022: Epoch [2], Iteration [200/391/], Data(s): 0.036, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 91.053, Top5: 99.4597, Loss: 0.277\n",
            "Mon Apr 25 16:25:45 2022: Epoch [2], Iteration [300/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 90.885, Top5: 99.4653, Loss: 0.286\n",
            "Mon Apr 25 16:25:53 2022: Epoch [3], Iteration [0/391/], Data(s): 0.063, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 87.500, Top5: 99.2188, Loss: 0.278\n",
            "Mon Apr 25 16:26:01 2022: Epoch [3], Iteration [100/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 91.190, Top5: 99.5668, Loss: 0.272\n",
            "Mon Apr 25 16:26:09 2022: Epoch [3], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 91.507, Top5: 99.5219, Loss: 0.258\n",
            "Mon Apr 25 16:26:17 2022: Epoch [3], Iteration [300/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 91.497, Top5: 99.5380, Loss: 0.265\n",
            "Mon Apr 25 16:26:25 2022: Epoch [4], Iteration [0/391/], Data(s): 0.055, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 87.500, Top5: 100.0000, Loss: 0.268\n",
            "Mon Apr 25 16:26:33 2022: Epoch [4], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 91.429, Top5: 99.5823, Loss: 0.263\n",
            "Mon Apr 25 16:26:41 2022: Epoch [4], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 91.352, Top5: 99.4986, Loss: 0.266\n",
            "Mon Apr 25 16:26:49 2022: Epoch [4], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 91.502, Top5: 99.5250, Loss: 0.250\n",
            "Mon Apr 25 16:26:56 2022: Epoch [5], Iteration [0/391/], Data(s): 0.055, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 91.406, Top5: 99.2188, Loss: 0.244\n",
            "Mon Apr 25 16:27:04 2022: Epoch [5], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.010, Top5: 99.5514, Loss: 0.248\n",
            "Mon Apr 25 16:27:13 2022: Epoch [5], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 91.985, Top5: 99.5530, Loss: 0.252\n",
            "Mon Apr 25 16:27:21 2022: Epoch [5], Iteration [300/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.226, Top5: 99.5640, Loss: 0.233\n",
            "Mon Apr 25 16:27:28 2022: Epoch [6], Iteration [0/391/], Data(s): 0.057, Loss(s): 0.011, Forward(s): 0.004, Backward(s): 0.007, Top1: 94.531, Top5: 100.0000, Loss: 0.251\n",
            "Mon Apr 25 16:27:36 2022: Epoch [6], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.396, Top5: 99.5359, Loss: 0.237\n",
            "Mon Apr 25 16:27:45 2022: Epoch [6], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.308, Top5: 99.5880, Loss: 0.239\n",
            "Mon Apr 25 16:27:53 2022: Epoch [6], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.200, Top5: 99.5691, Loss: 0.247\n",
            "Mon Apr 25 16:28:00 2022: Epoch [7], Iteration [0/391/], Data(s): 0.056, Loss(s): 0.010, Forward(s): 0.004, Backward(s): 0.009, Top1: 93.750, Top5: 100.0000, Loss: 0.240\n",
            "Mon Apr 25 16:28:08 2022: Epoch [7], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.830, Top5: 99.5823, Loss: 0.234\n",
            "Mon Apr 25 16:28:16 2022: Epoch [7], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.518, Top5: 99.5569, Loss: 0.240\n",
            "Mon Apr 25 16:28:24 2022: Epoch [7], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.460, Top5: 99.5588, Loss: 0.235\n",
            "Mon Apr 25 16:28:32 2022: Epoch [8], Iteration [0/391/], Data(s): 0.061, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 86.719, Top5: 98.4375, Loss: 0.238\n",
            "Mon Apr 25 16:28:40 2022: Epoch [8], Iteration [100/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.180, Top5: 99.5823, Loss: 0.237\n",
            "Mon Apr 25 16:28:48 2022: Epoch [8], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.312, Top5: 99.5725, Loss: 0.235\n",
            "Mon Apr 25 16:28:56 2022: Epoch [8], Iteration [300/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.385, Top5: 99.6159, Loss: 0.224\n",
            "Mon Apr 25 16:29:04 2022: Epoch [9], Iteration [0/391/], Data(s): 0.061, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 90.625, Top5: 99.2188, Loss: 0.228\n",
            "Mon Apr 25 16:29:12 2022: Epoch [9], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.644, Top5: 99.5436, Loss: 0.227\n",
            "Mon Apr 25 16:29:20 2022: Epoch [9], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.359, Top5: 99.5491, Loss: 0.235\n",
            "Mon Apr 25 16:29:28 2022: Epoch [9], Iteration [300/391/], Data(s): 0.035, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.393, Top5: 99.5614, Loss: 0.226\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 16:29:39 2022: Test information, Data(s): 1.627, Forward(s): 0.305, Top1: 90.080, Top5: 99.310, \n",
            "\n",
            "Mon Apr 25 16:29:39 2022: conv13 Layer, 131 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 381, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(381, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=381, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]          73,856\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "             ReLU-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]         147,584\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         295,168\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]       1,180,160\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 381, 2, 2]       1,756,029\n",
            "      BatchNorm2d-42            [-1, 381, 2, 2]             762\n",
            "             ReLU-43            [-1, 381, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 381, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         195,584\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 14,320,833\n",
            "Trainable params: 14,320,833\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 6.56\n",
            "Params size (MB): 54.63\n",
            "Estimated Total Size (MB): 61.20\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 381, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(381, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=381, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 16:29:40 2022: Epoch [0], Iteration [0/391/], Data(s): 0.046, Loss(s): 0.001, Forward(s): 0.059, Backward(s): 0.123, Top1: 94.531, Top5: 100.0000, Loss: 0.168\n",
            "Mon Apr 25 16:29:48 2022: Epoch [0], Iteration [100/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.004, Backward(s): 0.007, Top1: 92.597, Top5: 99.5050, Loss: 0.229\n",
            "Mon Apr 25 16:29:56 2022: Epoch [0], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.739, Top5: 99.5608, Loss: 0.220\n",
            "Mon Apr 25 16:30:04 2022: Epoch [0], Iteration [300/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.725, Top5: 99.5821, Loss: 0.226\n",
            "Mon Apr 25 16:30:12 2022: Epoch [1], Iteration [0/391/], Data(s): 0.056, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.188, Top5: 100.0000, Loss: 0.221\n",
            "Mon Apr 25 16:30:20 2022: Epoch [1], Iteration [100/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.193, Top5: 99.7293, Loss: 0.209\n",
            "Mon Apr 25 16:30:28 2022: Epoch [1], Iteration [200/391/], Data(s): 0.036, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.938, Top5: 99.7085, Loss: 0.217\n",
            "Mon Apr 25 16:30:37 2022: Epoch [1], Iteration [300/391/], Data(s): 0.036, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.756, Top5: 99.7015, Loss: 0.224\n",
            "Mon Apr 25 16:30:44 2022: Epoch [2], Iteration [0/391/], Data(s): 0.049, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 91.406, Top5: 99.2188, Loss: 0.221\n",
            "Mon Apr 25 16:30:52 2022: Epoch [2], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.922, Top5: 99.5900, Loss: 0.213\n",
            "Mon Apr 25 16:31:01 2022: Epoch [2], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.218, Top5: 99.6269, Loss: 0.200\n",
            "Mon Apr 25 16:31:09 2022: Epoch [2], Iteration [300/391/], Data(s): 0.035, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.096, Top5: 99.6704, Loss: 0.217\n",
            "Mon Apr 25 16:31:16 2022: Epoch [3], Iteration [0/391/], Data(s): 0.053, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 91.406, Top5: 99.2188, Loss: 0.216\n",
            "Mon Apr 25 16:31:24 2022: Epoch [3], Iteration [100/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.922, Top5: 99.6751, Loss: 0.219\n",
            "Mon Apr 25 16:31:32 2022: Epoch [3], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.078, Top5: 99.7046, Loss: 0.206\n",
            "Mon Apr 25 16:31:41 2022: Epoch [3], Iteration [300/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.145, Top5: 99.7067, Loss: 0.208\n",
            "Mon Apr 25 16:31:48 2022: Epoch [4], Iteration [0/391/], Data(s): 0.055, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.009, Top1: 93.750, Top5: 100.0000, Loss: 0.201\n",
            "Mon Apr 25 16:31:56 2022: Epoch [4], Iteration [100/391/], Data(s): 0.036, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.472, Top5: 99.6906, Loss: 0.202\n",
            "Mon Apr 25 16:32:05 2022: Epoch [4], Iteration [200/391/], Data(s): 0.036, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.299, Top5: 99.6968, Loss: 0.210\n",
            "Mon Apr 25 16:32:13 2022: Epoch [4], Iteration [300/391/], Data(s): 0.036, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.327, Top5: 99.7041, Loss: 0.202\n",
            "Mon Apr 25 16:32:20 2022: Epoch [5], Iteration [0/391/], Data(s): 0.059, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.531, Top5: 100.0000, Loss: 0.211\n",
            "Mon Apr 25 16:32:28 2022: Epoch [5], Iteration [100/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.093, Top5: 99.7293, Loss: 0.205\n",
            "Mon Apr 25 16:32:37 2022: Epoch [5], Iteration [200/391/], Data(s): 0.036, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.023, Top5: 99.7046, Loss: 0.212\n",
            "Mon Apr 25 16:32:45 2022: Epoch [5], Iteration [300/391/], Data(s): 0.036, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.208, Top5: 99.6833, Loss: 0.193\n",
            "Mon Apr 25 16:32:52 2022: Epoch [6], Iteration [0/391/], Data(s): 0.051, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.969, Top5: 100.0000, Loss: 0.199\n",
            "Mon Apr 25 16:33:01 2022: Epoch [6], Iteration [100/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.510, Top5: 99.7293, Loss: 0.194\n",
            "Mon Apr 25 16:33:09 2022: Epoch [6], Iteration [200/391/], Data(s): 0.036, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.408, Top5: 99.7279, Loss: 0.202\n",
            "Mon Apr 25 16:33:17 2022: Epoch [6], Iteration [300/391/], Data(s): 0.036, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.392, Top5: 99.6963, Loss: 0.204\n",
            "Mon Apr 25 16:33:25 2022: Epoch [7], Iteration [0/391/], Data(s): 0.053, Loss(s): 0.012, Forward(s): 0.003, Backward(s): 0.010, Top1: 92.969, Top5: 100.0000, Loss: 0.202\n",
            "Mon Apr 25 16:33:33 2022: Epoch [7], Iteration [100/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.487, Top5: 99.6983, Loss: 0.199\n",
            "Mon Apr 25 16:33:41 2022: Epoch [7], Iteration [200/391/], Data(s): 0.036, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.532, Top5: 99.7279, Loss: 0.195\n",
            "Mon Apr 25 16:33:49 2022: Epoch [7], Iteration [300/391/], Data(s): 0.036, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.579, Top5: 99.7223, Loss: 0.194\n",
            "Mon Apr 25 16:33:57 2022: Epoch [8], Iteration [0/391/], Data(s): 0.055, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.875, Top5: 100.0000, Loss: 0.192\n",
            "Mon Apr 25 16:34:05 2022: Epoch [8], Iteration [100/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.572, Top5: 99.7834, Loss: 0.194\n",
            "Mon Apr 25 16:34:13 2022: Epoch [8], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.513, Top5: 99.7551, Loss: 0.203\n",
            "Mon Apr 25 16:34:21 2022: Epoch [8], Iteration [300/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.695, Top5: 99.7301, Loss: 0.183\n",
            "Mon Apr 25 16:34:29 2022: Epoch [9], Iteration [0/391/], Data(s): 0.059, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.188, Top5: 99.2188, Loss: 0.196\n",
            "Mon Apr 25 16:34:37 2022: Epoch [9], Iteration [100/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.603, Top5: 99.7525, Loss: 0.191\n",
            "Mon Apr 25 16:34:45 2022: Epoch [9], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.766, Top5: 99.7823, Loss: 0.184\n",
            "Mon Apr 25 16:34:53 2022: Epoch [9], Iteration [300/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.672, Top5: 99.7716, Loss: 0.197\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 16:35:04 2022: Test information, Data(s): 1.664, Forward(s): 0.296, Top1: 90.660, Top5: 99.320, \n",
            "\n",
            "Mon Apr 25 16:35:04 2022: conv13 Layer, 197 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 315, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(315, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=315, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]          73,856\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "             ReLU-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]         147,584\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         295,168\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]       1,180,160\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 315, 2, 2]       1,451,835\n",
            "      BatchNorm2d-42            [-1, 315, 2, 2]             630\n",
            "             ReLU-43            [-1, 315, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 315, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         161,792\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 13,982,715\n",
            "Trainable params: 13,982,715\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 6.55\n",
            "Params size (MB): 53.34\n",
            "Estimated Total Size (MB): 59.91\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 315, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(315, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=315, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 16:35:05 2022: Epoch [0], Iteration [0/391/], Data(s): 0.038, Loss(s): 0.000, Forward(s): 0.051, Backward(s): 0.104, Top1: 94.531, Top5: 100.0000, Loss: 0.162\n",
            "Mon Apr 25 16:35:13 2022: Epoch [0], Iteration [100/391/], Data(s): 0.036, Loss(s): 0.011, Forward(s): 0.004, Backward(s): 0.007, Top1: 94.106, Top5: 99.7679, Loss: 0.181\n",
            "Mon Apr 25 16:35:21 2022: Epoch [0], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.108, Top5: 99.7551, Loss: 0.183\n",
            "Mon Apr 25 16:35:29 2022: Epoch [0], Iteration [300/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.051, Top5: 99.7456, Loss: 0.190\n",
            "Mon Apr 25 16:35:37 2022: Epoch [1], Iteration [0/391/], Data(s): 0.052, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.750, Top5: 100.0000, Loss: 0.185\n",
            "Mon Apr 25 16:35:45 2022: Epoch [1], Iteration [100/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.539, Top5: 99.8066, Loss: 0.174\n",
            "Mon Apr 25 16:35:53 2022: Epoch [1], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.162, Top5: 99.7785, Loss: 0.185\n",
            "Mon Apr 25 16:36:01 2022: Epoch [1], Iteration [300/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.025, Top5: 99.7846, Loss: 0.193\n",
            "Mon Apr 25 16:36:09 2022: Epoch [2], Iteration [0/391/], Data(s): 0.054, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.312, Top5: 99.2188, Loss: 0.184\n",
            "Mon Apr 25 16:36:17 2022: Epoch [2], Iteration [100/391/], Data(s): 0.036, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.214, Top5: 99.7061, Loss: 0.175\n",
            "Mon Apr 25 16:36:25 2022: Epoch [2], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.049, Top5: 99.7474, Loss: 0.185\n",
            "Mon Apr 25 16:36:33 2022: Epoch [2], Iteration [300/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.020, Top5: 99.7716, Loss: 0.184\n",
            "Mon Apr 25 16:36:41 2022: Epoch [3], Iteration [0/391/], Data(s): 0.053, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.188, Top5: 100.0000, Loss: 0.177\n",
            "Mon Apr 25 16:36:49 2022: Epoch [3], Iteration [100/391/], Data(s): 0.036, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.083, Top5: 99.8066, Loss: 0.179\n",
            "Mon Apr 25 16:36:57 2022: Epoch [3], Iteration [200/391/], Data(s): 0.036, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.038, Top5: 99.7551, Loss: 0.185\n",
            "Mon Apr 25 16:37:05 2022: Epoch [3], Iteration [300/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.033, Top5: 99.7612, Loss: 0.178\n",
            "Mon Apr 25 16:37:12 2022: Epoch [4], Iteration [0/391/], Data(s): 0.056, Loss(s): 0.010, Forward(s): 0.004, Backward(s): 0.006, Top1: 97.656, Top5: 100.0000, Loss: 0.180\n",
            "Mon Apr 25 16:37:21 2022: Epoch [4], Iteration [100/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.307, Top5: 99.7525, Loss: 0.179\n",
            "Mon Apr 25 16:37:29 2022: Epoch [4], Iteration [200/391/], Data(s): 0.036, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.201, Top5: 99.7590, Loss: 0.177\n",
            "Mon Apr 25 16:37:37 2022: Epoch [4], Iteration [300/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.108, Top5: 99.7768, Loss: 0.179\n",
            "Mon Apr 25 16:37:44 2022: Epoch [5], Iteration [0/391/], Data(s): 0.052, Loss(s): 0.011, Forward(s): 0.004, Backward(s): 0.006, Top1: 92.188, Top5: 97.6562, Loss: 0.185\n",
            "Mon Apr 25 16:37:52 2022: Epoch [5], Iteration [100/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.477, Top5: 99.8376, Loss: 0.167\n",
            "Mon Apr 25 16:38:01 2022: Epoch [5], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.275, Top5: 99.8057, Loss: 0.176\n",
            "Mon Apr 25 16:38:09 2022: Epoch [5], Iteration [300/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.285, Top5: 99.7872, Loss: 0.172\n",
            "Mon Apr 25 16:38:16 2022: Epoch [6], Iteration [0/391/], Data(s): 0.051, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 91.406, Top5: 99.2188, Loss: 0.174\n",
            "Mon Apr 25 16:38:24 2022: Epoch [6], Iteration [100/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.059, Top5: 99.8221, Loss: 0.173\n",
            "Mon Apr 25 16:38:33 2022: Epoch [6], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.096, Top5: 99.8212, Loss: 0.174\n",
            "Mon Apr 25 16:38:41 2022: Epoch [6], Iteration [300/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.150, Top5: 99.7975, Loss: 0.175\n",
            "Mon Apr 25 16:38:48 2022: Epoch [7], Iteration [0/391/], Data(s): 0.055, Loss(s): 0.011, Forward(s): 0.004, Backward(s): 0.006, Top1: 96.875, Top5: 100.0000, Loss: 0.165\n",
            "Mon Apr 25 16:38:56 2022: Epoch [7], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.740, Top5: 99.7989, Loss: 0.165\n",
            "Mon Apr 25 16:39:04 2022: Epoch [7], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.376, Top5: 99.7979, Loss: 0.180\n",
            "Mon Apr 25 16:39:13 2022: Epoch [7], Iteration [300/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.487, Top5: 99.8079, Loss: 0.169\n",
            "Mon Apr 25 16:39:20 2022: Epoch [8], Iteration [0/391/], Data(s): 0.052, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.188, Top5: 100.0000, Loss: 0.170\n",
            "Mon Apr 25 16:39:28 2022: Epoch [8], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.299, Top5: 99.8298, Loss: 0.168\n",
            "Mon Apr 25 16:39:36 2022: Epoch [8], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.314, Top5: 99.8212, Loss: 0.169\n",
            "Mon Apr 25 16:39:44 2022: Epoch [8], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.246, Top5: 99.8209, Loss: 0.172\n",
            "Mon Apr 25 16:39:52 2022: Epoch [9], Iteration [0/391/], Data(s): 0.053, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.312, Top5: 100.0000, Loss: 0.163\n",
            "Mon Apr 25 16:40:00 2022: Epoch [9], Iteration [100/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.369, Top5: 99.8685, Loss: 0.165\n",
            "Mon Apr 25 16:40:08 2022: Epoch [9], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.609, Top5: 99.8251, Loss: 0.158\n",
            "Mon Apr 25 16:40:16 2022: Epoch [9], Iteration [300/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.552, Top5: 99.7924, Loss: 0.172\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 16:40:26 2022: Test information, Data(s): 1.631, Forward(s): 0.254, Top1: 91.020, Top5: 99.310, \n",
            "\n",
            "Mon Apr 25 16:40:26 2022: conv13 Layer, 262 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 250, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(250, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=250, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]          73,856\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "             ReLU-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]         147,584\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         295,168\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]       1,180,160\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 250, 2, 2]       1,152,250\n",
            "      BatchNorm2d-42            [-1, 250, 2, 2]             500\n",
            "             ReLU-43            [-1, 250, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 250, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         128,512\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 13,649,720\n",
            "Trainable params: 13,649,720\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 6.55\n",
            "Params size (MB): 52.07\n",
            "Estimated Total Size (MB): 58.63\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 250, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(250, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=250, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 16:40:27 2022: Epoch [0], Iteration [0/391/], Data(s): 0.046, Loss(s): 0.000, Forward(s): 0.044, Backward(s): 0.072, Top1: 92.188, Top5: 100.0000, Loss: 0.200\n",
            "Mon Apr 25 16:40:36 2022: Epoch [0], Iteration [100/391/], Data(s): 0.036, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.624, Top5: 99.7525, Loss: 0.163\n",
            "Mon Apr 25 16:40:44 2022: Epoch [0], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.609, Top5: 99.8057, Loss: 0.161\n",
            "Mon Apr 25 16:40:52 2022: Epoch [0], Iteration [300/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.599, Top5: 99.7975, Loss: 0.165\n",
            "Mon Apr 25 16:40:59 2022: Epoch [1], Iteration [0/391/], Data(s): 0.052, Loss(s): 0.010, Forward(s): 0.004, Backward(s): 0.006, Top1: 94.531, Top5: 100.0000, Loss: 0.166\n",
            "Mon Apr 25 16:41:07 2022: Epoch [1], Iteration [100/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.879, Top5: 99.7525, Loss: 0.159\n",
            "Mon Apr 25 16:41:15 2022: Epoch [1], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.663, Top5: 99.7590, Loss: 0.169\n",
            "Mon Apr 25 16:41:23 2022: Epoch [1], Iteration [300/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.788, Top5: 99.7898, Loss: 0.154\n",
            "Mon Apr 25 16:41:31 2022: Epoch [2], Iteration [0/391/], Data(s): 0.068, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.188, Top5: 100.0000, Loss: 0.151\n",
            "Mon Apr 25 16:41:39 2022: Epoch [2], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.779, Top5: 99.8066, Loss: 0.153\n",
            "Mon Apr 25 16:41:47 2022: Epoch [2], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.873, Top5: 99.8484, Loss: 0.155\n",
            "Mon Apr 25 16:41:55 2022: Epoch [2], Iteration [300/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.812, Top5: 99.8339, Loss: 0.162\n",
            "Mon Apr 25 16:42:02 2022: Epoch [3], Iteration [0/391/], Data(s): 0.060, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.094, Top5: 98.4375, Loss: 0.166\n",
            "Mon Apr 25 16:42:10 2022: Epoch [3], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.817, Top5: 99.7525, Loss: 0.156\n",
            "Mon Apr 25 16:42:18 2022: Epoch [3], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.768, Top5: 99.8368, Loss: 0.157\n",
            "Mon Apr 25 16:42:26 2022: Epoch [3], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.754, Top5: 99.8365, Loss: 0.154\n",
            "Mon Apr 25 16:42:33 2022: Epoch [4], Iteration [0/391/], Data(s): 0.053, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.531, Top5: 100.0000, Loss: 0.157\n",
            "Mon Apr 25 16:42:41 2022: Epoch [4], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.524, Top5: 99.7757, Loss: 0.161\n",
            "Mon Apr 25 16:42:49 2022: Epoch [4], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.648, Top5: 99.8057, Loss: 0.158\n",
            "Mon Apr 25 16:42:57 2022: Epoch [4], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.793, Top5: 99.8001, Loss: 0.151\n",
            "Mon Apr 25 16:43:04 2022: Epoch [5], Iteration [0/391/], Data(s): 0.051, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.969, Top5: 99.2188, Loss: 0.153\n",
            "Mon Apr 25 16:43:12 2022: Epoch [5], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.856, Top5: 99.8685, Loss: 0.151\n",
            "Mon Apr 25 16:43:20 2022: Epoch [5], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.862, Top5: 99.8562, Loss: 0.154\n",
            "Mon Apr 25 16:43:28 2022: Epoch [5], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.926, Top5: 99.8547, Loss: 0.154\n",
            "Mon Apr 25 16:43:36 2022: Epoch [6], Iteration [0/391/], Data(s): 0.054, Loss(s): 0.010, Forward(s): 0.004, Backward(s): 0.006, Top1: 96.875, Top5: 100.0000, Loss: 0.153\n",
            "Mon Apr 25 16:43:44 2022: Epoch [6], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.980, Top5: 99.8840, Loss: 0.148\n",
            "Mon Apr 25 16:43:52 2022: Epoch [6], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.005, Top5: 99.8640, Loss: 0.147\n",
            "Mon Apr 25 16:44:00 2022: Epoch [6], Iteration [300/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.988, Top5: 99.8650, Loss: 0.151\n",
            "Mon Apr 25 16:44:07 2022: Epoch [7], Iteration [0/391/], Data(s): 0.053, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.750, Top5: 99.2188, Loss: 0.148\n",
            "Mon Apr 25 16:44:15 2022: Epoch [7], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.320, Top5: 99.8608, Loss: 0.147\n",
            "Mon Apr 25 16:44:23 2022: Epoch [7], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.161, Top5: 99.8756, Loss: 0.148\n",
            "Mon Apr 25 16:44:31 2022: Epoch [7], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.043, Top5: 99.8650, Loss: 0.153\n",
            "Mon Apr 25 16:44:38 2022: Epoch [8], Iteration [0/391/], Data(s): 0.049, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 98.438, Top5: 100.0000, Loss: 0.157\n",
            "Mon Apr 25 16:44:46 2022: Epoch [8], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.413, Top5: 99.8376, Loss: 0.144\n",
            "Mon Apr 25 16:44:54 2022: Epoch [8], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.262, Top5: 99.8406, Loss: 0.146\n",
            "Mon Apr 25 16:45:02 2022: Epoch [8], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.274, Top5: 99.8443, Loss: 0.140\n",
            "Mon Apr 25 16:45:10 2022: Epoch [9], Iteration [0/391/], Data(s): 0.056, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.007, Top1: 94.531, Top5: 100.0000, Loss: 0.150\n",
            "Mon Apr 25 16:45:18 2022: Epoch [9], Iteration [100/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.343, Top5: 99.7989, Loss: 0.142\n",
            "Mon Apr 25 16:45:25 2022: Epoch [9], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.215, Top5: 99.8173, Loss: 0.140\n",
            "Mon Apr 25 16:45:33 2022: Epoch [9], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.185, Top5: 99.8365, Loss: 0.146\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 16:45:44 2022: Test information, Data(s): 1.636, Forward(s): 0.247, Top1: 91.330, Top5: 99.250, \n",
            "\n",
            "Mon Apr 25 16:45:44 2022: conv13 Layer, 328 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=184, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]          73,856\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "             ReLU-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]         147,584\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         295,168\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]       1,180,160\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 184, 2, 2]         848,056\n",
            "      BatchNorm2d-42            [-1, 184, 2, 2]             368\n",
            "             ReLU-43            [-1, 184, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 184, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]          94,720\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 13,311,602\n",
            "Trainable params: 13,311,602\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 6.54\n",
            "Params size (MB): 50.78\n",
            "Estimated Total Size (MB): 57.33\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=184, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 16:45:45 2022: Epoch [0], Iteration [0/391/], Data(s): 0.036, Loss(s): 0.000, Forward(s): 0.038, Backward(s): 0.056, Top1: 89.844, Top5: 100.0000, Loss: 0.237\n",
            "Mon Apr 25 16:45:53 2022: Epoch [0], Iteration [100/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.390, Top5: 99.8762, Loss: 0.141\n",
            "Mon Apr 25 16:46:01 2022: Epoch [0], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.305, Top5: 99.8678, Loss: 0.146\n",
            "Mon Apr 25 16:46:09 2022: Epoch [0], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.372, Top5: 99.8547, Loss: 0.142\n",
            "Mon Apr 25 16:46:16 2022: Epoch [1], Iteration [0/391/], Data(s): 0.054, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.312, Top5: 100.0000, Loss: 0.144\n",
            "Mon Apr 25 16:46:24 2022: Epoch [1], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.514, Top5: 99.8685, Loss: 0.142\n",
            "Mon Apr 25 16:46:32 2022: Epoch [1], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.429, Top5: 99.8912, Loss: 0.137\n",
            "Mon Apr 25 16:46:40 2022: Epoch [1], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.284, Top5: 99.8806, Loss: 0.147\n",
            "Mon Apr 25 16:46:47 2022: Epoch [2], Iteration [0/391/], Data(s): 0.059, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 94.531, Top5: 100.0000, Loss: 0.142\n",
            "Mon Apr 25 16:46:55 2022: Epoch [2], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.289, Top5: 99.8608, Loss: 0.139\n",
            "Mon Apr 25 16:47:03 2022: Epoch [2], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.344, Top5: 99.8601, Loss: 0.140\n",
            "Mon Apr 25 16:47:11 2022: Epoch [2], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.455, Top5: 99.8495, Loss: 0.135\n",
            "Mon Apr 25 16:47:18 2022: Epoch [3], Iteration [0/391/], Data(s): 0.052, Loss(s): 0.010, Forward(s): 0.004, Backward(s): 0.006, Top1: 96.094, Top5: 98.4375, Loss: 0.137\n",
            "Mon Apr 25 16:47:26 2022: Epoch [3], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.637, Top5: 99.8994, Loss: 0.131\n",
            "Mon Apr 25 16:47:34 2022: Epoch [3], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.639, Top5: 99.8795, Loss: 0.130\n",
            "Mon Apr 25 16:47:42 2022: Epoch [3], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.489, Top5: 99.8650, Loss: 0.141\n",
            "Mon Apr 25 16:47:49 2022: Epoch [4], Iteration [0/391/], Data(s): 0.060, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 97.656, Top5: 100.0000, Loss: 0.139\n",
            "Mon Apr 25 16:47:57 2022: Epoch [4], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.676, Top5: 99.8840, Loss: 0.132\n",
            "Mon Apr 25 16:48:05 2022: Epoch [4], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.752, Top5: 99.9028, Loss: 0.130\n",
            "Mon Apr 25 16:48:13 2022: Epoch [4], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.619, Top5: 99.8780, Loss: 0.135\n",
            "Mon Apr 25 16:48:20 2022: Epoch [5], Iteration [0/391/], Data(s): 0.051, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 90.625, Top5: 100.0000, Loss: 0.143\n",
            "Mon Apr 25 16:48:28 2022: Epoch [5], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.560, Top5: 99.8917, Loss: 0.133\n",
            "Mon Apr 25 16:48:36 2022: Epoch [5], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.487, Top5: 99.8717, Loss: 0.136\n",
            "Mon Apr 25 16:48:44 2022: Epoch [5], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.549, Top5: 99.8780, Loss: 0.131\n",
            "Mon Apr 25 16:48:51 2022: Epoch [6], Iteration [0/391/], Data(s): 0.050, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.875, Top5: 100.0000, Loss: 0.133\n",
            "Mon Apr 25 16:48:59 2022: Epoch [6], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.568, Top5: 99.8685, Loss: 0.134\n",
            "Mon Apr 25 16:49:07 2022: Epoch [6], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.658, Top5: 99.8756, Loss: 0.127\n",
            "Mon Apr 25 16:49:15 2022: Epoch [6], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.694, Top5: 99.8884, Loss: 0.130\n",
            "Mon Apr 25 16:49:22 2022: Epoch [7], Iteration [0/391/], Data(s): 0.051, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.094, Top5: 100.0000, Loss: 0.141\n",
            "Mon Apr 25 16:49:30 2022: Epoch [7], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.931, Top5: 99.8685, Loss: 0.126\n",
            "Mon Apr 25 16:49:38 2022: Epoch [7], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.903, Top5: 99.8989, Loss: 0.123\n",
            "Mon Apr 25 16:49:45 2022: Epoch [7], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.712, Top5: 99.8884, Loss: 0.135\n",
            "Mon Apr 25 16:49:53 2022: Epoch [8], Iteration [0/391/], Data(s): 0.051, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.094, Top5: 100.0000, Loss: 0.131\n",
            "Mon Apr 25 16:50:01 2022: Epoch [8], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.869, Top5: 99.8840, Loss: 0.122\n",
            "Mon Apr 25 16:50:09 2022: Epoch [8], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.814, Top5: 99.8523, Loss: 0.133\n",
            "Mon Apr 25 16:50:16 2022: Epoch [8], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.860, Top5: 99.8624, Loss: 0.122\n",
            "Mon Apr 25 16:50:24 2022: Epoch [9], Iteration [0/391/], Data(s): 0.055, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 92.969, Top5: 100.0000, Loss: 0.127\n",
            "Mon Apr 25 16:50:31 2022: Epoch [9], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.869, Top5: 99.8840, Loss: 0.125\n",
            "Mon Apr 25 16:50:39 2022: Epoch [9], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.888, Top5: 99.9028, Loss: 0.123\n",
            "Mon Apr 25 16:50:47 2022: Epoch [9], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.943, Top5: 99.8858, Loss: 0.121\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 16:50:57 2022: Test information, Data(s): 1.609, Forward(s): 0.241, Top1: 91.370, Top5: 99.300, \n",
            "\n",
            "Mon Apr 25 16:50:57 2022: conv13 Layer, 394 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 118, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(118, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=118, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]          73,856\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "             ReLU-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]         147,584\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         295,168\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]       1,180,160\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 118, 2, 2]         543,862\n",
            "      BatchNorm2d-42            [-1, 118, 2, 2]             236\n",
            "             ReLU-43            [-1, 118, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 118, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]          60,928\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 12,973,484\n",
            "Trainable params: 12,973,484\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 6.54\n",
            "Params size (MB): 49.49\n",
            "Estimated Total Size (MB): 56.04\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 118, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(118, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=118, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 16:50:59 2022: Epoch [0], Iteration [0/391/], Data(s): 0.035, Loss(s): 0.000, Forward(s): 0.032, Backward(s): 0.055, Top1: 94.531, Top5: 100.0000, Loss: 0.154\n",
            "Mon Apr 25 16:51:06 2022: Epoch [0], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.931, Top5: 99.8840, Loss: 0.122\n",
            "Mon Apr 25 16:51:14 2022: Epoch [0], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.032, Top5: 99.9106, Loss: 0.117\n",
            "Mon Apr 25 16:51:22 2022: Epoch [0], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.031, Top5: 99.8858, Loss: 0.124\n",
            "Mon Apr 25 16:51:29 2022: Epoch [1], Iteration [0/391/], Data(s): 0.049, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 98.438, Top5: 100.0000, Loss: 0.127\n",
            "Mon Apr 25 16:51:37 2022: Epoch [1], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.163, Top5: 99.8762, Loss: 0.115\n",
            "Mon Apr 25 16:51:45 2022: Epoch [1], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.942, Top5: 99.9067, Loss: 0.125\n",
            "Mon Apr 25 16:51:53 2022: Epoch [1], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.951, Top5: 99.9066, Loss: 0.123\n",
            "Mon Apr 25 16:52:00 2022: Epoch [2], Iteration [0/391/], Data(s): 0.053, Loss(s): 0.010, Forward(s): 0.004, Backward(s): 0.006, Top1: 96.875, Top5: 100.0000, Loss: 0.118\n",
            "Mon Apr 25 16:52:08 2022: Epoch [2], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.924, Top5: 99.9459, Loss: 0.117\n",
            "Mon Apr 25 16:52:16 2022: Epoch [2], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.148, Top5: 99.9339, Loss: 0.114\n",
            "Mon Apr 25 16:52:24 2022: Epoch [2], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.034, Top5: 99.9143, Loss: 0.127\n",
            "Mon Apr 25 16:52:31 2022: Epoch [3], Iteration [0/391/], Data(s): 0.057, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 97.656, Top5: 100.0000, Loss: 0.113\n",
            "Mon Apr 25 16:52:39 2022: Epoch [3], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.287, Top5: 99.9381, Loss: 0.117\n",
            "Mon Apr 25 16:52:47 2022: Epoch [3], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.253, Top5: 99.8989, Loss: 0.113\n",
            "Mon Apr 25 16:52:55 2022: Epoch [3], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.179, Top5: 99.8988, Loss: 0.118\n",
            "Mon Apr 25 16:53:02 2022: Epoch [4], Iteration [0/391/], Data(s): 0.061, Loss(s): 0.010, Forward(s): 0.004, Backward(s): 0.006, Top1: 93.750, Top5: 100.0000, Loss: 0.123\n",
            "Mon Apr 25 16:53:11 2022: Epoch [4], Iteration [100/391/], Data(s): 0.038, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.380, Top5: 99.8762, Loss: 0.113\n",
            "Mon Apr 25 16:53:19 2022: Epoch [4], Iteration [200/391/], Data(s): 0.039, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.374, Top5: 99.8717, Loss: 0.114\n",
            "Mon Apr 25 16:53:28 2022: Epoch [4], Iteration [300/391/], Data(s): 0.039, Loss(s): 0.011, Forward(s): 0.004, Backward(s): 0.006, Top1: 96.416, Top5: 99.8806, Loss: 0.108\n",
            "Mon Apr 25 16:53:36 2022: Epoch [5], Iteration [0/391/], Data(s): 0.058, Loss(s): 0.010, Forward(s): 0.004, Backward(s): 0.006, Top1: 95.312, Top5: 100.0000, Loss: 0.118\n",
            "Mon Apr 25 16:53:44 2022: Epoch [5], Iteration [100/391/], Data(s): 0.037, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.047, Top5: 99.8917, Loss: 0.116\n",
            "Mon Apr 25 16:53:52 2022: Epoch [5], Iteration [200/391/], Data(s): 0.036, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.012, Top5: 99.8951, Loss: 0.116\n",
            "Mon Apr 25 16:54:00 2022: Epoch [5], Iteration [300/391/], Data(s): 0.036, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.104, Top5: 99.8910, Loss: 0.113\n",
            "Mon Apr 25 16:54:07 2022: Epoch [6], Iteration [0/391/], Data(s): 0.053, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.875, Top5: 99.2188, Loss: 0.114\n",
            "Mon Apr 25 16:54:15 2022: Epoch [6], Iteration [100/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.256, Top5: 99.9149, Loss: 0.108\n",
            "Mon Apr 25 16:54:23 2022: Epoch [6], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.323, Top5: 99.8873, Loss: 0.112\n",
            "Mon Apr 25 16:54:31 2022: Epoch [6], Iteration [300/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.333, Top5: 99.9066, Loss: 0.111\n",
            "Mon Apr 25 16:54:39 2022: Epoch [7], Iteration [0/391/], Data(s): 0.052, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 95.312, Top5: 100.0000, Loss: 0.106\n",
            "Mon Apr 25 16:54:46 2022: Epoch [7], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.434, Top5: 99.9613, Loss: 0.107\n",
            "Mon Apr 25 16:54:55 2022: Epoch [7], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.514, Top5: 99.9300, Loss: 0.105\n",
            "Mon Apr 25 16:55:03 2022: Epoch [7], Iteration [300/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.478, Top5: 99.9325, Loss: 0.110\n",
            "Mon Apr 25 16:55:10 2022: Epoch [8], Iteration [0/391/], Data(s): 0.054, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 97.656, Top5: 100.0000, Loss: 0.113\n",
            "Mon Apr 25 16:55:18 2022: Epoch [8], Iteration [100/391/], Data(s): 0.037, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.442, Top5: 99.9381, Loss: 0.103\n",
            "Mon Apr 25 16:55:26 2022: Epoch [8], Iteration [200/391/], Data(s): 0.036, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.397, Top5: 99.9456, Loss: 0.110\n",
            "Mon Apr 25 16:55:34 2022: Epoch [8], Iteration [300/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.371, Top5: 99.9377, Loss: 0.105\n",
            "Mon Apr 25 16:55:41 2022: Epoch [9], Iteration [0/391/], Data(s): 0.052, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.094, Top5: 100.0000, Loss: 0.110\n",
            "Mon Apr 25 16:55:49 2022: Epoch [9], Iteration [100/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.651, Top5: 99.9304, Loss: 0.101\n",
            "Mon Apr 25 16:55:57 2022: Epoch [9], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.638, Top5: 99.9145, Loss: 0.106\n",
            "Mon Apr 25 16:56:05 2022: Epoch [9], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.512, Top5: 99.9195, Loss: 0.109\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 16:56:15 2022: Test information, Data(s): 1.603, Forward(s): 0.238, Top1: 91.470, Top5: 99.250, \n",
            "\n",
            "Mon Apr 25 16:56:15 2022: conv13 Layer, 460 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 52, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=52, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]          73,856\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "             ReLU-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]         147,584\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         295,168\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]       1,180,160\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41             [-1, 52, 2, 2]         239,668\n",
            "      BatchNorm2d-42             [-1, 52, 2, 2]             104\n",
            "             ReLU-43             [-1, 52, 2, 2]               0\n",
            "        MaxPool2d-44             [-1, 52, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]          27,136\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 12,635,366\n",
            "Trainable params: 12,635,366\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 6.53\n",
            "Params size (MB): 48.20\n",
            "Estimated Total Size (MB): 54.74\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 52, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=52, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 16:56:16 2022: Epoch [0], Iteration [0/391/], Data(s): 0.036, Loss(s): 0.000, Forward(s): 0.026, Backward(s): 0.025, Top1: 96.094, Top5: 100.0000, Loss: 0.118\n",
            "Mon Apr 25 16:56:24 2022: Epoch [0], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.643, Top5: 99.9613, Loss: 0.110\n",
            "Mon Apr 25 16:56:32 2022: Epoch [0], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.428, Top5: 99.8989, Loss: 0.117\n",
            "Mon Apr 25 16:56:40 2022: Epoch [0], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.465, Top5: 99.9014, Loss: 0.105\n",
            "Mon Apr 25 16:56:47 2022: Epoch [1], Iteration [0/391/], Data(s): 0.053, Loss(s): 0.009, Forward(s): 0.004, Backward(s): 0.006, Top1: 94.531, Top5: 100.0000, Loss: 0.105\n",
            "Mon Apr 25 16:56:55 2022: Epoch [1], Iteration [100/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.852, Top5: 99.9613, Loss: 0.097\n",
            "Mon Apr 25 16:57:03 2022: Epoch [1], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.622, Top5: 99.9534, Loss: 0.109\n",
            "Mon Apr 25 16:57:11 2022: Epoch [1], Iteration [300/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.683, Top5: 99.9377, Loss: 0.097\n",
            "Mon Apr 25 16:57:18 2022: Epoch [2], Iteration [0/391/], Data(s): 0.050, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 97.656, Top5: 100.0000, Loss: 0.099\n",
            "Mon Apr 25 16:57:26 2022: Epoch [2], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.805, Top5: 99.9072, Loss: 0.099\n",
            "Mon Apr 25 16:57:34 2022: Epoch [2], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.840, Top5: 99.9145, Loss: 0.099\n",
            "Mon Apr 25 16:57:41 2022: Epoch [2], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.719, Top5: 99.9195, Loss: 0.105\n",
            "Mon Apr 25 16:57:49 2022: Epoch [3], Iteration [0/391/], Data(s): 0.052, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 93.750, Top5: 100.0000, Loss: 0.103\n",
            "Mon Apr 25 16:57:56 2022: Epoch [3], Iteration [100/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.341, Top5: 99.9613, Loss: 0.103\n",
            "Mon Apr 25 16:58:04 2022: Epoch [3], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.580, Top5: 99.9495, Loss: 0.096\n",
            "Mon Apr 25 16:58:12 2022: Epoch [3], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.706, Top5: 99.9533, Loss: 0.098\n",
            "Mon Apr 25 16:58:19 2022: Epoch [4], Iteration [0/391/], Data(s): 0.053, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 99.219, Top5: 100.0000, Loss: 0.096\n",
            "Mon Apr 25 16:58:27 2022: Epoch [4], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.836, Top5: 99.9459, Loss: 0.100\n",
            "Mon Apr 25 16:58:35 2022: Epoch [4], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.758, Top5: 99.9378, Loss: 0.097\n",
            "Mon Apr 25 16:58:43 2022: Epoch [4], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.758, Top5: 99.9325, Loss: 0.098\n",
            "Mon Apr 25 16:58:50 2022: Epoch [5], Iteration [0/391/], Data(s): 0.056, Loss(s): 0.010, Forward(s): 0.004, Backward(s): 0.006, Top1: 93.750, Top5: 99.2188, Loss: 0.096\n",
            "Mon Apr 25 16:58:58 2022: Epoch [5], Iteration [100/391/], Data(s): 0.033, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.759, Top5: 99.9304, Loss: 0.096\n",
            "Mon Apr 25 16:59:06 2022: Epoch [5], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.836, Top5: 99.9223, Loss: 0.095\n",
            "Mon Apr 25 16:59:14 2022: Epoch [5], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.849, Top5: 99.9299, Loss: 0.096\n",
            "Mon Apr 25 16:59:21 2022: Epoch [6], Iteration [0/391/], Data(s): 0.061, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 98.438, Top5: 100.0000, Loss: 0.095\n",
            "Mon Apr 25 16:59:29 2022: Epoch [6], Iteration [100/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.852, Top5: 99.9226, Loss: 0.091\n",
            "Mon Apr 25 16:59:37 2022: Epoch [6], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.988, Top5: 99.9300, Loss: 0.090\n",
            "Mon Apr 25 16:59:45 2022: Epoch [6], Iteration [300/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.963, Top5: 99.9351, Loss: 0.094\n",
            "Mon Apr 25 16:59:52 2022: Epoch [7], Iteration [0/391/], Data(s): 0.055, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.009, Top1: 96.875, Top5: 100.0000, Loss: 0.096\n",
            "Mon Apr 25 17:00:00 2022: Epoch [7], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.689, Top5: 99.9226, Loss: 0.095\n",
            "Mon Apr 25 17:00:08 2022: Epoch [7], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.891, Top5: 99.9378, Loss: 0.089\n",
            "Mon Apr 25 17:00:16 2022: Epoch [7], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 96.885, Top5: 99.9429, Loss: 0.092\n",
            "Mon Apr 25 17:00:23 2022: Epoch [8], Iteration [0/391/], Data(s): 0.054, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.006, Top1: 98.438, Top5: 100.0000, Loss: 0.096\n",
            "Mon Apr 25 17:00:31 2022: Epoch [8], Iteration [100/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 97.014, Top5: 99.9768, Loss: 0.089\n",
            "Mon Apr 25 17:00:39 2022: Epoch [8], Iteration [200/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 97.015, Top5: 99.9650, Loss: 0.090\n",
            "Mon Apr 25 17:00:46 2022: Epoch [8], Iteration [300/391/], Data(s): 0.034, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 97.020, Top5: 99.9585, Loss: 0.088\n",
            "Mon Apr 25 17:00:54 2022: Epoch [9], Iteration [0/391/], Data(s): 0.060, Loss(s): 0.010, Forward(s): 0.003, Backward(s): 0.007, Top1: 97.656, Top5: 100.0000, Loss: 0.086\n",
            "Mon Apr 25 17:01:02 2022: Epoch [9], Iteration [100/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 97.300, Top5: 99.9304, Loss: 0.084\n",
            "Mon Apr 25 17:01:10 2022: Epoch [9], Iteration [200/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 97.236, Top5: 99.9534, Loss: 0.084\n",
            "Mon Apr 25 17:01:17 2022: Epoch [9], Iteration [300/391/], Data(s): 0.035, Loss(s): 0.011, Forward(s): 0.003, Backward(s): 0.006, Top1: 97.114, Top5: 99.9481, Loss: 0.094\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 17:01:27 2022: Test information, Data(s): 1.597, Forward(s): 0.228, Top1: 91.440, Top5: 99.360, \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top1_accuracies"
      ],
      "metadata": {
        "id": "YjU6tuVaBeeF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5859605-df32-46d0-be2d-674419abf125"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'conv11': [89.84, 90.73, 91.1, 91.27, 91.17, 91.28, 91.14],\n",
              " 'conv12': [89.88, 90.67, 91.07, 91.28, 91.41, 91.37, 91.2],\n",
              " 'conv13': [90.08, 90.66, 91.02, 91.33, 91.37, 91.47, 91.44],\n",
              " 'conv4': [90.06, 90.46, 90.86, 90.61, 90.41, 90.21, 88.37]}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top5_accuracies"
      ],
      "metadata": {
        "id": "HnCYpQs1BeeF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8dd964f0-7920-41e2-9a3e-1c33b8ae429d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'conv11': [99.27, 99.31, 99.27, 99.3, 99.26, 99.23, 99.24],\n",
              " 'conv12': [99.33, 99.31, 99.32, 99.34, 99.25, 99.26, 99.32],\n",
              " 'conv13': [99.31, 99.32, 99.31, 99.25, 99.3, 99.25, 99.36],\n",
              " 'conv4': [99.23, 99.29, 99.32, 99.33, 99.26, 99.38, 99.32]}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "qZn7Fpo3qXX6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top1_accuracies = {}\n",
        "top5_accuracies = {}"
      ],
      "metadata": {
        "id": "LWlEoRU0rQ1l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for conv, channel in zip(prune_layers[1:2], prune_channels[1:2]):    \n",
        "    top1_accuracies[conv] = []\n",
        "    top5_accuracies[conv] = []\n",
        "    \n",
        "    # load new network and check accuracy\n",
        "    network, _, _ = test_network(args, data_set=test_set)\n",
        "        \n",
        "    # remove 0 channels ~ M (max_channel_ratio) % of total channels\n",
        "    step = np.linspace(0, int(channel*max_channel_ratio), int(1/prune_step_ratio), dtype=np.int)\n",
        "    steps = (step[1:] - step[:-1]).tolist()\n",
        "    \n",
        "    for i in range(len(steps)):\n",
        "        print(\"\\n%s: %s Layer, %d Channels pruned\"%(time.ctime(), conv, sum(steps[:i+1])))\n",
        "        \n",
        "        # set prune information\n",
        "        args.prune_layers = [conv]\n",
        "        args.prune_channels =[steps[i]]\n",
        "\n",
        "        network = prune_network(args, network)\n",
        "        \n",
        "        network, _, (top1, top5) = test_network(args, network, test_set)\n",
        "            \n",
        "        top1_accuracies[conv].append(top1)\n",
        "        top5_accuracies[conv].append(top5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cefc0039-6681-4c58-9069-2ff2604d083c",
        "id": "uthnAm14qXoj"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 17:08:52 2022: Test information, Data(s): 2.465, Forward(s): 0.465, Top1: 77.870, Top5: 97.560, \n",
            "\n",
            "Mon Apr 25 17:08:52 2022: conv2 Layer, 8 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 56, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(56, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 56, 32, 32]          32,312\n",
            "       BatchNorm2d-5           [-1, 56, 32, 32]             112\n",
            "              ReLU-6           [-1, 56, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 56, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]          64,640\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "             ReLU-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]         147,584\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         295,168\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]       1,180,160\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 14,978,098\n",
            "Trainable params: 14,978,098\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 6.37\n",
            "Params size (MB): 57.14\n",
            "Estimated Total Size (MB): 63.52\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 56, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(56, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  if __name__ == '__main__':\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 17:08:54 2022: Epoch [0], Iteration [0/391/], Data(s): 0.050, Loss(s): 0.009, Forward(s): 0.206, Backward(s): 0.396, Top1: 84.375, Top5: 97.6562, Loss: 0.547\n",
            "Mon Apr 25 17:09:10 2022: Epoch [0], Iteration [100/391/], Data(s): 0.049, Loss(s): 0.028, Forward(s): 0.008, Backward(s): 0.016, Top1: 87.314, Top5: 98.7469, Loss: 0.397\n",
            "Mon Apr 25 17:09:26 2022: Epoch [0], Iteration [200/391/], Data(s): 0.049, Loss(s): 0.029, Forward(s): 0.007, Backward(s): 0.014, Top1: 88.036, Top5: 98.9506, Loss: 0.356\n",
            "Mon Apr 25 17:09:42 2022: Epoch [0], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.029, Forward(s): 0.006, Backward(s): 0.013, Top1: 88.541, Top5: 99.0293, Loss: 0.330\n",
            "Mon Apr 25 17:09:57 2022: Epoch [1], Iteration [0/391/], Data(s): 0.077, Loss(s): 0.029, Forward(s): 0.007, Backward(s): 0.012, Top1: 91.406, Top5: 100.0000, Loss: 0.326\n",
            "Mon Apr 25 17:10:13 2022: Epoch [1], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 90.161, Top5: 99.2729, Loss: 0.309\n",
            "Mon Apr 25 17:10:29 2022: Epoch [1], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 90.400, Top5: 99.3587, Loss: 0.295\n",
            "Mon Apr 25 17:10:45 2022: Epoch [1], Iteration [300/391/], Data(s): 0.051, Loss(s): 0.029, Forward(s): 0.006, Backward(s): 0.012, Top1: 90.329, Top5: 99.4108, Loss: 0.301\n",
            "Mon Apr 25 17:11:00 2022: Epoch [2], Iteration [0/391/], Data(s): 0.076, Loss(s): 0.029, Forward(s): 0.006, Backward(s): 0.012, Top1: 87.500, Top5: 100.0000, Loss: 0.295\n",
            "Mon Apr 25 17:11:16 2022: Epoch [2], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.029, Forward(s): 0.006, Backward(s): 0.012, Top1: 90.687, Top5: 99.4508, Loss: 0.282\n",
            "Mon Apr 25 17:11:32 2022: Epoch [2], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.029, Forward(s): 0.006, Backward(s): 0.012, Top1: 90.804, Top5: 99.4403, Loss: 0.285\n",
            "Mon Apr 25 17:11:48 2022: Epoch [2], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.029, Forward(s): 0.006, Backward(s): 0.012, Top1: 90.934, Top5: 99.4498, Loss: 0.277\n",
            "Mon Apr 25 17:12:03 2022: Epoch [3], Iteration [0/391/], Data(s): 0.073, Loss(s): 0.029, Forward(s): 0.006, Backward(s): 0.011, Top1: 93.750, Top5: 99.2188, Loss: 0.272\n",
            "Mon Apr 25 17:12:19 2022: Epoch [3], Iteration [100/391/], Data(s): 0.053, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 91.406, Top5: 99.5127, Loss: 0.268\n",
            "Mon Apr 25 17:12:35 2022: Epoch [3], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 91.220, Top5: 99.5103, Loss: 0.273\n",
            "Mon Apr 25 17:12:51 2022: Epoch [3], Iteration [300/391/], Data(s): 0.051, Loss(s): 0.029, Forward(s): 0.006, Backward(s): 0.012, Top1: 91.271, Top5: 99.5380, Loss: 0.264\n",
            "Mon Apr 25 17:13:05 2022: Epoch [4], Iteration [0/391/], Data(s): 0.077, Loss(s): 0.029, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.969, Top5: 99.2188, Loss: 0.265\n",
            "Mon Apr 25 17:13:21 2022: Epoch [4], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.029, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.164, Top5: 99.5591, Loss: 0.244\n",
            "Mon Apr 25 17:13:37 2022: Epoch [4], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.029, Forward(s): 0.006, Backward(s): 0.012, Top1: 91.756, Top5: 99.5452, Loss: 0.262\n",
            "Mon Apr 25 17:13:53 2022: Epoch [4], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.029, Forward(s): 0.006, Backward(s): 0.012, Top1: 91.816, Top5: 99.5172, Loss: 0.253\n",
            "Mon Apr 25 17:14:08 2022: Epoch [5], Iteration [0/391/], Data(s): 0.085, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.312, Top5: 100.0000, Loss: 0.253\n",
            "Mon Apr 25 17:14:24 2022: Epoch [5], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 91.592, Top5: 99.6364, Loss: 0.251\n",
            "Mon Apr 25 17:14:40 2022: Epoch [5], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 91.686, Top5: 99.5841, Loss: 0.254\n",
            "Mon Apr 25 17:14:56 2022: Epoch [5], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.029, Forward(s): 0.006, Backward(s): 0.012, Top1: 91.801, Top5: 99.5691, Loss: 0.245\n",
            "Mon Apr 25 17:15:11 2022: Epoch [6], Iteration [0/391/], Data(s): 0.092, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.094, Top5: 100.0000, Loss: 0.250\n",
            "Mon Apr 25 17:15:27 2022: Epoch [6], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.029, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.157, Top5: 99.6132, Loss: 0.244\n",
            "Mon Apr 25 17:15:43 2022: Epoch [6], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.029, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.355, Top5: 99.6385, Loss: 0.229\n",
            "Mon Apr 25 17:15:59 2022: Epoch [6], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.029, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.224, Top5: 99.6444, Loss: 0.243\n",
            "Mon Apr 25 17:16:13 2022: Epoch [7], Iteration [0/391/], Data(s): 0.074, Loss(s): 0.029, Forward(s): 0.006, Backward(s): 0.012, Top1: 90.625, Top5: 100.0000, Loss: 0.243\n",
            "Mon Apr 25 17:16:29 2022: Epoch [7], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.029, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.234, Top5: 99.5050, Loss: 0.244\n",
            "Mon Apr 25 17:16:45 2022: Epoch [7], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.029, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.561, Top5: 99.5569, Loss: 0.224\n",
            "Mon Apr 25 17:17:01 2022: Epoch [7], Iteration [300/391/], Data(s): 0.051, Loss(s): 0.029, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.460, Top5: 99.5562, Loss: 0.238\n",
            "Mon Apr 25 17:17:16 2022: Epoch [8], Iteration [0/391/], Data(s): 0.071, Loss(s): 0.029, Forward(s): 0.005, Backward(s): 0.012, Top1: 91.406, Top5: 99.2188, Loss: 0.230\n",
            "Mon Apr 25 17:17:32 2022: Epoch [8], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.613, Top5: 99.5823, Loss: 0.229\n",
            "Mon Apr 25 17:17:48 2022: Epoch [8], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.029, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.565, Top5: 99.6035, Loss: 0.226\n",
            "Mon Apr 25 17:18:04 2022: Epoch [8], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.029, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.450, Top5: 99.5925, Loss: 0.236\n",
            "Mon Apr 25 17:18:19 2022: Epoch [9], Iteration [0/391/], Data(s): 0.078, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 86.719, Top5: 98.4375, Loss: 0.226\n",
            "Mon Apr 25 17:18:35 2022: Epoch [9], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.029, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.845, Top5: 99.6519, Loss: 0.222\n",
            "Mon Apr 25 17:18:51 2022: Epoch [9], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.029, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.852, Top5: 99.6269, Loss: 0.222\n",
            "Mon Apr 25 17:19:07 2022: Epoch [9], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.029, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.849, Top5: 99.6470, Loss: 0.216\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 17:19:27 2022: Test information, Data(s): 2.423, Forward(s): 0.572, Top1: 90.050, Top5: 99.280, \n",
            "\n",
            "Mon Apr 25 17:19:27 2022: conv2 Layer, 16 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(48, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 48, 32, 32]          27,696\n",
            "       BatchNorm2d-5           [-1, 48, 32, 32]              96\n",
            "              ReLU-6           [-1, 48, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 48, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]          55,424\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "             ReLU-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]         147,584\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         295,168\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]       1,180,160\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 14,964,250\n",
            "Trainable params: 14,964,250\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 6.17\n",
            "Params size (MB): 57.08\n",
            "Estimated Total Size (MB): 63.26\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(48, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 17:19:29 2022: Epoch [0], Iteration [0/391/], Data(s): 0.058, Loss(s): 0.003, Forward(s): 0.121, Backward(s): 0.231, Top1: 89.844, Top5: 98.4375, Loss: 0.261\n",
            "Mon Apr 25 17:19:45 2022: Epoch [0], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.014, Top1: 92.775, Top5: 99.6829, Loss: 0.216\n",
            "Mon Apr 25 17:20:01 2022: Epoch [0], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.013, Top1: 92.530, Top5: 99.6424, Loss: 0.236\n",
            "Mon Apr 25 17:20:17 2022: Epoch [0], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.507, Top5: 99.6444, Loss: 0.232\n",
            "Mon Apr 25 17:20:31 2022: Epoch [1], Iteration [0/391/], Data(s): 0.079, Loss(s): 0.029, Forward(s): 0.007, Backward(s): 0.011, Top1: 95.312, Top5: 100.0000, Loss: 0.225\n",
            "Mon Apr 25 17:20:47 2022: Epoch [1], Iteration [100/391/], Data(s): 0.052, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.760, Top5: 99.5900, Loss: 0.219\n",
            "Mon Apr 25 17:21:03 2022: Epoch [1], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.658, Top5: 99.6385, Loss: 0.228\n",
            "Mon Apr 25 17:21:19 2022: Epoch [1], Iteration [300/391/], Data(s): 0.051, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.673, Top5: 99.6548, Loss: 0.221\n",
            "Mon Apr 25 17:21:34 2022: Epoch [2], Iteration [0/391/], Data(s): 0.078, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.312, Top5: 100.0000, Loss: 0.217\n",
            "Mon Apr 25 17:21:50 2022: Epoch [2], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.822, Top5: 99.7602, Loss: 0.216\n",
            "Mon Apr 25 17:22:06 2022: Epoch [2], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.883, Top5: 99.6852, Loss: 0.218\n",
            "Mon Apr 25 17:22:22 2022: Epoch [2], Iteration [300/391/], Data(s): 0.051, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.935, Top5: 99.6574, Loss: 0.215\n",
            "Mon Apr 25 17:22:36 2022: Epoch [3], Iteration [0/391/], Data(s): 0.076, Loss(s): 0.028, Forward(s): 0.005, Backward(s): 0.012, Top1: 91.406, Top5: 100.0000, Loss: 0.213\n",
            "Mon Apr 25 17:22:52 2022: Epoch [3], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.969, Top5: 99.6983, Loss: 0.212\n",
            "Mon Apr 25 17:23:08 2022: Epoch [3], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.058, Top5: 99.6385, Loss: 0.209\n",
            "Mon Apr 25 17:23:23 2022: Epoch [3], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.011, Top1: 93.075, Top5: 99.6522, Loss: 0.213\n",
            "Mon Apr 25 17:23:38 2022: Epoch [4], Iteration [0/391/], Data(s): 0.070, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.011, Top1: 89.844, Top5: 98.4375, Loss: 0.219\n",
            "Mon Apr 25 17:23:54 2022: Epoch [4], Iteration [100/391/], Data(s): 0.050, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.969, Top5: 99.6519, Loss: 0.214\n",
            "Mon Apr 25 17:24:10 2022: Epoch [4], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.011, Top1: 93.148, Top5: 99.6502, Loss: 0.201\n",
            "Mon Apr 25 17:24:25 2022: Epoch [4], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.011, Top1: 93.135, Top5: 99.6937, Loss: 0.208\n",
            "Mon Apr 25 17:24:40 2022: Epoch [5], Iteration [0/391/], Data(s): 0.074, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.011, Top1: 89.844, Top5: 100.0000, Loss: 0.214\n",
            "Mon Apr 25 17:24:56 2022: Epoch [5], Iteration [100/391/], Data(s): 0.052, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.216, Top5: 99.6906, Loss: 0.203\n",
            "Mon Apr 25 17:25:12 2022: Epoch [5], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.252, Top5: 99.6774, Loss: 0.208\n",
            "Mon Apr 25 17:25:28 2022: Epoch [5], Iteration [300/391/], Data(s): 0.051, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.348, Top5: 99.6808, Loss: 0.202\n",
            "Mon Apr 25 17:25:42 2022: Epoch [6], Iteration [0/391/], Data(s): 0.079, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.010, Top1: 89.844, Top5: 100.0000, Loss: 0.200\n",
            "Mon Apr 25 17:25:58 2022: Epoch [6], Iteration [100/391/], Data(s): 0.050, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.301, Top5: 99.7215, Loss: 0.205\n",
            "Mon Apr 25 17:26:14 2022: Epoch [6], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.280, Top5: 99.6968, Loss: 0.200\n",
            "Mon Apr 25 17:26:30 2022: Epoch [6], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.314, Top5: 99.6808, Loss: 0.200\n",
            "Mon Apr 25 17:26:44 2022: Epoch [7], Iteration [0/391/], Data(s): 0.090, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.010, Top1: 95.312, Top5: 100.0000, Loss: 0.202\n",
            "Mon Apr 25 17:27:00 2022: Epoch [7], Iteration [100/391/], Data(s): 0.052, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.688, Top5: 99.7370, Loss: 0.194\n",
            "Mon Apr 25 17:27:16 2022: Epoch [7], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.011, Top1: 93.762, Top5: 99.7474, Loss: 0.192\n",
            "Mon Apr 25 17:27:32 2022: Epoch [7], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.011, Top1: 93.729, Top5: 99.7586, Loss: 0.196\n",
            "Mon Apr 25 17:27:46 2022: Epoch [8], Iteration [0/391/], Data(s): 0.076, Loss(s): 0.028, Forward(s): 0.005, Backward(s): 0.011, Top1: 91.406, Top5: 100.0000, Loss: 0.204\n",
            "Mon Apr 25 17:28:02 2022: Epoch [8], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.170, Top5: 99.7679, Loss: 0.205\n",
            "Mon Apr 25 17:28:18 2022: Epoch [8], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.326, Top5: 99.7474, Loss: 0.195\n",
            "Mon Apr 25 17:28:34 2022: Epoch [8], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.011, Top1: 93.384, Top5: 99.7327, Loss: 0.198\n",
            "Mon Apr 25 17:28:48 2022: Epoch [9], Iteration [0/391/], Data(s): 0.081, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.969, Top5: 99.2188, Loss: 0.194\n",
            "Mon Apr 25 17:29:04 2022: Epoch [9], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.549, Top5: 99.6364, Loss: 0.199\n",
            "Mon Apr 25 17:29:20 2022: Epoch [9], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.548, Top5: 99.6696, Loss: 0.195\n",
            "Mon Apr 25 17:29:36 2022: Epoch [9], Iteration [300/391/], Data(s): 0.051, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.654, Top5: 99.7119, Loss: 0.188\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 17:29:57 2022: Test information, Data(s): 2.519, Forward(s): 0.611, Top1: 90.570, Top5: 99.260, \n",
            "\n",
            "Mon Apr 25 17:29:57 2022: conv2 Layer, 24 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(40, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 40, 32, 32]          23,080\n",
            "       BatchNorm2d-5           [-1, 40, 32, 32]              80\n",
            "              ReLU-6           [-1, 40, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 40, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]          46,208\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "             ReLU-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]         147,584\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         295,168\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]       1,180,160\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 14,950,402\n",
            "Trainable params: 14,950,402\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 5.96\n",
            "Params size (MB): 57.03\n",
            "Estimated Total Size (MB): 63.01\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(40, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 17:29:58 2022: Epoch [0], Iteration [0/391/], Data(s): 0.058, Loss(s): 0.019, Forward(s): 0.090, Backward(s): 0.229, Top1: 92.188, Top5: 100.0000, Loss: 0.172\n",
            "Mon Apr 25 17:30:14 2022: Epoch [0], Iteration [100/391/], Data(s): 0.052, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.014, Top1: 93.123, Top5: 99.6829, Loss: 0.205\n",
            "Mon Apr 25 17:30:30 2022: Epoch [0], Iteration [200/391/], Data(s): 0.052, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 93.280, Top5: 99.6735, Loss: 0.201\n",
            "Mon Apr 25 17:30:46 2022: Epoch [0], Iteration [300/391/], Data(s): 0.052, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 93.259, Top5: 99.6859, Loss: 0.203\n",
            "Mon Apr 25 17:31:01 2022: Epoch [1], Iteration [0/391/], Data(s): 0.075, Loss(s): 0.029, Forward(s): 0.007, Backward(s): 0.016, Top1: 91.406, Top5: 99.2188, Loss: 0.209\n",
            "Mon Apr 25 17:31:17 2022: Epoch [1], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.719, Top5: 99.7061, Loss: 0.186\n",
            "Mon Apr 25 17:31:32 2022: Epoch [1], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.703, Top5: 99.7163, Loss: 0.193\n",
            "Mon Apr 25 17:31:48 2022: Epoch [1], Iteration [300/391/], Data(s): 0.051, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.628, Top5: 99.7145, Loss: 0.196\n",
            "Mon Apr 25 17:32:03 2022: Epoch [2], Iteration [0/391/], Data(s): 0.073, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.011, Top1: 90.625, Top5: 99.2188, Loss: 0.201\n",
            "Mon Apr 25 17:32:18 2022: Epoch [2], Iteration [100/391/], Data(s): 0.052, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.804, Top5: 99.7602, Loss: 0.191\n",
            "Mon Apr 25 17:32:34 2022: Epoch [2], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.715, Top5: 99.7435, Loss: 0.193\n",
            "Mon Apr 25 17:32:50 2022: Epoch [2], Iteration [300/391/], Data(s): 0.051, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.794, Top5: 99.7456, Loss: 0.184\n",
            "Mon Apr 25 17:33:04 2022: Epoch [3], Iteration [0/391/], Data(s): 0.075, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.188, Top5: 100.0000, Loss: 0.190\n",
            "Mon Apr 25 17:33:20 2022: Epoch [3], Iteration [100/391/], Data(s): 0.052, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.750, Top5: 99.7447, Loss: 0.191\n",
            "Mon Apr 25 17:33:36 2022: Epoch [3], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.929, Top5: 99.7901, Loss: 0.178\n",
            "Mon Apr 25 17:33:52 2022: Epoch [3], Iteration [300/391/], Data(s): 0.051, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.004, Top5: 99.7794, Loss: 0.186\n",
            "Mon Apr 25 17:34:06 2022: Epoch [4], Iteration [0/391/], Data(s): 0.077, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.011, Top1: 93.750, Top5: 100.0000, Loss: 0.191\n",
            "Mon Apr 25 17:34:22 2022: Epoch [4], Iteration [100/391/], Data(s): 0.052, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.974, Top5: 99.6983, Loss: 0.182\n",
            "Mon Apr 25 17:34:38 2022: Epoch [4], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.913, Top5: 99.7474, Loss: 0.181\n",
            "Mon Apr 25 17:34:54 2022: Epoch [4], Iteration [300/391/], Data(s): 0.051, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.841, Top5: 99.7586, Loss: 0.182\n",
            "Mon Apr 25 17:35:08 2022: Epoch [5], Iteration [0/391/], Data(s): 0.087, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.011, Top1: 95.312, Top5: 100.0000, Loss: 0.190\n",
            "Mon Apr 25 17:35:24 2022: Epoch [5], Iteration [100/391/], Data(s): 0.052, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.711, Top5: 99.7525, Loss: 0.187\n",
            "Mon Apr 25 17:35:40 2022: Epoch [5], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.964, Top5: 99.7124, Loss: 0.173\n",
            "Mon Apr 25 17:35:55 2022: Epoch [5], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.986, Top5: 99.7508, Loss: 0.177\n",
            "Mon Apr 25 17:36:10 2022: Epoch [6], Iteration [0/391/], Data(s): 0.074, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.312, Top5: 99.2188, Loss: 0.177\n",
            "Mon Apr 25 17:36:26 2022: Epoch [6], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.338, Top5: 99.7834, Loss: 0.174\n",
            "Mon Apr 25 17:36:41 2022: Epoch [6], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.415, Top5: 99.8212, Loss: 0.169\n",
            "Mon Apr 25 17:36:57 2022: Epoch [6], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.254, Top5: 99.7924, Loss: 0.184\n",
            "Mon Apr 25 17:37:11 2022: Epoch [7], Iteration [0/391/], Data(s): 0.085, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.011, Top1: 94.531, Top5: 100.0000, Loss: 0.176\n",
            "Mon Apr 25 17:37:27 2022: Epoch [7], Iteration [100/391/], Data(s): 0.052, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.732, Top5: 99.8298, Loss: 0.163\n",
            "Mon Apr 25 17:37:43 2022: Epoch [7], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.438, Top5: 99.8212, Loss: 0.174\n",
            "Mon Apr 25 17:37:59 2022: Epoch [7], Iteration [300/391/], Data(s): 0.051, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.414, Top5: 99.7846, Loss: 0.170\n",
            "Mon Apr 25 17:38:13 2022: Epoch [8], Iteration [0/391/], Data(s): 0.074, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.015, Top1: 92.969, Top5: 100.0000, Loss: 0.174\n",
            "Mon Apr 25 17:38:29 2022: Epoch [8], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.377, Top5: 99.8066, Loss: 0.168\n",
            "Mon Apr 25 17:38:45 2022: Epoch [8], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.442, Top5: 99.8057, Loss: 0.167\n",
            "Mon Apr 25 17:39:00 2022: Epoch [8], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.435, Top5: 99.7898, Loss: 0.171\n",
            "Mon Apr 25 17:39:15 2022: Epoch [9], Iteration [0/391/], Data(s): 0.077, Loss(s): 0.025, Forward(s): 0.008, Backward(s): 0.011, Top1: 92.969, Top5: 100.0000, Loss: 0.177\n",
            "Mon Apr 25 17:39:30 2022: Epoch [9], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.361, Top5: 99.8298, Loss: 0.170\n",
            "Mon Apr 25 17:39:46 2022: Epoch [9], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.520, Top5: 99.8018, Loss: 0.161\n",
            "Mon Apr 25 17:40:02 2022: Epoch [9], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.472, Top5: 99.7924, Loss: 0.168\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 17:40:22 2022: Test information, Data(s): 2.419, Forward(s): 0.599, Top1: 90.780, Top5: 99.290, \n",
            "\n",
            "Mon Apr 25 17:40:22 2022: conv2 Layer, 32 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 32, 32, 32]          18,464\n",
            "       BatchNorm2d-5           [-1, 32, 32, 32]              64\n",
            "              ReLU-6           [-1, 32, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 32, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]          36,992\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "             ReLU-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]         147,584\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         295,168\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]       1,180,160\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 14,936,554\n",
            "Trainable params: 14,936,554\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 5.76\n",
            "Params size (MB): 56.98\n",
            "Estimated Total Size (MB): 62.75\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 17:40:24 2022: Epoch [0], Iteration [0/391/], Data(s): 0.051, Loss(s): 0.019, Forward(s): 0.073, Backward(s): 0.194, Top1: 94.531, Top5: 100.0000, Loss: 0.150\n",
            "Mon Apr 25 17:40:39 2022: Epoch [0], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 93.518, Top5: 99.7834, Loss: 0.190\n",
            "Mon Apr 25 17:40:55 2022: Epoch [0], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 93.532, Top5: 99.7862, Loss: 0.187\n",
            "Mon Apr 25 17:41:10 2022: Epoch [0], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.680, Top5: 99.8105, Loss: 0.179\n",
            "Mon Apr 25 17:41:24 2022: Epoch [1], Iteration [0/391/], Data(s): 0.074, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.011, Top1: 96.094, Top5: 100.0000, Loss: 0.174\n",
            "Mon Apr 25 17:41:40 2022: Epoch [1], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.299, Top5: 99.7989, Loss: 0.171\n",
            "Mon Apr 25 17:41:55 2022: Epoch [1], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.096, Top5: 99.7474, Loss: 0.186\n",
            "Mon Apr 25 17:42:10 2022: Epoch [1], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.048, Top5: 99.7664, Loss: 0.178\n",
            "Mon Apr 25 17:42:24 2022: Epoch [2], Iteration [0/391/], Data(s): 0.077, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.011, Top1: 92.188, Top5: 100.0000, Loss: 0.174\n",
            "Mon Apr 25 17:42:40 2022: Epoch [2], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.160, Top5: 99.7989, Loss: 0.170\n",
            "Mon Apr 25 17:42:55 2022: Epoch [2], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.011, Top1: 94.232, Top5: 99.8095, Loss: 0.169\n",
            "Mon Apr 25 17:43:11 2022: Epoch [2], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.011, Top1: 94.274, Top5: 99.7820, Loss: 0.170\n",
            "Mon Apr 25 17:43:25 2022: Epoch [3], Iteration [0/391/], Data(s): 0.086, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 97.656, Top5: 100.0000, Loss: 0.170\n",
            "Mon Apr 25 17:43:40 2022: Epoch [3], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.670, Top5: 99.8530, Loss: 0.160\n",
            "Mon Apr 25 17:43:58 2022: Epoch [3], Iteration [200/391/], Data(s): 0.065, Loss(s): 0.026, Forward(s): 0.007, Backward(s): 0.014, Top1: 94.469, Top5: 99.8212, Loss: 0.173\n",
            "Mon Apr 25 17:44:14 2022: Epoch [3], Iteration [300/391/], Data(s): 0.060, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.013, Top1: 94.394, Top5: 99.8209, Loss: 0.169\n",
            "Mon Apr 25 17:44:28 2022: Epoch [4], Iteration [0/391/], Data(s): 0.069, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 91.406, Top5: 99.2188, Loss: 0.165\n",
            "Mon Apr 25 17:44:43 2022: Epoch [4], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.585, Top5: 99.7989, Loss: 0.165\n",
            "Mon Apr 25 17:44:59 2022: Epoch [4], Iteration [200/391/], Data(s): 0.052, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.543, Top5: 99.8018, Loss: 0.165\n",
            "Mon Apr 25 17:45:14 2022: Epoch [4], Iteration [300/391/], Data(s): 0.051, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.542, Top5: 99.8027, Loss: 0.165\n",
            "Mon Apr 25 17:45:28 2022: Epoch [5], Iteration [0/391/], Data(s): 0.085, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.011, Top1: 92.969, Top5: 99.2188, Loss: 0.164\n",
            "Mon Apr 25 17:45:44 2022: Epoch [5], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.011, Top1: 94.609, Top5: 99.7525, Loss: 0.160\n",
            "Mon Apr 25 17:45:59 2022: Epoch [5], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.011, Top1: 94.496, Top5: 99.7823, Loss: 0.163\n",
            "Mon Apr 25 17:46:14 2022: Epoch [5], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.011, Top1: 94.479, Top5: 99.7794, Loss: 0.165\n",
            "Mon Apr 25 17:46:29 2022: Epoch [6], Iteration [0/391/], Data(s): 0.079, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.011, Top1: 94.531, Top5: 99.2188, Loss: 0.163\n",
            "Mon Apr 25 17:46:44 2022: Epoch [6], Iteration [100/391/], Data(s): 0.050, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.756, Top5: 99.7757, Loss: 0.161\n",
            "Mon Apr 25 17:46:59 2022: Epoch [6], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.660, Top5: 99.7823, Loss: 0.163\n",
            "Mon Apr 25 17:47:14 2022: Epoch [6], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.703, Top5: 99.7768, Loss: 0.158\n",
            "Mon Apr 25 17:47:29 2022: Epoch [7], Iteration [0/391/], Data(s): 0.069, Loss(s): 0.027, Forward(s): 0.005, Backward(s): 0.011, Top1: 96.094, Top5: 100.0000, Loss: 0.163\n",
            "Mon Apr 25 17:47:44 2022: Epoch [7], Iteration [100/391/], Data(s): 0.050, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.678, Top5: 99.7525, Loss: 0.164\n",
            "Mon Apr 25 17:47:59 2022: Epoch [7], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.652, Top5: 99.7707, Loss: 0.160\n",
            "Mon Apr 25 17:48:15 2022: Epoch [7], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.734, Top5: 99.7872, Loss: 0.153\n",
            "Mon Apr 25 17:48:29 2022: Epoch [8], Iteration [0/391/], Data(s): 0.080, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.011, Top1: 94.531, Top5: 99.2188, Loss: 0.164\n",
            "Mon Apr 25 17:48:44 2022: Epoch [8], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.011, Top1: 94.670, Top5: 99.8066, Loss: 0.157\n",
            "Mon Apr 25 17:48:59 2022: Epoch [8], Iteration [200/391/], Data(s): 0.049, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.011, Top1: 94.691, Top5: 99.8251, Loss: 0.166\n",
            "Mon Apr 25 17:49:14 2022: Epoch [8], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.011, Top1: 94.726, Top5: 99.8313, Loss: 0.153\n",
            "Mon Apr 25 17:49:28 2022: Epoch [9], Iteration [0/391/], Data(s): 0.071, Loss(s): 0.027, Forward(s): 0.005, Backward(s): 0.011, Top1: 92.969, Top5: 100.0000, Loss: 0.157\n",
            "Mon Apr 25 17:49:44 2022: Epoch [9], Iteration [100/391/], Data(s): 0.049, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.957, Top5: 99.8762, Loss: 0.151\n",
            "Mon Apr 25 17:49:59 2022: Epoch [9], Iteration [200/391/], Data(s): 0.049, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.011, Top1: 94.928, Top5: 99.8601, Loss: 0.154\n",
            "Mon Apr 25 17:50:14 2022: Epoch [9], Iteration [300/391/], Data(s): 0.048, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.011, Top1: 94.931, Top5: 99.8365, Loss: 0.156\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 17:50:34 2022: Test information, Data(s): 2.370, Forward(s): 0.587, Top1: 91.040, Top5: 99.280, \n",
            "\n",
            "Mon Apr 25 17:50:34 2022: conv2 Layer, 40 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(24, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 24, 32, 32]          13,848\n",
            "       BatchNorm2d-5           [-1, 24, 32, 32]              48\n",
            "              ReLU-6           [-1, 24, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 24, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]          27,776\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "             ReLU-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]         147,584\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         295,168\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]       1,180,160\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 14,922,706\n",
            "Trainable params: 14,922,706\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 5.56\n",
            "Params size (MB): 56.93\n",
            "Estimated Total Size (MB): 62.50\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(24, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 17:50:35 2022: Epoch [0], Iteration [0/391/], Data(s): 0.065, Loss(s): 0.009, Forward(s): 0.093, Backward(s): 0.177, Top1: 92.188, Top5: 100.0000, Loss: 0.192\n",
            "Mon Apr 25 17:50:51 2022: Epoch [0], Iteration [100/391/], Data(s): 0.050, Loss(s): 0.026, Forward(s): 0.007, Backward(s): 0.013, Top1: 93.417, Top5: 99.7679, Loss: 0.194\n",
            "Mon Apr 25 17:51:06 2022: Epoch [0], Iteration [200/391/], Data(s): 0.049, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.412, Top5: 99.7862, Loss: 0.191\n",
            "Mon Apr 25 17:51:21 2022: Epoch [0], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.605, Top5: 99.7898, Loss: 0.178\n",
            "Mon Apr 25 17:51:35 2022: Epoch [1], Iteration [0/391/], Data(s): 0.078, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.011, Top1: 96.094, Top5: 100.0000, Loss: 0.175\n",
            "Mon Apr 25 17:51:50 2022: Epoch [1], Iteration [100/391/], Data(s): 0.050, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.011, Top1: 94.268, Top5: 99.7834, Loss: 0.174\n",
            "Mon Apr 25 17:52:05 2022: Epoch [1], Iteration [200/391/], Data(s): 0.049, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.011, Top1: 94.232, Top5: 99.7823, Loss: 0.171\n",
            "Mon Apr 25 17:52:20 2022: Epoch [1], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.011, Top1: 94.292, Top5: 99.8001, Loss: 0.166\n",
            "Mon Apr 25 17:52:34 2022: Epoch [2], Iteration [0/391/], Data(s): 0.080, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.011, Top1: 96.094, Top5: 99.2188, Loss: 0.160\n",
            "Mon Apr 25 17:52:49 2022: Epoch [2], Iteration [100/391/], Data(s): 0.050, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.384, Top5: 99.8144, Loss: 0.165\n",
            "Mon Apr 25 17:53:04 2022: Epoch [2], Iteration [200/391/], Data(s): 0.049, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.011, Top1: 94.578, Top5: 99.8018, Loss: 0.157\n",
            "Mon Apr 25 17:53:19 2022: Epoch [2], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.011, Top1: 94.453, Top5: 99.7898, Loss: 0.168\n",
            "Mon Apr 25 17:53:33 2022: Epoch [3], Iteration [0/391/], Data(s): 0.075, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.015, Top1: 96.094, Top5: 99.2188, Loss: 0.163\n",
            "Mon Apr 25 17:53:48 2022: Epoch [3], Iteration [100/391/], Data(s): 0.050, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.011, Top1: 94.903, Top5: 99.8221, Loss: 0.159\n",
            "Mon Apr 25 17:54:04 2022: Epoch [3], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.011, Top1: 94.858, Top5: 99.8095, Loss: 0.158\n",
            "Mon Apr 25 17:54:19 2022: Epoch [3], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.011, Top1: 94.889, Top5: 99.8261, Loss: 0.154\n",
            "Mon Apr 25 17:54:33 2022: Epoch [4], Iteration [0/391/], Data(s): 0.071, Loss(s): 0.027, Forward(s): 0.005, Backward(s): 0.012, Top1: 94.531, Top5: 99.2188, Loss: 0.153\n",
            "Mon Apr 25 17:54:48 2022: Epoch [4], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.926, Top5: 99.8298, Loss: 0.150\n",
            "Mon Apr 25 17:55:03 2022: Epoch [4], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.850, Top5: 99.8290, Loss: 0.158\n",
            "Mon Apr 25 17:55:18 2022: Epoch [4], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.889, Top5: 99.8443, Loss: 0.154\n",
            "Mon Apr 25 17:55:32 2022: Epoch [5], Iteration [0/391/], Data(s): 0.071, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.011, Top1: 97.656, Top5: 100.0000, Loss: 0.158\n",
            "Mon Apr 25 17:55:47 2022: Epoch [5], Iteration [100/391/], Data(s): 0.050, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.011, Top1: 95.057, Top5: 99.7602, Loss: 0.151\n",
            "Mon Apr 25 17:56:03 2022: Epoch [5], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.011, Top1: 94.951, Top5: 99.8057, Loss: 0.153\n",
            "Mon Apr 25 17:56:18 2022: Epoch [5], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.011, Top1: 94.892, Top5: 99.8287, Loss: 0.155\n",
            "Mon Apr 25 17:56:32 2022: Epoch [6], Iteration [0/391/], Data(s): 0.073, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.013, Top1: 92.188, Top5: 98.4375, Loss: 0.150\n",
            "Mon Apr 25 17:56:47 2022: Epoch [6], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.166, Top5: 99.9149, Loss: 0.146\n",
            "Mon Apr 25 17:57:02 2022: Epoch [6], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.281, Top5: 99.8795, Loss: 0.139\n",
            "Mon Apr 25 17:57:17 2022: Epoch [6], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.185, Top5: 99.8495, Loss: 0.155\n",
            "Mon Apr 25 17:57:31 2022: Epoch [7], Iteration [0/391/], Data(s): 0.073, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.011, Top1: 92.969, Top5: 99.2188, Loss: 0.159\n",
            "Mon Apr 25 17:57:46 2022: Epoch [7], Iteration [100/391/], Data(s): 0.050, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.119, Top5: 99.8221, Loss: 0.145\n",
            "Mon Apr 25 17:58:01 2022: Epoch [7], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.982, Top5: 99.8368, Loss: 0.152\n",
            "Mon Apr 25 17:58:17 2022: Epoch [7], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.050, Top5: 99.8339, Loss: 0.144\n",
            "Mon Apr 25 17:58:30 2022: Epoch [8], Iteration [0/391/], Data(s): 0.071, Loss(s): 0.027, Forward(s): 0.005, Backward(s): 0.011, Top1: 95.312, Top5: 100.0000, Loss: 0.137\n",
            "Mon Apr 25 17:58:46 2022: Epoch [8], Iteration [100/391/], Data(s): 0.050, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.011, Top1: 95.127, Top5: 99.8762, Loss: 0.143\n",
            "Mon Apr 25 17:59:01 2022: Epoch [8], Iteration [200/391/], Data(s): 0.049, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.011, Top1: 95.243, Top5: 99.8523, Loss: 0.143\n",
            "Mon Apr 25 17:59:16 2022: Epoch [8], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.011, Top1: 95.102, Top5: 99.8495, Loss: 0.153\n",
            "Mon Apr 25 17:59:30 2022: Epoch [9], Iteration [0/391/], Data(s): 0.074, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.750, Top5: 100.0000, Loss: 0.141\n",
            "Mon Apr 25 17:59:45 2022: Epoch [9], Iteration [100/391/], Data(s): 0.050, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.359, Top5: 99.8994, Loss: 0.136\n",
            "Mon Apr 25 18:00:00 2022: Epoch [9], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.363, Top5: 99.8795, Loss: 0.142\n",
            "Mon Apr 25 18:00:16 2022: Epoch [9], Iteration [300/391/], Data(s): 0.052, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.320, Top5: 99.8728, Loss: 0.143\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 18:00:36 2022: Test information, Data(s): 2.410, Forward(s): 0.563, Top1: 90.950, Top5: 99.260, \n",
            "\n",
            "Mon Apr 25 18:00:36 2022: conv2 Layer, 48 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(16, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 16, 32, 32]           9,232\n",
            "       BatchNorm2d-5           [-1, 16, 32, 32]              32\n",
            "              ReLU-6           [-1, 16, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 16, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]          18,560\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "             ReLU-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]         147,584\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         295,168\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]       1,180,160\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 14,908,858\n",
            "Trainable params: 14,908,858\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 5.36\n",
            "Params size (MB): 56.87\n",
            "Estimated Total Size (MB): 62.24\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(16, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 18:00:37 2022: Epoch [0], Iteration [0/391/], Data(s): 0.051, Loss(s): 0.020, Forward(s): 0.062, Backward(s): 0.171, Top1: 85.156, Top5: 100.0000, Loss: 0.389\n",
            "Mon Apr 25 18:00:52 2022: Epoch [0], Iteration [100/391/], Data(s): 0.050, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.013, Top1: 90.261, Top5: 99.3812, Loss: 0.307\n",
            "Mon Apr 25 18:01:07 2022: Epoch [0], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 91.274, Top5: 99.5725, Loss: 0.225\n",
            "Mon Apr 25 18:01:22 2022: Epoch [0], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 91.806, Top5: 99.6055, Loss: 0.209\n",
            "Mon Apr 25 18:01:37 2022: Epoch [1], Iteration [0/391/], Data(s): 0.074, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.011, Top1: 94.531, Top5: 100.0000, Loss: 0.209\n",
            "Mon Apr 25 18:01:52 2022: Epoch [1], Iteration [100/391/], Data(s): 0.050, Loss(s): 0.026, Forward(s): 0.005, Backward(s): 0.011, Top1: 93.765, Top5: 99.7912, Loss: 0.188\n",
            "Mon Apr 25 18:02:07 2022: Epoch [1], Iteration [200/391/], Data(s): 0.049, Loss(s): 0.026, Forward(s): 0.005, Backward(s): 0.011, Top1: 93.859, Top5: 99.7823, Loss: 0.185\n",
            "Mon Apr 25 18:02:22 2022: Epoch [1], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.026, Forward(s): 0.005, Backward(s): 0.011, Top1: 93.760, Top5: 99.7768, Loss: 0.189\n",
            "Mon Apr 25 18:02:36 2022: Epoch [2], Iteration [0/391/], Data(s): 0.087, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.011, Top1: 88.281, Top5: 100.0000, Loss: 0.185\n",
            "Mon Apr 25 18:02:51 2022: Epoch [2], Iteration [100/391/], Data(s): 0.050, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.268, Top5: 99.7912, Loss: 0.173\n",
            "Mon Apr 25 18:03:06 2022: Epoch [2], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.011, Top1: 94.216, Top5: 99.8018, Loss: 0.171\n",
            "Mon Apr 25 18:03:21 2022: Epoch [2], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.026, Forward(s): 0.005, Backward(s): 0.011, Top1: 94.215, Top5: 99.8131, Loss: 0.170\n",
            "Mon Apr 25 18:03:35 2022: Epoch [3], Iteration [0/391/], Data(s): 0.080, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.019, Top1: 94.531, Top5: 100.0000, Loss: 0.171\n",
            "Mon Apr 25 18:03:50 2022: Epoch [3], Iteration [100/391/], Data(s): 0.050, Loss(s): 0.026, Forward(s): 0.005, Backward(s): 0.011, Top1: 94.407, Top5: 99.7834, Loss: 0.173\n",
            "Mon Apr 25 18:04:06 2022: Epoch [3], Iteration [200/391/], Data(s): 0.049, Loss(s): 0.026, Forward(s): 0.005, Backward(s): 0.011, Top1: 94.434, Top5: 99.8095, Loss: 0.168\n",
            "Mon Apr 25 18:04:21 2022: Epoch [3], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.026, Forward(s): 0.005, Backward(s): 0.011, Top1: 94.459, Top5: 99.8261, Loss: 0.164\n",
            "Mon Apr 25 18:04:34 2022: Epoch [4], Iteration [0/391/], Data(s): 0.077, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.011, Top1: 95.312, Top5: 100.0000, Loss: 0.169\n",
            "Mon Apr 25 18:04:50 2022: Epoch [4], Iteration [100/391/], Data(s): 0.050, Loss(s): 0.026, Forward(s): 0.005, Backward(s): 0.011, Top1: 94.725, Top5: 99.8221, Loss: 0.161\n",
            "Mon Apr 25 18:05:05 2022: Epoch [4], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.026, Forward(s): 0.005, Backward(s): 0.011, Top1: 94.753, Top5: 99.7901, Loss: 0.160\n",
            "Mon Apr 25 18:05:20 2022: Epoch [4], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.026, Forward(s): 0.005, Backward(s): 0.011, Top1: 94.695, Top5: 99.7950, Loss: 0.162\n",
            "Mon Apr 25 18:05:34 2022: Epoch [5], Iteration [0/391/], Data(s): 0.068, Loss(s): 0.026, Forward(s): 0.005, Backward(s): 0.011, Top1: 96.875, Top5: 100.0000, Loss: 0.158\n",
            "Mon Apr 25 18:05:49 2022: Epoch [5], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.026, Forward(s): 0.005, Backward(s): 0.011, Top1: 94.709, Top5: 99.7757, Loss: 0.163\n",
            "Mon Apr 25 18:06:04 2022: Epoch [5], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.026, Forward(s): 0.005, Backward(s): 0.011, Top1: 94.613, Top5: 99.7785, Loss: 0.157\n",
            "Mon Apr 25 18:06:19 2022: Epoch [5], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.026, Forward(s): 0.005, Backward(s): 0.011, Top1: 94.614, Top5: 99.7898, Loss: 0.160\n",
            "Mon Apr 25 18:06:33 2022: Epoch [6], Iteration [0/391/], Data(s): 0.073, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.010, Top1: 95.312, Top5: 100.0000, Loss: 0.160\n",
            "Mon Apr 25 18:06:48 2022: Epoch [6], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.026, Forward(s): 0.005, Backward(s): 0.012, Top1: 95.003, Top5: 99.8840, Loss: 0.148\n",
            "Mon Apr 25 18:07:03 2022: Epoch [6], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.026, Forward(s): 0.005, Backward(s): 0.011, Top1: 95.106, Top5: 99.8562, Loss: 0.143\n",
            "Mon Apr 25 18:07:18 2022: Epoch [6], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.026, Forward(s): 0.005, Backward(s): 0.011, Top1: 95.092, Top5: 99.8521, Loss: 0.151\n",
            "Mon Apr 25 18:07:32 2022: Epoch [7], Iteration [0/391/], Data(s): 0.072, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.011, Top1: 96.875, Top5: 100.0000, Loss: 0.165\n",
            "Mon Apr 25 18:07:47 2022: Epoch [7], Iteration [100/391/], Data(s): 0.050, Loss(s): 0.026, Forward(s): 0.005, Backward(s): 0.011, Top1: 94.678, Top5: 99.8376, Loss: 0.155\n",
            "Mon Apr 25 18:08:02 2022: Epoch [7], Iteration [200/391/], Data(s): 0.049, Loss(s): 0.026, Forward(s): 0.005, Backward(s): 0.011, Top1: 94.842, Top5: 99.8601, Loss: 0.150\n",
            "Mon Apr 25 18:08:17 2022: Epoch [7], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.026, Forward(s): 0.005, Backward(s): 0.011, Top1: 94.936, Top5: 99.8365, Loss: 0.150\n",
            "Mon Apr 25 18:08:31 2022: Epoch [8], Iteration [0/391/], Data(s): 0.075, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.011, Top1: 95.312, Top5: 100.0000, Loss: 0.148\n",
            "Mon Apr 25 18:08:46 2022: Epoch [8], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.026, Forward(s): 0.005, Backward(s): 0.011, Top1: 95.227, Top5: 99.8144, Loss: 0.146\n",
            "Mon Apr 25 18:09:01 2022: Epoch [8], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.026, Forward(s): 0.005, Backward(s): 0.011, Top1: 95.274, Top5: 99.8290, Loss: 0.142\n",
            "Mon Apr 25 18:09:16 2022: Epoch [8], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.026, Forward(s): 0.005, Backward(s): 0.011, Top1: 95.248, Top5: 99.8053, Loss: 0.151\n",
            "Mon Apr 25 18:09:30 2022: Epoch [9], Iteration [0/391/], Data(s): 0.072, Loss(s): 0.026, Forward(s): 0.005, Backward(s): 0.011, Top1: 92.969, Top5: 100.0000, Loss: 0.146\n",
            "Mon Apr 25 18:09:46 2022: Epoch [9], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.026, Forward(s): 0.005, Backward(s): 0.011, Top1: 95.320, Top5: 99.8608, Loss: 0.142\n",
            "Mon Apr 25 18:10:01 2022: Epoch [9], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.026, Forward(s): 0.005, Backward(s): 0.011, Top1: 95.095, Top5: 99.8601, Loss: 0.145\n",
            "Mon Apr 25 18:10:16 2022: Epoch [9], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.026, Forward(s): 0.005, Backward(s): 0.011, Top1: 95.162, Top5: 99.8650, Loss: 0.141\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 18:10:35 2022: Test information, Data(s): 2.453, Forward(s): 0.553, Top1: 90.510, Top5: 99.320, \n",
            "\n",
            "Mon Apr 25 18:10:35 2022: conv2 Layer, 57 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(7, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4            [-1, 7, 32, 32]           4,039\n",
            "       BatchNorm2d-5            [-1, 7, 32, 32]              14\n",
            "              ReLU-6            [-1, 7, 32, 32]               0\n",
            "         MaxPool2d-7            [-1, 7, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]           8,192\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "             ReLU-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]         147,584\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         295,168\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]       1,180,160\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 14,893,279\n",
            "Trainable params: 14,893,279\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 5.13\n",
            "Params size (MB): 56.81\n",
            "Estimated Total Size (MB): 61.95\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(7, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 18:10:37 2022: Epoch [0], Iteration [0/391/], Data(s): 0.054, Loss(s): 0.019, Forward(s): 0.062, Backward(s): 0.159, Top1: 69.531, Top5: 96.0938, Loss: 1.404\n",
            "Mon Apr 25 18:10:52 2022: Epoch [0], Iteration [100/391/], Data(s): 0.050, Loss(s): 0.025, Forward(s): 0.006, Backward(s): 0.013, Top1: 79.448, Top5: 97.1148, Loss: 0.779\n",
            "Mon Apr 25 18:11:06 2022: Epoch [0], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.025, Forward(s): 0.006, Backward(s): 0.012, Top1: 81.950, Top5: 97.8817, Loss: 0.498\n",
            "Mon Apr 25 18:11:21 2022: Epoch [0], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.025, Forward(s): 0.005, Backward(s): 0.011, Top1: 83.487, Top5: 98.2299, Loss: 0.424\n",
            "Mon Apr 25 18:11:34 2022: Epoch [1], Iteration [0/391/], Data(s): 0.071, Loss(s): 0.025, Forward(s): 0.006, Backward(s): 0.012, Top1: 89.844, Top5: 98.4375, Loss: 0.378\n",
            "Mon Apr 25 18:11:49 2022: Epoch [1], Iteration [100/391/], Data(s): 0.050, Loss(s): 0.025, Forward(s): 0.005, Backward(s): 0.011, Top1: 88.792, Top5: 99.1491, Loss: 0.346\n",
            "Mon Apr 25 18:12:04 2022: Epoch [1], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.025, Forward(s): 0.005, Backward(s): 0.011, Top1: 89.012, Top5: 99.2110, Loss: 0.330\n",
            "Mon Apr 25 18:12:18 2022: Epoch [1], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.025, Forward(s): 0.005, Backward(s): 0.011, Top1: 89.052, Top5: 99.2369, Loss: 0.328\n",
            "Mon Apr 25 18:12:32 2022: Epoch [2], Iteration [0/391/], Data(s): 0.075, Loss(s): 0.023, Forward(s): 0.008, Backward(s): 0.010, Top1: 92.969, Top5: 100.0000, Loss: 0.317\n",
            "Mon Apr 25 18:12:46 2022: Epoch [2], Iteration [100/391/], Data(s): 0.050, Loss(s): 0.025, Forward(s): 0.005, Backward(s): 0.011, Top1: 89.805, Top5: 99.4121, Loss: 0.307\n",
            "Mon Apr 25 18:13:01 2022: Epoch [2], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.025, Forward(s): 0.005, Backward(s): 0.011, Top1: 90.054, Top5: 99.4520, Loss: 0.293\n",
            "Mon Apr 25 18:13:16 2022: Epoch [2], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.025, Forward(s): 0.005, Backward(s): 0.011, Top1: 90.059, Top5: 99.4368, Loss: 0.297\n",
            "Mon Apr 25 18:13:29 2022: Epoch [3], Iteration [0/391/], Data(s): 0.079, Loss(s): 0.025, Forward(s): 0.006, Backward(s): 0.010, Top1: 90.625, Top5: 100.0000, Loss: 0.282\n",
            "Mon Apr 25 18:13:44 2022: Epoch [3], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.025, Forward(s): 0.005, Backward(s): 0.011, Top1: 90.849, Top5: 99.5127, Loss: 0.275\n",
            "Mon Apr 25 18:13:59 2022: Epoch [3], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.025, Forward(s): 0.005, Backward(s): 0.011, Top1: 90.986, Top5: 99.4908, Loss: 0.270\n",
            "Mon Apr 25 18:14:13 2022: Epoch [3], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.026, Forward(s): 0.005, Backward(s): 0.011, Top1: 91.022, Top5: 99.5017, Loss: 0.269\n",
            "Mon Apr 25 18:14:27 2022: Epoch [4], Iteration [0/391/], Data(s): 0.074, Loss(s): 0.025, Forward(s): 0.006, Backward(s): 0.011, Top1: 85.938, Top5: 100.0000, Loss: 0.268\n",
            "Mon Apr 25 18:14:41 2022: Epoch [4], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.025, Forward(s): 0.005, Backward(s): 0.011, Top1: 91.004, Top5: 99.5282, Loss: 0.269\n",
            "Mon Apr 25 18:14:56 2022: Epoch [4], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.025, Forward(s): 0.005, Backward(s): 0.011, Top1: 91.329, Top5: 99.5569, Loss: 0.256\n",
            "Mon Apr 25 18:15:10 2022: Epoch [4], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.025, Forward(s): 0.005, Backward(s): 0.011, Top1: 91.510, Top5: 99.5328, Loss: 0.244\n",
            "Mon Apr 25 18:15:24 2022: Epoch [5], Iteration [0/391/], Data(s): 0.070, Loss(s): 0.026, Forward(s): 0.005, Backward(s): 0.010, Top1: 89.844, Top5: 98.4375, Loss: 0.249\n",
            "Mon Apr 25 18:15:39 2022: Epoch [5], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.025, Forward(s): 0.005, Backward(s): 0.011, Top1: 91.669, Top5: 99.5900, Loss: 0.247\n",
            "Mon Apr 25 18:15:53 2022: Epoch [5], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.026, Forward(s): 0.005, Backward(s): 0.011, Top1: 91.772, Top5: 99.5725, Loss: 0.242\n",
            "Mon Apr 25 18:16:08 2022: Epoch [5], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.025, Forward(s): 0.005, Backward(s): 0.011, Top1: 91.835, Top5: 99.5717, Loss: 0.242\n",
            "Mon Apr 25 18:16:21 2022: Epoch [6], Iteration [0/391/], Data(s): 0.090, Loss(s): 0.025, Forward(s): 0.005, Backward(s): 0.011, Top1: 96.875, Top5: 100.0000, Loss: 0.241\n",
            "Mon Apr 25 18:16:36 2022: Epoch [6], Iteration [100/391/], Data(s): 0.050, Loss(s): 0.025, Forward(s): 0.005, Backward(s): 0.011, Top1: 92.133, Top5: 99.7061, Loss: 0.229\n",
            "Mon Apr 25 18:16:51 2022: Epoch [6], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.025, Forward(s): 0.005, Backward(s): 0.011, Top1: 92.149, Top5: 99.6424, Loss: 0.236\n",
            "Mon Apr 25 18:17:05 2022: Epoch [6], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.025, Forward(s): 0.005, Backward(s): 0.011, Top1: 92.221, Top5: 99.6340, Loss: 0.231\n",
            "Mon Apr 25 18:17:19 2022: Epoch [7], Iteration [0/391/], Data(s): 0.083, Loss(s): 0.025, Forward(s): 0.006, Backward(s): 0.011, Top1: 89.844, Top5: 100.0000, Loss: 0.227\n",
            "Mon Apr 25 18:17:33 2022: Epoch [7], Iteration [100/391/], Data(s): 0.050, Loss(s): 0.025, Forward(s): 0.005, Backward(s): 0.011, Top1: 92.033, Top5: 99.6674, Loss: 0.236\n",
            "Mon Apr 25 18:17:48 2022: Epoch [7], Iteration [200/391/], Data(s): 0.049, Loss(s): 0.025, Forward(s): 0.005, Backward(s): 0.011, Top1: 92.308, Top5: 99.6580, Loss: 0.221\n",
            "Mon Apr 25 18:18:02 2022: Epoch [7], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.025, Forward(s): 0.005, Backward(s): 0.011, Top1: 92.359, Top5: 99.6522, Loss: 0.225\n",
            "Mon Apr 25 18:18:16 2022: Epoch [8], Iteration [0/391/], Data(s): 0.080, Loss(s): 0.025, Forward(s): 0.006, Backward(s): 0.011, Top1: 87.500, Top5: 100.0000, Loss: 0.226\n",
            "Mon Apr 25 18:18:31 2022: Epoch [8], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.025, Forward(s): 0.005, Backward(s): 0.011, Top1: 92.520, Top5: 99.6751, Loss: 0.216\n",
            "Mon Apr 25 18:18:45 2022: Epoch [8], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.025, Forward(s): 0.005, Backward(s): 0.011, Top1: 92.576, Top5: 99.7085, Loss: 0.222\n",
            "Mon Apr 25 18:19:00 2022: Epoch [8], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.025, Forward(s): 0.005, Backward(s): 0.011, Top1: 92.709, Top5: 99.6911, Loss: 0.216\n",
            "Mon Apr 25 18:19:13 2022: Epoch [9], Iteration [0/391/], Data(s): 0.070, Loss(s): 0.026, Forward(s): 0.005, Backward(s): 0.011, Top1: 92.188, Top5: 98.4375, Loss: 0.215\n",
            "Mon Apr 25 18:19:28 2022: Epoch [9], Iteration [100/391/], Data(s): 0.050, Loss(s): 0.025, Forward(s): 0.005, Backward(s): 0.011, Top1: 92.737, Top5: 99.6442, Loss: 0.213\n",
            "Mon Apr 25 18:19:43 2022: Epoch [9], Iteration [200/391/], Data(s): 0.049, Loss(s): 0.025, Forward(s): 0.005, Backward(s): 0.011, Top1: 92.774, Top5: 99.6735, Loss: 0.214\n",
            "Mon Apr 25 18:19:57 2022: Epoch [9], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.025, Forward(s): 0.005, Backward(s): 0.011, Top1: 92.875, Top5: 99.6600, Loss: 0.208\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 18:20:17 2022: Test information, Data(s): 2.371, Forward(s): 0.526, Top1: 88.920, Top5: 99.210, \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "39qt7qfEqXVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for conv, channel in zip(prune_layers[6:8], prune_channels[6:8]):    \n",
        "    top1_accuracies[conv] = []\n",
        "    top5_accuracies[conv] = []\n",
        "    \n",
        "    # load new network and check accuracy\n",
        "    network, _, _ = test_network(args, data_set=test_set)\n",
        "        \n",
        "    # remove 0 channels ~ M (max_channel_ratio) % of total channels\n",
        "    step = np.linspace(0, int(channel*max_channel_ratio), int(1/prune_step_ratio), dtype=np.int)\n",
        "    steps = (step[1:] - step[:-1]).tolist()\n",
        "    \n",
        "    for i in range(len(steps)):\n",
        "        print(\"\\n%s: %s Layer, %d Channels pruned\"%(time.ctime(), conv, sum(steps[:i+1])))\n",
        "        \n",
        "        # set prune information\n",
        "        args.prune_layers = [conv]\n",
        "        args.prune_channels =[steps[i]]\n",
        "\n",
        "        network = prune_network(args, network)\n",
        "        \n",
        "        network, _, (top1, top5) = test_network(args, network, test_set)\n",
        "            \n",
        "        top1_accuracies[conv].append(top1)\n",
        "        top5_accuracies[conv].append(top5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35357991-c53d-4048-c7c0-2dae4c6c0fe8",
        "id": "wU5wyAZeqc3Q"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 14:38:11 2022: Test information, Data(s): 2.533, Forward(s): 0.485, Top1: 77.870, Top5: 97.560, \n",
            "\n",
            "Mon Apr 25 14:38:11 2022: conv7 Layer, 32 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(224, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]          73,856\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "             ReLU-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]         147,584\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         295,168\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 224, 8, 8]         516,320\n",
            "      BatchNorm2d-22            [-1, 224, 8, 8]             448\n",
            "             ReLU-23            [-1, 224, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 224, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]       1,032,704\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 14,770,666\n",
            "Trainable params: 14,770,666\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 6.52\n",
            "Params size (MB): 56.35\n",
            "Estimated Total Size (MB): 62.88\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(224, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  if __name__ == '__main__':\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 14:38:15 2022: Epoch [0], Iteration [0/391/], Data(s): 0.053, Loss(s): 0.009, Forward(s): 0.792, Backward(s): 1.483, Top1: 89.844, Top5: 99.2188, Loss: 0.306\n",
            "Mon Apr 25 14:38:31 2022: Epoch [0], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.029, Forward(s): 0.014, Backward(s): 0.027, Top1: 87.051, Top5: 98.7933, Loss: 0.410\n",
            "Mon Apr 25 14:38:47 2022: Epoch [0], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.029, Forward(s): 0.010, Backward(s): 0.019, Top1: 87.687, Top5: 98.9583, Loss: 0.356\n",
            "Mon Apr 25 14:39:04 2022: Epoch [0], Iteration [300/391/], Data(s): 0.054, Loss(s): 0.028, Forward(s): 0.009, Backward(s): 0.017, Top1: 88.437, Top5: 99.0526, Loss: 0.324\n",
            "Mon Apr 25 14:39:21 2022: Epoch [1], Iteration [0/391/], Data(s): 0.059, Loss(s): 0.033, Forward(s): 0.007, Backward(s): 0.012, Top1: 91.406, Top5: 99.2188, Loss: 0.308\n",
            "Mon Apr 25 14:39:37 2022: Epoch [1], Iteration [100/391/], Data(s): 0.053, Loss(s): 0.029, Forward(s): 0.006, Backward(s): 0.013, Top1: 89.650, Top5: 99.3502, Loss: 0.311\n",
            "Mon Apr 25 14:39:54 2022: Epoch [1], Iteration [200/391/], Data(s): 0.052, Loss(s): 0.029, Forward(s): 0.006, Backward(s): 0.012, Top1: 90.073, Top5: 99.3548, Loss: 0.300\n",
            "Mon Apr 25 14:40:10 2022: Epoch [1], Iteration [300/391/], Data(s): 0.052, Loss(s): 0.029, Forward(s): 0.006, Backward(s): 0.012, Top1: 90.254, Top5: 99.3693, Loss: 0.293\n",
            "Mon Apr 25 14:40:25 2022: Epoch [2], Iteration [0/391/], Data(s): 0.093, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 87.500, Top5: 100.0000, Loss: 0.284\n",
            "Mon Apr 25 14:40:41 2022: Epoch [2], Iteration [100/391/], Data(s): 0.053, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.013, Top1: 90.903, Top5: 99.5359, Loss: 0.279\n",
            "Mon Apr 25 14:40:57 2022: Epoch [2], Iteration [200/391/], Data(s): 0.053, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.013, Top1: 90.983, Top5: 99.4908, Loss: 0.279\n",
            "Mon Apr 25 14:41:14 2022: Epoch [2], Iteration [300/391/], Data(s): 0.053, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.013, Top1: 90.939, Top5: 99.5172, Loss: 0.287\n",
            "Mon Apr 25 14:41:29 2022: Epoch [3], Iteration [0/391/], Data(s): 0.101, Loss(s): 0.029, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.969, Top5: 100.0000, Loss: 0.266\n",
            "Mon Apr 25 14:41:45 2022: Epoch [3], Iteration [100/391/], Data(s): 0.053, Loss(s): 0.029, Forward(s): 0.006, Backward(s): 0.013, Top1: 91.174, Top5: 99.5127, Loss: 0.266\n",
            "Mon Apr 25 14:42:01 2022: Epoch [3], Iteration [200/391/], Data(s): 0.052, Loss(s): 0.029, Forward(s): 0.006, Backward(s): 0.012, Top1: 91.274, Top5: 99.4714, Loss: 0.273\n",
            "Mon Apr 25 14:42:17 2022: Epoch [3], Iteration [300/391/], Data(s): 0.052, Loss(s): 0.029, Forward(s): 0.006, Backward(s): 0.012, Top1: 91.432, Top5: 99.4757, Loss: 0.258\n",
            "Mon Apr 25 14:42:32 2022: Epoch [4], Iteration [0/391/], Data(s): 0.083, Loss(s): 0.029, Forward(s): 0.006, Backward(s): 0.012, Top1: 88.281, Top5: 100.0000, Loss: 0.264\n",
            "Mon Apr 25 14:42:48 2022: Epoch [4], Iteration [100/391/], Data(s): 0.053, Loss(s): 0.029, Forward(s): 0.006, Backward(s): 0.013, Top1: 91.437, Top5: 99.5900, Loss: 0.258\n",
            "Mon Apr 25 14:43:05 2022: Epoch [4], Iteration [200/391/], Data(s): 0.052, Loss(s): 0.029, Forward(s): 0.006, Backward(s): 0.012, Top1: 91.480, Top5: 99.4986, Loss: 0.263\n",
            "Mon Apr 25 14:43:21 2022: Epoch [4], Iteration [300/391/], Data(s): 0.052, Loss(s): 0.029, Forward(s): 0.006, Backward(s): 0.012, Top1: 91.663, Top5: 99.5094, Loss: 0.248\n",
            "Mon Apr 25 14:43:36 2022: Epoch [5], Iteration [0/391/], Data(s): 0.077, Loss(s): 0.029, Forward(s): 0.006, Backward(s): 0.011, Top1: 95.312, Top5: 100.0000, Loss: 0.257\n",
            "Mon Apr 25 14:43:52 2022: Epoch [5], Iteration [100/391/], Data(s): 0.053, Loss(s): 0.029, Forward(s): 0.006, Backward(s): 0.012, Top1: 91.723, Top5: 99.5050, Loss: 0.254\n",
            "Mon Apr 25 14:44:08 2022: Epoch [5], Iteration [200/391/], Data(s): 0.052, Loss(s): 0.029, Forward(s): 0.006, Backward(s): 0.012, Top1: 91.737, Top5: 99.5375, Loss: 0.254\n",
            "Mon Apr 25 14:44:24 2022: Epoch [5], Iteration [300/391/], Data(s): 0.052, Loss(s): 0.029, Forward(s): 0.006, Backward(s): 0.012, Top1: 91.941, Top5: 99.5795, Loss: 0.236\n",
            "Mon Apr 25 14:44:39 2022: Epoch [6], Iteration [0/391/], Data(s): 0.070, Loss(s): 0.029, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.750, Top5: 100.0000, Loss: 0.255\n",
            "Mon Apr 25 14:44:56 2022: Epoch [6], Iteration [100/391/], Data(s): 0.052, Loss(s): 0.029, Forward(s): 0.006, Backward(s): 0.013, Top1: 92.056, Top5: 99.5591, Loss: 0.248\n",
            "Mon Apr 25 14:45:12 2022: Epoch [6], Iteration [200/391/], Data(s): 0.052, Loss(s): 0.029, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.067, Top5: 99.5452, Loss: 0.245\n",
            "Mon Apr 25 14:45:28 2022: Epoch [6], Iteration [300/391/], Data(s): 0.052, Loss(s): 0.029, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.149, Top5: 99.5847, Loss: 0.238\n",
            "Mon Apr 25 14:45:43 2022: Epoch [7], Iteration [0/391/], Data(s): 0.076, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.013, Top1: 92.969, Top5: 99.2188, Loss: 0.233\n",
            "Mon Apr 25 14:45:59 2022: Epoch [7], Iteration [100/391/], Data(s): 0.053, Loss(s): 0.029, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.126, Top5: 99.5668, Loss: 0.243\n",
            "Mon Apr 25 14:46:15 2022: Epoch [7], Iteration [200/391/], Data(s): 0.053, Loss(s): 0.029, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.079, Top5: 99.5569, Loss: 0.244\n",
            "Mon Apr 25 14:46:32 2022: Epoch [7], Iteration [300/391/], Data(s): 0.052, Loss(s): 0.029, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.234, Top5: 99.5665, Loss: 0.230\n",
            "Mon Apr 25 14:46:46 2022: Epoch [8], Iteration [0/391/], Data(s): 0.079, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.188, Top5: 98.4375, Loss: 0.227\n",
            "Mon Apr 25 14:47:03 2022: Epoch [8], Iteration [100/391/], Data(s): 0.053, Loss(s): 0.029, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.481, Top5: 99.7138, Loss: 0.234\n",
            "Mon Apr 25 14:47:19 2022: Epoch [8], Iteration [200/391/], Data(s): 0.052, Loss(s): 0.029, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.658, Top5: 99.6502, Loss: 0.224\n",
            "Mon Apr 25 14:47:35 2022: Epoch [8], Iteration [300/391/], Data(s): 0.052, Loss(s): 0.029, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.642, Top5: 99.6340, Loss: 0.227\n",
            "Mon Apr 25 14:47:50 2022: Epoch [9], Iteration [0/391/], Data(s): 0.085, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 91.406, Top5: 98.4375, Loss: 0.227\n",
            "Mon Apr 25 14:48:06 2022: Epoch [9], Iteration [100/391/], Data(s): 0.053, Loss(s): 0.029, Forward(s): 0.006, Backward(s): 0.013, Top1: 92.396, Top5: 99.6519, Loss: 0.231\n",
            "Mon Apr 25 14:48:23 2022: Epoch [9], Iteration [200/391/], Data(s): 0.052, Loss(s): 0.029, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.716, Top5: 99.6308, Loss: 0.223\n",
            "Mon Apr 25 14:48:39 2022: Epoch [9], Iteration [300/391/], Data(s): 0.052, Loss(s): 0.029, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.774, Top5: 99.6496, Loss: 0.220\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 14:49:00 2022: Test information, Data(s): 2.520, Forward(s): 0.601, Top1: 90.210, Top5: 99.240, \n",
            "\n",
            "Mon Apr 25 14:49:00 2022: conv7 Layer, 65 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 191, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(191, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(191, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]          73,856\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "             ReLU-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]         147,584\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         295,168\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 191, 8, 8]         440,255\n",
            "      BatchNorm2d-22            [-1, 191, 8, 8]             382\n",
            "             ReLU-23            [-1, 191, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 191, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]         880,640\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 14,542,471\n",
            "Trainable params: 14,542,471\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 6.47\n",
            "Params size (MB): 55.48\n",
            "Estimated Total Size (MB): 61.96\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 191, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(191, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(191, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 14:49:02 2022: Epoch [0], Iteration [0/391/], Data(s): 0.059, Loss(s): 0.003, Forward(s): 0.154, Backward(s): 0.350, Top1: 92.969, Top5: 99.2188, Loss: 0.232\n",
            "Mon Apr 25 14:49:18 2022: Epoch [0], Iteration [100/391/], Data(s): 0.053, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.016, Top1: 92.806, Top5: 99.6906, Loss: 0.218\n",
            "Mon Apr 25 14:49:34 2022: Epoch [0], Iteration [200/391/], Data(s): 0.052, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.014, Top1: 92.572, Top5: 99.6618, Loss: 0.230\n",
            "Mon Apr 25 14:49:50 2022: Epoch [0], Iteration [300/391/], Data(s): 0.052, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.013, Top1: 92.647, Top5: 99.6574, Loss: 0.226\n",
            "Mon Apr 25 14:50:06 2022: Epoch [1], Iteration [0/391/], Data(s): 0.113, Loss(s): 0.028, Forward(s): 0.010, Backward(s): 0.023, Top1: 86.719, Top5: 99.2188, Loss: 0.227\n",
            "Mon Apr 25 14:50:22 2022: Epoch [1], Iteration [100/391/], Data(s): 0.054, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.013, Top1: 92.915, Top5: 99.6597, Loss: 0.211\n",
            "Mon Apr 25 14:50:38 2022: Epoch [1], Iteration [200/391/], Data(s): 0.053, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.910, Top5: 99.6502, Loss: 0.222\n",
            "Mon Apr 25 14:50:54 2022: Epoch [1], Iteration [300/391/], Data(s): 0.053, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.805, Top5: 99.6392, Loss: 0.223\n",
            "Mon Apr 25 14:51:09 2022: Epoch [2], Iteration [0/391/], Data(s): 0.084, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.875, Top5: 98.4375, Loss: 0.213\n",
            "Mon Apr 25 14:51:25 2022: Epoch [2], Iteration [100/391/], Data(s): 0.053, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.185, Top5: 99.6519, Loss: 0.210\n",
            "Mon Apr 25 14:51:41 2022: Epoch [2], Iteration [200/391/], Data(s): 0.052, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.066, Top5: 99.6929, Loss: 0.208\n",
            "Mon Apr 25 14:51:57 2022: Epoch [2], Iteration [300/391/], Data(s): 0.052, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.067, Top5: 99.6730, Loss: 0.214\n",
            "Mon Apr 25 14:52:12 2022: Epoch [3], Iteration [0/391/], Data(s): 0.073, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.969, Top5: 99.2188, Loss: 0.224\n",
            "Mon Apr 25 14:52:28 2022: Epoch [3], Iteration [100/391/], Data(s): 0.053, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.495, Top5: 99.6674, Loss: 0.202\n",
            "Mon Apr 25 14:52:44 2022: Epoch [3], Iteration [200/391/], Data(s): 0.052, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.404, Top5: 99.6541, Loss: 0.210\n",
            "Mon Apr 25 14:53:00 2022: Epoch [3], Iteration [300/391/], Data(s): 0.052, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.309, Top5: 99.6626, Loss: 0.208\n",
            "Mon Apr 25 14:53:15 2022: Epoch [4], Iteration [0/391/], Data(s): 0.076, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 90.625, Top5: 100.0000, Loss: 0.220\n",
            "Mon Apr 25 14:53:31 2022: Epoch [4], Iteration [100/391/], Data(s): 0.054, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.013, Top1: 92.976, Top5: 99.6983, Loss: 0.210\n",
            "Mon Apr 25 14:53:48 2022: Epoch [4], Iteration [200/391/], Data(s): 0.053, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.124, Top5: 99.6696, Loss: 0.207\n",
            "Mon Apr 25 14:54:04 2022: Epoch [4], Iteration [300/391/], Data(s): 0.053, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.124, Top5: 99.6833, Loss: 0.208\n",
            "Mon Apr 25 14:54:18 2022: Epoch [5], Iteration [0/391/], Data(s): 0.072, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.011, Top1: 95.312, Top5: 99.2188, Loss: 0.205\n",
            "Mon Apr 25 14:54:35 2022: Epoch [5], Iteration [100/391/], Data(s): 0.052, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.247, Top5: 99.6906, Loss: 0.209\n",
            "Mon Apr 25 14:54:51 2022: Epoch [5], Iteration [200/391/], Data(s): 0.052, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.268, Top5: 99.6774, Loss: 0.208\n",
            "Mon Apr 25 14:55:07 2022: Epoch [5], Iteration [300/391/], Data(s): 0.052, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.221, Top5: 99.6678, Loss: 0.203\n",
            "Mon Apr 25 14:55:21 2022: Epoch [6], Iteration [0/391/], Data(s): 0.082, Loss(s): 0.026, Forward(s): 0.007, Backward(s): 0.012, Top1: 94.531, Top5: 99.2188, Loss: 0.200\n",
            "Mon Apr 25 14:55:38 2022: Epoch [6], Iteration [100/391/], Data(s): 0.053, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.013, Top1: 93.379, Top5: 99.6287, Loss: 0.201\n",
            "Mon Apr 25 14:55:54 2022: Epoch [6], Iteration [200/391/], Data(s): 0.053, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.013, Top1: 93.451, Top5: 99.6813, Loss: 0.199\n",
            "Mon Apr 25 14:56:10 2022: Epoch [6], Iteration [300/391/], Data(s): 0.053, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.013, Top1: 93.529, Top5: 99.6600, Loss: 0.198\n",
            "Mon Apr 25 14:56:25 2022: Epoch [7], Iteration [0/391/], Data(s): 0.076, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.011, Top1: 93.750, Top5: 98.4375, Loss: 0.198\n",
            "Mon Apr 25 14:56:41 2022: Epoch [7], Iteration [100/391/], Data(s): 0.053, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.557, Top5: 99.6983, Loss: 0.198\n",
            "Mon Apr 25 14:56:57 2022: Epoch [7], Iteration [200/391/], Data(s): 0.052, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.501, Top5: 99.7046, Loss: 0.200\n",
            "Mon Apr 25 14:57:13 2022: Epoch [7], Iteration [300/391/], Data(s): 0.053, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.571, Top5: 99.7249, Loss: 0.190\n",
            "Mon Apr 25 14:57:28 2022: Epoch [8], Iteration [0/391/], Data(s): 0.078, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 91.406, Top5: 100.0000, Loss: 0.196\n",
            "Mon Apr 25 14:57:44 2022: Epoch [8], Iteration [100/391/], Data(s): 0.053, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.549, Top5: 99.7293, Loss: 0.194\n",
            "Mon Apr 25 14:58:00 2022: Epoch [8], Iteration [200/391/], Data(s): 0.053, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.013, Top1: 93.750, Top5: 99.7124, Loss: 0.185\n",
            "Mon Apr 25 14:58:16 2022: Epoch [8], Iteration [300/391/], Data(s): 0.053, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.013, Top1: 93.576, Top5: 99.7119, Loss: 0.202\n",
            "Mon Apr 25 14:58:31 2022: Epoch [9], Iteration [0/391/], Data(s): 0.075, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.312, Top5: 100.0000, Loss: 0.193\n",
            "Mon Apr 25 14:58:47 2022: Epoch [9], Iteration [100/391/], Data(s): 0.053, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.013, Top1: 94.075, Top5: 99.7834, Loss: 0.188\n",
            "Mon Apr 25 14:59:03 2022: Epoch [9], Iteration [200/391/], Data(s): 0.052, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.069, Top5: 99.7512, Loss: 0.181\n",
            "Mon Apr 25 14:59:19 2022: Epoch [9], Iteration [300/391/], Data(s): 0.052, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.942, Top5: 99.7690, Loss: 0.188\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 14:59:41 2022: Test information, Data(s): 2.598, Forward(s): 0.615, Top1: 90.680, Top5: 99.310, \n",
            "\n",
            "Mon Apr 25 14:59:41 2022: conv7 Layer, 98 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 158, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(158, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(158, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]          73,856\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "             ReLU-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]         147,584\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         295,168\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 158, 8, 8]         364,190\n",
            "      BatchNorm2d-22            [-1, 158, 8, 8]             316\n",
            "             ReLU-23            [-1, 158, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 158, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]         728,576\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 14,314,276\n",
            "Trainable params: 14,314,276\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 6.42\n",
            "Params size (MB): 54.60\n",
            "Estimated Total Size (MB): 61.04\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 158, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(158, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(158, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 14:59:43 2022: Epoch [0], Iteration [0/391/], Data(s): 0.053, Loss(s): 0.003, Forward(s): 0.140, Backward(s): 0.326, Top1: 94.531, Top5: 100.0000, Loss: 0.148\n",
            "Mon Apr 25 14:59:59 2022: Epoch [0], Iteration [100/391/], Data(s): 0.054, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.016, Top1: 93.379, Top5: 99.6829, Loss: 0.202\n",
            "Mon Apr 25 15:00:15 2022: Epoch [0], Iteration [200/391/], Data(s): 0.053, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.014, Top1: 93.606, Top5: 99.6735, Loss: 0.192\n",
            "Mon Apr 25 15:00:31 2022: Epoch [0], Iteration [300/391/], Data(s): 0.053, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.013, Top1: 93.716, Top5: 99.7093, Loss: 0.183\n",
            "Mon Apr 25 15:00:46 2022: Epoch [1], Iteration [0/391/], Data(s): 0.071, Loss(s): 0.030, Forward(s): 0.007, Backward(s): 0.012, Top1: 96.094, Top5: 100.0000, Loss: 0.192\n",
            "Mon Apr 25 15:01:02 2022: Epoch [1], Iteration [100/391/], Data(s): 0.055, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.742, Top5: 99.7447, Loss: 0.188\n",
            "Mon Apr 25 15:01:18 2022: Epoch [1], Iteration [200/391/], Data(s): 0.053, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.797, Top5: 99.7512, Loss: 0.186\n",
            "Mon Apr 25 15:01:34 2022: Epoch [1], Iteration [300/391/], Data(s): 0.053, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.766, Top5: 99.7327, Loss: 0.195\n",
            "Mon Apr 25 15:01:49 2022: Epoch [2], Iteration [0/391/], Data(s): 0.077, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.011, Top1: 93.750, Top5: 100.0000, Loss: 0.187\n",
            "Mon Apr 25 15:02:05 2022: Epoch [2], Iteration [100/391/], Data(s): 0.053, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.974, Top5: 99.7215, Loss: 0.185\n",
            "Mon Apr 25 15:02:21 2022: Epoch [2], Iteration [200/391/], Data(s): 0.052, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.960, Top5: 99.7590, Loss: 0.182\n",
            "Mon Apr 25 15:02:37 2022: Epoch [2], Iteration [300/391/], Data(s): 0.052, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.960, Top5: 99.7794, Loss: 0.178\n",
            "Mon Apr 25 15:02:51 2022: Epoch [3], Iteration [0/391/], Data(s): 0.070, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.531, Top5: 99.2188, Loss: 0.185\n",
            "Mon Apr 25 15:03:08 2022: Epoch [3], Iteration [100/391/], Data(s): 0.053, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.013, Top1: 94.005, Top5: 99.7525, Loss: 0.180\n",
            "Mon Apr 25 15:03:23 2022: Epoch [3], Iteration [200/391/], Data(s): 0.052, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.022, Top5: 99.7474, Loss: 0.181\n",
            "Mon Apr 25 15:03:39 2022: Epoch [3], Iteration [300/391/], Data(s): 0.052, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.048, Top5: 99.7612, Loss: 0.178\n",
            "Mon Apr 25 15:03:54 2022: Epoch [4], Iteration [0/391/], Data(s): 0.073, Loss(s): 0.029, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.188, Top5: 99.2188, Loss: 0.180\n",
            "Mon Apr 25 15:04:10 2022: Epoch [4], Iteration [100/391/], Data(s): 0.053, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.175, Top5: 99.7293, Loss: 0.176\n",
            "Mon Apr 25 15:04:26 2022: Epoch [4], Iteration [200/391/], Data(s): 0.052, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.166, Top5: 99.6852, Loss: 0.184\n",
            "Mon Apr 25 15:04:42 2022: Epoch [4], Iteration [300/391/], Data(s): 0.052, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.228, Top5: 99.7171, Loss: 0.171\n",
            "Mon Apr 25 15:04:57 2022: Epoch [5], Iteration [0/391/], Data(s): 0.094, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.012, Top1: 95.312, Top5: 100.0000, Loss: 0.180\n",
            "Mon Apr 25 15:05:13 2022: Epoch [5], Iteration [100/391/], Data(s): 0.054, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.021, Top5: 99.7679, Loss: 0.177\n",
            "Mon Apr 25 15:05:29 2022: Epoch [5], Iteration [200/391/], Data(s): 0.053, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.166, Top5: 99.7979, Loss: 0.171\n",
            "Mon Apr 25 15:05:45 2022: Epoch [5], Iteration [300/391/], Data(s): 0.052, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.147, Top5: 99.7924, Loss: 0.177\n",
            "Mon Apr 25 15:05:59 2022: Epoch [6], Iteration [0/391/], Data(s): 0.072, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.969, Top5: 100.0000, Loss: 0.176\n",
            "Mon Apr 25 15:06:16 2022: Epoch [6], Iteration [100/391/], Data(s): 0.053, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.446, Top5: 99.7447, Loss: 0.175\n",
            "Mon Apr 25 15:06:32 2022: Epoch [6], Iteration [200/391/], Data(s): 0.052, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.364, Top5: 99.7862, Loss: 0.169\n",
            "Mon Apr 25 15:06:47 2022: Epoch [6], Iteration [300/391/], Data(s): 0.052, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.388, Top5: 99.7898, Loss: 0.166\n",
            "Mon Apr 25 15:07:02 2022: Epoch [7], Iteration [0/391/], Data(s): 0.074, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.188, Top5: 100.0000, Loss: 0.176\n",
            "Mon Apr 25 15:07:18 2022: Epoch [7], Iteration [100/391/], Data(s): 0.053, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.253, Top5: 99.7679, Loss: 0.175\n",
            "Mon Apr 25 15:07:34 2022: Epoch [7], Iteration [200/391/], Data(s): 0.052, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.352, Top5: 99.7785, Loss: 0.170\n",
            "Mon Apr 25 15:07:50 2022: Epoch [7], Iteration [300/391/], Data(s): 0.051, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.446, Top5: 99.8053, Loss: 0.164\n",
            "Mon Apr 25 15:08:04 2022: Epoch [8], Iteration [0/391/], Data(s): 0.074, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 97.656, Top5: 100.0000, Loss: 0.173\n",
            "Mon Apr 25 15:08:20 2022: Epoch [8], Iteration [100/391/], Data(s): 0.052, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.400, Top5: 99.8221, Loss: 0.170\n",
            "Mon Apr 25 15:08:36 2022: Epoch [8], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.329, Top5: 99.7901, Loss: 0.173\n",
            "Mon Apr 25 15:08:52 2022: Epoch [8], Iteration [300/391/], Data(s): 0.051, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.308, Top5: 99.7820, Loss: 0.174\n",
            "Mon Apr 25 15:09:06 2022: Epoch [9], Iteration [0/391/], Data(s): 0.070, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.011, Top1: 95.312, Top5: 99.2188, Loss: 0.172\n",
            "Mon Apr 25 15:09:22 2022: Epoch [9], Iteration [100/391/], Data(s): 0.052, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.539, Top5: 99.7834, Loss: 0.164\n",
            "Mon Apr 25 15:09:38 2022: Epoch [9], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.574, Top5: 99.7940, Loss: 0.161\n",
            "Mon Apr 25 15:09:54 2022: Epoch [9], Iteration [300/391/], Data(s): 0.051, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.575, Top5: 99.8053, Loss: 0.163\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 15:10:15 2022: Test information, Data(s): 2.544, Forward(s): 0.603, Top1: 90.970, Top5: 99.290, \n",
            "\n",
            "Mon Apr 25 15:10:15 2022: conv7 Layer, 131 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 125, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(125, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(125, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]          73,856\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "             ReLU-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]         147,584\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         295,168\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 125, 8, 8]         288,125\n",
            "      BatchNorm2d-22            [-1, 125, 8, 8]             250\n",
            "             ReLU-23            [-1, 125, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 125, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]         576,512\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 14,086,081\n",
            "Trainable params: 14,086,081\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 6.37\n",
            "Params size (MB): 53.73\n",
            "Estimated Total Size (MB): 60.11\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 125, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(125, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(125, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 15:10:17 2022: Epoch [0], Iteration [0/391/], Data(s): 0.057, Loss(s): 0.003, Forward(s): 0.118, Backward(s): 0.274, Top1: 89.844, Top5: 100.0000, Loss: 0.254\n",
            "Mon Apr 25 15:10:33 2022: Epoch [0], Iteration [100/391/], Data(s): 0.053, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.015, Top1: 94.315, Top5: 99.8144, Loss: 0.167\n",
            "Mon Apr 25 15:10:49 2022: Epoch [0], Iteration [200/391/], Data(s): 0.052, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.014, Top1: 94.236, Top5: 99.7551, Loss: 0.176\n",
            "Mon Apr 25 15:11:04 2022: Epoch [0], Iteration [300/391/], Data(s): 0.052, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 94.303, Top5: 99.7404, Loss: 0.171\n",
            "Mon Apr 25 15:11:19 2022: Epoch [1], Iteration [0/391/], Data(s): 0.077, Loss(s): 0.029, Forward(s): 0.007, Backward(s): 0.012, Top1: 93.750, Top5: 100.0000, Loss: 0.168\n",
            "Mon Apr 25 15:11:35 2022: Epoch [1], Iteration [100/391/], Data(s): 0.052, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.585, Top5: 99.8298, Loss: 0.163\n",
            "Mon Apr 25 15:11:51 2022: Epoch [1], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.601, Top5: 99.8601, Loss: 0.161\n",
            "Mon Apr 25 15:12:06 2022: Epoch [1], Iteration [300/391/], Data(s): 0.051, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.469, Top5: 99.8287, Loss: 0.174\n",
            "Mon Apr 25 15:12:21 2022: Epoch [2], Iteration [0/391/], Data(s): 0.073, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.188, Top5: 100.0000, Loss: 0.164\n",
            "Mon Apr 25 15:12:36 2022: Epoch [2], Iteration [100/391/], Data(s): 0.052, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 94.369, Top5: 99.8453, Loss: 0.167\n",
            "Mon Apr 25 15:12:52 2022: Epoch [2], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.539, Top5: 99.8173, Loss: 0.157\n",
            "Mon Apr 25 15:13:08 2022: Epoch [2], Iteration [300/391/], Data(s): 0.051, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.666, Top5: 99.8209, Loss: 0.156\n",
            "Mon Apr 25 15:13:22 2022: Epoch [3], Iteration [0/391/], Data(s): 0.079, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.969, Top5: 100.0000, Loss: 0.161\n",
            "Mon Apr 25 15:13:38 2022: Epoch [3], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.477, Top5: 99.8298, Loss: 0.159\n",
            "Mon Apr 25 15:13:53 2022: Epoch [3], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.663, Top5: 99.8445, Loss: 0.157\n",
            "Mon Apr 25 15:14:09 2022: Epoch [3], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.656, Top5: 99.8417, Loss: 0.157\n",
            "Mon Apr 25 15:14:23 2022: Epoch [4], Iteration [0/391/], Data(s): 0.076, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.875, Top5: 100.0000, Loss: 0.156\n",
            "Mon Apr 25 15:14:39 2022: Epoch [4], Iteration [100/391/], Data(s): 0.052, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.019, Top5: 99.8608, Loss: 0.157\n",
            "Mon Apr 25 15:14:55 2022: Epoch [4], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.935, Top5: 99.8251, Loss: 0.155\n",
            "Mon Apr 25 15:15:10 2022: Epoch [4], Iteration [300/391/], Data(s): 0.051, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.900, Top5: 99.8157, Loss: 0.157\n",
            "Mon Apr 25 15:15:25 2022: Epoch [5], Iteration [0/391/], Data(s): 0.076, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.011, Top1: 89.062, Top5: 99.2188, Loss: 0.159\n",
            "Mon Apr 25 15:15:40 2022: Epoch [5], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.694, Top5: 99.7912, Loss: 0.157\n",
            "Mon Apr 25 15:15:56 2022: Epoch [5], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.815, Top5: 99.7901, Loss: 0.151\n",
            "Mon Apr 25 15:16:12 2022: Epoch [5], Iteration [300/391/], Data(s): 0.051, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.895, Top5: 99.8053, Loss: 0.148\n",
            "Mon Apr 25 15:16:26 2022: Epoch [6], Iteration [0/391/], Data(s): 0.071, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.094, Top5: 100.0000, Loss: 0.163\n",
            "Mon Apr 25 15:16:42 2022: Epoch [6], Iteration [100/391/], Data(s): 0.052, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.158, Top5: 99.8221, Loss: 0.145\n",
            "Mon Apr 25 15:16:58 2022: Epoch [6], Iteration [200/391/], Data(s): 0.052, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.838, Top5: 99.8445, Loss: 0.162\n",
            "Mon Apr 25 15:17:14 2022: Epoch [6], Iteration [300/391/], Data(s): 0.052, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 94.809, Top5: 99.8183, Loss: 0.159\n",
            "Mon Apr 25 15:17:28 2022: Epoch [7], Iteration [0/391/], Data(s): 0.071, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 96.875, Top5: 100.0000, Loss: 0.147\n",
            "Mon Apr 25 15:17:44 2022: Epoch [7], Iteration [100/391/], Data(s): 0.053, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.429, Top5: 99.8376, Loss: 0.140\n",
            "Mon Apr 25 15:18:00 2022: Epoch [7], Iteration [200/391/], Data(s): 0.052, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.289, Top5: 99.8484, Loss: 0.149\n",
            "Mon Apr 25 15:18:15 2022: Epoch [7], Iteration [300/391/], Data(s): 0.051, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.069, Top5: 99.8365, Loss: 0.162\n",
            "Mon Apr 25 15:18:30 2022: Epoch [8], Iteration [0/391/], Data(s): 0.074, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.875, Top5: 100.0000, Loss: 0.158\n",
            "Mon Apr 25 15:18:45 2022: Epoch [8], Iteration [100/391/], Data(s): 0.052, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.429, Top5: 99.8530, Loss: 0.143\n",
            "Mon Apr 25 15:19:01 2022: Epoch [8], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.274, Top5: 99.8290, Loss: 0.150\n",
            "Mon Apr 25 15:19:17 2022: Epoch [8], Iteration [300/391/], Data(s): 0.051, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.266, Top5: 99.8339, Loss: 0.144\n",
            "Mon Apr 25 15:19:31 2022: Epoch [9], Iteration [0/391/], Data(s): 0.073, Loss(s): 0.025, Forward(s): 0.008, Backward(s): 0.012, Top1: 96.875, Top5: 100.0000, Loss: 0.147\n",
            "Mon Apr 25 15:19:47 2022: Epoch [9], Iteration [100/391/], Data(s): 0.052, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.848, Top5: 99.8221, Loss: 0.151\n",
            "Mon Apr 25 15:20:03 2022: Epoch [9], Iteration [200/391/], Data(s): 0.052, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.141, Top5: 99.8406, Loss: 0.139\n",
            "Mon Apr 25 15:20:18 2022: Epoch [9], Iteration [300/391/], Data(s): 0.051, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.149, Top5: 99.8469, Loss: 0.147\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 15:20:40 2022: Test information, Data(s): 2.524, Forward(s): 0.588, Top1: 91.120, Top5: 99.320, \n",
            "\n",
            "Mon Apr 25 15:20:40 2022: conv7 Layer, 164 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 92, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(92, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(92, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]          73,856\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "             ReLU-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]         147,584\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         295,168\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21             [-1, 92, 8, 8]         212,060\n",
            "      BatchNorm2d-22             [-1, 92, 8, 8]             184\n",
            "             ReLU-23             [-1, 92, 8, 8]               0\n",
            "        MaxPool2d-24             [-1, 92, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]         424,448\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 13,857,886\n",
            "Trainable params: 13,857,886\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 6.31\n",
            "Params size (MB): 52.86\n",
            "Estimated Total Size (MB): 59.19\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 92, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(92, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(92, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 15:20:41 2022: Epoch [0], Iteration [0/391/], Data(s): 0.050, Loss(s): 0.003, Forward(s): 0.105, Backward(s): 0.159, Top1: 94.531, Top5: 99.2188, Loss: 0.134\n",
            "Mon Apr 25 15:20:57 2022: Epoch [0], Iteration [100/391/], Data(s): 0.052, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.014, Top1: 94.663, Top5: 99.7525, Loss: 0.162\n",
            "Mon Apr 25 15:21:13 2022: Epoch [0], Iteration [200/391/], Data(s): 0.052, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 94.889, Top5: 99.8095, Loss: 0.147\n",
            "Mon Apr 25 15:21:28 2022: Epoch [0], Iteration [300/391/], Data(s): 0.052, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 94.793, Top5: 99.8001, Loss: 0.160\n",
            "Mon Apr 25 15:21:43 2022: Epoch [1], Iteration [0/391/], Data(s): 0.072, Loss(s): 0.026, Forward(s): 0.008, Backward(s): 0.012, Top1: 97.656, Top5: 100.0000, Loss: 0.154\n",
            "Mon Apr 25 15:21:59 2022: Epoch [1], Iteration [100/391/], Data(s): 0.053, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.196, Top5: 99.8530, Loss: 0.144\n",
            "Mon Apr 25 15:22:14 2022: Epoch [1], Iteration [200/391/], Data(s): 0.053, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.130, Top5: 99.8562, Loss: 0.150\n",
            "Mon Apr 25 15:22:30 2022: Epoch [1], Iteration [300/391/], Data(s): 0.052, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.154, Top5: 99.8521, Loss: 0.144\n",
            "Mon Apr 25 15:22:45 2022: Epoch [2], Iteration [0/391/], Data(s): 0.074, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.531, Top5: 100.0000, Loss: 0.148\n",
            "Mon Apr 25 15:23:00 2022: Epoch [2], Iteration [100/391/], Data(s): 0.054, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.181, Top5: 99.8608, Loss: 0.146\n",
            "Mon Apr 25 15:23:16 2022: Epoch [2], Iteration [200/391/], Data(s): 0.053, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.122, Top5: 99.8406, Loss: 0.148\n",
            "Mon Apr 25 15:23:32 2022: Epoch [2], Iteration [300/391/], Data(s): 0.053, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.165, Top5: 99.8521, Loss: 0.145\n",
            "Mon Apr 25 15:23:46 2022: Epoch [3], Iteration [0/391/], Data(s): 0.080, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.011, Top1: 96.094, Top5: 99.2188, Loss: 0.143\n",
            "Mon Apr 25 15:24:02 2022: Epoch [3], Iteration [100/391/], Data(s): 0.053, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.374, Top5: 99.8530, Loss: 0.139\n",
            "Mon Apr 25 15:24:18 2022: Epoch [3], Iteration [200/391/], Data(s): 0.053, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.192, Top5: 99.8601, Loss: 0.144\n",
            "Mon Apr 25 15:24:33 2022: Epoch [3], Iteration [300/391/], Data(s): 0.052, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.219, Top5: 99.8624, Loss: 0.141\n",
            "Mon Apr 25 15:24:48 2022: Epoch [4], Iteration [0/391/], Data(s): 0.072, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 96.094, Top5: 100.0000, Loss: 0.143\n",
            "Mon Apr 25 15:25:04 2022: Epoch [4], Iteration [100/391/], Data(s): 0.053, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.583, Top5: 99.8530, Loss: 0.136\n",
            "Mon Apr 25 15:25:19 2022: Epoch [4], Iteration [200/391/], Data(s): 0.053, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.561, Top5: 99.8640, Loss: 0.142\n",
            "Mon Apr 25 15:25:35 2022: Epoch [4], Iteration [300/391/], Data(s): 0.053, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.611, Top5: 99.8572, Loss: 0.132\n",
            "Mon Apr 25 15:25:50 2022: Epoch [5], Iteration [0/391/], Data(s): 0.076, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.094, Top5: 100.0000, Loss: 0.149\n",
            "Mon Apr 25 15:26:05 2022: Epoch [5], Iteration [100/391/], Data(s): 0.053, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.436, Top5: 99.8762, Loss: 0.136\n",
            "Mon Apr 25 15:26:21 2022: Epoch [5], Iteration [200/391/], Data(s): 0.053, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.289, Top5: 99.8795, Loss: 0.143\n",
            "Mon Apr 25 15:26:37 2022: Epoch [5], Iteration [300/391/], Data(s): 0.053, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.258, Top5: 99.8728, Loss: 0.140\n",
            "Mon Apr 25 15:26:51 2022: Epoch [6], Iteration [0/391/], Data(s): 0.083, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.188, Top5: 100.0000, Loss: 0.138\n",
            "Mon Apr 25 15:27:07 2022: Epoch [6], Iteration [100/391/], Data(s): 0.053, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.529, Top5: 99.8840, Loss: 0.134\n",
            "Mon Apr 25 15:27:23 2022: Epoch [6], Iteration [200/391/], Data(s): 0.053, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.697, Top5: 99.8795, Loss: 0.128\n",
            "Mon Apr 25 15:27:38 2022: Epoch [6], Iteration [300/391/], Data(s): 0.052, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.608, Top5: 99.8832, Loss: 0.141\n",
            "Mon Apr 25 15:27:53 2022: Epoch [7], Iteration [0/391/], Data(s): 0.077, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.312, Top5: 100.0000, Loss: 0.131\n",
            "Mon Apr 25 15:28:09 2022: Epoch [7], Iteration [100/391/], Data(s): 0.053, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.583, Top5: 99.9304, Loss: 0.130\n",
            "Mon Apr 25 15:28:24 2022: Epoch [7], Iteration [200/391/], Data(s): 0.053, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.728, Top5: 99.9223, Loss: 0.129\n",
            "Mon Apr 25 15:28:40 2022: Epoch [7], Iteration [300/391/], Data(s): 0.052, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.663, Top5: 99.9040, Loss: 0.138\n",
            "Mon Apr 25 15:28:54 2022: Epoch [8], Iteration [0/391/], Data(s): 0.089, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.094, Top5: 100.0000, Loss: 0.132\n",
            "Mon Apr 25 15:29:10 2022: Epoch [8], Iteration [100/391/], Data(s): 0.054, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.854, Top5: 99.8762, Loss: 0.130\n",
            "Mon Apr 25 15:29:26 2022: Epoch [8], Iteration [200/391/], Data(s): 0.053, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.864, Top5: 99.8756, Loss: 0.128\n",
            "Mon Apr 25 15:29:42 2022: Epoch [8], Iteration [300/391/], Data(s): 0.053, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.767, Top5: 99.8754, Loss: 0.130\n",
            "Mon Apr 25 15:29:56 2022: Epoch [9], Iteration [0/391/], Data(s): 0.074, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.312, Top5: 100.0000, Loss: 0.127\n",
            "Mon Apr 25 15:30:12 2022: Epoch [9], Iteration [100/391/], Data(s): 0.054, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.552, Top5: 99.8762, Loss: 0.136\n",
            "Mon Apr 25 15:30:28 2022: Epoch [9], Iteration [200/391/], Data(s): 0.053, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.748, Top5: 99.8795, Loss: 0.124\n",
            "Mon Apr 25 15:30:43 2022: Epoch [9], Iteration [300/391/], Data(s): 0.052, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.795, Top5: 99.8780, Loss: 0.124\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 15:31:04 2022: Test information, Data(s): 2.542, Forward(s): 0.580, Top1: 91.180, Top5: 99.300, \n",
            "\n",
            "Mon Apr 25 15:31:04 2022: conv7 Layer, 197 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 59, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(59, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(59, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]          73,856\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "             ReLU-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]         147,584\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         295,168\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21             [-1, 59, 8, 8]         135,995\n",
            "      BatchNorm2d-22             [-1, 59, 8, 8]             118\n",
            "             ReLU-23             [-1, 59, 8, 8]               0\n",
            "        MaxPool2d-24             [-1, 59, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]         272,384\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 13,629,691\n",
            "Trainable params: 13,629,691\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 6.26\n",
            "Params size (MB): 51.99\n",
            "Estimated Total Size (MB): 58.27\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 59, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(59, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(59, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 15:31:06 2022: Epoch [0], Iteration [0/391/], Data(s): 0.053, Loss(s): 0.003, Forward(s): 0.104, Backward(s): 0.118, Top1: 93.750, Top5: 99.2188, Loss: 0.168\n",
            "Mon Apr 25 15:31:21 2022: Epoch [0], Iteration [100/391/], Data(s): 0.054, Loss(s): 0.026, Forward(s): 0.007, Backward(s): 0.014, Top1: 94.539, Top5: 99.8453, Loss: 0.162\n",
            "Mon Apr 25 15:31:37 2022: Epoch [0], Iteration [200/391/], Data(s): 0.052, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.013, Top1: 94.636, Top5: 99.8445, Loss: 0.157\n",
            "Mon Apr 25 15:31:52 2022: Epoch [0], Iteration [300/391/], Data(s): 0.052, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.013, Top1: 94.845, Top5: 99.8365, Loss: 0.145\n",
            "Mon Apr 25 15:32:07 2022: Epoch [1], Iteration [0/391/], Data(s): 0.076, Loss(s): 0.026, Forward(s): 0.008, Backward(s): 0.012, Top1: 95.312, Top5: 100.0000, Loss: 0.148\n",
            "Mon Apr 25 15:32:22 2022: Epoch [1], Iteration [100/391/], Data(s): 0.054, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.514, Top5: 99.8840, Loss: 0.137\n",
            "Mon Apr 25 15:32:38 2022: Epoch [1], Iteration [200/391/], Data(s): 0.053, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.445, Top5: 99.8717, Loss: 0.137\n",
            "Mon Apr 25 15:32:53 2022: Epoch [1], Iteration [300/391/], Data(s): 0.052, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.453, Top5: 99.8780, Loss: 0.140\n",
            "Mon Apr 25 15:33:08 2022: Epoch [2], Iteration [0/391/], Data(s): 0.077, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.094, Top5: 100.0000, Loss: 0.138\n",
            "Mon Apr 25 15:33:23 2022: Epoch [2], Iteration [100/391/], Data(s): 0.053, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.637, Top5: 99.8762, Loss: 0.129\n",
            "Mon Apr 25 15:33:39 2022: Epoch [2], Iteration [200/391/], Data(s): 0.052, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.581, Top5: 99.8562, Loss: 0.136\n",
            "Mon Apr 25 15:33:54 2022: Epoch [2], Iteration [300/391/], Data(s): 0.052, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.481, Top5: 99.8495, Loss: 0.142\n",
            "Mon Apr 25 15:34:09 2022: Epoch [3], Iteration [0/391/], Data(s): 0.072, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.750, Top5: 100.0000, Loss: 0.139\n",
            "Mon Apr 25 15:34:24 2022: Epoch [3], Iteration [100/391/], Data(s): 0.053, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.715, Top5: 99.8453, Loss: 0.130\n",
            "Mon Apr 25 15:34:40 2022: Epoch [3], Iteration [200/391/], Data(s): 0.052, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.674, Top5: 99.8717, Loss: 0.131\n",
            "Mon Apr 25 15:34:55 2022: Epoch [3], Iteration [300/391/], Data(s): 0.052, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.593, Top5: 99.8624, Loss: 0.138\n",
            "Mon Apr 25 15:35:09 2022: Epoch [4], Iteration [0/391/], Data(s): 0.075, Loss(s): 0.023, Forward(s): 0.009, Backward(s): 0.012, Top1: 94.531, Top5: 99.2188, Loss: 0.135\n",
            "Mon Apr 25 15:35:25 2022: Epoch [4], Iteration [100/391/], Data(s): 0.053, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.668, Top5: 99.8917, Loss: 0.127\n",
            "Mon Apr 25 15:35:40 2022: Epoch [4], Iteration [200/391/], Data(s): 0.052, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.826, Top5: 99.8834, Loss: 0.125\n",
            "Mon Apr 25 15:35:56 2022: Epoch [4], Iteration [300/391/], Data(s): 0.052, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.873, Top5: 99.8598, Loss: 0.125\n",
            "Mon Apr 25 15:36:10 2022: Epoch [5], Iteration [0/391/], Data(s): 0.074, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.750, Top5: 100.0000, Loss: 0.135\n",
            "Mon Apr 25 15:36:26 2022: Epoch [5], Iteration [100/391/], Data(s): 0.053, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.900, Top5: 99.8685, Loss: 0.126\n",
            "Mon Apr 25 15:36:41 2022: Epoch [5], Iteration [200/391/], Data(s): 0.052, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.682, Top5: 99.8951, Loss: 0.131\n",
            "Mon Apr 25 15:36:57 2022: Epoch [5], Iteration [300/391/], Data(s): 0.052, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.678, Top5: 99.8806, Loss: 0.129\n",
            "Mon Apr 25 15:37:11 2022: Epoch [6], Iteration [0/391/], Data(s): 0.074, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.312, Top5: 100.0000, Loss: 0.131\n",
            "Mon Apr 25 15:37:27 2022: Epoch [6], Iteration [100/391/], Data(s): 0.053, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.086, Top5: 99.9536, Loss: 0.119\n",
            "Mon Apr 25 15:37:42 2022: Epoch [6], Iteration [200/391/], Data(s): 0.052, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.985, Top5: 99.9145, Loss: 0.124\n",
            "Mon Apr 25 15:37:58 2022: Epoch [6], Iteration [300/391/], Data(s): 0.052, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.959, Top5: 99.9040, Loss: 0.121\n",
            "Mon Apr 25 15:38:12 2022: Epoch [7], Iteration [0/391/], Data(s): 0.076, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.875, Top5: 100.0000, Loss: 0.121\n",
            "Mon Apr 25 15:38:27 2022: Epoch [7], Iteration [100/391/], Data(s): 0.052, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.078, Top5: 99.8762, Loss: 0.118\n",
            "Mon Apr 25 15:38:43 2022: Epoch [7], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.763, Top5: 99.8912, Loss: 0.132\n",
            "Mon Apr 25 15:38:58 2022: Epoch [7], Iteration [300/391/], Data(s): 0.051, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.884, Top5: 99.8936, Loss: 0.115\n",
            "Mon Apr 25 15:39:12 2022: Epoch [8], Iteration [0/391/], Data(s): 0.069, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 97.656, Top5: 100.0000, Loss: 0.118\n",
            "Mon Apr 25 15:39:28 2022: Epoch [8], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.908, Top5: 99.8994, Loss: 0.125\n",
            "Mon Apr 25 15:39:43 2022: Epoch [8], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.125, Top5: 99.8989, Loss: 0.113\n",
            "Mon Apr 25 15:39:59 2022: Epoch [8], Iteration [300/391/], Data(s): 0.051, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.120, Top5: 99.9040, Loss: 0.115\n",
            "Mon Apr 25 15:40:13 2022: Epoch [9], Iteration [0/391/], Data(s): 0.075, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 97.656, Top5: 100.0000, Loss: 0.119\n",
            "Mon Apr 25 15:40:29 2022: Epoch [9], Iteration [100/391/], Data(s): 0.053, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.013, Top1: 96.179, Top5: 99.8762, Loss: 0.119\n",
            "Mon Apr 25 15:40:44 2022: Epoch [9], Iteration [200/391/], Data(s): 0.052, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.059, Top5: 99.9028, Loss: 0.118\n",
            "Mon Apr 25 15:40:59 2022: Epoch [9], Iteration [300/391/], Data(s): 0.052, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.083, Top5: 99.9169, Loss: 0.118\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 15:41:20 2022: Test information, Data(s): 2.538, Forward(s): 0.568, Top1: 90.880, Top5: 99.260, \n",
            "\n",
            "Mon Apr 25 15:41:20 2022: conv7 Layer, 230 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 26, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(26, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]          73,856\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "             ReLU-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]         147,584\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         295,168\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21             [-1, 26, 8, 8]          59,930\n",
            "      BatchNorm2d-22             [-1, 26, 8, 8]              52\n",
            "             ReLU-23             [-1, 26, 8, 8]               0\n",
            "        MaxPool2d-24             [-1, 26, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]         120,320\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 13,401,496\n",
            "Trainable params: 13,401,496\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 6.21\n",
            "Params size (MB): 51.12\n",
            "Estimated Total Size (MB): 57.34\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 26, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(26, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 15:41:22 2022: Epoch [0], Iteration [0/391/], Data(s): 0.064, Loss(s): 0.003, Forward(s): 0.083, Backward(s): 0.089, Top1: 90.625, Top5: 99.2188, Loss: 0.286\n",
            "Mon Apr 25 15:41:37 2022: Epoch [0], Iteration [100/391/], Data(s): 0.052, Loss(s): 0.026, Forward(s): 0.007, Backward(s): 0.013, Top1: 91.468, Top5: 99.4972, Loss: 0.252\n",
            "Mon Apr 25 15:41:53 2022: Epoch [0], Iteration [200/391/], Data(s): 0.052, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.013, Top1: 92.432, Top5: 99.5802, Loss: 0.198\n",
            "Mon Apr 25 15:42:08 2022: Epoch [0], Iteration [300/391/], Data(s): 0.052, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.013, Top1: 92.821, Top5: 99.6081, Loss: 0.188\n",
            "Mon Apr 25 15:42:22 2022: Epoch [1], Iteration [0/391/], Data(s): 0.071, Loss(s): 0.025, Forward(s): 0.007, Backward(s): 0.012, Top1: 95.312, Top5: 100.0000, Loss: 0.184\n",
            "Mon Apr 25 15:42:38 2022: Epoch [1], Iteration [100/391/], Data(s): 0.053, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.013, Top1: 94.299, Top5: 99.7912, Loss: 0.164\n",
            "Mon Apr 25 15:42:53 2022: Epoch [1], Iteration [200/391/], Data(s): 0.052, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.356, Top5: 99.7707, Loss: 0.173\n",
            "Mon Apr 25 15:43:08 2022: Epoch [1], Iteration [300/391/], Data(s): 0.052, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.433, Top5: 99.7950, Loss: 0.164\n",
            "Mon Apr 25 15:43:23 2022: Epoch [2], Iteration [0/391/], Data(s): 0.073, Loss(s): 0.025, Forward(s): 0.007, Backward(s): 0.012, Top1: 97.656, Top5: 100.0000, Loss: 0.153\n",
            "Mon Apr 25 15:43:38 2022: Epoch [2], Iteration [100/391/], Data(s): 0.052, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.771, Top5: 99.8685, Loss: 0.156\n",
            "Mon Apr 25 15:43:53 2022: Epoch [2], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.807, Top5: 99.8406, Loss: 0.152\n",
            "Mon Apr 25 15:44:09 2022: Epoch [2], Iteration [300/391/], Data(s): 0.051, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.876, Top5: 99.8365, Loss: 0.147\n",
            "Mon Apr 25 15:44:23 2022: Epoch [3], Iteration [0/391/], Data(s): 0.067, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.312, Top5: 100.0000, Loss: 0.158\n",
            "Mon Apr 25 15:44:38 2022: Epoch [3], Iteration [100/391/], Data(s): 0.052, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.088, Top5: 99.8530, Loss: 0.147\n",
            "Mon Apr 25 15:44:53 2022: Epoch [3], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.932, Top5: 99.8640, Loss: 0.153\n",
            "Mon Apr 25 15:45:09 2022: Epoch [3], Iteration [300/391/], Data(s): 0.051, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.001, Top5: 99.8598, Loss: 0.144\n",
            "Mon Apr 25 15:45:23 2022: Epoch [4], Iteration [0/391/], Data(s): 0.073, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.011, Top1: 94.531, Top5: 100.0000, Loss: 0.139\n",
            "Mon Apr 25 15:45:38 2022: Epoch [4], Iteration [100/391/], Data(s): 0.052, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.421, Top5: 99.8221, Loss: 0.140\n",
            "Mon Apr 25 15:45:54 2022: Epoch [4], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.519, Top5: 99.8445, Loss: 0.134\n",
            "Mon Apr 25 15:46:09 2022: Epoch [4], Iteration [300/391/], Data(s): 0.051, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.349, Top5: 99.8417, Loss: 0.149\n",
            "Mon Apr 25 15:46:23 2022: Epoch [5], Iteration [0/391/], Data(s): 0.085, Loss(s): 0.026, Forward(s): 0.005, Backward(s): 0.012, Top1: 96.094, Top5: 100.0000, Loss: 0.141\n",
            "Mon Apr 25 15:46:38 2022: Epoch [5], Iteration [100/391/], Data(s): 0.052, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.436, Top5: 99.8298, Loss: 0.138\n",
            "Mon Apr 25 15:46:54 2022: Epoch [5], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.596, Top5: 99.8717, Loss: 0.122\n",
            "Mon Apr 25 15:47:09 2022: Epoch [5], Iteration [300/391/], Data(s): 0.051, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.497, Top5: 99.8650, Loss: 0.135\n",
            "Mon Apr 25 15:47:23 2022: Epoch [6], Iteration [0/391/], Data(s): 0.071, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.094, Top5: 100.0000, Loss: 0.133\n",
            "Mon Apr 25 15:47:38 2022: Epoch [6], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.653, Top5: 99.9072, Loss: 0.130\n",
            "Mon Apr 25 15:47:53 2022: Epoch [6], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.670, Top5: 99.8795, Loss: 0.128\n",
            "Mon Apr 25 15:48:09 2022: Epoch [6], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.660, Top5: 99.8676, Loss: 0.132\n",
            "Mon Apr 25 15:48:23 2022: Epoch [7], Iteration [0/391/], Data(s): 0.071, Loss(s): 0.025, Forward(s): 0.006, Backward(s): 0.013, Top1: 96.094, Top5: 100.0000, Loss: 0.128\n",
            "Mon Apr 25 15:48:38 2022: Epoch [7], Iteration [100/391/], Data(s): 0.052, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.063, Top5: 99.8762, Loss: 0.118\n",
            "Mon Apr 25 15:48:54 2022: Epoch [7], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.969, Top5: 99.8912, Loss: 0.125\n",
            "Mon Apr 25 15:49:09 2022: Epoch [7], Iteration [300/391/], Data(s): 0.051, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.896, Top5: 99.8754, Loss: 0.130\n",
            "Mon Apr 25 15:49:23 2022: Epoch [8], Iteration [0/391/], Data(s): 0.083, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.011, Top1: 96.094, Top5: 99.2188, Loss: 0.125\n",
            "Mon Apr 25 15:49:38 2022: Epoch [8], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.823, Top5: 99.8994, Loss: 0.129\n",
            "Mon Apr 25 15:49:53 2022: Epoch [8], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.927, Top5: 99.9067, Loss: 0.124\n",
            "Mon Apr 25 15:50:08 2022: Epoch [8], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.951, Top5: 99.8962, Loss: 0.123\n",
            "Mon Apr 25 15:50:22 2022: Epoch [9], Iteration [0/391/], Data(s): 0.071, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.013, Top1: 96.875, Top5: 99.2188, Loss: 0.121\n",
            "Mon Apr 25 15:50:38 2022: Epoch [9], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.893, Top5: 99.9149, Loss: 0.119\n",
            "Mon Apr 25 15:50:53 2022: Epoch [9], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.063, Top5: 99.8951, Loss: 0.118\n",
            "Mon Apr 25 15:51:08 2022: Epoch [9], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.008, Top5: 99.8988, Loss: 0.122\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 15:51:29 2022: Test information, Data(s): 2.435, Forward(s): 0.542, Top1: 90.730, Top5: 99.260, \n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 15:51:38 2022: Test information, Data(s): 2.487, Forward(s): 0.475, Top1: 77.870, Top5: 97.560, \n",
            "\n",
            "Mon Apr 25 15:51:38 2022: conv8 Layer, 65 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 447, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(447, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(447, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]          73,856\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "             ReLU-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]         147,584\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         295,168\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 447, 4, 4]       1,030,335\n",
            "      BatchNorm2d-26            [-1, 447, 4, 4]             894\n",
            "             ReLU-27            [-1, 447, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       2,060,288\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 14,542,471\n",
            "Trainable params: 14,542,471\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 6.55\n",
            "Params size (MB): 55.48\n",
            "Estimated Total Size (MB): 62.04\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 447, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(447, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(447, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 15:51:40 2022: Epoch [0], Iteration [0/391/], Data(s): 0.054, Loss(s): 0.003, Forward(s): 0.269, Backward(s): 0.736, Top1: 85.156, Top5: 98.4375, Loss: 0.506\n",
            "Mon Apr 25 15:51:56 2022: Epoch [0], Iteration [100/391/], Data(s): 0.050, Loss(s): 0.028, Forward(s): 0.009, Backward(s): 0.019, Top1: 87.183, Top5: 99.0640, Loss: 0.399\n",
            "Mon Apr 25 15:52:12 2022: Epoch [0], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.016, Top1: 87.939, Top5: 99.1099, Loss: 0.350\n",
            "Mon Apr 25 15:52:28 2022: Epoch [0], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.014, Top1: 88.190, Top5: 99.1175, Loss: 0.341\n",
            "Mon Apr 25 15:52:44 2022: Epoch [1], Iteration [0/391/], Data(s): 0.074, Loss(s): 0.029, Forward(s): 0.007, Backward(s): 0.012, Top1: 89.844, Top5: 96.8750, Loss: 0.315\n",
            "Mon Apr 25 15:53:00 2022: Epoch [1], Iteration [100/391/], Data(s): 0.053, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.013, Top1: 89.991, Top5: 99.3270, Loss: 0.312\n",
            "Mon Apr 25 15:53:16 2022: Epoch [1], Iteration [200/391/], Data(s): 0.052, Loss(s): 0.029, Forward(s): 0.006, Backward(s): 0.013, Top1: 89.991, Top5: 99.3043, Loss: 0.304\n",
            "Mon Apr 25 15:53:32 2022: Epoch [1], Iteration [300/391/], Data(s): 0.052, Loss(s): 0.029, Forward(s): 0.006, Backward(s): 0.012, Top1: 90.267, Top5: 99.3511, Loss: 0.289\n",
            "Mon Apr 25 15:53:47 2022: Epoch [2], Iteration [0/391/], Data(s): 0.075, Loss(s): 0.029, Forward(s): 0.006, Backward(s): 0.011, Top1: 86.719, Top5: 99.2188, Loss: 0.294\n",
            "Mon Apr 25 15:54:03 2022: Epoch [2], Iteration [100/391/], Data(s): 0.052, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 91.120, Top5: 99.4663, Loss: 0.273\n",
            "Mon Apr 25 15:54:19 2022: Epoch [2], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.029, Forward(s): 0.006, Backward(s): 0.012, Top1: 90.905, Top5: 99.4364, Loss: 0.284\n",
            "Mon Apr 25 15:54:36 2022: Epoch [2], Iteration [300/391/], Data(s): 0.051, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 90.923, Top5: 99.4627, Loss: 0.277\n",
            "Mon Apr 25 15:54:50 2022: Epoch [3], Iteration [0/391/], Data(s): 0.075, Loss(s): 0.029, Forward(s): 0.006, Backward(s): 0.012, Top1: 90.625, Top5: 100.0000, Loss: 0.283\n",
            "Mon Apr 25 15:55:07 2022: Epoch [3], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.013, Top1: 91.066, Top5: 99.5436, Loss: 0.273\n",
            "Mon Apr 25 15:55:23 2022: Epoch [3], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 91.301, Top5: 99.5219, Loss: 0.265\n",
            "Mon Apr 25 15:55:39 2022: Epoch [3], Iteration [300/391/], Data(s): 0.051, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 91.398, Top5: 99.5614, Loss: 0.261\n",
            "Mon Apr 25 15:55:54 2022: Epoch [4], Iteration [0/391/], Data(s): 0.077, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 90.625, Top5: 98.4375, Loss: 0.273\n",
            "Mon Apr 25 15:56:10 2022: Epoch [4], Iteration [100/391/], Data(s): 0.052, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 91.925, Top5: 99.5359, Loss: 0.251\n",
            "Mon Apr 25 15:56:26 2022: Epoch [4], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.029, Forward(s): 0.006, Backward(s): 0.012, Top1: 91.935, Top5: 99.5141, Loss: 0.255\n",
            "Mon Apr 25 15:56:42 2022: Epoch [4], Iteration [300/391/], Data(s): 0.051, Loss(s): 0.029, Forward(s): 0.006, Backward(s): 0.012, Top1: 91.809, Top5: 99.5380, Loss: 0.261\n",
            "Mon Apr 25 15:56:57 2022: Epoch [5], Iteration [0/391/], Data(s): 0.075, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.012, Top1: 88.281, Top5: 99.2188, Loss: 0.259\n",
            "Mon Apr 25 15:57:13 2022: Epoch [5], Iteration [100/391/], Data(s): 0.052, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.327, Top5: 99.5359, Loss: 0.238\n",
            "Mon Apr 25 15:57:29 2022: Epoch [5], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.075, Top5: 99.5414, Loss: 0.256\n",
            "Mon Apr 25 15:57:45 2022: Epoch [5], Iteration [300/391/], Data(s): 0.051, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 91.962, Top5: 99.5406, Loss: 0.255\n",
            "Mon Apr 25 15:58:00 2022: Epoch [6], Iteration [0/391/], Data(s): 0.076, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.531, Top5: 100.0000, Loss: 0.242\n",
            "Mon Apr 25 15:58:16 2022: Epoch [6], Iteration [100/391/], Data(s): 0.053, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.543, Top5: 99.6287, Loss: 0.236\n",
            "Mon Apr 25 15:58:32 2022: Epoch [6], Iteration [200/391/], Data(s): 0.052, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.335, Top5: 99.5997, Loss: 0.245\n",
            "Mon Apr 25 15:58:48 2022: Epoch [6], Iteration [300/391/], Data(s): 0.052, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.348, Top5: 99.5769, Loss: 0.236\n",
            "Mon Apr 25 15:59:03 2022: Epoch [7], Iteration [0/391/], Data(s): 0.073, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 86.719, Top5: 99.2188, Loss: 0.241\n",
            "Mon Apr 25 15:59:19 2022: Epoch [7], Iteration [100/391/], Data(s): 0.052, Loss(s): 0.029, Forward(s): 0.006, Backward(s): 0.013, Top1: 92.605, Top5: 99.6906, Loss: 0.228\n",
            "Mon Apr 25 15:59:36 2022: Epoch [7], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.029, Forward(s): 0.006, Backward(s): 0.013, Top1: 92.479, Top5: 99.6813, Loss: 0.236\n",
            "Mon Apr 25 15:59:52 2022: Epoch [7], Iteration [300/391/], Data(s): 0.051, Loss(s): 0.029, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.395, Top5: 99.6626, Loss: 0.239\n",
            "Mon Apr 25 16:00:06 2022: Epoch [8], Iteration [0/391/], Data(s): 0.074, Loss(s): 0.029, Forward(s): 0.006, Backward(s): 0.011, Top1: 97.656, Top5: 100.0000, Loss: 0.238\n",
            "Mon Apr 25 16:00:23 2022: Epoch [8], Iteration [100/391/], Data(s): 0.052, Loss(s): 0.029, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.435, Top5: 99.5900, Loss: 0.237\n",
            "Mon Apr 25 16:00:39 2022: Epoch [8], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.029, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.479, Top5: 99.6385, Loss: 0.225\n",
            "Mon Apr 25 16:00:55 2022: Epoch [8], Iteration [300/391/], Data(s): 0.051, Loss(s): 0.029, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.559, Top5: 99.6366, Loss: 0.224\n",
            "Mon Apr 25 16:01:10 2022: Epoch [9], Iteration [0/391/], Data(s): 0.079, Loss(s): 0.025, Forward(s): 0.009, Backward(s): 0.012, Top1: 92.969, Top5: 100.0000, Loss: 0.241\n",
            "Mon Apr 25 16:01:26 2022: Epoch [9], Iteration [100/391/], Data(s): 0.052, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.621, Top5: 99.6906, Loss: 0.223\n",
            "Mon Apr 25 16:01:42 2022: Epoch [9], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.561, Top5: 99.6385, Loss: 0.226\n",
            "Mon Apr 25 16:01:58 2022: Epoch [9], Iteration [300/391/], Data(s): 0.051, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.566, Top5: 99.6392, Loss: 0.230\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 16:02:20 2022: Test information, Data(s): 2.512, Forward(s): 0.729, Top1: 90.060, Top5: 99.270, \n",
            "\n",
            "Mon Apr 25 16:02:20 2022: conv8 Layer, 131 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 381, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(381, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(381, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]          73,856\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "             ReLU-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]         147,584\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         295,168\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 381, 4, 4]         878,205\n",
            "      BatchNorm2d-26            [-1, 381, 4, 4]             762\n",
            "             ReLU-27            [-1, 381, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       1,756,160\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 14,086,081\n",
            "Trainable params: 14,086,081\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 6.53\n",
            "Params size (MB): 53.73\n",
            "Estimated Total Size (MB): 60.27\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 381, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(381, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(381, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 16:02:22 2022: Epoch [0], Iteration [0/391/], Data(s): 0.052, Loss(s): 0.003, Forward(s): 0.229, Backward(s): 0.592, Top1: 92.969, Top5: 100.0000, Loss: 0.201\n",
            "Mon Apr 25 16:02:38 2022: Epoch [0], Iteration [100/391/], Data(s): 0.052, Loss(s): 0.028, Forward(s): 0.008, Backward(s): 0.018, Top1: 93.023, Top5: 99.6906, Loss: 0.215\n",
            "Mon Apr 25 16:02:54 2022: Epoch [0], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.015, Top1: 92.837, Top5: 99.6735, Loss: 0.231\n",
            "Mon Apr 25 16:03:10 2022: Epoch [0], Iteration [300/391/], Data(s): 0.051, Loss(s): 0.028, Forward(s): 0.007, Backward(s): 0.014, Top1: 92.904, Top5: 99.6678, Loss: 0.211\n",
            "Mon Apr 25 16:03:25 2022: Epoch [1], Iteration [0/391/], Data(s): 0.074, Loss(s): 0.035, Forward(s): 0.007, Backward(s): 0.012, Top1: 96.094, Top5: 100.0000, Loss: 0.215\n",
            "Mon Apr 25 16:03:41 2022: Epoch [1], Iteration [100/391/], Data(s): 0.052, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.013, Top1: 92.636, Top5: 99.5900, Loss: 0.227\n",
            "Mon Apr 25 16:03:57 2022: Epoch [1], Iteration [200/391/], Data(s): 0.052, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.817, Top5: 99.6269, Loss: 0.213\n",
            "Mon Apr 25 16:04:13 2022: Epoch [1], Iteration [300/391/], Data(s): 0.051, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.868, Top5: 99.6470, Loss: 0.208\n",
            "Mon Apr 25 16:04:28 2022: Epoch [2], Iteration [0/391/], Data(s): 0.074, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.013, Top1: 96.094, Top5: 100.0000, Loss: 0.215\n",
            "Mon Apr 25 16:04:44 2022: Epoch [2], Iteration [100/391/], Data(s): 0.052, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.013, Top1: 93.147, Top5: 99.7602, Loss: 0.209\n",
            "Mon Apr 25 16:05:00 2022: Epoch [2], Iteration [200/391/], Data(s): 0.052, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.957, Top5: 99.7318, Loss: 0.217\n",
            "Mon Apr 25 16:05:16 2022: Epoch [2], Iteration [300/391/], Data(s): 0.051, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.015, Top5: 99.6730, Loss: 0.214\n",
            "Mon Apr 25 16:05:30 2022: Epoch [3], Iteration [0/391/], Data(s): 0.073, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 88.281, Top5: 98.4375, Loss: 0.215\n",
            "Mon Apr 25 16:05:47 2022: Epoch [3], Iteration [100/391/], Data(s): 0.052, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.013, Top1: 92.961, Top5: 99.6674, Loss: 0.216\n",
            "Mon Apr 25 16:06:03 2022: Epoch [3], Iteration [200/391/], Data(s): 0.052, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.256, Top5: 99.6813, Loss: 0.200\n",
            "Mon Apr 25 16:06:19 2022: Epoch [3], Iteration [300/391/], Data(s): 0.051, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.210, Top5: 99.6730, Loss: 0.202\n",
            "Mon Apr 25 16:06:33 2022: Epoch [4], Iteration [0/391/], Data(s): 0.074, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.531, Top5: 99.2188, Loss: 0.208\n",
            "Mon Apr 25 16:06:49 2022: Epoch [4], Iteration [100/391/], Data(s): 0.052, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.013, Top1: 93.162, Top5: 99.7757, Loss: 0.202\n",
            "Mon Apr 25 16:07:05 2022: Epoch [4], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.013, Top1: 93.272, Top5: 99.7551, Loss: 0.197\n",
            "Mon Apr 25 16:07:21 2022: Epoch [4], Iteration [300/391/], Data(s): 0.051, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.283, Top5: 99.7353, Loss: 0.204\n",
            "Mon Apr 25 16:07:36 2022: Epoch [5], Iteration [0/391/], Data(s): 0.075, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.188, Top5: 99.2188, Loss: 0.214\n",
            "Mon Apr 25 16:07:52 2022: Epoch [5], Iteration [100/391/], Data(s): 0.052, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.013, Top1: 93.619, Top5: 99.7834, Loss: 0.197\n",
            "Mon Apr 25 16:08:08 2022: Epoch [5], Iteration [200/391/], Data(s): 0.052, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.610, Top5: 99.7823, Loss: 0.202\n",
            "Mon Apr 25 16:08:24 2022: Epoch [5], Iteration [300/391/], Data(s): 0.051, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.553, Top5: 99.7664, Loss: 0.202\n",
            "Mon Apr 25 16:08:38 2022: Epoch [6], Iteration [0/391/], Data(s): 0.082, Loss(s): 0.026, Forward(s): 0.008, Backward(s): 0.012, Top1: 89.844, Top5: 100.0000, Loss: 0.205\n",
            "Mon Apr 25 16:08:54 2022: Epoch [6], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.611, Top5: 99.7912, Loss: 0.193\n",
            "Mon Apr 25 16:09:10 2022: Epoch [6], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.672, Top5: 99.7823, Loss: 0.190\n",
            "Mon Apr 25 16:09:26 2022: Epoch [6], Iteration [300/391/], Data(s): 0.051, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.428, Top5: 99.7560, Loss: 0.209\n",
            "Mon Apr 25 16:09:41 2022: Epoch [7], Iteration [0/391/], Data(s): 0.075, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.750, Top5: 100.0000, Loss: 0.205\n",
            "Mon Apr 25 16:09:57 2022: Epoch [7], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.332, Top5: 99.7602, Loss: 0.203\n",
            "Mon Apr 25 16:10:13 2022: Epoch [7], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.497, Top5: 99.7396, Loss: 0.192\n",
            "Mon Apr 25 16:10:29 2022: Epoch [7], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.568, Top5: 99.7482, Loss: 0.195\n",
            "Mon Apr 25 16:10:43 2022: Epoch [8], Iteration [0/391/], Data(s): 0.077, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.094, Top5: 100.0000, Loss: 0.201\n",
            "Mon Apr 25 16:10:59 2022: Epoch [8], Iteration [100/391/], Data(s): 0.052, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.688, Top5: 99.6674, Loss: 0.197\n",
            "Mon Apr 25 16:11:15 2022: Epoch [8], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.657, Top5: 99.6968, Loss: 0.194\n",
            "Mon Apr 25 16:11:31 2022: Epoch [8], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.654, Top5: 99.7093, Loss: 0.190\n",
            "Mon Apr 25 16:11:45 2022: Epoch [9], Iteration [0/391/], Data(s): 0.087, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.969, Top5: 99.2188, Loss: 0.190\n",
            "Mon Apr 25 16:12:01 2022: Epoch [9], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.874, Top5: 99.7370, Loss: 0.188\n",
            "Mon Apr 25 16:12:17 2022: Epoch [9], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.680, Top5: 99.7318, Loss: 0.197\n",
            "Mon Apr 25 16:12:33 2022: Epoch [9], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.810, Top5: 99.7353, Loss: 0.182\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 16:12:55 2022: Test information, Data(s): 2.418, Forward(s): 0.701, Top1: 90.740, Top5: 99.340, \n",
            "\n",
            "Mon Apr 25 16:12:55 2022: conv8 Layer, 197 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 315, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(315, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(315, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]          73,856\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "             ReLU-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]         147,584\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         295,168\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 315, 4, 4]         726,075\n",
            "      BatchNorm2d-26            [-1, 315, 4, 4]             630\n",
            "             ReLU-27            [-1, 315, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       1,452,032\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 13,629,691\n",
            "Trainable params: 13,629,691\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 6.50\n",
            "Params size (MB): 51.99\n",
            "Estimated Total Size (MB): 58.51\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 315, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(315, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(315, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 16:12:56 2022: Epoch [0], Iteration [0/391/], Data(s): 0.053, Loss(s): 0.006, Forward(s): 0.151, Backward(s): 0.548, Top1: 94.531, Top5: 100.0000, Loss: 0.166\n",
            "Mon Apr 25 16:13:12 2022: Epoch [0], Iteration [100/391/], Data(s): 0.052, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.018, Top1: 93.998, Top5: 99.7989, Loss: 0.190\n",
            "Mon Apr 25 16:13:28 2022: Epoch [0], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.015, Top1: 93.925, Top5: 99.7707, Loss: 0.191\n",
            "Mon Apr 25 16:13:44 2022: Epoch [0], Iteration [300/391/], Data(s): 0.051, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.014, Top1: 93.872, Top5: 99.7716, Loss: 0.193\n",
            "Mon Apr 25 16:13:59 2022: Epoch [1], Iteration [0/391/], Data(s): 0.072, Loss(s): 0.034, Forward(s): 0.007, Backward(s): 0.011, Top1: 96.094, Top5: 99.2188, Loss: 0.193\n",
            "Mon Apr 25 16:14:15 2022: Epoch [1], Iteration [100/391/], Data(s): 0.052, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.013, Top1: 93.456, Top5: 99.6829, Loss: 0.195\n",
            "Mon Apr 25 16:14:30 2022: Epoch [1], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.707, Top5: 99.7046, Loss: 0.182\n",
            "Mon Apr 25 16:14:46 2022: Epoch [1], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.828, Top5: 99.7301, Loss: 0.181\n",
            "Mon Apr 25 16:15:01 2022: Epoch [2], Iteration [0/391/], Data(s): 0.071, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.013, Top1: 96.875, Top5: 100.0000, Loss: 0.174\n",
            "Mon Apr 25 16:15:16 2022: Epoch [2], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.013, Top1: 94.005, Top5: 99.7447, Loss: 0.187\n",
            "Mon Apr 25 16:15:32 2022: Epoch [2], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.146, Top5: 99.7357, Loss: 0.181\n",
            "Mon Apr 25 16:15:48 2022: Epoch [2], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.010, Top5: 99.7353, Loss: 0.185\n",
            "Mon Apr 25 16:16:02 2022: Epoch [3], Iteration [0/391/], Data(s): 0.075, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.531, Top5: 100.0000, Loss: 0.185\n",
            "Mon Apr 25 16:16:18 2022: Epoch [3], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.152, Top5: 99.6983, Loss: 0.182\n",
            "Mon Apr 25 16:16:34 2022: Epoch [3], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.069, Top5: 99.7590, Loss: 0.181\n",
            "Mon Apr 25 16:16:49 2022: Epoch [3], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.085, Top5: 99.7560, Loss: 0.180\n",
            "Mon Apr 25 16:17:04 2022: Epoch [4], Iteration [0/391/], Data(s): 0.073, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.750, Top5: 100.0000, Loss: 0.179\n",
            "Mon Apr 25 16:17:20 2022: Epoch [4], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.013, Top1: 94.160, Top5: 99.7447, Loss: 0.183\n",
            "Mon Apr 25 16:17:35 2022: Epoch [4], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.228, Top5: 99.8057, Loss: 0.173\n",
            "Mon Apr 25 16:17:51 2022: Epoch [4], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.222, Top5: 99.8131, Loss: 0.177\n",
            "Mon Apr 25 16:18:05 2022: Epoch [5], Iteration [0/391/], Data(s): 0.072, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.531, Top5: 100.0000, Loss: 0.175\n",
            "Mon Apr 25 16:18:21 2022: Epoch [5], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.175, Top5: 99.7912, Loss: 0.174\n",
            "Mon Apr 25 16:18:37 2022: Epoch [5], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.236, Top5: 99.7823, Loss: 0.175\n",
            "Mon Apr 25 16:18:53 2022: Epoch [5], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.282, Top5: 99.7820, Loss: 0.172\n",
            "Mon Apr 25 16:19:07 2022: Epoch [6], Iteration [0/391/], Data(s): 0.088, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.011, Top1: 96.875, Top5: 100.0000, Loss: 0.171\n",
            "Mon Apr 25 16:19:23 2022: Epoch [6], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.013, Top1: 94.585, Top5: 99.7989, Loss: 0.171\n",
            "Mon Apr 25 16:19:38 2022: Epoch [6], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.013, Top1: 94.450, Top5: 99.8057, Loss: 0.172\n",
            "Mon Apr 25 16:19:54 2022: Epoch [6], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.446, Top5: 99.7716, Loss: 0.178\n",
            "Mon Apr 25 16:20:09 2022: Epoch [7], Iteration [0/391/], Data(s): 0.072, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.011, Top1: 93.750, Top5: 100.0000, Loss: 0.170\n",
            "Mon Apr 25 16:20:24 2022: Epoch [7], Iteration [100/391/], Data(s): 0.050, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.353, Top5: 99.7525, Loss: 0.169\n",
            "Mon Apr 25 16:20:40 2022: Epoch [7], Iteration [200/391/], Data(s): 0.049, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.271, Top5: 99.7396, Loss: 0.177\n",
            "Mon Apr 25 16:20:56 2022: Epoch [7], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.365, Top5: 99.7846, Loss: 0.167\n",
            "Mon Apr 25 16:21:10 2022: Epoch [8], Iteration [0/391/], Data(s): 0.072, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.011, Top1: 95.312, Top5: 100.0000, Loss: 0.178\n",
            "Mon Apr 25 16:21:26 2022: Epoch [8], Iteration [100/391/], Data(s): 0.050, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.756, Top5: 99.7757, Loss: 0.162\n",
            "Mon Apr 25 16:21:41 2022: Epoch [8], Iteration [200/391/], Data(s): 0.049, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.496, Top5: 99.7707, Loss: 0.171\n",
            "Mon Apr 25 16:21:57 2022: Epoch [8], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.609, Top5: 99.7872, Loss: 0.158\n",
            "Mon Apr 25 16:22:11 2022: Epoch [9], Iteration [0/391/], Data(s): 0.071, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.750, Top5: 100.0000, Loss: 0.175\n",
            "Mon Apr 25 16:22:27 2022: Epoch [9], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.477, Top5: 99.7602, Loss: 0.165\n",
            "Mon Apr 25 16:22:43 2022: Epoch [9], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.590, Top5: 99.7862, Loss: 0.160\n",
            "Mon Apr 25 16:22:59 2022: Epoch [9], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.503, Top5: 99.8001, Loss: 0.172\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 16:23:20 2022: Test information, Data(s): 2.415, Forward(s): 0.595, Top1: 91.060, Top5: 99.320, \n",
            "\n",
            "Mon Apr 25 16:23:20 2022: conv8 Layer, 262 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 250, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(250, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(250, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]          73,856\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "             ReLU-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]         147,584\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         295,168\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 250, 4, 4]         576,250\n",
            "      BatchNorm2d-26            [-1, 250, 4, 4]             500\n",
            "             ReLU-27            [-1, 250, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       1,152,512\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 13,180,216\n",
            "Trainable params: 13,180,216\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 6.48\n",
            "Params size (MB): 50.28\n",
            "Estimated Total Size (MB): 56.77\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 250, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(250, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(250, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 16:23:21 2022: Epoch [0], Iteration [0/391/], Data(s): 0.052, Loss(s): 0.008, Forward(s): 0.145, Backward(s): 0.313, Top1: 89.062, Top5: 100.0000, Loss: 0.268\n",
            "Mon Apr 25 16:23:37 2022: Epoch [0], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.016, Top1: 94.261, Top5: 99.7834, Loss: 0.170\n",
            "Mon Apr 25 16:23:53 2022: Epoch [0], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.014, Top1: 94.496, Top5: 99.7862, Loss: 0.161\n",
            "Mon Apr 25 16:24:08 2022: Epoch [0], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 94.573, Top5: 99.7846, Loss: 0.160\n",
            "Mon Apr 25 16:24:23 2022: Epoch [1], Iteration [0/391/], Data(s): 0.067, Loss(s): 0.030, Forward(s): 0.007, Backward(s): 0.012, Top1: 96.875, Top5: 100.0000, Loss: 0.167\n",
            "Mon Apr 25 16:24:38 2022: Epoch [1], Iteration [100/391/], Data(s): 0.049, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.756, Top5: 99.7912, Loss: 0.161\n",
            "Mon Apr 25 16:24:54 2022: Epoch [1], Iteration [200/391/], Data(s): 0.049, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.698, Top5: 99.7862, Loss: 0.161\n",
            "Mon Apr 25 16:25:09 2022: Epoch [1], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.638, Top5: 99.7924, Loss: 0.165\n",
            "Mon Apr 25 16:25:23 2022: Epoch [2], Iteration [0/391/], Data(s): 0.071, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 97.656, Top5: 99.2188, Loss: 0.159\n",
            "Mon Apr 25 16:25:39 2022: Epoch [2], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.879, Top5: 99.8144, Loss: 0.153\n",
            "Mon Apr 25 16:25:54 2022: Epoch [2], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.784, Top5: 99.8095, Loss: 0.162\n",
            "Mon Apr 25 16:26:10 2022: Epoch [2], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.853, Top5: 99.7924, Loss: 0.153\n",
            "Mon Apr 25 16:26:24 2022: Epoch [3], Iteration [0/391/], Data(s): 0.071, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.969, Top5: 100.0000, Loss: 0.152\n",
            "Mon Apr 25 16:26:40 2022: Epoch [3], Iteration [100/391/], Data(s): 0.050, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.042, Top5: 99.9072, Loss: 0.151\n",
            "Mon Apr 25 16:26:55 2022: Epoch [3], Iteration [200/391/], Data(s): 0.049, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.044, Top5: 99.8601, Loss: 0.149\n",
            "Mon Apr 25 16:27:10 2022: Epoch [3], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.985, Top5: 99.8469, Loss: 0.154\n",
            "Mon Apr 25 16:27:25 2022: Epoch [4], Iteration [0/391/], Data(s): 0.070, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 97.656, Top5: 100.0000, Loss: 0.164\n",
            "Mon Apr 25 16:27:40 2022: Epoch [4], Iteration [100/391/], Data(s): 0.050, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.794, Top5: 99.8066, Loss: 0.151\n",
            "Mon Apr 25 16:27:56 2022: Epoch [4], Iteration [200/391/], Data(s): 0.049, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.955, Top5: 99.8678, Loss: 0.153\n",
            "Mon Apr 25 16:28:11 2022: Epoch [4], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.858, Top5: 99.8157, Loss: 0.160\n",
            "Mon Apr 25 16:28:25 2022: Epoch [5], Iteration [0/391/], Data(s): 0.073, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.094, Top5: 100.0000, Loss: 0.154\n",
            "Mon Apr 25 16:28:41 2022: Epoch [5], Iteration [100/391/], Data(s): 0.052, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.150, Top5: 99.8376, Loss: 0.152\n",
            "Mon Apr 25 16:28:57 2022: Epoch [5], Iteration [200/391/], Data(s): 0.052, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.052, Top5: 99.8057, Loss: 0.153\n",
            "Mon Apr 25 16:29:12 2022: Epoch [5], Iteration [300/391/], Data(s): 0.051, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.947, Top5: 99.8001, Loss: 0.158\n",
            "Mon Apr 25 16:29:27 2022: Epoch [6], Iteration [0/391/], Data(s): 0.072, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.094, Top5: 100.0000, Loss: 0.152\n",
            "Mon Apr 25 16:29:42 2022: Epoch [6], Iteration [100/391/], Data(s): 0.052, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.980, Top5: 99.8762, Loss: 0.155\n",
            "Mon Apr 25 16:29:58 2022: Epoch [6], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.951, Top5: 99.8601, Loss: 0.149\n",
            "Mon Apr 25 16:30:14 2022: Epoch [6], Iteration [300/391/], Data(s): 0.051, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.001, Top5: 99.8469, Loss: 0.154\n",
            "Mon Apr 25 16:30:28 2022: Epoch [7], Iteration [0/391/], Data(s): 0.077, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.969, Top5: 100.0000, Loss: 0.148\n",
            "Mon Apr 25 16:30:44 2022: Epoch [7], Iteration [100/391/], Data(s): 0.052, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.189, Top5: 99.8144, Loss: 0.148\n",
            "Mon Apr 25 16:30:59 2022: Epoch [7], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.998, Top5: 99.8173, Loss: 0.157\n",
            "Mon Apr 25 16:31:15 2022: Epoch [7], Iteration [300/391/], Data(s): 0.051, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.107, Top5: 99.8339, Loss: 0.138\n",
            "Mon Apr 25 16:31:29 2022: Epoch [8], Iteration [0/391/], Data(s): 0.069, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.011, Top1: 95.312, Top5: 99.2188, Loss: 0.138\n",
            "Mon Apr 25 16:31:45 2022: Epoch [8], Iteration [100/391/], Data(s): 0.050, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.810, Top5: 99.7679, Loss: 0.158\n",
            "Mon Apr 25 16:32:00 2022: Epoch [8], Iteration [200/391/], Data(s): 0.049, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.103, Top5: 99.8018, Loss: 0.141\n",
            "Mon Apr 25 16:32:16 2022: Epoch [8], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.180, Top5: 99.8105, Loss: 0.139\n",
            "Mon Apr 25 16:32:30 2022: Epoch [9], Iteration [0/391/], Data(s): 0.063, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 97.656, Top5: 100.0000, Loss: 0.147\n",
            "Mon Apr 25 16:32:45 2022: Epoch [9], Iteration [100/391/], Data(s): 0.050, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.119, Top5: 99.8530, Loss: 0.145\n",
            "Mon Apr 25 16:33:01 2022: Epoch [9], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.250, Top5: 99.8640, Loss: 0.143\n",
            "Mon Apr 25 16:33:16 2022: Epoch [9], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.227, Top5: 99.8469, Loss: 0.142\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 16:33:37 2022: Test information, Data(s): 2.392, Forward(s): 0.595, Top1: 91.270, Top5: 99.330, \n",
            "\n",
            "Mon Apr 25 16:33:37 2022: conv8 Layer, 328 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(184, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]          73,856\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "             ReLU-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]         147,584\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         295,168\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 184, 4, 4]         424,120\n",
            "      BatchNorm2d-26            [-1, 184, 4, 4]             368\n",
            "             ReLU-27            [-1, 184, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]         848,384\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 12,723,826\n",
            "Trainable params: 12,723,826\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 6.45\n",
            "Params size (MB): 48.54\n",
            "Estimated Total Size (MB): 55.00\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(184, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 16:33:39 2022: Epoch [0], Iteration [0/391/], Data(s): 0.063, Loss(s): 0.007, Forward(s): 0.099, Backward(s): 0.234, Top1: 92.188, Top5: 100.0000, Loss: 0.175\n",
            "Mon Apr 25 16:33:54 2022: Epoch [0], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.027, Forward(s): 0.007, Backward(s): 0.014, Top1: 95.320, Top5: 99.8453, Loss: 0.142\n",
            "Mon Apr 25 16:34:09 2022: Epoch [0], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.367, Top5: 99.8601, Loss: 0.139\n",
            "Mon Apr 25 16:34:25 2022: Epoch [0], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.281, Top5: 99.8572, Loss: 0.145\n",
            "Mon Apr 25 16:34:39 2022: Epoch [1], Iteration [0/391/], Data(s): 0.069, Loss(s): 0.028, Forward(s): 0.006, Backward(s): 0.011, Top1: 94.531, Top5: 100.0000, Loss: 0.147\n",
            "Mon Apr 25 16:34:54 2022: Epoch [1], Iteration [100/391/], Data(s): 0.050, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.900, Top5: 99.9149, Loss: 0.128\n",
            "Mon Apr 25 16:35:10 2022: Epoch [1], Iteration [200/391/], Data(s): 0.049, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.581, Top5: 99.8873, Loss: 0.139\n",
            "Mon Apr 25 16:35:25 2022: Epoch [1], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.411, Top5: 99.8598, Loss: 0.151\n",
            "Mon Apr 25 16:35:39 2022: Epoch [2], Iteration [0/391/], Data(s): 0.082, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.011, Top1: 94.531, Top5: 100.0000, Loss: 0.145\n",
            "Mon Apr 25 16:35:54 2022: Epoch [2], Iteration [100/391/], Data(s): 0.050, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.591, Top5: 99.9149, Loss: 0.132\n",
            "Mon Apr 25 16:36:10 2022: Epoch [2], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.476, Top5: 99.8951, Loss: 0.140\n",
            "Mon Apr 25 16:36:25 2022: Epoch [2], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.393, Top5: 99.8910, Loss: 0.138\n",
            "Mon Apr 25 16:36:39 2022: Epoch [3], Iteration [0/391/], Data(s): 0.078, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.875, Top5: 100.0000, Loss: 0.141\n",
            "Mon Apr 25 16:36:55 2022: Epoch [3], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.514, Top5: 99.8994, Loss: 0.133\n",
            "Mon Apr 25 16:37:10 2022: Epoch [3], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.538, Top5: 99.8873, Loss: 0.137\n",
            "Mon Apr 25 16:37:25 2022: Epoch [3], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.468, Top5: 99.8624, Loss: 0.139\n",
            "Mon Apr 25 16:37:40 2022: Epoch [4], Iteration [0/391/], Data(s): 0.067, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 98.438, Top5: 100.0000, Loss: 0.142\n",
            "Mon Apr 25 16:37:55 2022: Epoch [4], Iteration [100/391/], Data(s): 0.049, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.761, Top5: 99.9226, Loss: 0.127\n",
            "Mon Apr 25 16:38:10 2022: Epoch [4], Iteration [200/391/], Data(s): 0.049, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.553, Top5: 99.9067, Loss: 0.133\n",
            "Mon Apr 25 16:38:25 2022: Epoch [4], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.525, Top5: 99.8910, Loss: 0.139\n",
            "Mon Apr 25 16:38:39 2022: Epoch [5], Iteration [0/391/], Data(s): 0.071, Loss(s): 0.027, Forward(s): 0.005, Backward(s): 0.012, Top1: 93.750, Top5: 99.2188, Loss: 0.140\n",
            "Mon Apr 25 16:38:55 2022: Epoch [5], Iteration [100/391/], Data(s): 0.050, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.993, Top5: 99.9149, Loss: 0.124\n",
            "Mon Apr 25 16:39:10 2022: Epoch [5], Iteration [200/391/], Data(s): 0.049, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.806, Top5: 99.9262, Loss: 0.129\n",
            "Mon Apr 25 16:39:25 2022: Epoch [5], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.751, Top5: 99.9040, Loss: 0.132\n",
            "Mon Apr 25 16:39:39 2022: Epoch [6], Iteration [0/391/], Data(s): 0.072, Loss(s): 0.027, Forward(s): 0.005, Backward(s): 0.011, Top1: 97.656, Top5: 100.0000, Loss: 0.130\n",
            "Mon Apr 25 16:39:55 2022: Epoch [6], Iteration [100/391/], Data(s): 0.050, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.823, Top5: 99.8453, Loss: 0.131\n",
            "Mon Apr 25 16:40:10 2022: Epoch [6], Iteration [200/391/], Data(s): 0.049, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.794, Top5: 99.8834, Loss: 0.125\n",
            "Mon Apr 25 16:40:25 2022: Epoch [6], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.759, Top5: 99.8806, Loss: 0.131\n",
            "Mon Apr 25 16:40:39 2022: Epoch [7], Iteration [0/391/], Data(s): 0.069, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.011, Top1: 94.531, Top5: 100.0000, Loss: 0.127\n",
            "Mon Apr 25 16:40:55 2022: Epoch [7], Iteration [100/391/], Data(s): 0.050, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.001, Top5: 99.9072, Loss: 0.124\n",
            "Mon Apr 25 16:41:10 2022: Epoch [7], Iteration [200/391/], Data(s): 0.049, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.993, Top5: 99.9223, Loss: 0.119\n",
            "Mon Apr 25 16:41:25 2022: Epoch [7], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.860, Top5: 99.8962, Loss: 0.135\n",
            "Mon Apr 25 16:41:39 2022: Epoch [8], Iteration [0/391/], Data(s): 0.070, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.094, Top5: 100.0000, Loss: 0.131\n",
            "Mon Apr 25 16:41:55 2022: Epoch [8], Iteration [100/391/], Data(s): 0.050, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.846, Top5: 99.8608, Loss: 0.128\n",
            "Mon Apr 25 16:42:10 2022: Epoch [8], Iteration [200/391/], Data(s): 0.049, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.810, Top5: 99.8756, Loss: 0.125\n",
            "Mon Apr 25 16:42:25 2022: Epoch [8], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.884, Top5: 99.8884, Loss: 0.121\n",
            "Mon Apr 25 16:42:39 2022: Epoch [9], Iteration [0/391/], Data(s): 0.068, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.011, Top1: 97.656, Top5: 100.0000, Loss: 0.125\n",
            "Mon Apr 25 16:42:55 2022: Epoch [9], Iteration [100/391/], Data(s): 0.049, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.032, Top5: 99.8917, Loss: 0.122\n",
            "Mon Apr 25 16:43:10 2022: Epoch [9], Iteration [200/391/], Data(s): 0.048, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.047, Top5: 99.8951, Loss: 0.120\n",
            "Mon Apr 25 16:43:25 2022: Epoch [9], Iteration [300/391/], Data(s): 0.048, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.037, Top5: 99.8988, Loss: 0.122\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 16:43:46 2022: Test information, Data(s): 2.384, Forward(s): 0.557, Top1: 91.510, Top5: 99.250, \n",
            "\n",
            "Mon Apr 25 16:43:46 2022: conv8 Layer, 394 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 118, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(118, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(118, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]          73,856\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "             ReLU-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]         147,584\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         295,168\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 118, 4, 4]         271,990\n",
            "      BatchNorm2d-26            [-1, 118, 4, 4]             236\n",
            "             ReLU-27            [-1, 118, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]         544,256\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 12,267,436\n",
            "Trainable params: 12,267,436\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 6.43\n",
            "Params size (MB): 46.80\n",
            "Estimated Total Size (MB): 53.24\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 118, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(118, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(118, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 16:43:47 2022: Epoch [0], Iteration [0/391/], Data(s): 0.053, Loss(s): 0.007, Forward(s): 0.079, Backward(s): 0.216, Top1: 95.312, Top5: 100.0000, Loss: 0.118\n",
            "Mon Apr 25 16:44:02 2022: Epoch [0], Iteration [100/391/], Data(s): 0.050, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.014, Top1: 95.676, Top5: 99.9149, Loss: 0.129\n",
            "Mon Apr 25 16:44:17 2022: Epoch [0], Iteration [200/391/], Data(s): 0.049, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.655, Top5: 99.9184, Loss: 0.127\n",
            "Mon Apr 25 16:44:33 2022: Epoch [0], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.611, Top5: 99.9014, Loss: 0.132\n",
            "Mon Apr 25 16:44:47 2022: Epoch [1], Iteration [0/391/], Data(s): 0.067, Loss(s): 0.026, Forward(s): 0.007, Backward(s): 0.012, Top1: 97.656, Top5: 100.0000, Loss: 0.126\n",
            "Mon Apr 25 16:45:02 2022: Epoch [1], Iteration [100/391/], Data(s): 0.049, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.148, Top5: 99.8608, Loss: 0.118\n",
            "Mon Apr 25 16:45:17 2022: Epoch [1], Iteration [200/391/], Data(s): 0.048, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.102, Top5: 99.8912, Loss: 0.120\n",
            "Mon Apr 25 16:45:32 2022: Epoch [1], Iteration [300/391/], Data(s): 0.048, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.034, Top5: 99.8884, Loss: 0.128\n",
            "Mon Apr 25 16:45:46 2022: Epoch [2], Iteration [0/391/], Data(s): 0.071, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 98.438, Top5: 100.0000, Loss: 0.119\n",
            "Mon Apr 25 16:46:01 2022: Epoch [2], Iteration [100/391/], Data(s): 0.049, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.924, Top5: 99.9226, Loss: 0.120\n",
            "Mon Apr 25 16:46:16 2022: Epoch [2], Iteration [200/391/], Data(s): 0.048, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.915, Top5: 99.9145, Loss: 0.120\n",
            "Mon Apr 25 16:46:31 2022: Epoch [2], Iteration [300/391/], Data(s): 0.048, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.907, Top5: 99.9066, Loss: 0.120\n",
            "Mon Apr 25 16:46:45 2022: Epoch [3], Iteration [0/391/], Data(s): 0.065, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 99.219, Top5: 100.0000, Loss: 0.114\n",
            "Mon Apr 25 16:47:00 2022: Epoch [3], Iteration [100/391/], Data(s): 0.048, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.279, Top5: 99.9072, Loss: 0.113\n",
            "Mon Apr 25 16:47:15 2022: Epoch [3], Iteration [200/391/], Data(s): 0.048, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.121, Top5: 99.9145, Loss: 0.120\n",
            "Mon Apr 25 16:47:30 2022: Epoch [3], Iteration [300/391/], Data(s): 0.048, Loss(s): 0.027, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.086, Top5: 99.9247, Loss: 0.116\n",
            "Mon Apr 25 16:47:44 2022: Epoch [4], Iteration [0/391/], Data(s): 0.067, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.011, Top1: 96.094, Top5: 100.0000, Loss: 0.122\n",
            "Mon Apr 25 16:47:59 2022: Epoch [4], Iteration [100/391/], Data(s): 0.048, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.264, Top5: 99.8840, Loss: 0.112\n",
            "Mon Apr 25 16:48:14 2022: Epoch [4], Iteration [200/391/], Data(s): 0.048, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.284, Top5: 99.9145, Loss: 0.112\n",
            "Mon Apr 25 16:48:29 2022: Epoch [4], Iteration [300/391/], Data(s): 0.048, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.249, Top5: 99.9169, Loss: 0.112\n",
            "Mon Apr 25 16:48:43 2022: Epoch [5], Iteration [0/391/], Data(s): 0.068, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 97.656, Top5: 100.0000, Loss: 0.118\n",
            "Mon Apr 25 16:48:58 2022: Epoch [5], Iteration [100/391/], Data(s): 0.049, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.241, Top5: 99.9304, Loss: 0.119\n",
            "Mon Apr 25 16:49:13 2022: Epoch [5], Iteration [200/391/], Data(s): 0.049, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.331, Top5: 99.8873, Loss: 0.110\n",
            "Mon Apr 25 16:49:28 2022: Epoch [5], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.327, Top5: 99.8962, Loss: 0.112\n",
            "Mon Apr 25 16:49:42 2022: Epoch [6], Iteration [0/391/], Data(s): 0.070, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.875, Top5: 100.0000, Loss: 0.117\n",
            "Mon Apr 25 16:49:57 2022: Epoch [6], Iteration [100/391/], Data(s): 0.050, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.055, Top5: 99.9149, Loss: 0.114\n",
            "Mon Apr 25 16:50:12 2022: Epoch [6], Iteration [200/391/], Data(s): 0.049, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.234, Top5: 99.9067, Loss: 0.109\n",
            "Mon Apr 25 16:50:27 2022: Epoch [6], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.242, Top5: 99.9118, Loss: 0.113\n",
            "Mon Apr 25 16:50:41 2022: Epoch [7], Iteration [0/391/], Data(s): 0.070, Loss(s): 0.026, Forward(s): 0.005, Backward(s): 0.012, Top1: 96.094, Top5: 100.0000, Loss: 0.107\n",
            "Mon Apr 25 16:50:56 2022: Epoch [7], Iteration [100/391/], Data(s): 0.049, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.573, Top5: 99.9226, Loss: 0.107\n",
            "Mon Apr 25 16:51:11 2022: Epoch [7], Iteration [200/391/], Data(s): 0.049, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.514, Top5: 99.9223, Loss: 0.108\n",
            "Mon Apr 25 16:51:26 2022: Epoch [7], Iteration [300/391/], Data(s): 0.048, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.545, Top5: 99.9221, Loss: 0.105\n",
            "Mon Apr 25 16:51:40 2022: Epoch [8], Iteration [0/391/], Data(s): 0.066, Loss(s): 0.025, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.094, Top5: 99.2188, Loss: 0.110\n",
            "Mon Apr 25 16:51:55 2022: Epoch [8], Iteration [100/391/], Data(s): 0.050, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.558, Top5: 99.9226, Loss: 0.106\n",
            "Mon Apr 25 16:52:11 2022: Epoch [8], Iteration [200/391/], Data(s): 0.049, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.502, Top5: 99.9184, Loss: 0.101\n",
            "Mon Apr 25 16:52:26 2022: Epoch [8], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.452, Top5: 99.9299, Loss: 0.106\n",
            "Mon Apr 25 16:52:40 2022: Epoch [9], Iteration [0/391/], Data(s): 0.069, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 98.438, Top5: 100.0000, Loss: 0.109\n",
            "Mon Apr 25 16:52:55 2022: Epoch [9], Iteration [100/391/], Data(s): 0.050, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.535, Top5: 99.9381, Loss: 0.103\n",
            "Mon Apr 25 16:53:10 2022: Epoch [9], Iteration [200/391/], Data(s): 0.049, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.533, Top5: 99.9262, Loss: 0.107\n",
            "Mon Apr 25 16:53:25 2022: Epoch [9], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.587, Top5: 99.9195, Loss: 0.103\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 16:53:45 2022: Test information, Data(s): 2.358, Forward(s): 0.517, Top1: 91.570, Top5: 99.230, \n",
            "\n",
            "Mon Apr 25 16:53:45 2022: conv8 Layer, 460 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 52, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(52, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]          73,856\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "             ReLU-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]         147,584\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         295,168\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25             [-1, 52, 4, 4]         119,860\n",
            "      BatchNorm2d-26             [-1, 52, 4, 4]             104\n",
            "             ReLU-27             [-1, 52, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]         240,128\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 11,811,046\n",
            "Trainable params: 11,811,046\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 6.41\n",
            "Params size (MB): 45.06\n",
            "Estimated Total Size (MB): 51.47\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 52, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(52, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 16:53:47 2022: Epoch [0], Iteration [0/391/], Data(s): 0.052, Loss(s): 0.003, Forward(s): 0.082, Backward(s): 0.151, Top1: 92.969, Top5: 100.0000, Loss: 0.265\n",
            "Mon Apr 25 16:54:02 2022: Epoch [0], Iteration [100/391/], Data(s): 0.049, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.312, Top5: 99.8453, Loss: 0.136\n",
            "Mon Apr 25 16:54:17 2022: Epoch [0], Iteration [200/391/], Data(s): 0.049, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.655, Top5: 99.8484, Loss: 0.127\n",
            "Mon Apr 25 16:54:32 2022: Epoch [0], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.816, Top5: 99.8832, Loss: 0.116\n",
            "Mon Apr 25 16:54:46 2022: Epoch [1], Iteration [0/391/], Data(s): 0.070, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.011, Top1: 96.094, Top5: 100.0000, Loss: 0.125\n",
            "Mon Apr 25 16:55:01 2022: Epoch [1], Iteration [100/391/], Data(s): 0.050, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.256, Top5: 99.8994, Loss: 0.112\n",
            "Mon Apr 25 16:55:16 2022: Epoch [1], Iteration [200/391/], Data(s): 0.049, Loss(s): 0.026, Forward(s): 0.005, Backward(s): 0.012, Top1: 96.315, Top5: 99.8989, Loss: 0.107\n",
            "Mon Apr 25 16:55:31 2022: Epoch [1], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.026, Forward(s): 0.005, Backward(s): 0.012, Top1: 96.288, Top5: 99.8936, Loss: 0.114\n",
            "Mon Apr 25 16:55:45 2022: Epoch [2], Iteration [0/391/], Data(s): 0.068, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.094, Top5: 100.0000, Loss: 0.111\n",
            "Mon Apr 25 16:56:00 2022: Epoch [2], Iteration [100/391/], Data(s): 0.049, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.403, Top5: 99.9226, Loss: 0.109\n",
            "Mon Apr 25 16:56:15 2022: Epoch [2], Iteration [200/391/], Data(s): 0.049, Loss(s): 0.026, Forward(s): 0.005, Backward(s): 0.012, Top1: 96.323, Top5: 99.9223, Loss: 0.111\n",
            "Mon Apr 25 16:56:30 2022: Epoch [2], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.026, Forward(s): 0.005, Backward(s): 0.012, Top1: 96.322, Top5: 99.9143, Loss: 0.111\n",
            "Mon Apr 25 16:56:43 2022: Epoch [3], Iteration [0/391/], Data(s): 0.068, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.013, Top1: 98.438, Top5: 100.0000, Loss: 0.107\n",
            "Mon Apr 25 16:56:58 2022: Epoch [3], Iteration [100/391/], Data(s): 0.049, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.627, Top5: 99.9381, Loss: 0.102\n",
            "Mon Apr 25 16:57:14 2022: Epoch [3], Iteration [200/391/], Data(s): 0.049, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.646, Top5: 99.9378, Loss: 0.102\n",
            "Mon Apr 25 16:57:29 2022: Epoch [3], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.595, Top5: 99.9325, Loss: 0.108\n",
            "Mon Apr 25 16:57:42 2022: Epoch [4], Iteration [0/391/], Data(s): 0.069, Loss(s): 0.026, Forward(s): 0.005, Backward(s): 0.012, Top1: 98.438, Top5: 100.0000, Loss: 0.111\n",
            "Mon Apr 25 16:57:58 2022: Epoch [4], Iteration [100/391/], Data(s): 0.050, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.744, Top5: 99.9613, Loss: 0.100\n",
            "Mon Apr 25 16:58:13 2022: Epoch [4], Iteration [200/391/], Data(s): 0.049, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.599, Top5: 99.9339, Loss: 0.108\n",
            "Mon Apr 25 16:58:28 2022: Epoch [4], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.026, Forward(s): 0.005, Backward(s): 0.012, Top1: 96.545, Top5: 99.9273, Loss: 0.108\n",
            "Mon Apr 25 16:58:41 2022: Epoch [5], Iteration [0/391/], Data(s): 0.065, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.011, Top1: 97.656, Top5: 100.0000, Loss: 0.108\n",
            "Mon Apr 25 16:58:57 2022: Epoch [5], Iteration [100/391/], Data(s): 0.050, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.620, Top5: 99.9226, Loss: 0.101\n",
            "Mon Apr 25 16:59:12 2022: Epoch [5], Iteration [200/391/], Data(s): 0.049, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.599, Top5: 99.9184, Loss: 0.101\n",
            "Mon Apr 25 16:59:27 2022: Epoch [5], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.662, Top5: 99.9325, Loss: 0.097\n",
            "Mon Apr 25 16:59:41 2022: Epoch [6], Iteration [0/391/], Data(s): 0.068, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 98.438, Top5: 100.0000, Loss: 0.098\n",
            "Mon Apr 25 16:59:56 2022: Epoch [6], Iteration [100/391/], Data(s): 0.050, Loss(s): 0.026, Forward(s): 0.005, Backward(s): 0.012, Top1: 96.976, Top5: 99.9304, Loss: 0.096\n",
            "Mon Apr 25 17:00:11 2022: Epoch [6], Iteration [200/391/], Data(s): 0.049, Loss(s): 0.026, Forward(s): 0.005, Backward(s): 0.012, Top1: 96.824, Top5: 99.9417, Loss: 0.097\n",
            "Mon Apr 25 17:00:26 2022: Epoch [6], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.026, Forward(s): 0.005, Backward(s): 0.012, Top1: 96.885, Top5: 99.9429, Loss: 0.093\n",
            "Mon Apr 25 17:00:39 2022: Epoch [7], Iteration [0/391/], Data(s): 0.081, Loss(s): 0.026, Forward(s): 0.005, Backward(s): 0.011, Top1: 96.875, Top5: 100.0000, Loss: 0.099\n",
            "Mon Apr 25 17:00:55 2022: Epoch [7], Iteration [100/391/], Data(s): 0.050, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.906, Top5: 99.9536, Loss: 0.097\n",
            "Mon Apr 25 17:01:10 2022: Epoch [7], Iteration [200/391/], Data(s): 0.049, Loss(s): 0.026, Forward(s): 0.005, Backward(s): 0.012, Top1: 96.937, Top5: 99.9339, Loss: 0.093\n",
            "Mon Apr 25 17:01:25 2022: Epoch [7], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.026, Forward(s): 0.005, Backward(s): 0.012, Top1: 96.813, Top5: 99.9377, Loss: 0.100\n",
            "Mon Apr 25 17:01:38 2022: Epoch [8], Iteration [0/391/], Data(s): 0.070, Loss(s): 0.025, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.094, Top5: 100.0000, Loss: 0.092\n",
            "Mon Apr 25 17:01:54 2022: Epoch [8], Iteration [100/391/], Data(s): 0.050, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 97.123, Top5: 99.9459, Loss: 0.088\n",
            "Mon Apr 25 17:02:09 2022: Epoch [8], Iteration [200/391/], Data(s): 0.049, Loss(s): 0.026, Forward(s): 0.005, Backward(s): 0.012, Top1: 97.147, Top5: 99.9262, Loss: 0.088\n",
            "Mon Apr 25 17:02:24 2022: Epoch [8], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.026, Forward(s): 0.005, Backward(s): 0.012, Top1: 97.075, Top5: 99.9377, Loss: 0.096\n",
            "Mon Apr 25 17:02:37 2022: Epoch [9], Iteration [0/391/], Data(s): 0.068, Loss(s): 0.026, Forward(s): 0.005, Backward(s): 0.012, Top1: 98.438, Top5: 100.0000, Loss: 0.096\n",
            "Mon Apr 25 17:02:52 2022: Epoch [9], Iteration [100/391/], Data(s): 0.050, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 97.200, Top5: 99.9691, Loss: 0.087\n",
            "Mon Apr 25 17:03:08 2022: Epoch [9], Iteration [200/391/], Data(s): 0.049, Loss(s): 0.026, Forward(s): 0.006, Backward(s): 0.012, Top1: 97.108, Top5: 99.9689, Loss: 0.091\n",
            "Mon Apr 25 17:03:23 2022: Epoch [9], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.026, Forward(s): 0.005, Backward(s): 0.012, Top1: 97.054, Top5: 99.9714, Loss: 0.091\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 17:03:43 2022: Test information, Data(s): 2.354, Forward(s): 0.478, Top1: 91.240, Top5: 99.310, \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "6HSSpJrCqXSz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top1_accuracies"
      ],
      "metadata": {
        "id": "jhWAiaTSByEt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec1bc79d-8bdf-40c6-c849-c7d4a1ad387a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'conv2': [90.05, 90.57, 90.78, 91.04, 90.95, 90.51, 88.92],\n",
              " 'conv7': [90.21, 90.68, 90.97, 91.12, 91.18, 90.88, 90.73],\n",
              " 'conv8': [90.06, 90.74, 91.06, 91.27, 91.51, 91.57, 91.24]}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top5_accuracies"
      ],
      "metadata": {
        "id": "BJ3Q4RUPByEu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b231c4a1-4068-4d6c-ea4a-f35dd9b76b60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'conv2': [99.28, 99.26, 99.29, 99.28, 99.26, 99.32, 99.21],\n",
              " 'conv7': [99.24, 99.31, 99.29, 99.32, 99.3, 99.26, 99.26],\n",
              " 'conv8': [99.27, 99.34, 99.32, 99.33, 99.25, 99.23, 99.31]}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top1_accuracies = {}\n",
        "top5_accuracies = {}"
      ],
      "metadata": {
        "id": "Je_sWeypqXPt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for conv, channel in zip(prune_layers[2:3], prune_channels[2:3]):    \n",
        "    top1_accuracies[conv] = []\n",
        "    top5_accuracies[conv] = []\n",
        "    \n",
        "    # load new network and check accuracy\n",
        "    network, _, _ = test_network(args, data_set=test_set)\n",
        "        \n",
        "    # remove 0 channels ~ M (max_channel_ratio) % of total channels\n",
        "    step = np.linspace(0, int(channel*max_channel_ratio), int(1/prune_step_ratio), dtype=np.int)\n",
        "    steps = (step[1:] - step[:-1]).tolist()\n",
        "    \n",
        "    for i in range(len(steps)):\n",
        "        print(\"\\n%s: %s Layer, %d Channels pruned\"%(time.ctime(), conv, sum(steps[:i+1])))\n",
        "        \n",
        "        # set prune information\n",
        "        args.prune_layers = [conv]\n",
        "        args.prune_channels =[steps[i]]\n",
        "\n",
        "        network = prune_network(args, network)\n",
        "        \n",
        "        network, _, (top1, top5) = test_network(args, network, test_set)\n",
        "            \n",
        "        top1_accuracies[conv].append(top1)\n",
        "        top5_accuracies[conv].append(top5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "565a3900-a4b5-4227-fa28-00df609fb6bc",
        "id": "lI5Zc9g9sXMw"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 17:43:27 2022: Test information, Data(s): 2.395, Forward(s): 0.454, Top1: 77.870, Top5: 97.560, \n",
            "\n",
            "Mon Apr 25 17:43:27 2022: conv3 Layer, 16 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 112, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(112, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8          [-1, 112, 16, 16]          64,624\n",
            "       BatchNorm2d-9          [-1, 112, 16, 16]             224\n",
            "             ReLU-10          [-1, 112, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]         129,152\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         295,168\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]       1,180,160\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 14,964,250\n",
            "Trainable params: 14,964,250\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 6.48\n",
            "Params size (MB): 57.08\n",
            "Estimated Total Size (MB): 63.58\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 112, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(112, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  if __name__ == '__main__':\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 17:43:29 2022: Epoch [0], Iteration [0/391/], Data(s): 0.059, Loss(s): 0.028, Forward(s): 0.107, Backward(s): 0.241, Top1: 93.750, Top5: 99.2188, Loss: 0.299\n",
            "Mon Apr 25 17:43:49 2022: Epoch [0], Iteration [100/391/], Data(s): 0.052, Loss(s): 0.042, Forward(s): 0.007, Backward(s): 0.014, Top1: 86.920, Top5: 98.7933, Loss: 0.409\n",
            "Mon Apr 25 17:44:09 2022: Epoch [0], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.042, Forward(s): 0.006, Backward(s): 0.013, Top1: 87.655, Top5: 98.9933, Loss: 0.359\n",
            "Mon Apr 25 17:44:29 2022: Epoch [0], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.042, Forward(s): 0.006, Backward(s): 0.012, Top1: 88.141, Top5: 99.0786, Loss: 0.334\n",
            "Mon Apr 25 17:44:48 2022: Epoch [1], Iteration [0/391/], Data(s): 0.071, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.011, Top1: 89.062, Top5: 98.4375, Loss: 0.323\n",
            "Mon Apr 25 17:45:08 2022: Epoch [1], Iteration [100/391/], Data(s): 0.052, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 90.354, Top5: 99.3348, Loss: 0.304\n",
            "Mon Apr 25 17:45:28 2022: Epoch [1], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.042, Forward(s): 0.006, Backward(s): 0.012, Top1: 90.275, Top5: 99.3548, Loss: 0.304\n",
            "Mon Apr 25 17:45:48 2022: Epoch [1], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.042, Forward(s): 0.006, Backward(s): 0.012, Top1: 90.269, Top5: 99.3978, Loss: 0.296\n",
            "Mon Apr 25 17:46:06 2022: Epoch [2], Iteration [0/391/], Data(s): 0.072, Loss(s): 0.042, Forward(s): 0.006, Backward(s): 0.011, Top1: 90.625, Top5: 98.4375, Loss: 0.293\n",
            "Mon Apr 25 17:46:26 2022: Epoch [2], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.042, Forward(s): 0.006, Backward(s): 0.012, Top1: 91.066, Top5: 99.4585, Loss: 0.280\n",
            "Mon Apr 25 17:46:46 2022: Epoch [2], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.042, Forward(s): 0.006, Backward(s): 0.012, Top1: 91.053, Top5: 99.4248, Loss: 0.280\n",
            "Mon Apr 25 17:47:07 2022: Epoch [2], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.042, Forward(s): 0.006, Backward(s): 0.012, Top1: 90.947, Top5: 99.4523, Loss: 0.287\n",
            "Mon Apr 25 17:47:25 2022: Epoch [3], Iteration [0/391/], Data(s): 0.076, Loss(s): 0.040, Forward(s): 0.007, Backward(s): 0.011, Top1: 92.188, Top5: 100.0000, Loss: 0.268\n",
            "Mon Apr 25 17:47:45 2022: Epoch [3], Iteration [100/391/], Data(s): 0.050, Loss(s): 0.042, Forward(s): 0.006, Backward(s): 0.011, Top1: 90.517, Top5: 99.3889, Loss: 0.286\n",
            "Mon Apr 25 17:48:05 2022: Epoch [3], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.042, Forward(s): 0.006, Backward(s): 0.011, Top1: 90.878, Top5: 99.4869, Loss: 0.265\n",
            "Mon Apr 25 17:48:25 2022: Epoch [3], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.042, Forward(s): 0.006, Backward(s): 0.012, Top1: 90.991, Top5: 99.4601, Loss: 0.272\n",
            "Mon Apr 25 17:48:44 2022: Epoch [4], Iteration [0/391/], Data(s): 0.074, Loss(s): 0.042, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.188, Top5: 98.4375, Loss: 0.258\n",
            "Mon Apr 25 17:49:04 2022: Epoch [4], Iteration [100/391/], Data(s): 0.050, Loss(s): 0.042, Forward(s): 0.006, Backward(s): 0.012, Top1: 91.793, Top5: 99.4740, Loss: 0.256\n",
            "Mon Apr 25 17:49:24 2022: Epoch [4], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.042, Forward(s): 0.006, Backward(s): 0.012, Top1: 91.741, Top5: 99.5219, Loss: 0.257\n",
            "Mon Apr 25 17:49:44 2022: Epoch [4], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.042, Forward(s): 0.006, Backward(s): 0.012, Top1: 91.806, Top5: 99.5302, Loss: 0.247\n",
            "Mon Apr 25 17:50:02 2022: Epoch [5], Iteration [0/391/], Data(s): 0.074, Loss(s): 0.042, Forward(s): 0.006, Backward(s): 0.012, Top1: 88.281, Top5: 97.6562, Loss: 0.265\n",
            "Mon Apr 25 17:50:22 2022: Epoch [5], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.042, Forward(s): 0.006, Backward(s): 0.012, Top1: 91.677, Top5: 99.4817, Loss: 0.258\n",
            "Mon Apr 25 17:50:42 2022: Epoch [5], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.042, Forward(s): 0.006, Backward(s): 0.012, Top1: 91.822, Top5: 99.5180, Loss: 0.244\n",
            "Mon Apr 25 17:51:02 2022: Epoch [5], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.042, Forward(s): 0.006, Backward(s): 0.012, Top1: 91.881, Top5: 99.5354, Loss: 0.250\n",
            "Mon Apr 25 17:51:21 2022: Epoch [6], Iteration [0/391/], Data(s): 0.073, Loss(s): 0.042, Forward(s): 0.005, Backward(s): 0.011, Top1: 94.531, Top5: 100.0000, Loss: 0.248\n",
            "Mon Apr 25 17:51:41 2022: Epoch [6], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.042, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.071, Top5: 99.4740, Loss: 0.246\n",
            "Mon Apr 25 17:52:01 2022: Epoch [6], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.042, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.176, Top5: 99.4908, Loss: 0.235\n",
            "Mon Apr 25 17:52:21 2022: Epoch [6], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.042, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.156, Top5: 99.5406, Loss: 0.244\n",
            "Mon Apr 25 17:52:39 2022: Epoch [7], Iteration [0/391/], Data(s): 0.074, Loss(s): 0.042, Forward(s): 0.006, Backward(s): 0.011, Top1: 89.844, Top5: 100.0000, Loss: 0.244\n",
            "Mon Apr 25 17:52:59 2022: Epoch [7], Iteration [100/391/], Data(s): 0.050, Loss(s): 0.042, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.095, Top5: 99.6751, Loss: 0.240\n",
            "Mon Apr 25 17:53:19 2022: Epoch [7], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.042, Forward(s): 0.006, Backward(s): 0.011, Top1: 92.327, Top5: 99.6191, Loss: 0.230\n",
            "Mon Apr 25 17:53:39 2022: Epoch [7], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.042, Forward(s): 0.006, Backward(s): 0.011, Top1: 92.330, Top5: 99.6314, Loss: 0.234\n",
            "Mon Apr 25 17:53:58 2022: Epoch [8], Iteration [0/391/], Data(s): 0.079, Loss(s): 0.040, Forward(s): 0.008, Backward(s): 0.011, Top1: 96.875, Top5: 100.0000, Loss: 0.229\n",
            "Mon Apr 25 17:54:18 2022: Epoch [8], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.042, Forward(s): 0.006, Backward(s): 0.011, Top1: 92.350, Top5: 99.6287, Loss: 0.236\n",
            "Mon Apr 25 17:54:38 2022: Epoch [8], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.042, Forward(s): 0.006, Backward(s): 0.011, Top1: 92.444, Top5: 99.6541, Loss: 0.228\n",
            "Mon Apr 25 17:54:58 2022: Epoch [8], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.042, Forward(s): 0.006, Backward(s): 0.011, Top1: 92.515, Top5: 99.6288, Loss: 0.227\n",
            "Mon Apr 25 17:55:16 2022: Epoch [9], Iteration [0/391/], Data(s): 0.073, Loss(s): 0.042, Forward(s): 0.006, Backward(s): 0.011, Top1: 85.156, Top5: 99.2188, Loss: 0.236\n",
            "Mon Apr 25 17:55:36 2022: Epoch [9], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.042, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.435, Top5: 99.6674, Loss: 0.230\n",
            "Mon Apr 25 17:55:56 2022: Epoch [9], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.042, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.638, Top5: 99.6735, Loss: 0.217\n",
            "Mon Apr 25 17:56:16 2022: Epoch [9], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.042, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.572, Top5: 99.6314, Loss: 0.227\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 17:56:43 2022: Test information, Data(s): 2.400, Forward(s): 0.567, Top1: 90.000, Top5: 99.270, \n",
            "\n",
            "Mon Apr 25 17:56:43 2022: conv3 Layer, 32 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8           [-1, 96, 16, 16]          55,392\n",
            "       BatchNorm2d-9           [-1, 96, 16, 16]             192\n",
            "             ReLU-10           [-1, 96, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]         110,720\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         295,168\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]       1,180,160\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 14,936,554\n",
            "Trainable params: 14,936,554\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 6.39\n",
            "Params size (MB): 56.98\n",
            "Estimated Total Size (MB): 63.38\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 17:56:44 2022: Epoch [0], Iteration [0/391/], Data(s): 0.047, Loss(s): 0.027, Forward(s): 0.100, Backward(s): 0.257, Top1: 91.406, Top5: 100.0000, Loss: 0.213\n",
            "Mon Apr 25 17:57:04 2022: Epoch [0], Iteration [100/391/], Data(s): 0.050, Loss(s): 0.041, Forward(s): 0.007, Backward(s): 0.014, Top1: 92.938, Top5: 99.6597, Loss: 0.219\n",
            "Mon Apr 25 17:57:24 2022: Epoch [0], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.013, Top1: 92.934, Top5: 99.6580, Loss: 0.218\n",
            "Mon Apr 25 17:57:44 2022: Epoch [0], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.886, Top5: 99.6470, Loss: 0.223\n",
            "Mon Apr 25 17:58:02 2022: Epoch [1], Iteration [0/391/], Data(s): 0.075, Loss(s): 0.041, Forward(s): 0.007, Backward(s): 0.011, Top1: 96.875, Top5: 100.0000, Loss: 0.226\n",
            "Mon Apr 25 17:58:22 2022: Epoch [1], Iteration [100/391/], Data(s): 0.050, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.884, Top5: 99.6364, Loss: 0.221\n",
            "Mon Apr 25 17:58:42 2022: Epoch [1], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.786, Top5: 99.6308, Loss: 0.226\n",
            "Mon Apr 25 17:59:02 2022: Epoch [1], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.792, Top5: 99.6444, Loss: 0.224\n",
            "Mon Apr 25 17:59:20 2022: Epoch [2], Iteration [0/391/], Data(s): 0.072, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.011, Top1: 92.969, Top5: 99.2188, Loss: 0.211\n",
            "Mon Apr 25 17:59:40 2022: Epoch [2], Iteration [100/391/], Data(s): 0.050, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.822, Top5: 99.6442, Loss: 0.216\n",
            "Mon Apr 25 18:00:00 2022: Epoch [2], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.759, Top5: 99.6580, Loss: 0.219\n",
            "Mon Apr 25 18:00:20 2022: Epoch [2], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.875, Top5: 99.6730, Loss: 0.208\n",
            "Mon Apr 25 18:00:38 2022: Epoch [3], Iteration [0/391/], Data(s): 0.093, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 90.625, Top5: 99.2188, Loss: 0.216\n",
            "Mon Apr 25 18:00:58 2022: Epoch [3], Iteration [100/391/], Data(s): 0.050, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.011, Top1: 93.015, Top5: 99.6906, Loss: 0.211\n",
            "Mon Apr 25 18:01:17 2022: Epoch [3], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.011, Top1: 93.031, Top5: 99.7046, Loss: 0.208\n",
            "Mon Apr 25 18:01:37 2022: Epoch [3], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.011, Top1: 93.117, Top5: 99.6782, Loss: 0.209\n",
            "Mon Apr 25 18:01:55 2022: Epoch [4], Iteration [0/391/], Data(s): 0.073, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.014, Top1: 93.750, Top5: 99.2188, Loss: 0.213\n",
            "Mon Apr 25 18:02:15 2022: Epoch [4], Iteration [100/391/], Data(s): 0.050, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.325, Top5: 99.6751, Loss: 0.210\n",
            "Mon Apr 25 18:02:35 2022: Epoch [4], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.326, Top5: 99.6580, Loss: 0.205\n",
            "Mon Apr 25 18:02:55 2022: Epoch [4], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.296, Top5: 99.6808, Loss: 0.209\n",
            "Mon Apr 25 18:03:13 2022: Epoch [5], Iteration [0/391/], Data(s): 0.074, Loss(s): 0.042, Forward(s): 0.006, Backward(s): 0.014, Top1: 91.406, Top5: 99.2188, Loss: 0.210\n",
            "Mon Apr 25 18:03:33 2022: Epoch [5], Iteration [100/391/], Data(s): 0.052, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.441, Top5: 99.6751, Loss: 0.200\n",
            "Mon Apr 25 18:03:53 2022: Epoch [5], Iteration [200/391/], Data(s): 0.052, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.420, Top5: 99.6968, Loss: 0.203\n",
            "Mon Apr 25 18:04:13 2022: Epoch [5], Iteration [300/391/], Data(s): 0.051, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.410, Top5: 99.6937, Loss: 0.209\n",
            "Mon Apr 25 18:04:32 2022: Epoch [6], Iteration [0/391/], Data(s): 0.079, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.011, Top1: 93.750, Top5: 100.0000, Loss: 0.207\n",
            "Mon Apr 25 18:04:52 2022: Epoch [6], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.154, Top5: 99.7293, Loss: 0.200\n",
            "Mon Apr 25 18:05:12 2022: Epoch [6], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.241, Top5: 99.7279, Loss: 0.206\n",
            "Mon Apr 25 18:05:32 2022: Epoch [6], Iteration [300/391/], Data(s): 0.051, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.306, Top5: 99.7379, Loss: 0.200\n",
            "Mon Apr 25 18:05:50 2022: Epoch [7], Iteration [0/391/], Data(s): 0.076, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.013, Top1: 93.750, Top5: 100.0000, Loss: 0.211\n",
            "Mon Apr 25 18:06:10 2022: Epoch [7], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.162, Top5: 99.7061, Loss: 0.206\n",
            "Mon Apr 25 18:06:30 2022: Epoch [7], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.412, Top5: 99.7124, Loss: 0.193\n",
            "Mon Apr 25 18:06:50 2022: Epoch [7], Iteration [300/391/], Data(s): 0.051, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.433, Top5: 99.7119, Loss: 0.199\n",
            "Mon Apr 25 18:07:08 2022: Epoch [8], Iteration [0/391/], Data(s): 0.073, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.188, Top5: 100.0000, Loss: 0.197\n",
            "Mon Apr 25 18:07:28 2022: Epoch [8], Iteration [100/391/], Data(s): 0.052, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.580, Top5: 99.7525, Loss: 0.194\n",
            "Mon Apr 25 18:07:48 2022: Epoch [8], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.567, Top5: 99.7163, Loss: 0.199\n",
            "Mon Apr 25 18:08:08 2022: Epoch [8], Iteration [300/391/], Data(s): 0.051, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.641, Top5: 99.7482, Loss: 0.191\n",
            "Mon Apr 25 18:08:27 2022: Epoch [9], Iteration [0/391/], Data(s): 0.077, Loss(s): 0.039, Forward(s): 0.008, Backward(s): 0.011, Top1: 90.625, Top5: 100.0000, Loss: 0.198\n",
            "Mon Apr 25 18:08:47 2022: Epoch [9], Iteration [100/391/], Data(s): 0.052, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.077, Top5: 99.7602, Loss: 0.206\n",
            "Mon Apr 25 18:09:07 2022: Epoch [9], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.579, Top5: 99.8057, Loss: 0.178\n",
            "Mon Apr 25 18:09:27 2022: Epoch [9], Iteration [300/391/], Data(s): 0.051, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.581, Top5: 99.7716, Loss: 0.193\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 18:09:53 2022: Test information, Data(s): 2.512, Forward(s): 0.603, Top1: 90.570, Top5: 99.260, \n",
            "\n",
            "Mon Apr 25 18:09:53 2022: conv3 Layer, 49 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 79, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(79, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(79, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8           [-1, 79, 16, 16]          45,583\n",
            "       BatchNorm2d-9           [-1, 79, 16, 16]             158\n",
            "             ReLU-10           [-1, 79, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]          91,136\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         295,168\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]       1,180,160\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 14,907,127\n",
            "Trainable params: 14,907,127\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 6.29\n",
            "Params size (MB): 56.87\n",
            "Estimated Total Size (MB): 63.17\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 79, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(79, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(79, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 18:09:55 2022: Epoch [0], Iteration [0/391/], Data(s): 0.052, Loss(s): 0.028, Forward(s): 0.134, Backward(s): 0.282, Top1: 93.750, Top5: 100.0000, Loss: 0.205\n",
            "Mon Apr 25 18:10:15 2022: Epoch [0], Iteration [100/391/], Data(s): 0.052, Loss(s): 0.041, Forward(s): 0.007, Backward(s): 0.014, Top1: 93.371, Top5: 99.6751, Loss: 0.199\n",
            "Mon Apr 25 18:10:35 2022: Epoch [0], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.041, Forward(s): 0.007, Backward(s): 0.013, Top1: 93.396, Top5: 99.6696, Loss: 0.203\n",
            "Mon Apr 25 18:10:55 2022: Epoch [0], Iteration [300/391/], Data(s): 0.051, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.013, Top1: 93.358, Top5: 99.6859, Loss: 0.200\n",
            "Mon Apr 25 18:11:13 2022: Epoch [1], Iteration [0/391/], Data(s): 0.077, Loss(s): 0.039, Forward(s): 0.008, Backward(s): 0.012, Top1: 92.969, Top5: 100.0000, Loss: 0.196\n",
            "Mon Apr 25 18:11:33 2022: Epoch [1], Iteration [100/391/], Data(s): 0.052, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.472, Top5: 99.6983, Loss: 0.196\n",
            "Mon Apr 25 18:11:53 2022: Epoch [1], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.711, Top5: 99.7435, Loss: 0.186\n",
            "Mon Apr 25 18:12:13 2022: Epoch [1], Iteration [300/391/], Data(s): 0.051, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.708, Top5: 99.7456, Loss: 0.192\n",
            "Mon Apr 25 18:12:31 2022: Epoch [2], Iteration [0/391/], Data(s): 0.074, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.312, Top5: 100.0000, Loss: 0.190\n",
            "Mon Apr 25 18:12:51 2022: Epoch [2], Iteration [100/391/], Data(s): 0.052, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.425, Top5: 99.7215, Loss: 0.196\n",
            "Mon Apr 25 18:13:11 2022: Epoch [2], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.645, Top5: 99.7279, Loss: 0.186\n",
            "Mon Apr 25 18:13:31 2022: Epoch [2], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.641, Top5: 99.7534, Loss: 0.192\n",
            "Mon Apr 25 18:13:49 2022: Epoch [3], Iteration [0/391/], Data(s): 0.075, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.011, Top1: 94.531, Top5: 100.0000, Loss: 0.186\n",
            "Mon Apr 25 18:14:09 2022: Epoch [3], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.036, Top5: 99.7679, Loss: 0.184\n",
            "Mon Apr 25 18:14:29 2022: Epoch [3], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.987, Top5: 99.7124, Loss: 0.186\n",
            "Mon Apr 25 18:14:48 2022: Epoch [3], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.815, Top5: 99.7041, Loss: 0.195\n",
            "Mon Apr 25 18:15:07 2022: Epoch [4], Iteration [0/391/], Data(s): 0.073, Loss(s): 0.041, Forward(s): 0.005, Backward(s): 0.013, Top1: 96.094, Top5: 100.0000, Loss: 0.174\n",
            "Mon Apr 25 18:15:26 2022: Epoch [4], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.028, Top5: 99.7679, Loss: 0.181\n",
            "Mon Apr 25 18:15:46 2022: Epoch [4], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.991, Top5: 99.7318, Loss: 0.182\n",
            "Mon Apr 25 18:16:06 2022: Epoch [4], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.880, Top5: 99.7534, Loss: 0.185\n",
            "Mon Apr 25 18:16:24 2022: Epoch [5], Iteration [0/391/], Data(s): 0.061, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.011, Top1: 92.969, Top5: 100.0000, Loss: 0.176\n",
            "Mon Apr 25 18:16:44 2022: Epoch [5], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.230, Top5: 99.8066, Loss: 0.178\n",
            "Mon Apr 25 18:17:04 2022: Epoch [5], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.205, Top5: 99.8018, Loss: 0.174\n",
            "Mon Apr 25 18:17:24 2022: Epoch [5], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.225, Top5: 99.7846, Loss: 0.178\n",
            "Mon Apr 25 18:17:42 2022: Epoch [6], Iteration [0/391/], Data(s): 0.076, Loss(s): 0.037, Forward(s): 0.009, Backward(s): 0.014, Top1: 95.312, Top5: 100.0000, Loss: 0.192\n",
            "Mon Apr 25 18:18:02 2022: Epoch [6], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.477, Top5: 99.7834, Loss: 0.170\n",
            "Mon Apr 25 18:18:21 2022: Epoch [6], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.345, Top5: 99.7551, Loss: 0.178\n",
            "Mon Apr 25 18:18:41 2022: Epoch [6], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.173, Top5: 99.7353, Loss: 0.184\n",
            "Mon Apr 25 18:18:59 2022: Epoch [7], Iteration [0/391/], Data(s): 0.077, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.011, Top1: 92.188, Top5: 98.4375, Loss: 0.175\n",
            "Mon Apr 25 18:19:19 2022: Epoch [7], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.268, Top5: 99.7912, Loss: 0.171\n",
            "Mon Apr 25 18:19:39 2022: Epoch [7], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.290, Top5: 99.7746, Loss: 0.172\n",
            "Mon Apr 25 18:19:58 2022: Epoch [7], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.337, Top5: 99.7742, Loss: 0.170\n",
            "Mon Apr 25 18:20:17 2022: Epoch [8], Iteration [0/391/], Data(s): 0.083, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.969, Top5: 100.0000, Loss: 0.168\n",
            "Mon Apr 25 18:20:36 2022: Epoch [8], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.307, Top5: 99.8298, Loss: 0.171\n",
            "Mon Apr 25 18:20:56 2022: Epoch [8], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.306, Top5: 99.8018, Loss: 0.177\n",
            "Mon Apr 25 18:21:16 2022: Epoch [8], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.311, Top5: 99.8001, Loss: 0.169\n",
            "Mon Apr 25 18:21:34 2022: Epoch [9], Iteration [0/391/], Data(s): 0.073, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.011, Top1: 92.969, Top5: 100.0000, Loss: 0.170\n",
            "Mon Apr 25 18:21:54 2022: Epoch [9], Iteration [100/391/], Data(s): 0.050, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.647, Top5: 99.7912, Loss: 0.171\n",
            "Mon Apr 25 18:22:13 2022: Epoch [9], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.504, Top5: 99.7901, Loss: 0.173\n",
            "Mon Apr 25 18:22:33 2022: Epoch [9], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.500, Top5: 99.7742, Loss: 0.168\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 18:22:59 2022: Test information, Data(s): 2.445, Forward(s): 0.655, Top1: 90.840, Top5: 99.280, \n",
            "\n",
            "Mon Apr 25 18:22:59 2022: conv3 Layer, 65 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 63, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(63, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(63, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8           [-1, 63, 16, 16]          36,351\n",
            "       BatchNorm2d-9           [-1, 63, 16, 16]             126\n",
            "             ReLU-10           [-1, 63, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]          72,704\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         295,168\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]       1,180,160\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 14,879,431\n",
            "Trainable params: 14,879,431\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 6.19\n",
            "Params size (MB): 56.76\n",
            "Estimated Total Size (MB): 62.97\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 63, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(63, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(63, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 18:23:01 2022: Epoch [0], Iteration [0/391/], Data(s): 0.050, Loss(s): 0.017, Forward(s): 0.119, Backward(s): 0.209, Top1: 95.312, Top5: 100.0000, Loss: 0.154\n",
            "Mon Apr 25 18:23:20 2022: Epoch [0], Iteration [100/391/], Data(s): 0.050, Loss(s): 0.039, Forward(s): 0.007, Backward(s): 0.014, Top1: 94.191, Top5: 99.7370, Loss: 0.178\n",
            "Mon Apr 25 18:23:40 2022: Epoch [0], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.013, Top1: 93.999, Top5: 99.7396, Loss: 0.189\n",
            "Mon Apr 25 18:23:59 2022: Epoch [0], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.965, Top5: 99.7379, Loss: 0.182\n",
            "Mon Apr 25 18:24:17 2022: Epoch [1], Iteration [0/391/], Data(s): 0.077, Loss(s): 0.038, Forward(s): 0.008, Backward(s): 0.012, Top1: 96.875, Top5: 100.0000, Loss: 0.183\n",
            "Mon Apr 25 18:24:36 2022: Epoch [1], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.160, Top5: 99.7215, Loss: 0.178\n",
            "Mon Apr 25 18:24:56 2022: Epoch [1], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.232, Top5: 99.7279, Loss: 0.171\n",
            "Mon Apr 25 18:25:15 2022: Epoch [1], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.186, Top5: 99.7301, Loss: 0.178\n",
            "Mon Apr 25 18:25:33 2022: Epoch [2], Iteration [0/391/], Data(s): 0.079, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.875, Top5: 100.0000, Loss: 0.178\n",
            "Mon Apr 25 18:25:52 2022: Epoch [2], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.678, Top5: 99.7602, Loss: 0.162\n",
            "Mon Apr 25 18:26:12 2022: Epoch [2], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.566, Top5: 99.7474, Loss: 0.168\n",
            "Mon Apr 25 18:26:31 2022: Epoch [2], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.461, Top5: 99.7664, Loss: 0.176\n",
            "Mon Apr 25 18:26:49 2022: Epoch [3], Iteration [0/391/], Data(s): 0.073, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.188, Top5: 99.2188, Loss: 0.176\n",
            "Mon Apr 25 18:27:08 2022: Epoch [3], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.415, Top5: 99.6906, Loss: 0.170\n",
            "Mon Apr 25 18:27:28 2022: Epoch [3], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.461, Top5: 99.7435, Loss: 0.170\n",
            "Mon Apr 25 18:27:47 2022: Epoch [3], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.474, Top5: 99.7690, Loss: 0.168\n",
            "Mon Apr 25 18:28:05 2022: Epoch [4], Iteration [0/391/], Data(s): 0.079, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.011, Top1: 91.406, Top5: 98.4375, Loss: 0.159\n",
            "Mon Apr 25 18:28:24 2022: Epoch [4], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.632, Top5: 99.8530, Loss: 0.161\n",
            "Mon Apr 25 18:28:44 2022: Epoch [4], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.496, Top5: 99.7940, Loss: 0.166\n",
            "Mon Apr 25 18:29:03 2022: Epoch [4], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.492, Top5: 99.8053, Loss: 0.165\n",
            "Mon Apr 25 18:29:21 2022: Epoch [5], Iteration [0/391/], Data(s): 0.076, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.312, Top5: 100.0000, Loss: 0.165\n",
            "Mon Apr 25 18:29:40 2022: Epoch [5], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.802, Top5: 99.8066, Loss: 0.160\n",
            "Mon Apr 25 18:30:00 2022: Epoch [5], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.803, Top5: 99.8134, Loss: 0.159\n",
            "Mon Apr 25 18:30:19 2022: Epoch [5], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.731, Top5: 99.8079, Loss: 0.165\n",
            "Mon Apr 25 18:30:37 2022: Epoch [6], Iteration [0/391/], Data(s): 0.075, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.011, Top1: 96.094, Top5: 100.0000, Loss: 0.158\n",
            "Mon Apr 25 18:30:56 2022: Epoch [6], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.732, Top5: 99.7912, Loss: 0.162\n",
            "Mon Apr 25 18:31:16 2022: Epoch [6], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.617, Top5: 99.8095, Loss: 0.168\n",
            "Mon Apr 25 18:31:35 2022: Epoch [6], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.684, Top5: 99.8053, Loss: 0.165\n",
            "Mon Apr 25 18:31:53 2022: Epoch [7], Iteration [0/391/], Data(s): 0.078, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.750, Top5: 100.0000, Loss: 0.150\n",
            "Mon Apr 25 18:32:13 2022: Epoch [7], Iteration [100/391/], Data(s): 0.052, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.585, Top5: 99.7834, Loss: 0.162\n",
            "Mon Apr 25 18:32:32 2022: Epoch [7], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.694, Top5: 99.8212, Loss: 0.158\n",
            "Mon Apr 25 18:32:52 2022: Epoch [7], Iteration [300/391/], Data(s): 0.051, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.705, Top5: 99.8001, Loss: 0.158\n",
            "Mon Apr 25 18:33:09 2022: Epoch [8], Iteration [0/391/], Data(s): 0.082, Loss(s): 0.040, Forward(s): 0.005, Backward(s): 0.012, Top1: 96.875, Top5: 99.2188, Loss: 0.159\n",
            "Mon Apr 25 18:33:29 2022: Epoch [8], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.988, Top5: 99.8144, Loss: 0.155\n",
            "Mon Apr 25 18:33:48 2022: Epoch [8], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.990, Top5: 99.8290, Loss: 0.152\n",
            "Mon Apr 25 18:34:08 2022: Epoch [8], Iteration [300/391/], Data(s): 0.051, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.975, Top5: 99.8417, Loss: 0.154\n",
            "Mon Apr 25 18:34:26 2022: Epoch [9], Iteration [0/391/], Data(s): 0.074, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.969, Top5: 100.0000, Loss: 0.156\n",
            "Mon Apr 25 18:34:45 2022: Epoch [9], Iteration [100/391/], Data(s): 0.050, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.050, Top5: 99.8453, Loss: 0.151\n",
            "Mon Apr 25 18:35:04 2022: Epoch [9], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.033, Top5: 99.8445, Loss: 0.149\n",
            "Mon Apr 25 18:35:24 2022: Epoch [9], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.941, Top5: 99.8495, Loss: 0.156\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 18:35:50 2022: Test information, Data(s): 2.466, Forward(s): 0.609, Top1: 90.920, Top5: 99.260, \n",
            "\n",
            "Mon Apr 25 18:35:50 2022: conv3 Layer, 82 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 46, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(46, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(46, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8           [-1, 46, 16, 16]          26,542\n",
            "       BatchNorm2d-9           [-1, 46, 16, 16]              92\n",
            "             ReLU-10           [-1, 46, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]          53,120\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         295,168\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]       1,180,160\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 14,850,004\n",
            "Trainable params: 14,850,004\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 6.09\n",
            "Params size (MB): 56.65\n",
            "Estimated Total Size (MB): 62.75\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 46, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(46, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(46, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 18:35:51 2022: Epoch [0], Iteration [0/391/], Data(s): 0.054, Loss(s): 0.022, Forward(s): 0.095, Backward(s): 0.209, Top1: 92.188, Top5: 99.2188, Loss: 0.253\n",
            "Mon Apr 25 18:36:10 2022: Epoch [0], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.039, Forward(s): 0.007, Backward(s): 0.014, Top1: 93.889, Top5: 99.7293, Loss: 0.189\n",
            "Mon Apr 25 18:36:30 2022: Epoch [0], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.013, Top1: 93.801, Top5: 99.7512, Loss: 0.182\n",
            "Mon Apr 25 18:36:49 2022: Epoch [0], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.906, Top5: 99.7586, Loss: 0.178\n",
            "Mon Apr 25 18:37:07 2022: Epoch [1], Iteration [0/391/], Data(s): 0.074, Loss(s): 0.037, Forward(s): 0.007, Backward(s): 0.012, Top1: 96.875, Top5: 100.0000, Loss: 0.176\n",
            "Mon Apr 25 18:37:26 2022: Epoch [1], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.469, Top5: 99.8221, Loss: 0.166\n",
            "Mon Apr 25 18:37:46 2022: Epoch [1], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.473, Top5: 99.8095, Loss: 0.167\n",
            "Mon Apr 25 18:38:05 2022: Epoch [1], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.287, Top5: 99.8027, Loss: 0.179\n",
            "Mon Apr 25 18:38:23 2022: Epoch [2], Iteration [0/391/], Data(s): 0.078, Loss(s): 0.040, Forward(s): 0.005, Backward(s): 0.012, Top1: 95.312, Top5: 100.0000, Loss: 0.170\n",
            "Mon Apr 25 18:38:42 2022: Epoch [2], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.493, Top5: 99.8066, Loss: 0.161\n",
            "Mon Apr 25 18:39:01 2022: Epoch [2], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.523, Top5: 99.8057, Loss: 0.160\n",
            "Mon Apr 25 18:39:21 2022: Epoch [2], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.409, Top5: 99.7898, Loss: 0.174\n",
            "Mon Apr 25 18:39:39 2022: Epoch [3], Iteration [0/391/], Data(s): 0.073, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.014, Top1: 95.312, Top5: 100.0000, Loss: 0.169\n",
            "Mon Apr 25 18:39:58 2022: Epoch [3], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.941, Top5: 99.8685, Loss: 0.153\n",
            "Mon Apr 25 18:40:17 2022: Epoch [3], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.644, Top5: 99.8251, Loss: 0.169\n",
            "Mon Apr 25 18:40:37 2022: Epoch [3], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.547, Top5: 99.8183, Loss: 0.167\n",
            "Mon Apr 25 18:40:54 2022: Epoch [4], Iteration [0/391/], Data(s): 0.074, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.969, Top5: 100.0000, Loss: 0.160\n",
            "Mon Apr 25 18:41:14 2022: Epoch [4], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.841, Top5: 99.8298, Loss: 0.153\n",
            "Mon Apr 25 18:41:33 2022: Epoch [4], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.780, Top5: 99.8290, Loss: 0.159\n",
            "Mon Apr 25 18:41:52 2022: Epoch [4], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.770, Top5: 99.8235, Loss: 0.156\n",
            "Mon Apr 25 18:42:10 2022: Epoch [5], Iteration [0/391/], Data(s): 0.073, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.531, Top5: 100.0000, Loss: 0.159\n",
            "Mon Apr 25 18:42:29 2022: Epoch [5], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.034, Top5: 99.8066, Loss: 0.154\n",
            "Mon Apr 25 18:42:49 2022: Epoch [5], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.807, Top5: 99.8368, Loss: 0.160\n",
            "Mon Apr 25 18:43:08 2022: Epoch [5], Iteration [300/391/], Data(s): 0.051, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.845, Top5: 99.8209, Loss: 0.157\n",
            "Mon Apr 25 18:43:26 2022: Epoch [6], Iteration [0/391/], Data(s): 0.076, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.011, Top1: 92.969, Top5: 100.0000, Loss: 0.153\n",
            "Mon Apr 25 18:43:45 2022: Epoch [6], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.026, Top5: 99.8453, Loss: 0.148\n",
            "Mon Apr 25 18:44:05 2022: Epoch [6], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.959, Top5: 99.8523, Loss: 0.154\n",
            "Mon Apr 25 18:44:24 2022: Epoch [6], Iteration [300/391/], Data(s): 0.051, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.024, Top5: 99.8183, Loss: 0.151\n",
            "Mon Apr 25 18:44:42 2022: Epoch [7], Iteration [0/391/], Data(s): 0.077, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.011, Top1: 89.844, Top5: 99.2188, Loss: 0.146\n",
            "Mon Apr 25 18:45:01 2022: Epoch [7], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.158, Top5: 99.8376, Loss: 0.145\n",
            "Mon Apr 25 18:45:20 2022: Epoch [7], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.134, Top5: 99.8329, Loss: 0.146\n",
            "Mon Apr 25 18:45:40 2022: Epoch [7], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.035, Top5: 99.8391, Loss: 0.154\n",
            "Mon Apr 25 18:45:57 2022: Epoch [8], Iteration [0/391/], Data(s): 0.071, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.011, Top1: 96.875, Top5: 100.0000, Loss: 0.142\n",
            "Mon Apr 25 18:46:17 2022: Epoch [8], Iteration [100/391/], Data(s): 0.052, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.359, Top5: 99.7989, Loss: 0.143\n",
            "Mon Apr 25 18:46:36 2022: Epoch [8], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.227, Top5: 99.8406, Loss: 0.145\n",
            "Mon Apr 25 18:46:55 2022: Epoch [8], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.276, Top5: 99.8521, Loss: 0.136\n",
            "Mon Apr 25 18:47:13 2022: Epoch [9], Iteration [0/391/], Data(s): 0.075, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.011, Top1: 94.531, Top5: 100.0000, Loss: 0.148\n",
            "Mon Apr 25 18:47:32 2022: Epoch [9], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.429, Top5: 99.8453, Loss: 0.139\n",
            "Mon Apr 25 18:47:52 2022: Epoch [9], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.305, Top5: 99.8290, Loss: 0.145\n",
            "Mon Apr 25 18:48:11 2022: Epoch [9], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.346, Top5: 99.8547, Loss: 0.136\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 18:48:37 2022: Test information, Data(s): 2.454, Forward(s): 0.612, Top1: 90.820, Top5: 99.300, \n",
            "\n",
            "Mon Apr 25 18:48:37 2022: conv3 Layer, 98 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(30, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8           [-1, 30, 16, 16]          17,310\n",
            "       BatchNorm2d-9           [-1, 30, 16, 16]              60\n",
            "             ReLU-10           [-1, 30, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]          34,688\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         295,168\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]       1,180,160\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 14,822,308\n",
            "Trainable params: 14,822,308\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 6.00\n",
            "Params size (MB): 56.54\n",
            "Estimated Total Size (MB): 62.55\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(30, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 18:48:38 2022: Epoch [0], Iteration [0/391/], Data(s): 0.054, Loss(s): 0.027, Forward(s): 0.069, Backward(s): 0.190, Top1: 89.844, Top5: 99.2188, Loss: 0.266\n",
            "Mon Apr 25 18:48:58 2022: Epoch [0], Iteration [100/391/], Data(s): 0.052, Loss(s): 0.039, Forward(s): 0.007, Backward(s): 0.014, Top1: 92.218, Top5: 99.6597, Loss: 0.232\n",
            "Mon Apr 25 18:49:17 2022: Epoch [0], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.013, Top1: 92.596, Top5: 99.6735, Loss: 0.207\n",
            "Mon Apr 25 18:49:36 2022: Epoch [0], Iteration [300/391/], Data(s): 0.051, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.893, Top5: 99.6911, Loss: 0.194\n",
            "Mon Apr 25 18:49:54 2022: Epoch [1], Iteration [0/391/], Data(s): 0.075, Loss(s): 0.038, Forward(s): 0.007, Backward(s): 0.012, Top1: 96.094, Top5: 100.0000, Loss: 0.192\n",
            "Mon Apr 25 18:50:13 2022: Epoch [1], Iteration [100/391/], Data(s): 0.052, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.742, Top5: 99.8530, Loss: 0.184\n",
            "Mon Apr 25 18:50:32 2022: Epoch [1], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.812, Top5: 99.7901, Loss: 0.185\n",
            "Mon Apr 25 18:50:51 2022: Epoch [1], Iteration [300/391/], Data(s): 0.051, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.903, Top5: 99.7820, Loss: 0.180\n",
            "Mon Apr 25 18:51:09 2022: Epoch [2], Iteration [0/391/], Data(s): 0.076, Loss(s): 0.038, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.188, Top5: 100.0000, Loss: 0.170\n",
            "Mon Apr 25 18:51:28 2022: Epoch [2], Iteration [100/391/], Data(s): 0.052, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.291, Top5: 99.8608, Loss: 0.166\n",
            "Mon Apr 25 18:51:48 2022: Epoch [2], Iteration [200/391/], Data(s): 0.052, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.197, Top5: 99.8329, Loss: 0.170\n",
            "Mon Apr 25 18:52:07 2022: Epoch [2], Iteration [300/391/], Data(s): 0.052, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.165, Top5: 99.8183, Loss: 0.170\n",
            "Mon Apr 25 18:52:24 2022: Epoch [3], Iteration [0/391/], Data(s): 0.076, Loss(s): 0.039, Forward(s): 0.005, Backward(s): 0.011, Top1: 94.531, Top5: 100.0000, Loss: 0.169\n",
            "Mon Apr 25 18:52:44 2022: Epoch [3], Iteration [100/391/], Data(s): 0.052, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.013, Top1: 94.709, Top5: 99.8298, Loss: 0.157\n",
            "Mon Apr 25 18:53:03 2022: Epoch [3], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.605, Top5: 99.8290, Loss: 0.165\n",
            "Mon Apr 25 18:53:22 2022: Epoch [3], Iteration [300/391/], Data(s): 0.051, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.518, Top5: 99.8183, Loss: 0.168\n",
            "Mon Apr 25 18:53:40 2022: Epoch [4], Iteration [0/391/], Data(s): 0.075, Loss(s): 0.038, Forward(s): 0.006, Backward(s): 0.011, Top1: 93.750, Top5: 100.0000, Loss: 0.160\n",
            "Mon Apr 25 18:53:59 2022: Epoch [4], Iteration [100/391/], Data(s): 0.053, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.454, Top5: 99.8840, Loss: 0.158\n",
            "Mon Apr 25 18:54:18 2022: Epoch [4], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.593, Top5: 99.8756, Loss: 0.157\n",
            "Mon Apr 25 18:54:38 2022: Epoch [4], Iteration [300/391/], Data(s): 0.051, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.749, Top5: 99.8547, Loss: 0.154\n",
            "Mon Apr 25 18:54:55 2022: Epoch [5], Iteration [0/391/], Data(s): 0.075, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.011, Top1: 94.531, Top5: 100.0000, Loss: 0.156\n",
            "Mon Apr 25 18:55:15 2022: Epoch [5], Iteration [100/391/], Data(s): 0.052, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.748, Top5: 99.8066, Loss: 0.156\n",
            "Mon Apr 25 18:55:34 2022: Epoch [5], Iteration [200/391/], Data(s): 0.052, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.838, Top5: 99.8406, Loss: 0.146\n",
            "Mon Apr 25 18:55:53 2022: Epoch [5], Iteration [300/391/], Data(s): 0.051, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.853, Top5: 99.8261, Loss: 0.155\n",
            "Mon Apr 25 18:56:11 2022: Epoch [6], Iteration [0/391/], Data(s): 0.082, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.750, Top5: 99.2188, Loss: 0.150\n",
            "Mon Apr 25 18:56:30 2022: Epoch [6], Iteration [100/391/], Data(s): 0.053, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.135, Top5: 99.8685, Loss: 0.144\n",
            "Mon Apr 25 18:56:49 2022: Epoch [6], Iteration [200/391/], Data(s): 0.052, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.103, Top5: 99.8640, Loss: 0.146\n",
            "Mon Apr 25 18:57:09 2022: Epoch [6], Iteration [300/391/], Data(s): 0.052, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.118, Top5: 99.8521, Loss: 0.143\n",
            "Mon Apr 25 18:57:26 2022: Epoch [7], Iteration [0/391/], Data(s): 0.078, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.011, Top1: 94.531, Top5: 100.0000, Loss: 0.149\n",
            "Mon Apr 25 18:57:46 2022: Epoch [7], Iteration [100/391/], Data(s): 0.052, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.887, Top5: 99.8530, Loss: 0.150\n",
            "Mon Apr 25 18:58:05 2022: Epoch [7], Iteration [200/391/], Data(s): 0.052, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.974, Top5: 99.8756, Loss: 0.149\n",
            "Mon Apr 25 18:58:24 2022: Epoch [7], Iteration [300/391/], Data(s): 0.051, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.139, Top5: 99.8469, Loss: 0.141\n",
            "Mon Apr 25 18:58:42 2022: Epoch [8], Iteration [0/391/], Data(s): 0.071, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.531, Top5: 99.2188, Loss: 0.144\n",
            "Mon Apr 25 18:59:01 2022: Epoch [8], Iteration [100/391/], Data(s): 0.053, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.189, Top5: 99.8298, Loss: 0.144\n",
            "Mon Apr 25 18:59:21 2022: Epoch [8], Iteration [200/391/], Data(s): 0.052, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.161, Top5: 99.8368, Loss: 0.145\n",
            "Mon Apr 25 18:59:40 2022: Epoch [8], Iteration [300/391/], Data(s): 0.052, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.188, Top5: 99.8339, Loss: 0.145\n",
            "Mon Apr 25 18:59:58 2022: Epoch [9], Iteration [0/391/], Data(s): 0.077, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 97.656, Top5: 100.0000, Loss: 0.132\n",
            "Mon Apr 25 19:00:17 2022: Epoch [9], Iteration [100/391/], Data(s): 0.053, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.266, Top5: 99.8840, Loss: 0.141\n",
            "Mon Apr 25 19:00:36 2022: Epoch [9], Iteration [200/391/], Data(s): 0.052, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.375, Top5: 99.9184, Loss: 0.136\n",
            "Mon Apr 25 19:00:55 2022: Epoch [9], Iteration [300/391/], Data(s): 0.051, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.419, Top5: 99.8988, Loss: 0.133\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 19:01:21 2022: Test information, Data(s): 2.423, Forward(s): 0.619, Top1: 90.720, Top5: 99.350, \n",
            "\n",
            "Mon Apr 25 19:01:21 2022: conv3 Layer, 115 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 13, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(13, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8           [-1, 13, 16, 16]           7,501\n",
            "       BatchNorm2d-9           [-1, 13, 16, 16]              26\n",
            "             ReLU-10           [-1, 13, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]          15,104\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         295,168\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]       1,180,160\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 14,792,881\n",
            "Trainable params: 14,792,881\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 5.90\n",
            "Params size (MB): 56.43\n",
            "Estimated Total Size (MB): 62.34\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 13, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(13, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 19:01:22 2022: Epoch [0], Iteration [0/391/], Data(s): 0.054, Loss(s): 0.027, Forward(s): 0.052, Backward(s): 0.185, Top1: 78.125, Top5: 95.3125, Loss: 1.050\n",
            "Mon Apr 25 19:01:41 2022: Epoch [0], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.038, Forward(s): 0.006, Backward(s): 0.013, Top1: 86.371, Top5: 98.5767, Loss: 0.469\n",
            "Mon Apr 25 19:02:00 2022: Epoch [0], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.038, Forward(s): 0.006, Backward(s): 0.012, Top1: 87.512, Top5: 98.9078, Loss: 0.343\n",
            "Mon Apr 25 19:02:19 2022: Epoch [0], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.011, Top1: 88.294, Top5: 99.0708, Loss: 0.308\n",
            "Mon Apr 25 19:02:37 2022: Epoch [1], Iteration [0/391/], Data(s): 0.076, Loss(s): 0.037, Forward(s): 0.007, Backward(s): 0.011, Top1: 92.188, Top5: 99.2188, Loss: 0.297\n",
            "Mon Apr 25 19:02:56 2022: Epoch [1], Iteration [100/391/], Data(s): 0.052, Loss(s): 0.038, Forward(s): 0.006, Backward(s): 0.011, Top1: 91.012, Top5: 99.5359, Loss: 0.271\n",
            "Mon Apr 25 19:03:15 2022: Epoch [1], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.011, Top1: 91.181, Top5: 99.5336, Loss: 0.259\n",
            "Mon Apr 25 19:03:34 2022: Epoch [1], Iteration [300/391/], Data(s): 0.051, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.011, Top1: 91.393, Top5: 99.5691, Loss: 0.242\n",
            "Mon Apr 25 19:03:51 2022: Epoch [2], Iteration [0/391/], Data(s): 0.082, Loss(s): 0.039, Forward(s): 0.005, Backward(s): 0.010, Top1: 92.188, Top5: 99.2188, Loss: 0.248\n",
            "Mon Apr 25 19:04:10 2022: Epoch [2], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.011, Top1: 92.087, Top5: 99.6132, Loss: 0.232\n",
            "Mon Apr 25 19:04:29 2022: Epoch [2], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.011, Top1: 92.199, Top5: 99.6346, Loss: 0.233\n",
            "Mon Apr 25 19:04:48 2022: Epoch [2], Iteration [300/391/], Data(s): 0.051, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.011, Top1: 92.213, Top5: 99.6288, Loss: 0.232\n",
            "Mon Apr 25 19:05:06 2022: Epoch [3], Iteration [0/391/], Data(s): 0.076, Loss(s): 0.038, Forward(s): 0.006, Backward(s): 0.011, Top1: 93.750, Top5: 98.4375, Loss: 0.230\n",
            "Mon Apr 25 19:05:25 2022: Epoch [3], Iteration [100/391/], Data(s): 0.052, Loss(s): 0.038, Forward(s): 0.006, Backward(s): 0.011, Top1: 92.853, Top5: 99.6132, Loss: 0.211\n",
            "Mon Apr 25 19:05:44 2022: Epoch [3], Iteration [200/391/], Data(s): 0.052, Loss(s): 0.038, Forward(s): 0.006, Backward(s): 0.011, Top1: 92.910, Top5: 99.6463, Loss: 0.213\n",
            "Mon Apr 25 19:06:03 2022: Epoch [3], Iteration [300/391/], Data(s): 0.051, Loss(s): 0.038, Forward(s): 0.006, Backward(s): 0.011, Top1: 92.984, Top5: 99.6444, Loss: 0.206\n",
            "Mon Apr 25 19:06:21 2022: Epoch [4], Iteration [0/391/], Data(s): 0.083, Loss(s): 0.038, Forward(s): 0.006, Backward(s): 0.010, Top1: 95.312, Top5: 100.0000, Loss: 0.216\n",
            "Mon Apr 25 19:06:40 2022: Epoch [4], Iteration [100/391/], Data(s): 0.052, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.011, Top1: 93.518, Top5: 99.7525, Loss: 0.193\n",
            "Mon Apr 25 19:06:59 2022: Epoch [4], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.011, Top1: 93.478, Top5: 99.7201, Loss: 0.195\n",
            "Mon Apr 25 19:07:18 2022: Epoch [4], Iteration [300/391/], Data(s): 0.051, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.011, Top1: 93.332, Top5: 99.7482, Loss: 0.201\n",
            "Mon Apr 25 19:07:35 2022: Epoch [5], Iteration [0/391/], Data(s): 0.079, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.010, Top1: 93.750, Top5: 100.0000, Loss: 0.192\n",
            "Mon Apr 25 19:07:54 2022: Epoch [5], Iteration [100/391/], Data(s): 0.052, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.011, Top1: 93.781, Top5: 99.7757, Loss: 0.184\n",
            "Mon Apr 25 19:08:13 2022: Epoch [5], Iteration [200/391/], Data(s): 0.052, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.011, Top1: 93.851, Top5: 99.7901, Loss: 0.186\n",
            "Mon Apr 25 19:08:33 2022: Epoch [5], Iteration [300/391/], Data(s): 0.052, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.011, Top1: 93.724, Top5: 99.7820, Loss: 0.193\n",
            "Mon Apr 25 19:08:50 2022: Epoch [6], Iteration [0/391/], Data(s): 0.079, Loss(s): 0.038, Forward(s): 0.006, Backward(s): 0.010, Top1: 92.969, Top5: 99.2188, Loss: 0.197\n",
            "Mon Apr 25 19:09:09 2022: Epoch [6], Iteration [100/391/], Data(s): 0.053, Loss(s): 0.038, Forward(s): 0.006, Backward(s): 0.011, Top1: 93.897, Top5: 99.7912, Loss: 0.181\n",
            "Mon Apr 25 19:09:28 2022: Epoch [6], Iteration [200/391/], Data(s): 0.052, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.011, Top1: 93.843, Top5: 99.7785, Loss: 0.182\n",
            "Mon Apr 25 19:09:47 2022: Epoch [6], Iteration [300/391/], Data(s): 0.052, Loss(s): 0.038, Forward(s): 0.006, Backward(s): 0.011, Top1: 93.802, Top5: 99.8053, Loss: 0.184\n",
            "Mon Apr 25 19:10:05 2022: Epoch [7], Iteration [0/391/], Data(s): 0.082, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.011, Top1: 90.625, Top5: 100.0000, Loss: 0.182\n",
            "Mon Apr 25 19:10:24 2022: Epoch [7], Iteration [100/391/], Data(s): 0.052, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.011, Top1: 94.353, Top5: 99.7525, Loss: 0.171\n",
            "Mon Apr 25 19:10:43 2022: Epoch [7], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.011, Top1: 94.213, Top5: 99.7862, Loss: 0.173\n",
            "Mon Apr 25 19:11:02 2022: Epoch [7], Iteration [300/391/], Data(s): 0.051, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.011, Top1: 94.259, Top5: 99.7975, Loss: 0.173\n",
            "Mon Apr 25 19:11:19 2022: Epoch [8], Iteration [0/391/], Data(s): 0.082, Loss(s): 0.035, Forward(s): 0.010, Backward(s): 0.011, Top1: 94.531, Top5: 100.0000, Loss: 0.185\n",
            "Mon Apr 25 19:11:38 2022: Epoch [8], Iteration [100/391/], Data(s): 0.053, Loss(s): 0.038, Forward(s): 0.006, Backward(s): 0.011, Top1: 94.276, Top5: 99.8530, Loss: 0.173\n",
            "Mon Apr 25 19:11:58 2022: Epoch [8], Iteration [200/391/], Data(s): 0.052, Loss(s): 0.038, Forward(s): 0.006, Backward(s): 0.011, Top1: 94.380, Top5: 99.8406, Loss: 0.165\n",
            "Mon Apr 25 19:12:17 2022: Epoch [8], Iteration [300/391/], Data(s): 0.052, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.011, Top1: 94.331, Top5: 99.8339, Loss: 0.169\n",
            "Mon Apr 25 19:12:34 2022: Epoch [9], Iteration [0/391/], Data(s): 0.075, Loss(s): 0.038, Forward(s): 0.006, Backward(s): 0.011, Top1: 96.875, Top5: 100.0000, Loss: 0.162\n",
            "Mon Apr 25 19:12:53 2022: Epoch [9], Iteration [100/391/], Data(s): 0.053, Loss(s): 0.038, Forward(s): 0.006, Backward(s): 0.011, Top1: 94.601, Top5: 99.8762, Loss: 0.156\n",
            "Mon Apr 25 19:13:12 2022: Epoch [9], Iteration [200/391/], Data(s): 0.052, Loss(s): 0.038, Forward(s): 0.006, Backward(s): 0.011, Top1: 94.601, Top5: 99.8678, Loss: 0.159\n",
            "Mon Apr 25 19:13:31 2022: Epoch [9], Iteration [300/391/], Data(s): 0.052, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.011, Top1: 94.570, Top5: 99.8572, Loss: 0.163\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 19:13:57 2022: Test information, Data(s): 2.484, Forward(s): 0.565, Top1: 89.960, Top5: 99.240, \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "GXDMoyOuqXNG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for conv, channel in zip(prune_layers[8:10], prune_channels[8:10]):    \n",
        "    top1_accuracies[conv] = []\n",
        "    top5_accuracies[conv] = []\n",
        "    \n",
        "    # load new network and check accuracy\n",
        "    network, _, _ = test_network(args, data_set=test_set)\n",
        "        \n",
        "    # remove 0 channels ~ M (max_channel_ratio) % of total channels\n",
        "    step = np.linspace(0, int(channel*max_channel_ratio), int(1/prune_step_ratio), dtype=np.int)\n",
        "    steps = (step[1:] - step[:-1]).tolist()\n",
        "    \n",
        "    for i in range(len(steps)):\n",
        "        print(\"\\n%s: %s Layer, %d Channels pruned\"%(time.ctime(), conv, sum(steps[:i+1])))\n",
        "        \n",
        "        # set prune information\n",
        "        args.prune_layers = [conv]\n",
        "        args.prune_channels =[steps[i]]\n",
        "\n",
        "        network = prune_network(args, network)\n",
        "        \n",
        "        network, _, (top1, top5) = test_network(args, network, test_set)\n",
        "            \n",
        "        top1_accuracies[conv].append(top1)\n",
        "        top5_accuracies[conv].append(top5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1a0d6b8-7cf1-4ac2-a02e-30e182702cff",
        "id": "2ODTbi3jsaid"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 14:43:11 2022: Test information, Data(s): 2.525, Forward(s): 0.498, Top1: 77.870, Top5: 97.560, \n",
            "\n",
            "Mon Apr 25 14:43:11 2022: conv9 Layer, 65 Channels pruned\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  if __name__ == '__main__':\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 447, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(447, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(447, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]          73,856\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "             ReLU-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]         147,584\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         295,168\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]       1,180,160\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 447, 4, 4]       2,060,223\n",
            "      BatchNorm2d-29            [-1, 447, 4, 4]             894\n",
            "             ReLU-30            [-1, 447, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,060,288\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 14,392,711\n",
            "Trainable params: 14,392,711\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 6.55\n",
            "Params size (MB): 54.90\n",
            "Estimated Total Size (MB): 61.47\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 447, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(447, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(447, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 14:43:16 2022: Epoch [0], Iteration [0/391/], Data(s): 0.054, Loss(s): 0.008, Forward(s): 1.329, Backward(s): 1.980, Top1: 86.719, Top5: 98.4375, Loss: 0.420\n",
            "Mon Apr 25 14:43:36 2022: Epoch [0], Iteration [100/391/], Data(s): 0.053, Loss(s): 0.040, Forward(s): 0.019, Backward(s): 0.032, Top1: 87.345, Top5: 99.0254, Loss: 0.397\n",
            "Mon Apr 25 14:43:56 2022: Epoch [0], Iteration [200/391/], Data(s): 0.052, Loss(s): 0.041, Forward(s): 0.013, Backward(s): 0.022, Top1: 88.064, Top5: 99.1332, Loss: 0.350\n",
            "Mon Apr 25 14:44:17 2022: Epoch [0], Iteration [300/391/], Data(s): 0.053, Loss(s): 0.041, Forward(s): 0.011, Backward(s): 0.019, Top1: 88.372, Top5: 99.1513, Loss: 0.335\n",
            "Mon Apr 25 14:44:37 2022: Epoch [1], Iteration [0/391/], Data(s): 0.061, Loss(s): 0.039, Forward(s): 0.008, Backward(s): 0.012, Top1: 93.750, Top5: 99.2188, Loss: 0.318\n",
            "Mon Apr 25 14:44:57 2022: Epoch [1], Iteration [100/391/], Data(s): 0.052, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 90.370, Top5: 99.4121, Loss: 0.300\n",
            "Mon Apr 25 14:45:18 2022: Epoch [1], Iteration [200/391/], Data(s): 0.053, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 90.201, Top5: 99.4286, Loss: 0.306\n",
            "Mon Apr 25 14:45:38 2022: Epoch [1], Iteration [300/391/], Data(s): 0.052, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 90.280, Top5: 99.4212, Loss: 0.294\n",
            "Mon Apr 25 14:45:57 2022: Epoch [2], Iteration [0/391/], Data(s): 0.087, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.011, Top1: 90.625, Top5: 99.2188, Loss: 0.300\n",
            "Mon Apr 25 14:46:17 2022: Epoch [2], Iteration [100/391/], Data(s): 0.052, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 90.726, Top5: 99.4972, Loss: 0.287\n",
            "Mon Apr 25 14:46:37 2022: Epoch [2], Iteration [200/391/], Data(s): 0.052, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 90.757, Top5: 99.4753, Loss: 0.282\n",
            "Mon Apr 25 14:46:57 2022: Epoch [2], Iteration [300/391/], Data(s): 0.051, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 90.817, Top5: 99.4498, Loss: 0.284\n",
            "Mon Apr 25 14:47:16 2022: Epoch [3], Iteration [0/391/], Data(s): 0.082, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.188, Top5: 99.2188, Loss: 0.280\n",
            "Mon Apr 25 14:47:36 2022: Epoch [3], Iteration [100/391/], Data(s): 0.052, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 91.778, Top5: 99.4895, Loss: 0.268\n",
            "Mon Apr 25 14:47:56 2022: Epoch [3], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 91.577, Top5: 99.5414, Loss: 0.263\n",
            "Mon Apr 25 14:48:16 2022: Epoch [3], Iteration [300/391/], Data(s): 0.051, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 91.507, Top5: 99.5536, Loss: 0.266\n",
            "Mon Apr 25 14:48:34 2022: Epoch [4], Iteration [0/391/], Data(s): 0.078, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.011, Top1: 90.625, Top5: 100.0000, Loss: 0.273\n",
            "Mon Apr 25 14:48:54 2022: Epoch [4], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 91.778, Top5: 99.6287, Loss: 0.255\n",
            "Mon Apr 25 14:49:14 2022: Epoch [4], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 91.873, Top5: 99.5647, Loss: 0.255\n",
            "Mon Apr 25 14:49:34 2022: Epoch [4], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 91.728, Top5: 99.5614, Loss: 0.260\n",
            "Mon Apr 25 14:49:53 2022: Epoch [5], Iteration [0/391/], Data(s): 0.075, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.969, Top5: 100.0000, Loss: 0.259\n",
            "Mon Apr 25 14:50:13 2022: Epoch [5], Iteration [100/391/], Data(s): 0.052, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 91.855, Top5: 99.5591, Loss: 0.252\n",
            "Mon Apr 25 14:50:33 2022: Epoch [5], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 91.873, Top5: 99.5530, Loss: 0.251\n",
            "Mon Apr 25 14:50:53 2022: Epoch [5], Iteration [300/391/], Data(s): 0.051, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 91.863, Top5: 99.5769, Loss: 0.250\n",
            "Mon Apr 25 14:51:12 2022: Epoch [6], Iteration [0/391/], Data(s): 0.074, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.188, Top5: 100.0000, Loss: 0.251\n",
            "Mon Apr 25 14:51:32 2022: Epoch [6], Iteration [100/391/], Data(s): 0.052, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.396, Top5: 99.6442, Loss: 0.235\n",
            "Mon Apr 25 14:51:52 2022: Epoch [6], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.222, Top5: 99.6346, Loss: 0.236\n",
            "Mon Apr 25 14:52:12 2022: Epoch [6], Iteration [300/391/], Data(s): 0.051, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.136, Top5: 99.6237, Loss: 0.246\n",
            "Mon Apr 25 14:52:30 2022: Epoch [7], Iteration [0/391/], Data(s): 0.077, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.750, Top5: 99.2188, Loss: 0.238\n",
            "Mon Apr 25 14:52:50 2022: Epoch [7], Iteration [100/391/], Data(s): 0.052, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.311, Top5: 99.5823, Loss: 0.239\n",
            "Mon Apr 25 14:53:10 2022: Epoch [7], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.397, Top5: 99.5647, Loss: 0.234\n",
            "Mon Apr 25 14:53:30 2022: Epoch [7], Iteration [300/391/], Data(s): 0.051, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.343, Top5: 99.6133, Loss: 0.240\n",
            "Mon Apr 25 14:53:49 2022: Epoch [8], Iteration [0/391/], Data(s): 0.081, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.011, Top1: 92.969, Top5: 99.2188, Loss: 0.234\n",
            "Mon Apr 25 14:54:09 2022: Epoch [8], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.327, Top5: 99.5204, Loss: 0.233\n",
            "Mon Apr 25 14:54:29 2022: Epoch [8], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.460, Top5: 99.5569, Loss: 0.235\n",
            "Mon Apr 25 14:54:49 2022: Epoch [8], Iteration [300/391/], Data(s): 0.051, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.637, Top5: 99.5665, Loss: 0.223\n",
            "Mon Apr 25 14:55:07 2022: Epoch [9], Iteration [0/391/], Data(s): 0.075, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 89.844, Top5: 99.2188, Loss: 0.222\n",
            "Mon Apr 25 14:55:27 2022: Epoch [9], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.837, Top5: 99.6597, Loss: 0.223\n",
            "Mon Apr 25 14:55:47 2022: Epoch [9], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.720, Top5: 99.6191, Loss: 0.228\n",
            "Mon Apr 25 14:56:07 2022: Epoch [9], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.784, Top5: 99.6211, Loss: 0.221\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 14:56:34 2022: Test information, Data(s): 2.537, Forward(s): 0.810, Top1: 90.060, Top5: 99.270, \n",
            "\n",
            "Mon Apr 25 14:56:34 2022: conv9 Layer, 131 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 381, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(381, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(381, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]          73,856\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "             ReLU-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]         147,584\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         295,168\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]       1,180,160\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 381, 4, 4]       1,756,029\n",
            "      BatchNorm2d-29            [-1, 381, 4, 4]             762\n",
            "             ReLU-30            [-1, 381, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       1,756,160\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 13,784,257\n",
            "Trainable params: 13,784,257\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 6.53\n",
            "Params size (MB): 52.58\n",
            "Estimated Total Size (MB): 59.12\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 381, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(381, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(381, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 14:56:37 2022: Epoch [0], Iteration [0/391/], Data(s): 0.056, Loss(s): 0.008, Forward(s): 0.300, Backward(s): 0.626, Top1: 93.750, Top5: 99.2188, Loss: 0.159\n",
            "Mon Apr 25 14:56:56 2022: Epoch [0], Iteration [100/391/], Data(s): 0.049, Loss(s): 0.040, Forward(s): 0.009, Backward(s): 0.017, Top1: 92.597, Top5: 99.5746, Loss: 0.227\n",
            "Mon Apr 25 14:57:16 2022: Epoch [0], Iteration [200/391/], Data(s): 0.049, Loss(s): 0.040, Forward(s): 0.007, Backward(s): 0.014, Top1: 92.673, Top5: 99.6269, Loss: 0.218\n",
            "Mon Apr 25 14:57:35 2022: Epoch [0], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.040, Forward(s): 0.007, Backward(s): 0.013, Top1: 92.771, Top5: 99.6522, Loss: 0.213\n",
            "Mon Apr 25 14:57:54 2022: Epoch [1], Iteration [0/391/], Data(s): 0.071, Loss(s): 0.039, Forward(s): 0.007, Backward(s): 0.012, Top1: 94.531, Top5: 100.0000, Loss: 0.224\n",
            "Mon Apr 25 14:58:14 2022: Epoch [1], Iteration [100/391/], Data(s): 0.050, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.969, Top5: 99.6674, Loss: 0.216\n",
            "Mon Apr 25 14:58:34 2022: Epoch [1], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.969, Top5: 99.6813, Loss: 0.215\n",
            "Mon Apr 25 14:58:53 2022: Epoch [1], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.909, Top5: 99.6704, Loss: 0.222\n",
            "Mon Apr 25 14:59:11 2022: Epoch [2], Iteration [0/391/], Data(s): 0.070, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.011, Top1: 92.188, Top5: 100.0000, Loss: 0.208\n",
            "Mon Apr 25 14:59:31 2022: Epoch [2], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.992, Top5: 99.6829, Loss: 0.213\n",
            "Mon Apr 25 14:59:51 2022: Epoch [2], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.984, Top5: 99.6929, Loss: 0.211\n",
            "Mon Apr 25 15:00:11 2022: Epoch [2], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.078, Top5: 99.6885, Loss: 0.211\n",
            "Mon Apr 25 15:00:29 2022: Epoch [3], Iteration [0/391/], Data(s): 0.080, Loss(s): 0.041, Forward(s): 0.005, Backward(s): 0.012, Top1: 91.406, Top5: 100.0000, Loss: 0.217\n",
            "Mon Apr 25 15:00:48 2022: Epoch [3], Iteration [100/391/], Data(s): 0.050, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.011, Top1: 92.752, Top5: 99.6364, Loss: 0.219\n",
            "Mon Apr 25 15:01:08 2022: Epoch [3], Iteration [200/391/], Data(s): 0.049, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.011, Top1: 92.949, Top5: 99.6269, Loss: 0.210\n",
            "Mon Apr 25 15:01:28 2022: Epoch [3], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.011, Top1: 92.984, Top5: 99.6730, Loss: 0.204\n",
            "Mon Apr 25 15:01:46 2022: Epoch [4], Iteration [0/391/], Data(s): 0.087, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.011, Top1: 91.406, Top5: 99.2188, Loss: 0.210\n",
            "Mon Apr 25 15:02:05 2022: Epoch [4], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.317, Top5: 99.6597, Loss: 0.207\n",
            "Mon Apr 25 15:02:25 2022: Epoch [4], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.241, Top5: 99.6891, Loss: 0.207\n",
            "Mon Apr 25 15:02:45 2022: Epoch [4], Iteration [300/391/], Data(s): 0.051, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.280, Top5: 99.6937, Loss: 0.201\n",
            "Mon Apr 25 15:03:03 2022: Epoch [5], Iteration [0/391/], Data(s): 0.078, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.011, Top1: 89.062, Top5: 99.2188, Loss: 0.205\n",
            "Mon Apr 25 15:03:23 2022: Epoch [5], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.479, Top5: 99.7447, Loss: 0.197\n",
            "Mon Apr 25 15:03:43 2022: Epoch [5], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.470, Top5: 99.7201, Loss: 0.201\n",
            "Mon Apr 25 15:04:03 2022: Epoch [5], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.410, Top5: 99.7145, Loss: 0.208\n",
            "Mon Apr 25 15:04:21 2022: Epoch [6], Iteration [0/391/], Data(s): 0.084, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.875, Top5: 100.0000, Loss: 0.201\n",
            "Mon Apr 25 15:04:40 2022: Epoch [6], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.209, Top5: 99.7293, Loss: 0.202\n",
            "Mon Apr 25 15:05:00 2022: Epoch [6], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.159, Top5: 99.7124, Loss: 0.205\n",
            "Mon Apr 25 15:05:20 2022: Epoch [6], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.210, Top5: 99.7171, Loss: 0.202\n",
            "Mon Apr 25 15:05:38 2022: Epoch [7], Iteration [0/391/], Data(s): 0.077, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.094, Top5: 100.0000, Loss: 0.198\n",
            "Mon Apr 25 15:05:58 2022: Epoch [7], Iteration [100/391/], Data(s): 0.052, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.673, Top5: 99.7525, Loss: 0.194\n",
            "Mon Apr 25 15:06:18 2022: Epoch [7], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.618, Top5: 99.7357, Loss: 0.192\n",
            "Mon Apr 25 15:06:37 2022: Epoch [7], Iteration [300/391/], Data(s): 0.051, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.649, Top5: 99.7482, Loss: 0.194\n",
            "Mon Apr 25 15:06:55 2022: Epoch [8], Iteration [0/391/], Data(s): 0.083, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.011, Top1: 92.969, Top5: 100.0000, Loss: 0.198\n",
            "Mon Apr 25 15:07:15 2022: Epoch [8], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.386, Top5: 99.7370, Loss: 0.196\n",
            "Mon Apr 25 15:07:35 2022: Epoch [8], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.525, Top5: 99.7512, Loss: 0.192\n",
            "Mon Apr 25 15:07:55 2022: Epoch [8], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.594, Top5: 99.7664, Loss: 0.191\n",
            "Mon Apr 25 15:08:13 2022: Epoch [9], Iteration [0/391/], Data(s): 0.085, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.094, Top5: 98.4375, Loss: 0.188\n",
            "Mon Apr 25 15:08:33 2022: Epoch [9], Iteration [100/391/], Data(s): 0.052, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.719, Top5: 99.6829, Loss: 0.194\n",
            "Mon Apr 25 15:08:52 2022: Epoch [9], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.707, Top5: 99.6968, Loss: 0.190\n",
            "Mon Apr 25 15:09:12 2022: Epoch [9], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.820, Top5: 99.7197, Loss: 0.187\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 15:09:39 2022: Test information, Data(s): 2.496, Forward(s): 0.751, Top1: 90.530, Top5: 99.300, \n",
            "\n",
            "Mon Apr 25 15:09:39 2022: conv9 Layer, 197 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 315, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(315, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(315, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]          73,856\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "             ReLU-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]         147,584\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         295,168\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]       1,180,160\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 315, 4, 4]       1,451,835\n",
            "      BatchNorm2d-29            [-1, 315, 4, 4]             630\n",
            "             ReLU-30            [-1, 315, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       1,452,032\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 13,175,803\n",
            "Trainable params: 13,175,803\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 6.50\n",
            "Params size (MB): 50.26\n",
            "Estimated Total Size (MB): 56.78\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 315, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(315, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(315, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 15:09:41 2022: Epoch [0], Iteration [0/391/], Data(s): 0.080, Loss(s): 0.008, Forward(s): 0.264, Backward(s): 0.539, Top1: 93.750, Top5: 99.2188, Loss: 0.158\n",
            "Mon Apr 25 15:10:00 2022: Epoch [0], Iteration [100/391/], Data(s): 0.050, Loss(s): 0.039, Forward(s): 0.008, Backward(s): 0.017, Top1: 93.858, Top5: 99.6829, Loss: 0.189\n",
            "Mon Apr 25 15:10:20 2022: Epoch [0], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.039, Forward(s): 0.007, Backward(s): 0.014, Top1: 93.937, Top5: 99.7201, Loss: 0.186\n",
            "Mon Apr 25 15:10:39 2022: Epoch [0], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.040, Forward(s): 0.007, Backward(s): 0.013, Top1: 93.903, Top5: 99.7327, Loss: 0.190\n",
            "Mon Apr 25 15:10:58 2022: Epoch [1], Iteration [0/391/], Data(s): 0.089, Loss(s): 0.038, Forward(s): 0.007, Backward(s): 0.012, Top1: 92.188, Top5: 100.0000, Loss: 0.193\n",
            "Mon Apr 25 15:11:17 2022: Epoch [1], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.866, Top5: 99.7602, Loss: 0.184\n",
            "Mon Apr 25 15:11:37 2022: Epoch [1], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.746, Top5: 99.7318, Loss: 0.188\n",
            "Mon Apr 25 15:11:56 2022: Epoch [1], Iteration [300/391/], Data(s): 0.051, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.843, Top5: 99.7430, Loss: 0.184\n",
            "Mon Apr 25 15:12:14 2022: Epoch [2], Iteration [0/391/], Data(s): 0.071, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.969, Top5: 100.0000, Loss: 0.189\n",
            "Mon Apr 25 15:12:34 2022: Epoch [2], Iteration [100/391/], Data(s): 0.050, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.011, Top1: 93.827, Top5: 99.7989, Loss: 0.181\n",
            "Mon Apr 25 15:12:53 2022: Epoch [2], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.011, Top1: 93.859, Top5: 99.7707, Loss: 0.185\n",
            "Mon Apr 25 15:13:12 2022: Epoch [2], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.011, Top1: 93.924, Top5: 99.7716, Loss: 0.181\n",
            "Mon Apr 25 15:13:30 2022: Epoch [3], Iteration [0/391/], Data(s): 0.070, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.011, Top1: 92.188, Top5: 100.0000, Loss: 0.187\n",
            "Mon Apr 25 15:13:50 2022: Epoch [3], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.090, Top5: 99.7293, Loss: 0.177\n",
            "Mon Apr 25 15:14:09 2022: Epoch [3], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.960, Top5: 99.7357, Loss: 0.186\n",
            "Mon Apr 25 15:14:29 2022: Epoch [3], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.934, Top5: 99.7249, Loss: 0.189\n",
            "Mon Apr 25 15:14:47 2022: Epoch [4], Iteration [0/391/], Data(s): 0.071, Loss(s): 0.040, Forward(s): 0.005, Backward(s): 0.011, Top1: 93.750, Top5: 100.0000, Loss: 0.172\n",
            "Mon Apr 25 15:15:06 2022: Epoch [4], Iteration [100/391/], Data(s): 0.050, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.011, Top1: 93.835, Top5: 99.7215, Loss: 0.189\n",
            "Mon Apr 25 15:15:25 2022: Epoch [4], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.069, Top5: 99.7512, Loss: 0.173\n",
            "Mon Apr 25 15:15:45 2022: Epoch [4], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.011, Top1: 94.051, Top5: 99.7586, Loss: 0.183\n",
            "Mon Apr 25 15:16:03 2022: Epoch [5], Iteration [0/391/], Data(s): 0.073, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.011, Top1: 95.312, Top5: 100.0000, Loss: 0.170\n",
            "Mon Apr 25 15:16:22 2022: Epoch [5], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.508, Top5: 99.7989, Loss: 0.171\n",
            "Mon Apr 25 15:16:42 2022: Epoch [5], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.434, Top5: 99.7862, Loss: 0.173\n",
            "Mon Apr 25 15:17:01 2022: Epoch [5], Iteration [300/391/], Data(s): 0.051, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.287, Top5: 99.7794, Loss: 0.183\n",
            "Mon Apr 25 15:17:19 2022: Epoch [6], Iteration [0/391/], Data(s): 0.068, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 98.438, Top5: 100.0000, Loss: 0.171\n",
            "Mon Apr 25 15:17:39 2022: Epoch [6], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.369, Top5: 99.8221, Loss: 0.170\n",
            "Mon Apr 25 15:17:58 2022: Epoch [6], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.216, Top5: 99.7979, Loss: 0.175\n",
            "Mon Apr 25 15:18:18 2022: Epoch [6], Iteration [300/391/], Data(s): 0.051, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.241, Top5: 99.7716, Loss: 0.174\n",
            "Mon Apr 25 15:18:36 2022: Epoch [7], Iteration [0/391/], Data(s): 0.074, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.011, Top1: 93.750, Top5: 99.2188, Loss: 0.173\n",
            "Mon Apr 25 15:18:55 2022: Epoch [7], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.407, Top5: 99.7215, Loss: 0.167\n",
            "Mon Apr 25 15:19:15 2022: Epoch [7], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.325, Top5: 99.7707, Loss: 0.168\n",
            "Mon Apr 25 15:19:34 2022: Epoch [7], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.427, Top5: 99.8027, Loss: 0.162\n",
            "Mon Apr 25 15:19:52 2022: Epoch [8], Iteration [0/391/], Data(s): 0.074, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.969, Top5: 100.0000, Loss: 0.168\n",
            "Mon Apr 25 15:20:11 2022: Epoch [8], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.516, Top5: 99.7989, Loss: 0.166\n",
            "Mon Apr 25 15:20:31 2022: Epoch [8], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.434, Top5: 99.7396, Loss: 0.175\n",
            "Mon Apr 25 15:20:50 2022: Epoch [8], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.350, Top5: 99.7638, Loss: 0.170\n",
            "Mon Apr 25 15:21:08 2022: Epoch [9], Iteration [0/391/], Data(s): 0.070, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.750, Top5: 98.4375, Loss: 0.169\n",
            "Mon Apr 25 15:21:27 2022: Epoch [9], Iteration [100/391/], Data(s): 0.050, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.369, Top5: 99.7912, Loss: 0.165\n",
            "Mon Apr 25 15:21:47 2022: Epoch [9], Iteration [200/391/], Data(s): 0.049, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.011, Top1: 94.337, Top5: 99.7940, Loss: 0.166\n",
            "Mon Apr 25 15:22:06 2022: Epoch [9], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.011, Top1: 94.381, Top5: 99.7898, Loss: 0.168\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 15:22:32 2022: Test information, Data(s): 2.474, Forward(s): 0.720, Top1: 91.080, Top5: 99.330, \n",
            "\n",
            "Mon Apr 25 15:22:32 2022: conv9 Layer, 262 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 250, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(250, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(250, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]          73,856\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "             ReLU-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]         147,584\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         295,168\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]       1,180,160\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 250, 4, 4]       1,152,250\n",
            "      BatchNorm2d-29            [-1, 250, 4, 4]             500\n",
            "             ReLU-30            [-1, 250, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]       1,152,512\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 12,576,568\n",
            "Trainable params: 12,576,568\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 6.48\n",
            "Params size (MB): 47.98\n",
            "Estimated Total Size (MB): 54.47\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 250, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(250, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(250, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 15:22:34 2022: Epoch [0], Iteration [0/391/], Data(s): 0.056, Loss(s): 0.008, Forward(s): 0.291, Backward(s): 0.439, Top1: 96.875, Top5: 99.2188, Loss: 0.133\n",
            "Mon Apr 25 15:22:53 2022: Epoch [0], Iteration [100/391/], Data(s): 0.048, Loss(s): 0.039, Forward(s): 0.008, Backward(s): 0.016, Top1: 94.601, Top5: 99.8530, Loss: 0.163\n",
            "Mon Apr 25 15:23:12 2022: Epoch [0], Iteration [200/391/], Data(s): 0.048, Loss(s): 0.039, Forward(s): 0.007, Backward(s): 0.013, Top1: 94.663, Top5: 99.8251, Loss: 0.158\n",
            "Mon Apr 25 15:23:32 2022: Epoch [0], Iteration [300/391/], Data(s): 0.048, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.013, Top1: 94.586, Top5: 99.8235, Loss: 0.171\n",
            "Mon Apr 25 15:23:50 2022: Epoch [1], Iteration [0/391/], Data(s): 0.067, Loss(s): 0.038, Forward(s): 0.006, Backward(s): 0.011, Top1: 96.875, Top5: 100.0000, Loss: 0.168\n",
            "Mon Apr 25 15:24:09 2022: Epoch [1], Iteration [100/391/], Data(s): 0.050, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.787, Top5: 99.8221, Loss: 0.159\n",
            "Mon Apr 25 15:24:28 2022: Epoch [1], Iteration [200/391/], Data(s): 0.049, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.570, Top5: 99.8057, Loss: 0.165\n",
            "Mon Apr 25 15:24:47 2022: Epoch [1], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.578, Top5: 99.8079, Loss: 0.162\n",
            "Mon Apr 25 15:25:04 2022: Epoch [2], Iteration [0/391/], Data(s): 0.072, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.017, Top1: 97.656, Top5: 100.0000, Loss: 0.165\n",
            "Mon Apr 25 15:25:24 2022: Epoch [2], Iteration [100/391/], Data(s): 0.052, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.640, Top5: 99.8685, Loss: 0.160\n",
            "Mon Apr 25 15:25:43 2022: Epoch [2], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.873, Top5: 99.8717, Loss: 0.151\n",
            "Mon Apr 25 15:26:02 2022: Epoch [2], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.832, Top5: 99.8443, Loss: 0.163\n",
            "Mon Apr 25 15:26:20 2022: Epoch [3], Iteration [0/391/], Data(s): 0.072, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.312, Top5: 99.2188, Loss: 0.158\n",
            "Mon Apr 25 15:26:39 2022: Epoch [3], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.562, Top5: 99.7293, Loss: 0.164\n",
            "Mon Apr 25 15:26:58 2022: Epoch [3], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.768, Top5: 99.7901, Loss: 0.151\n",
            "Mon Apr 25 15:27:17 2022: Epoch [3], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.011, Top1: 94.783, Top5: 99.7898, Loss: 0.161\n",
            "Mon Apr 25 15:27:35 2022: Epoch [4], Iteration [0/391/], Data(s): 0.071, Loss(s): 0.038, Forward(s): 0.006, Backward(s): 0.011, Top1: 96.875, Top5: 100.0000, Loss: 0.150\n",
            "Mon Apr 25 15:27:54 2022: Epoch [4], Iteration [100/391/], Data(s): 0.050, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.289, Top5: 99.8685, Loss: 0.148\n",
            "Mon Apr 25 15:28:13 2022: Epoch [4], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.134, Top5: 99.8640, Loss: 0.151\n",
            "Mon Apr 25 15:28:33 2022: Epoch [4], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.094, Top5: 99.8624, Loss: 0.149\n",
            "Mon Apr 25 15:28:50 2022: Epoch [5], Iteration [0/391/], Data(s): 0.072, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.011, Top1: 95.312, Top5: 100.0000, Loss: 0.155\n",
            "Mon Apr 25 15:29:10 2022: Epoch [5], Iteration [100/391/], Data(s): 0.052, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.748, Top5: 99.7679, Loss: 0.156\n",
            "Mon Apr 25 15:29:29 2022: Epoch [5], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.866, Top5: 99.7901, Loss: 0.157\n",
            "Mon Apr 25 15:29:48 2022: Epoch [5], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.879, Top5: 99.8105, Loss: 0.148\n",
            "Mon Apr 25 15:30:05 2022: Epoch [6], Iteration [0/391/], Data(s): 0.069, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.875, Top5: 99.2188, Loss: 0.151\n",
            "Mon Apr 25 15:30:24 2022: Epoch [6], Iteration [100/391/], Data(s): 0.049, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.011, Top1: 95.220, Top5: 99.8453, Loss: 0.146\n",
            "Mon Apr 25 15:30:43 2022: Epoch [6], Iteration [200/391/], Data(s): 0.049, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.011, Top1: 95.072, Top5: 99.8368, Loss: 0.153\n",
            "Mon Apr 25 15:31:03 2022: Epoch [6], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.011, Top1: 95.123, Top5: 99.8313, Loss: 0.149\n",
            "Mon Apr 25 15:31:20 2022: Epoch [7], Iteration [0/391/], Data(s): 0.068, Loss(s): 0.039, Forward(s): 0.005, Backward(s): 0.011, Top1: 91.406, Top5: 99.2188, Loss: 0.151\n",
            "Mon Apr 25 15:31:39 2022: Epoch [7], Iteration [100/391/], Data(s): 0.049, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.011, Top1: 94.918, Top5: 99.8608, Loss: 0.147\n",
            "Mon Apr 25 15:31:58 2022: Epoch [7], Iteration [200/391/], Data(s): 0.049, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.970, Top5: 99.8873, Loss: 0.147\n",
            "Mon Apr 25 15:32:18 2022: Epoch [7], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.993, Top5: 99.8676, Loss: 0.151\n",
            "Mon Apr 25 15:32:35 2022: Epoch [8], Iteration [0/391/], Data(s): 0.071, Loss(s): 0.038, Forward(s): 0.006, Backward(s): 0.011, Top1: 96.094, Top5: 99.2188, Loss: 0.137\n",
            "Mon Apr 25 15:32:54 2022: Epoch [8], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.405, Top5: 99.8221, Loss: 0.142\n",
            "Mon Apr 25 15:33:14 2022: Epoch [8], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.011, Top1: 95.390, Top5: 99.8445, Loss: 0.138\n",
            "Mon Apr 25 15:33:33 2022: Epoch [8], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.011, Top1: 95.237, Top5: 99.8469, Loss: 0.153\n",
            "Mon Apr 25 15:33:50 2022: Epoch [9], Iteration [0/391/], Data(s): 0.081, Loss(s): 0.038, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.094, Top5: 99.2188, Loss: 0.140\n",
            "Mon Apr 25 15:34:09 2022: Epoch [9], Iteration [100/391/], Data(s): 0.050, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.088, Top5: 99.8066, Loss: 0.151\n",
            "Mon Apr 25 15:34:28 2022: Epoch [9], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.223, Top5: 99.8290, Loss: 0.141\n",
            "Mon Apr 25 15:34:48 2022: Epoch [9], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.409, Top5: 99.8469, Loss: 0.132\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 15:35:13 2022: Test information, Data(s): 2.397, Forward(s): 0.718, Top1: 91.280, Top5: 99.350, \n",
            "\n",
            "Mon Apr 25 15:35:13 2022: conv9 Layer, 328 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(184, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]          73,856\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "             ReLU-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]         147,584\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         295,168\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]       1,180,160\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 184, 4, 4]         848,056\n",
            "      BatchNorm2d-29            [-1, 184, 4, 4]             368\n",
            "             ReLU-30            [-1, 184, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]         848,384\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 11,968,114\n",
            "Trainable params: 11,968,114\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 6.45\n",
            "Params size (MB): 45.65\n",
            "Estimated Total Size (MB): 52.12\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(184, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 15:35:15 2022: Epoch [0], Iteration [0/391/], Data(s): 0.051, Loss(s): 0.006, Forward(s): 0.177, Backward(s): 0.348, Top1: 96.094, Top5: 100.0000, Loss: 0.137\n",
            "Mon Apr 25 15:35:34 2022: Epoch [0], Iteration [100/391/], Data(s): 0.050, Loss(s): 0.038, Forward(s): 0.007, Backward(s): 0.015, Top1: 95.421, Top5: 99.8221, Loss: 0.144\n",
            "Mon Apr 25 15:35:53 2022: Epoch [0], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.038, Forward(s): 0.007, Backward(s): 0.013, Top1: 95.289, Top5: 99.8445, Loss: 0.146\n",
            "Mon Apr 25 15:36:12 2022: Epoch [0], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.038, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.297, Top5: 99.8624, Loss: 0.136\n",
            "Mon Apr 25 15:36:30 2022: Epoch [1], Iteration [0/391/], Data(s): 0.072, Loss(s): 0.037, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.094, Top5: 100.0000, Loss: 0.145\n",
            "Mon Apr 25 15:36:49 2022: Epoch [1], Iteration [100/391/], Data(s): 0.050, Loss(s): 0.038, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.135, Top5: 99.8221, Loss: 0.146\n",
            "Mon Apr 25 15:37:08 2022: Epoch [1], Iteration [200/391/], Data(s): 0.049, Loss(s): 0.038, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.382, Top5: 99.8562, Loss: 0.135\n",
            "Mon Apr 25 15:37:26 2022: Epoch [1], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.038, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.388, Top5: 99.8650, Loss: 0.135\n",
            "Mon Apr 25 15:37:44 2022: Epoch [2], Iteration [0/391/], Data(s): 0.071, Loss(s): 0.038, Forward(s): 0.006, Backward(s): 0.011, Top1: 96.094, Top5: 100.0000, Loss: 0.141\n",
            "Mon Apr 25 15:38:03 2022: Epoch [2], Iteration [100/391/], Data(s): 0.049, Loss(s): 0.038, Forward(s): 0.006, Backward(s): 0.011, Top1: 95.552, Top5: 99.8608, Loss: 0.140\n",
            "Mon Apr 25 15:38:21 2022: Epoch [2], Iteration [200/391/], Data(s): 0.048, Loss(s): 0.038, Forward(s): 0.006, Backward(s): 0.011, Top1: 95.585, Top5: 99.8873, Loss: 0.134\n",
            "Mon Apr 25 15:38:40 2022: Epoch [2], Iteration [300/391/], Data(s): 0.048, Loss(s): 0.038, Forward(s): 0.006, Backward(s): 0.011, Top1: 95.572, Top5: 99.8676, Loss: 0.136\n",
            "Mon Apr 25 15:38:57 2022: Epoch [3], Iteration [0/391/], Data(s): 0.081, Loss(s): 0.038, Forward(s): 0.006, Backward(s): 0.012, Top1: 97.656, Top5: 100.0000, Loss: 0.145\n",
            "Mon Apr 25 15:39:16 2022: Epoch [3], Iteration [100/391/], Data(s): 0.049, Loss(s): 0.038, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.266, Top5: 99.8221, Loss: 0.144\n",
            "Mon Apr 25 15:39:35 2022: Epoch [3], Iteration [200/391/], Data(s): 0.048, Loss(s): 0.038, Forward(s): 0.006, Backward(s): 0.011, Top1: 95.340, Top5: 99.8445, Loss: 0.138\n",
            "Mon Apr 25 15:39:54 2022: Epoch [3], Iteration [300/391/], Data(s): 0.048, Loss(s): 0.038, Forward(s): 0.006, Backward(s): 0.011, Top1: 95.409, Top5: 99.8469, Loss: 0.135\n",
            "Mon Apr 25 15:40:11 2022: Epoch [4], Iteration [0/391/], Data(s): 0.073, Loss(s): 0.038, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.094, Top5: 100.0000, Loss: 0.133\n",
            "Mon Apr 25 15:40:30 2022: Epoch [4], Iteration [100/391/], Data(s): 0.049, Loss(s): 0.038, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.529, Top5: 99.8685, Loss: 0.134\n",
            "Mon Apr 25 15:40:49 2022: Epoch [4], Iteration [200/391/], Data(s): 0.048, Loss(s): 0.038, Forward(s): 0.006, Backward(s): 0.011, Top1: 95.503, Top5: 99.8989, Loss: 0.138\n",
            "Mon Apr 25 15:41:07 2022: Epoch [4], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.038, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.647, Top5: 99.8806, Loss: 0.125\n",
            "Mon Apr 25 15:41:25 2022: Epoch [5], Iteration [0/391/], Data(s): 0.070, Loss(s): 0.038, Forward(s): 0.006, Backward(s): 0.011, Top1: 94.531, Top5: 99.2188, Loss: 0.136\n",
            "Mon Apr 25 15:41:44 2022: Epoch [5], Iteration [100/391/], Data(s): 0.050, Loss(s): 0.038, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.831, Top5: 99.8066, Loss: 0.130\n",
            "Mon Apr 25 15:42:03 2022: Epoch [5], Iteration [200/391/], Data(s): 0.049, Loss(s): 0.038, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.771, Top5: 99.8290, Loss: 0.127\n",
            "Mon Apr 25 15:42:21 2022: Epoch [5], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.038, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.845, Top5: 99.8572, Loss: 0.124\n",
            "Mon Apr 25 15:42:38 2022: Epoch [6], Iteration [0/391/], Data(s): 0.068, Loss(s): 0.038, Forward(s): 0.005, Backward(s): 0.011, Top1: 96.094, Top5: 100.0000, Loss: 0.140\n",
            "Mon Apr 25 15:42:57 2022: Epoch [6], Iteration [100/391/], Data(s): 0.050, Loss(s): 0.038, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.668, Top5: 99.9149, Loss: 0.131\n",
            "Mon Apr 25 15:43:16 2022: Epoch [6], Iteration [200/391/], Data(s): 0.049, Loss(s): 0.038, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.709, Top5: 99.8717, Loss: 0.126\n",
            "Mon Apr 25 15:43:35 2022: Epoch [6], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.038, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.712, Top5: 99.8728, Loss: 0.128\n",
            "Mon Apr 25 15:43:52 2022: Epoch [7], Iteration [0/391/], Data(s): 0.067, Loss(s): 0.038, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.531, Top5: 100.0000, Loss: 0.136\n",
            "Mon Apr 25 15:44:12 2022: Epoch [7], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.038, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.985, Top5: 99.9149, Loss: 0.122\n",
            "Mon Apr 25 15:44:30 2022: Epoch [7], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.038, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.892, Top5: 99.9145, Loss: 0.128\n",
            "Mon Apr 25 15:44:49 2022: Epoch [7], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.038, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.868, Top5: 99.9169, Loss: 0.126\n",
            "Mon Apr 25 15:45:07 2022: Epoch [8], Iteration [0/391/], Data(s): 0.067, Loss(s): 0.038, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.875, Top5: 100.0000, Loss: 0.122\n",
            "Mon Apr 25 15:45:25 2022: Epoch [8], Iteration [100/391/], Data(s): 0.050, Loss(s): 0.038, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.552, Top5: 99.8994, Loss: 0.133\n",
            "Mon Apr 25 15:45:44 2022: Epoch [8], Iteration [200/391/], Data(s): 0.049, Loss(s): 0.038, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.740, Top5: 99.8989, Loss: 0.121\n",
            "Mon Apr 25 15:46:03 2022: Epoch [8], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.038, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.759, Top5: 99.8884, Loss: 0.127\n",
            "Mon Apr 25 15:46:20 2022: Epoch [9], Iteration [0/391/], Data(s): 0.069, Loss(s): 0.038, Forward(s): 0.006, Backward(s): 0.011, Top1: 93.750, Top5: 100.0000, Loss: 0.125\n",
            "Mon Apr 25 15:46:39 2022: Epoch [9], Iteration [100/391/], Data(s): 0.049, Loss(s): 0.038, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.001, Top5: 99.9613, Loss: 0.122\n",
            "Mon Apr 25 15:46:58 2022: Epoch [9], Iteration [200/391/], Data(s): 0.049, Loss(s): 0.038, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.993, Top5: 99.9300, Loss: 0.123\n",
            "Mon Apr 25 15:47:17 2022: Epoch [9], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.038, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.902, Top5: 99.9325, Loss: 0.124\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 15:47:42 2022: Test information, Data(s): 2.425, Forward(s): 0.639, Top1: 91.230, Top5: 99.290, \n",
            "\n",
            "Mon Apr 25 15:47:42 2022: conv9 Layer, 394 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 118, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(118, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(118, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]          73,856\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "             ReLU-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]         147,584\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         295,168\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]       1,180,160\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 118, 4, 4]         543,862\n",
            "      BatchNorm2d-29            [-1, 118, 4, 4]             236\n",
            "             ReLU-30            [-1, 118, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]         544,256\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 11,359,660\n",
            "Trainable params: 11,359,660\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 6.43\n",
            "Params size (MB): 43.33\n",
            "Estimated Total Size (MB): 49.78\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 118, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(118, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(118, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 15:47:44 2022: Epoch [0], Iteration [0/391/], Data(s): 0.056, Loss(s): 0.007, Forward(s): 0.135, Backward(s): 0.275, Top1: 94.531, Top5: 100.0000, Loss: 0.179\n",
            "Mon Apr 25 15:48:03 2022: Epoch [0], Iteration [100/391/], Data(s): 0.050, Loss(s): 0.037, Forward(s): 0.007, Backward(s): 0.014, Top1: 96.117, Top5: 99.8917, Loss: 0.118\n",
            "Mon Apr 25 15:48:21 2022: Epoch [0], Iteration [200/391/], Data(s): 0.049, Loss(s): 0.037, Forward(s): 0.006, Backward(s): 0.013, Top1: 96.032, Top5: 99.9067, Loss: 0.118\n",
            "Mon Apr 25 15:48:40 2022: Epoch [0], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.037, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.935, Top5: 99.8910, Loss: 0.126\n",
            "Mon Apr 25 15:48:57 2022: Epoch [1], Iteration [0/391/], Data(s): 0.068, Loss(s): 0.035, Forward(s): 0.008, Backward(s): 0.012, Top1: 92.188, Top5: 100.0000, Loss: 0.123\n",
            "Mon Apr 25 15:49:16 2022: Epoch [1], Iteration [100/391/], Data(s): 0.050, Loss(s): 0.037, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.885, Top5: 99.8762, Loss: 0.118\n",
            "Mon Apr 25 15:49:35 2022: Epoch [1], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.037, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.868, Top5: 99.8873, Loss: 0.120\n",
            "Mon Apr 25 15:49:53 2022: Epoch [1], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.037, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.863, Top5: 99.8702, Loss: 0.124\n",
            "Mon Apr 25 15:50:10 2022: Epoch [2], Iteration [0/391/], Data(s): 0.068, Loss(s): 0.037, Forward(s): 0.006, Backward(s): 0.011, Top1: 95.312, Top5: 100.0000, Loss: 0.116\n",
            "Mon Apr 25 15:50:29 2022: Epoch [2], Iteration [100/391/], Data(s): 0.049, Loss(s): 0.037, Forward(s): 0.006, Backward(s): 0.011, Top1: 95.900, Top5: 99.9304, Loss: 0.118\n",
            "Mon Apr 25 15:50:48 2022: Epoch [2], Iteration [200/391/], Data(s): 0.048, Loss(s): 0.037, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.074, Top5: 99.9456, Loss: 0.111\n",
            "Mon Apr 25 15:51:06 2022: Epoch [2], Iteration [300/391/], Data(s): 0.048, Loss(s): 0.037, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.016, Top5: 99.9403, Loss: 0.119\n",
            "Mon Apr 25 15:51:23 2022: Epoch [3], Iteration [0/391/], Data(s): 0.068, Loss(s): 0.037, Forward(s): 0.006, Backward(s): 0.011, Top1: 95.312, Top5: 100.0000, Loss: 0.119\n",
            "Mon Apr 25 15:51:42 2022: Epoch [3], Iteration [100/391/], Data(s): 0.049, Loss(s): 0.037, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.024, Top5: 99.9072, Loss: 0.115\n",
            "Mon Apr 25 15:52:00 2022: Epoch [3], Iteration [200/391/], Data(s): 0.049, Loss(s): 0.037, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.168, Top5: 99.9028, Loss: 0.114\n",
            "Mon Apr 25 15:52:19 2022: Epoch [3], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.037, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.177, Top5: 99.9169, Loss: 0.115\n",
            "Mon Apr 25 15:52:36 2022: Epoch [4], Iteration [0/391/], Data(s): 0.076, Loss(s): 0.037, Forward(s): 0.005, Backward(s): 0.012, Top1: 96.094, Top5: 100.0000, Loss: 0.118\n",
            "Mon Apr 25 15:52:54 2022: Epoch [4], Iteration [100/391/], Data(s): 0.049, Loss(s): 0.037, Forward(s): 0.006, Backward(s): 0.011, Top1: 96.426, Top5: 99.9072, Loss: 0.111\n",
            "Mon Apr 25 15:53:13 2022: Epoch [4], Iteration [200/391/], Data(s): 0.048, Loss(s): 0.037, Forward(s): 0.006, Backward(s): 0.011, Top1: 96.171, Top5: 99.8756, Loss: 0.126\n",
            "Mon Apr 25 15:53:32 2022: Epoch [4], Iteration [300/391/], Data(s): 0.048, Loss(s): 0.037, Forward(s): 0.006, Backward(s): 0.011, Top1: 96.257, Top5: 99.8910, Loss: 0.106\n",
            "Mon Apr 25 15:53:48 2022: Epoch [5], Iteration [0/391/], Data(s): 0.067, Loss(s): 0.037, Forward(s): 0.006, Backward(s): 0.011, Top1: 95.312, Top5: 100.0000, Loss: 0.116\n",
            "Mon Apr 25 15:54:07 2022: Epoch [5], Iteration [100/391/], Data(s): 0.049, Loss(s): 0.037, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.542, Top5: 99.9691, Loss: 0.104\n",
            "Mon Apr 25 15:54:26 2022: Epoch [5], Iteration [200/391/], Data(s): 0.049, Loss(s): 0.037, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.304, Top5: 99.9456, Loss: 0.117\n",
            "Mon Apr 25 15:54:44 2022: Epoch [5], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.037, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.314, Top5: 99.9299, Loss: 0.114\n",
            "Mon Apr 25 15:55:01 2022: Epoch [6], Iteration [0/391/], Data(s): 0.068, Loss(s): 0.037, Forward(s): 0.006, Backward(s): 0.011, Top1: 96.094, Top5: 100.0000, Loss: 0.111\n",
            "Mon Apr 25 15:55:20 2022: Epoch [6], Iteration [100/391/], Data(s): 0.049, Loss(s): 0.037, Forward(s): 0.006, Backward(s): 0.011, Top1: 96.256, Top5: 99.8840, Loss: 0.114\n",
            "Mon Apr 25 15:55:38 2022: Epoch [6], Iteration [200/391/], Data(s): 0.049, Loss(s): 0.037, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.238, Top5: 99.8989, Loss: 0.115\n",
            "Mon Apr 25 15:55:57 2022: Epoch [6], Iteration [300/391/], Data(s): 0.048, Loss(s): 0.037, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.343, Top5: 99.8858, Loss: 0.109\n",
            "Mon Apr 25 15:56:14 2022: Epoch [7], Iteration [0/391/], Data(s): 0.066, Loss(s): 0.037, Forward(s): 0.006, Backward(s): 0.011, Top1: 96.094, Top5: 100.0000, Loss: 0.113\n",
            "Mon Apr 25 15:56:33 2022: Epoch [7], Iteration [100/391/], Data(s): 0.049, Loss(s): 0.037, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.589, Top5: 99.9381, Loss: 0.103\n",
            "Mon Apr 25 15:56:51 2022: Epoch [7], Iteration [200/391/], Data(s): 0.049, Loss(s): 0.037, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.564, Top5: 99.9223, Loss: 0.103\n",
            "Mon Apr 25 15:57:10 2022: Epoch [7], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.037, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.496, Top5: 99.9273, Loss: 0.110\n",
            "Mon Apr 25 15:57:27 2022: Epoch [8], Iteration [0/391/], Data(s): 0.068, Loss(s): 0.037, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.875, Top5: 100.0000, Loss: 0.108\n",
            "Mon Apr 25 15:57:46 2022: Epoch [8], Iteration [100/391/], Data(s): 0.050, Loss(s): 0.037, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.542, Top5: 99.9459, Loss: 0.102\n",
            "Mon Apr 25 15:58:04 2022: Epoch [8], Iteration [200/391/], Data(s): 0.049, Loss(s): 0.037, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.650, Top5: 99.9495, Loss: 0.106\n",
            "Mon Apr 25 15:58:23 2022: Epoch [8], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.037, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.522, Top5: 99.9377, Loss: 0.109\n",
            "Mon Apr 25 15:58:40 2022: Epoch [9], Iteration [0/391/], Data(s): 0.069, Loss(s): 0.037, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.094, Top5: 99.2188, Loss: 0.108\n",
            "Mon Apr 25 15:58:58 2022: Epoch [9], Iteration [100/391/], Data(s): 0.050, Loss(s): 0.037, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.666, Top5: 99.9459, Loss: 0.100\n",
            "Mon Apr 25 15:59:17 2022: Epoch [9], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.037, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.692, Top5: 99.9456, Loss: 0.102\n",
            "Mon Apr 25 15:59:36 2022: Epoch [9], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.037, Forward(s): 0.006, Backward(s): 0.011, Top1: 96.628, Top5: 99.9325, Loss: 0.105\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 16:00:01 2022: Test information, Data(s): 2.438, Forward(s): 0.592, Top1: 91.370, Top5: 99.340, \n",
            "\n",
            "Mon Apr 25 16:00:01 2022: conv9 Layer, 460 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 52, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(52, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]          73,856\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "             ReLU-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]         147,584\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         295,168\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]       1,180,160\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28             [-1, 52, 4, 4]         239,668\n",
            "      BatchNorm2d-29             [-1, 52, 4, 4]             104\n",
            "             ReLU-30             [-1, 52, 4, 4]               0\n",
            "           Conv2d-31            [-1, 512, 4, 4]         240,128\n",
            "      BatchNorm2d-32            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-33            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 512, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 10,751,206\n",
            "Trainable params: 10,751,206\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 6.41\n",
            "Params size (MB): 41.01\n",
            "Estimated Total Size (MB): 47.43\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 52, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(52, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 16:00:02 2022: Epoch [0], Iteration [0/391/], Data(s): 0.103, Loss(s): 0.006, Forward(s): 0.110, Backward(s): 0.164, Top1: 92.969, Top5: 99.2188, Loss: 0.185\n",
            "Mon Apr 25 16:00:21 2022: Epoch [0], Iteration [100/391/], Data(s): 0.050, Loss(s): 0.036, Forward(s): 0.006, Backward(s): 0.013, Top1: 96.403, Top5: 99.8994, Loss: 0.109\n",
            "Mon Apr 25 16:00:39 2022: Epoch [0], Iteration [200/391/], Data(s): 0.049, Loss(s): 0.036, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.599, Top5: 99.9184, Loss: 0.098\n",
            "Mon Apr 25 16:00:58 2022: Epoch [0], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.036, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.545, Top5: 99.9143, Loss: 0.110\n",
            "Mon Apr 25 16:01:15 2022: Epoch [1], Iteration [0/391/], Data(s): 0.068, Loss(s): 0.035, Forward(s): 0.007, Backward(s): 0.012, Top1: 94.531, Top5: 100.0000, Loss: 0.107\n",
            "Mon Apr 25 16:01:33 2022: Epoch [1], Iteration [100/391/], Data(s): 0.050, Loss(s): 0.036, Forward(s): 0.005, Backward(s): 0.012, Top1: 96.388, Top5: 99.9226, Loss: 0.106\n",
            "Mon Apr 25 16:01:51 2022: Epoch [1], Iteration [200/391/], Data(s): 0.049, Loss(s): 0.036, Forward(s): 0.005, Backward(s): 0.011, Top1: 96.459, Top5: 99.9300, Loss: 0.105\n",
            "Mon Apr 25 16:02:10 2022: Epoch [1], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.036, Forward(s): 0.005, Backward(s): 0.011, Top1: 96.460, Top5: 99.9403, Loss: 0.104\n",
            "Mon Apr 25 16:02:27 2022: Epoch [2], Iteration [0/391/], Data(s): 0.065, Loss(s): 0.037, Forward(s): 0.005, Backward(s): 0.012, Top1: 96.875, Top5: 100.0000, Loss: 0.102\n",
            "Mon Apr 25 16:02:45 2022: Epoch [2], Iteration [100/391/], Data(s): 0.050, Loss(s): 0.036, Forward(s): 0.005, Backward(s): 0.012, Top1: 96.697, Top5: 99.9536, Loss: 0.099\n",
            "Mon Apr 25 16:03:04 2022: Epoch [2], Iteration [200/391/], Data(s): 0.049, Loss(s): 0.036, Forward(s): 0.005, Backward(s): 0.012, Top1: 96.688, Top5: 99.9339, Loss: 0.098\n",
            "Mon Apr 25 16:03:22 2022: Epoch [2], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.036, Forward(s): 0.005, Backward(s): 0.011, Top1: 96.628, Top5: 99.9195, Loss: 0.102\n",
            "Mon Apr 25 16:03:39 2022: Epoch [3], Iteration [0/391/], Data(s): 0.067, Loss(s): 0.036, Forward(s): 0.006, Backward(s): 0.012, Top1: 98.438, Top5: 100.0000, Loss: 0.107\n",
            "Mon Apr 25 16:03:57 2022: Epoch [3], Iteration [100/391/], Data(s): 0.050, Loss(s): 0.036, Forward(s): 0.005, Backward(s): 0.012, Top1: 96.736, Top5: 99.9459, Loss: 0.099\n",
            "Mon Apr 25 16:04:16 2022: Epoch [3], Iteration [200/391/], Data(s): 0.049, Loss(s): 0.036, Forward(s): 0.005, Backward(s): 0.012, Top1: 96.739, Top5: 99.9339, Loss: 0.097\n",
            "Mon Apr 25 16:04:34 2022: Epoch [3], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.036, Forward(s): 0.005, Backward(s): 0.012, Top1: 96.813, Top5: 99.9195, Loss: 0.099\n",
            "Mon Apr 25 16:04:51 2022: Epoch [4], Iteration [0/391/], Data(s): 0.072, Loss(s): 0.036, Forward(s): 0.006, Backward(s): 0.011, Top1: 96.094, Top5: 100.0000, Loss: 0.097\n",
            "Mon Apr 25 16:05:09 2022: Epoch [4], Iteration [100/391/], Data(s): 0.049, Loss(s): 0.036, Forward(s): 0.005, Backward(s): 0.012, Top1: 96.697, Top5: 99.9459, Loss: 0.099\n",
            "Mon Apr 25 16:05:28 2022: Epoch [4], Iteration [200/391/], Data(s): 0.049, Loss(s): 0.036, Forward(s): 0.005, Backward(s): 0.012, Top1: 96.805, Top5: 99.9223, Loss: 0.094\n",
            "Mon Apr 25 16:05:46 2022: Epoch [4], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.036, Forward(s): 0.005, Backward(s): 0.011, Top1: 96.748, Top5: 99.9195, Loss: 0.097\n",
            "Mon Apr 25 16:06:03 2022: Epoch [5], Iteration [0/391/], Data(s): 0.069, Loss(s): 0.036, Forward(s): 0.006, Backward(s): 0.011, Top1: 99.219, Top5: 100.0000, Loss: 0.096\n",
            "Mon Apr 25 16:06:21 2022: Epoch [5], Iteration [100/391/], Data(s): 0.049, Loss(s): 0.036, Forward(s): 0.005, Backward(s): 0.011, Top1: 96.960, Top5: 99.9304, Loss: 0.092\n",
            "Mon Apr 25 16:06:40 2022: Epoch [5], Iteration [200/391/], Data(s): 0.049, Loss(s): 0.036, Forward(s): 0.005, Backward(s): 0.011, Top1: 96.945, Top5: 99.9262, Loss: 0.092\n",
            "Mon Apr 25 16:06:58 2022: Epoch [5], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.036, Forward(s): 0.005, Backward(s): 0.011, Top1: 96.917, Top5: 99.9325, Loss: 0.093\n",
            "Mon Apr 25 16:07:15 2022: Epoch [6], Iteration [0/391/], Data(s): 0.068, Loss(s): 0.036, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.875, Top5: 100.0000, Loss: 0.097\n",
            "Mon Apr 25 16:07:33 2022: Epoch [6], Iteration [100/391/], Data(s): 0.049, Loss(s): 0.036, Forward(s): 0.005, Backward(s): 0.011, Top1: 96.860, Top5: 99.9459, Loss: 0.091\n",
            "Mon Apr 25 16:07:52 2022: Epoch [6], Iteration [200/391/], Data(s): 0.049, Loss(s): 0.036, Forward(s): 0.005, Backward(s): 0.011, Top1: 96.945, Top5: 99.9456, Loss: 0.092\n",
            "Mon Apr 25 16:08:10 2022: Epoch [6], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.036, Forward(s): 0.005, Backward(s): 0.011, Top1: 96.875, Top5: 99.9507, Loss: 0.093\n",
            "Mon Apr 25 16:08:27 2022: Epoch [7], Iteration [0/391/], Data(s): 0.068, Loss(s): 0.036, Forward(s): 0.005, Backward(s): 0.011, Top1: 94.531, Top5: 100.0000, Loss: 0.093\n",
            "Mon Apr 25 16:08:45 2022: Epoch [7], Iteration [100/391/], Data(s): 0.049, Loss(s): 0.036, Forward(s): 0.005, Backward(s): 0.012, Top1: 96.782, Top5: 99.9149, Loss: 0.092\n",
            "Mon Apr 25 16:09:04 2022: Epoch [7], Iteration [200/391/], Data(s): 0.049, Loss(s): 0.036, Forward(s): 0.005, Backward(s): 0.012, Top1: 96.902, Top5: 99.9145, Loss: 0.094\n",
            "Mon Apr 25 16:09:22 2022: Epoch [7], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.036, Forward(s): 0.005, Backward(s): 0.011, Top1: 96.932, Top5: 99.9247, Loss: 0.092\n",
            "Mon Apr 25 16:09:39 2022: Epoch [8], Iteration [0/391/], Data(s): 0.064, Loss(s): 0.036, Forward(s): 0.005, Backward(s): 0.011, Top1: 98.438, Top5: 100.0000, Loss: 0.089\n",
            "Mon Apr 25 16:09:57 2022: Epoch [8], Iteration [100/391/], Data(s): 0.049, Loss(s): 0.036, Forward(s): 0.005, Backward(s): 0.011, Top1: 97.115, Top5: 99.9459, Loss: 0.087\n",
            "Mon Apr 25 16:10:16 2022: Epoch [8], Iteration [200/391/], Data(s): 0.049, Loss(s): 0.036, Forward(s): 0.005, Backward(s): 0.011, Top1: 97.147, Top5: 99.9378, Loss: 0.090\n",
            "Mon Apr 25 16:10:34 2022: Epoch [8], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.036, Forward(s): 0.005, Backward(s): 0.011, Top1: 97.114, Top5: 99.9403, Loss: 0.088\n",
            "Mon Apr 25 16:10:51 2022: Epoch [9], Iteration [0/391/], Data(s): 0.064, Loss(s): 0.036, Forward(s): 0.005, Backward(s): 0.011, Top1: 100.000, Top5: 100.0000, Loss: 0.086\n",
            "Mon Apr 25 16:11:09 2022: Epoch [9], Iteration [100/391/], Data(s): 0.049, Loss(s): 0.036, Forward(s): 0.005, Backward(s): 0.011, Top1: 97.153, Top5: 99.9459, Loss: 0.088\n",
            "Mon Apr 25 16:11:28 2022: Epoch [9], Iteration [200/391/], Data(s): 0.049, Loss(s): 0.036, Forward(s): 0.005, Backward(s): 0.011, Top1: 97.062, Top5: 99.9572, Loss: 0.089\n",
            "Mon Apr 25 16:11:46 2022: Epoch [9], Iteration [300/391/], Data(s): 0.048, Loss(s): 0.036, Forward(s): 0.005, Backward(s): 0.011, Top1: 97.049, Top5: 99.9637, Loss: 0.086\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 16:12:11 2022: Test information, Data(s): 2.379, Forward(s): 0.544, Top1: 91.420, Top5: 99.280, \n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 16:12:21 2022: Test information, Data(s): 2.333, Forward(s): 0.463, Top1: 77.870, Top5: 97.560, \n",
            "\n",
            "Mon Apr 25 16:12:21 2022: conv10 Layer, 65 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 447, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(447, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(447, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]          73,856\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "             ReLU-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]         147,584\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         295,168\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]       1,180,160\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 447, 4, 4]       2,060,223\n",
            "      BatchNorm2d-32            [-1, 447, 4, 4]             894\n",
            "             ReLU-33            [-1, 447, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 447, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       2,060,288\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 14,392,711\n",
            "Trainable params: 14,392,711\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 6.55\n",
            "Params size (MB): 54.90\n",
            "Estimated Total Size (MB): 61.46\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 447, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(447, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(447, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 16:12:24 2022: Epoch [0], Iteration [0/391/], Data(s): 0.052, Loss(s): 0.006, Forward(s): 0.334, Backward(s): 1.241, Top1: 89.062, Top5: 99.2188, Loss: 0.339\n",
            "Mon Apr 25 16:12:44 2022: Epoch [0], Iteration [100/391/], Data(s): 0.049, Loss(s): 0.041, Forward(s): 0.009, Backward(s): 0.024, Top1: 87.330, Top5: 98.9790, Loss: 0.400\n",
            "Mon Apr 25 16:13:04 2022: Epoch [0], Iteration [200/391/], Data(s): 0.049, Loss(s): 0.041, Forward(s): 0.007, Backward(s): 0.018, Top1: 87.982, Top5: 99.1021, Loss: 0.352\n",
            "Mon Apr 25 16:13:24 2022: Epoch [0], Iteration [300/391/], Data(s): 0.048, Loss(s): 0.041, Forward(s): 0.007, Backward(s): 0.016, Top1: 88.455, Top5: 99.1253, Loss: 0.335\n",
            "Mon Apr 25 16:13:43 2022: Epoch [1], Iteration [0/391/], Data(s): 0.071, Loss(s): 0.039, Forward(s): 0.007, Backward(s): 0.012, Top1: 84.375, Top5: 96.8750, Loss: 0.319\n",
            "Mon Apr 25 16:14:03 2022: Epoch [1], Iteration [100/391/], Data(s): 0.050, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 89.364, Top5: 99.2884, Loss: 0.319\n",
            "Mon Apr 25 16:14:23 2022: Epoch [1], Iteration [200/391/], Data(s): 0.049, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 89.820, Top5: 99.3626, Loss: 0.302\n",
            "Mon Apr 25 16:14:42 2022: Epoch [1], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 90.080, Top5: 99.3459, Loss: 0.298\n",
            "Mon Apr 25 16:15:01 2022: Epoch [2], Iteration [0/391/], Data(s): 0.081, Loss(s): 0.042, Forward(s): 0.005, Backward(s): 0.012, Top1: 89.844, Top5: 99.2188, Loss: 0.296\n",
            "Mon Apr 25 16:15:21 2022: Epoch [2], Iteration [100/391/], Data(s): 0.050, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 90.756, Top5: 99.3580, Loss: 0.287\n",
            "Mon Apr 25 16:15:40 2022: Epoch [2], Iteration [200/391/], Data(s): 0.049, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.011, Top1: 90.893, Top5: 99.4869, Loss: 0.272\n",
            "Mon Apr 25 16:16:00 2022: Epoch [2], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.011, Top1: 91.012, Top5: 99.4783, Loss: 0.274\n",
            "Mon Apr 25 16:16:18 2022: Epoch [3], Iteration [0/391/], Data(s): 0.081, Loss(s): 0.042, Forward(s): 0.005, Backward(s): 0.011, Top1: 90.625, Top5: 99.2188, Loss: 0.283\n",
            "Mon Apr 25 16:16:38 2022: Epoch [3], Iteration [100/391/], Data(s): 0.049, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 91.344, Top5: 99.4817, Loss: 0.263\n",
            "Mon Apr 25 16:16:58 2022: Epoch [3], Iteration [200/391/], Data(s): 0.049, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 91.476, Top5: 99.4753, Loss: 0.267\n",
            "Mon Apr 25 16:17:18 2022: Epoch [3], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 91.461, Top5: 99.4939, Loss: 0.264\n",
            "Mon Apr 25 16:17:36 2022: Epoch [4], Iteration [0/391/], Data(s): 0.083, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.011, Top1: 88.281, Top5: 100.0000, Loss: 0.265\n",
            "Mon Apr 25 16:17:56 2022: Epoch [4], Iteration [100/391/], Data(s): 0.050, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 91.236, Top5: 99.5668, Loss: 0.268\n",
            "Mon Apr 25 16:18:16 2022: Epoch [4], Iteration [200/391/], Data(s): 0.049, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 91.589, Top5: 99.5686, Loss: 0.252\n",
            "Mon Apr 25 16:18:36 2022: Epoch [4], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 91.557, Top5: 99.5588, Loss: 0.256\n",
            "Mon Apr 25 16:18:54 2022: Epoch [5], Iteration [0/391/], Data(s): 0.088, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.011, Top1: 90.625, Top5: 100.0000, Loss: 0.262\n",
            "Mon Apr 25 16:19:14 2022: Epoch [5], Iteration [100/391/], Data(s): 0.050, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 91.692, Top5: 99.5746, Loss: 0.254\n",
            "Mon Apr 25 16:19:33 2022: Epoch [5], Iteration [200/391/], Data(s): 0.049, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 91.795, Top5: 99.5414, Loss: 0.251\n",
            "Mon Apr 25 16:19:53 2022: Epoch [5], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 91.873, Top5: 99.5484, Loss: 0.251\n",
            "Mon Apr 25 16:20:12 2022: Epoch [6], Iteration [0/391/], Data(s): 0.084, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.011, Top1: 90.625, Top5: 98.4375, Loss: 0.245\n",
            "Mon Apr 25 16:20:31 2022: Epoch [6], Iteration [100/391/], Data(s): 0.050, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.195, Top5: 99.6906, Loss: 0.237\n",
            "Mon Apr 25 16:20:51 2022: Epoch [6], Iteration [200/391/], Data(s): 0.049, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.048, Top5: 99.6152, Loss: 0.253\n",
            "Mon Apr 25 16:21:11 2022: Epoch [6], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.045, Top5: 99.5847, Loss: 0.245\n",
            "Mon Apr 25 16:21:29 2022: Epoch [7], Iteration [0/391/], Data(s): 0.072, Loss(s): 0.041, Forward(s): 0.005, Backward(s): 0.011, Top1: 93.750, Top5: 100.0000, Loss: 0.237\n",
            "Mon Apr 25 16:21:49 2022: Epoch [7], Iteration [100/391/], Data(s): 0.050, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.396, Top5: 99.6674, Loss: 0.231\n",
            "Mon Apr 25 16:22:09 2022: Epoch [7], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.304, Top5: 99.6424, Loss: 0.240\n",
            "Mon Apr 25 16:22:29 2022: Epoch [7], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.123, Top5: 99.6340, Loss: 0.247\n",
            "Mon Apr 25 16:22:47 2022: Epoch [8], Iteration [0/391/], Data(s): 0.069, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.011, Top1: 97.656, Top5: 100.0000, Loss: 0.223\n",
            "Mon Apr 25 16:23:07 2022: Epoch [8], Iteration [100/391/], Data(s): 0.050, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.605, Top5: 99.5668, Loss: 0.231\n",
            "Mon Apr 25 16:23:27 2022: Epoch [8], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.561, Top5: 99.5958, Loss: 0.229\n",
            "Mon Apr 25 16:23:47 2022: Epoch [8], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.390, Top5: 99.6081, Loss: 0.239\n",
            "Mon Apr 25 16:24:05 2022: Epoch [9], Iteration [0/391/], Data(s): 0.073, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.969, Top5: 100.0000, Loss: 0.222\n",
            "Mon Apr 25 16:24:25 2022: Epoch [9], Iteration [100/391/], Data(s): 0.050, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.512, Top5: 99.5668, Loss: 0.228\n",
            "Mon Apr 25 16:24:45 2022: Epoch [9], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.448, Top5: 99.5608, Loss: 0.235\n",
            "Mon Apr 25 16:25:05 2022: Epoch [9], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.569, Top5: 99.6081, Loss: 0.219\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 16:25:31 2022: Test information, Data(s): 2.428, Forward(s): 0.625, Top1: 90.070, Top5: 99.270, \n",
            "\n",
            "Mon Apr 25 16:25:31 2022: conv10 Layer, 131 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 381, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(381, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(381, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]          73,856\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "             ReLU-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]         147,584\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         295,168\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]       1,180,160\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 381, 4, 4]       1,756,029\n",
            "      BatchNorm2d-32            [-1, 381, 4, 4]             762\n",
            "             ReLU-33            [-1, 381, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 381, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       1,756,160\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 13,784,257\n",
            "Trainable params: 13,784,257\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 6.52\n",
            "Params size (MB): 52.58\n",
            "Estimated Total Size (MB): 59.12\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 381, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(381, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(381, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 16:25:33 2022: Epoch [0], Iteration [0/391/], Data(s): 0.086, Loss(s): 0.004, Forward(s): 0.151, Backward(s): 0.464, Top1: 94.531, Top5: 100.0000, Loss: 0.159\n",
            "Mon Apr 25 16:25:53 2022: Epoch [0], Iteration [100/391/], Data(s): 0.049, Loss(s): 0.040, Forward(s): 0.007, Backward(s): 0.016, Top1: 92.976, Top5: 99.6906, Loss: 0.218\n",
            "Mon Apr 25 16:26:13 2022: Epoch [0], Iteration [200/391/], Data(s): 0.049, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.014, Top1: 93.031, Top5: 99.6657, Loss: 0.217\n",
            "Mon Apr 25 16:26:32 2022: Epoch [0], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.013, Top1: 92.990, Top5: 99.6833, Loss: 0.217\n",
            "Mon Apr 25 16:26:51 2022: Epoch [1], Iteration [0/391/], Data(s): 0.075, Loss(s): 0.039, Forward(s): 0.007, Backward(s): 0.012, Top1: 90.625, Top5: 98.4375, Loss: 0.222\n",
            "Mon Apr 25 16:27:10 2022: Epoch [1], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.675, Top5: 99.6751, Loss: 0.218\n",
            "Mon Apr 25 16:27:30 2022: Epoch [1], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.763, Top5: 99.6968, Loss: 0.212\n",
            "Mon Apr 25 16:27:50 2022: Epoch [1], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.691, Top5: 99.7041, Loss: 0.217\n",
            "Mon Apr 25 16:28:08 2022: Epoch [2], Iteration [0/391/], Data(s): 0.074, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.875, Top5: 100.0000, Loss: 0.210\n",
            "Mon Apr 25 16:28:27 2022: Epoch [2], Iteration [100/391/], Data(s): 0.050, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.649, Top5: 99.7061, Loss: 0.200\n",
            "Mon Apr 25 16:28:47 2022: Epoch [2], Iteration [200/391/], Data(s): 0.049, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.186, Top5: 99.6580, Loss: 0.220\n",
            "Mon Apr 25 16:29:06 2022: Epoch [2], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.213, Top5: 99.6574, Loss: 0.212\n",
            "Mon Apr 25 16:29:24 2022: Epoch [3], Iteration [0/391/], Data(s): 0.069, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.011, Top1: 89.062, Top5: 100.0000, Loss: 0.220\n",
            "Mon Apr 25 16:29:44 2022: Epoch [3], Iteration [100/391/], Data(s): 0.052, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.013, Top1: 93.278, Top5: 99.7061, Loss: 0.209\n",
            "Mon Apr 25 16:30:04 2022: Epoch [3], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.113, Top5: 99.6618, Loss: 0.214\n",
            "Mon Apr 25 16:30:24 2022: Epoch [3], Iteration [300/391/], Data(s): 0.051, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.057, Top5: 99.6470, Loss: 0.215\n",
            "Mon Apr 25 16:30:42 2022: Epoch [4], Iteration [0/391/], Data(s): 0.074, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.750, Top5: 100.0000, Loss: 0.210\n",
            "Mon Apr 25 16:31:02 2022: Epoch [4], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.278, Top5: 99.6364, Loss: 0.212\n",
            "Mon Apr 25 16:31:22 2022: Epoch [4], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.015, Top5: 99.6580, Loss: 0.217\n",
            "Mon Apr 25 16:31:41 2022: Epoch [4], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.096, Top5: 99.6652, Loss: 0.206\n",
            "Mon Apr 25 16:31:59 2022: Epoch [5], Iteration [0/391/], Data(s): 0.070, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.094, Top5: 100.0000, Loss: 0.200\n",
            "Mon Apr 25 16:32:19 2022: Epoch [5], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.688, Top5: 99.7525, Loss: 0.199\n",
            "Mon Apr 25 16:32:39 2022: Epoch [5], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.501, Top5: 99.7007, Loss: 0.206\n",
            "Mon Apr 25 16:32:59 2022: Epoch [5], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.542, Top5: 99.6963, Loss: 0.195\n",
            "Mon Apr 25 16:33:17 2022: Epoch [6], Iteration [0/391/], Data(s): 0.073, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.013, Top1: 97.656, Top5: 100.0000, Loss: 0.209\n",
            "Mon Apr 25 16:33:36 2022: Epoch [6], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.502, Top5: 99.6829, Loss: 0.202\n",
            "Mon Apr 25 16:33:56 2022: Epoch [6], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.404, Top5: 99.7163, Loss: 0.203\n",
            "Mon Apr 25 16:34:16 2022: Epoch [6], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.439, Top5: 99.7353, Loss: 0.197\n",
            "Mon Apr 25 16:34:34 2022: Epoch [7], Iteration [0/391/], Data(s): 0.070, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.013, Top1: 93.750, Top5: 100.0000, Loss: 0.202\n",
            "Mon Apr 25 16:34:54 2022: Epoch [7], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.541, Top5: 99.7215, Loss: 0.200\n",
            "Mon Apr 25 16:35:14 2022: Epoch [7], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.396, Top5: 99.7318, Loss: 0.200\n",
            "Mon Apr 25 16:35:33 2022: Epoch [7], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.374, Top5: 99.7275, Loss: 0.195\n",
            "Mon Apr 25 16:35:51 2022: Epoch [8], Iteration [0/391/], Data(s): 0.073, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 91.406, Top5: 99.2188, Loss: 0.193\n",
            "Mon Apr 25 16:36:11 2022: Epoch [8], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.495, Top5: 99.7679, Loss: 0.197\n",
            "Mon Apr 25 16:36:31 2022: Epoch [8], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.738, Top5: 99.7396, Loss: 0.184\n",
            "Mon Apr 25 16:36:51 2022: Epoch [8], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.675, Top5: 99.7249, Loss: 0.201\n",
            "Mon Apr 25 16:37:09 2022: Epoch [9], Iteration [0/391/], Data(s): 0.076, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.312, Top5: 100.0000, Loss: 0.191\n",
            "Mon Apr 25 16:37:29 2022: Epoch [9], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.160, Top5: 99.7525, Loss: 0.182\n",
            "Mon Apr 25 16:37:48 2022: Epoch [9], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.867, Top5: 99.7707, Loss: 0.191\n",
            "Mon Apr 25 16:38:08 2022: Epoch [9], Iteration [300/391/], Data(s): 0.051, Loss(s): 0.041, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.714, Top5: 99.7379, Loss: 0.200\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 16:38:35 2022: Test information, Data(s): 2.602, Forward(s): 0.645, Top1: 90.800, Top5: 99.300, \n",
            "\n",
            "Mon Apr 25 16:38:35 2022: conv10 Layer, 197 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 315, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(315, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(315, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]          73,856\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "             ReLU-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]         147,584\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         295,168\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]       1,180,160\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 315, 4, 4]       1,451,835\n",
            "      BatchNorm2d-32            [-1, 315, 4, 4]             630\n",
            "             ReLU-33            [-1, 315, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 315, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       1,452,032\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 13,175,803\n",
            "Trainable params: 13,175,803\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 6.50\n",
            "Params size (MB): 50.26\n",
            "Estimated Total Size (MB): 56.77\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 315, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(315, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(315, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 16:38:37 2022: Epoch [0], Iteration [0/391/], Data(s): 0.053, Loss(s): 0.005, Forward(s): 0.133, Backward(s): 0.397, Top1: 93.750, Top5: 100.0000, Loss: 0.132\n",
            "Mon Apr 25 16:38:56 2022: Epoch [0], Iteration [100/391/], Data(s): 0.050, Loss(s): 0.040, Forward(s): 0.007, Backward(s): 0.016, Top1: 94.044, Top5: 99.7370, Loss: 0.184\n",
            "Mon Apr 25 16:39:16 2022: Epoch [0], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.014, Top1: 93.731, Top5: 99.7435, Loss: 0.193\n",
            "Mon Apr 25 16:39:35 2022: Epoch [0], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.013, Top1: 93.828, Top5: 99.7404, Loss: 0.186\n",
            "Mon Apr 25 16:39:53 2022: Epoch [1], Iteration [0/391/], Data(s): 0.072, Loss(s): 0.039, Forward(s): 0.007, Backward(s): 0.012, Top1: 92.188, Top5: 100.0000, Loss: 0.190\n",
            "Mon Apr 25 16:40:13 2022: Epoch [1], Iteration [100/391/], Data(s): 0.052, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.595, Top5: 99.7525, Loss: 0.190\n",
            "Mon Apr 25 16:40:33 2022: Epoch [1], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.801, Top5: 99.7629, Loss: 0.182\n",
            "Mon Apr 25 16:40:52 2022: Epoch [1], Iteration [300/391/], Data(s): 0.051, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.885, Top5: 99.7638, Loss: 0.182\n",
            "Mon Apr 25 16:41:10 2022: Epoch [2], Iteration [0/391/], Data(s): 0.075, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.188, Top5: 100.0000, Loss: 0.183\n",
            "Mon Apr 25 16:41:30 2022: Epoch [2], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.044, Top5: 99.6751, Loss: 0.179\n",
            "Mon Apr 25 16:41:49 2022: Epoch [2], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.092, Top5: 99.7163, Loss: 0.181\n",
            "Mon Apr 25 16:42:09 2022: Epoch [2], Iteration [300/391/], Data(s): 0.051, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.976, Top5: 99.7430, Loss: 0.190\n",
            "Mon Apr 25 16:42:27 2022: Epoch [3], Iteration [0/391/], Data(s): 0.071, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.013, Top1: 93.750, Top5: 100.0000, Loss: 0.180\n",
            "Mon Apr 25 16:42:46 2022: Epoch [3], Iteration [100/391/], Data(s): 0.052, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.261, Top5: 99.7834, Loss: 0.178\n",
            "Mon Apr 25 16:43:06 2022: Epoch [3], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.150, Top5: 99.7512, Loss: 0.178\n",
            "Mon Apr 25 16:43:25 2022: Epoch [3], Iteration [300/391/], Data(s): 0.051, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.002, Top5: 99.7456, Loss: 0.188\n",
            "Mon Apr 25 16:43:43 2022: Epoch [4], Iteration [0/391/], Data(s): 0.075, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.013, Top1: 92.969, Top5: 100.0000, Loss: 0.182\n",
            "Mon Apr 25 16:44:03 2022: Epoch [4], Iteration [100/391/], Data(s): 0.052, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.005, Top5: 99.7834, Loss: 0.177\n",
            "Mon Apr 25 16:44:23 2022: Epoch [4], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.018, Top5: 99.8057, Loss: 0.177\n",
            "Mon Apr 25 16:44:42 2022: Epoch [4], Iteration [300/391/], Data(s): 0.051, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.043, Top5: 99.7742, Loss: 0.183\n",
            "Mon Apr 25 16:45:00 2022: Epoch [5], Iteration [0/391/], Data(s): 0.071, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.094, Top5: 100.0000, Loss: 0.170\n",
            "Mon Apr 25 16:45:20 2022: Epoch [5], Iteration [100/391/], Data(s): 0.052, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.206, Top5: 99.7989, Loss: 0.169\n",
            "Mon Apr 25 16:45:39 2022: Epoch [5], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.403, Top5: 99.7785, Loss: 0.172\n",
            "Mon Apr 25 16:45:58 2022: Epoch [5], Iteration [300/391/], Data(s): 0.051, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.404, Top5: 99.7482, Loss: 0.174\n",
            "Mon Apr 25 16:46:16 2022: Epoch [6], Iteration [0/391/], Data(s): 0.070, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.011, Top1: 96.094, Top5: 99.2188, Loss: 0.175\n",
            "Mon Apr 25 16:46:36 2022: Epoch [6], Iteration [100/391/], Data(s): 0.052, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.469, Top5: 99.7293, Loss: 0.166\n",
            "Mon Apr 25 16:46:56 2022: Epoch [6], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.500, Top5: 99.7512, Loss: 0.171\n",
            "Mon Apr 25 16:47:15 2022: Epoch [6], Iteration [300/391/], Data(s): 0.051, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.427, Top5: 99.7768, Loss: 0.174\n",
            "Mon Apr 25 16:47:33 2022: Epoch [7], Iteration [0/391/], Data(s): 0.071, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.531, Top5: 100.0000, Loss: 0.176\n",
            "Mon Apr 25 16:47:53 2022: Epoch [7], Iteration [100/391/], Data(s): 0.052, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.230, Top5: 99.7447, Loss: 0.175\n",
            "Mon Apr 25 16:48:12 2022: Epoch [7], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.523, Top5: 99.7668, Loss: 0.159\n",
            "Mon Apr 25 16:48:32 2022: Epoch [7], Iteration [300/391/], Data(s): 0.051, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.456, Top5: 99.7794, Loss: 0.174\n",
            "Mon Apr 25 16:48:49 2022: Epoch [8], Iteration [0/391/], Data(s): 0.083, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.531, Top5: 99.2188, Loss: 0.171\n",
            "Mon Apr 25 16:49:09 2022: Epoch [8], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.400, Top5: 99.7602, Loss: 0.172\n",
            "Mon Apr 25 16:49:29 2022: Epoch [8], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.376, Top5: 99.7551, Loss: 0.172\n",
            "Mon Apr 25 16:49:48 2022: Epoch [8], Iteration [300/391/], Data(s): 0.051, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.490, Top5: 99.7716, Loss: 0.156\n",
            "Mon Apr 25 16:50:06 2022: Epoch [9], Iteration [0/391/], Data(s): 0.070, Loss(s): 0.040, Forward(s): 0.005, Backward(s): 0.012, Top1: 96.094, Top5: 100.0000, Loss: 0.162\n",
            "Mon Apr 25 16:50:25 2022: Epoch [9], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.013, Top1: 94.756, Top5: 99.7834, Loss: 0.165\n",
            "Mon Apr 25 16:50:45 2022: Epoch [9], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.780, Top5: 99.7590, Loss: 0.159\n",
            "Mon Apr 25 16:51:05 2022: Epoch [9], Iteration [300/391/], Data(s): 0.051, Loss(s): 0.040, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.645, Top5: 99.7690, Loss: 0.172\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 16:51:31 2022: Test information, Data(s): 2.487, Forward(s): 0.610, Top1: 90.960, Top5: 99.320, \n",
            "\n",
            "Mon Apr 25 16:51:31 2022: conv10 Layer, 262 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 250, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(250, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(250, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]          73,856\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "             ReLU-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]         147,584\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         295,168\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]       1,180,160\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 250, 4, 4]       1,152,250\n",
            "      BatchNorm2d-32            [-1, 250, 4, 4]             500\n",
            "             ReLU-33            [-1, 250, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 250, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]       1,152,512\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 12,576,568\n",
            "Trainable params: 12,576,568\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 6.47\n",
            "Params size (MB): 47.98\n",
            "Estimated Total Size (MB): 54.46\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 250, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(250, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(250, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 16:51:32 2022: Epoch [0], Iteration [0/391/], Data(s): 0.057, Loss(s): 0.004, Forward(s): 0.116, Backward(s): 0.329, Top1: 95.312, Top5: 100.0000, Loss: 0.152\n",
            "Mon Apr 25 16:51:52 2022: Epoch [0], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.039, Forward(s): 0.007, Backward(s): 0.015, Top1: 94.446, Top5: 99.8066, Loss: 0.168\n",
            "Mon Apr 25 16:52:11 2022: Epoch [0], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.014, Top1: 94.590, Top5: 99.8212, Loss: 0.162\n",
            "Mon Apr 25 16:52:30 2022: Epoch [0], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.013, Top1: 94.640, Top5: 99.8287, Loss: 0.160\n",
            "Mon Apr 25 16:52:48 2022: Epoch [1], Iteration [0/391/], Data(s): 0.071, Loss(s): 0.038, Forward(s): 0.007, Backward(s): 0.012, Top1: 95.312, Top5: 99.2188, Loss: 0.160\n",
            "Mon Apr 25 16:53:08 2022: Epoch [1], Iteration [100/391/], Data(s): 0.052, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.717, Top5: 99.7370, Loss: 0.160\n",
            "Mon Apr 25 16:53:27 2022: Epoch [1], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.644, Top5: 99.7901, Loss: 0.162\n",
            "Mon Apr 25 16:53:46 2022: Epoch [1], Iteration [300/391/], Data(s): 0.051, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.555, Top5: 99.8079, Loss: 0.163\n",
            "Mon Apr 25 16:54:04 2022: Epoch [2], Iteration [0/391/], Data(s): 0.071, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.875, Top5: 99.2188, Loss: 0.170\n",
            "Mon Apr 25 16:54:23 2022: Epoch [2], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.732, Top5: 99.8608, Loss: 0.161\n",
            "Mon Apr 25 16:54:42 2022: Epoch [2], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.757, Top5: 99.8406, Loss: 0.158\n",
            "Mon Apr 25 16:55:02 2022: Epoch [2], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.874, Top5: 99.8157, Loss: 0.153\n",
            "Mon Apr 25 16:55:19 2022: Epoch [3], Iteration [0/391/], Data(s): 0.074, Loss(s): 0.039, Forward(s): 0.005, Backward(s): 0.011, Top1: 96.094, Top5: 99.2188, Loss: 0.162\n",
            "Mon Apr 25 16:55:38 2022: Epoch [3], Iteration [100/391/], Data(s): 0.052, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.709, Top5: 99.7602, Loss: 0.159\n",
            "Mon Apr 25 16:55:58 2022: Epoch [3], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.679, Top5: 99.8251, Loss: 0.160\n",
            "Mon Apr 25 16:56:17 2022: Epoch [3], Iteration [300/391/], Data(s): 0.051, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.734, Top5: 99.8313, Loss: 0.155\n",
            "Mon Apr 25 16:56:35 2022: Epoch [4], Iteration [0/391/], Data(s): 0.072, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.750, Top5: 100.0000, Loss: 0.158\n",
            "Mon Apr 25 16:56:54 2022: Epoch [4], Iteration [100/391/], Data(s): 0.052, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.220, Top5: 99.8221, Loss: 0.141\n",
            "Mon Apr 25 16:57:13 2022: Epoch [4], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.033, Top5: 99.8134, Loss: 0.158\n",
            "Mon Apr 25 16:57:32 2022: Epoch [4], Iteration [300/391/], Data(s): 0.051, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.817, Top5: 99.8105, Loss: 0.162\n",
            "Mon Apr 25 16:57:50 2022: Epoch [5], Iteration [0/391/], Data(s): 0.072, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.013, Top1: 96.875, Top5: 100.0000, Loss: 0.149\n",
            "Mon Apr 25 16:58:09 2022: Epoch [5], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.212, Top5: 99.8144, Loss: 0.151\n",
            "Mon Apr 25 16:58:29 2022: Epoch [5], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.114, Top5: 99.8134, Loss: 0.151\n",
            "Mon Apr 25 16:58:48 2022: Epoch [5], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.144, Top5: 99.8521, Loss: 0.147\n",
            "Mon Apr 25 16:59:05 2022: Epoch [6], Iteration [0/391/], Data(s): 0.070, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.750, Top5: 100.0000, Loss: 0.152\n",
            "Mon Apr 25 16:59:25 2022: Epoch [6], Iteration [100/391/], Data(s): 0.052, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.794, Top5: 99.7912, Loss: 0.158\n",
            "Mon Apr 25 16:59:44 2022: Epoch [6], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.138, Top5: 99.8057, Loss: 0.142\n",
            "Mon Apr 25 17:00:03 2022: Epoch [6], Iteration [300/391/], Data(s): 0.051, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.123, Top5: 99.8235, Loss: 0.144\n",
            "Mon Apr 25 17:00:21 2022: Epoch [7], Iteration [0/391/], Data(s): 0.070, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.013, Top1: 96.875, Top5: 100.0000, Loss: 0.151\n",
            "Mon Apr 25 17:00:40 2022: Epoch [7], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.802, Top5: 99.8298, Loss: 0.153\n",
            "Mon Apr 25 17:01:00 2022: Epoch [7], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.928, Top5: 99.8134, Loss: 0.151\n",
            "Mon Apr 25 17:01:19 2022: Epoch [7], Iteration [300/391/], Data(s): 0.051, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.983, Top5: 99.8417, Loss: 0.146\n",
            "Mon Apr 25 17:01:36 2022: Epoch [8], Iteration [0/391/], Data(s): 0.069, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.011, Top1: 96.875, Top5: 100.0000, Loss: 0.147\n",
            "Mon Apr 25 17:01:56 2022: Epoch [8], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.367, Top5: 99.8453, Loss: 0.146\n",
            "Mon Apr 25 17:02:15 2022: Epoch [8], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.200, Top5: 99.8329, Loss: 0.149\n",
            "Mon Apr 25 17:02:34 2022: Epoch [8], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.123, Top5: 99.8417, Loss: 0.151\n",
            "Mon Apr 25 17:02:52 2022: Epoch [9], Iteration [0/391/], Data(s): 0.070, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.094, Top5: 100.0000, Loss: 0.144\n",
            "Mon Apr 25 17:03:11 2022: Epoch [9], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.057, Top5: 99.8298, Loss: 0.148\n",
            "Mon Apr 25 17:03:30 2022: Epoch [9], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.013, Top5: 99.8251, Loss: 0.147\n",
            "Mon Apr 25 17:03:49 2022: Epoch [9], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.040, Top5: 99.8339, Loss: 0.148\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 17:04:15 2022: Test information, Data(s): 2.477, Forward(s): 0.587, Top1: 91.260, Top5: 99.310, \n",
            "\n",
            "Mon Apr 25 17:04:15 2022: conv10 Layer, 328 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(184, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]          73,856\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "             ReLU-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]         147,584\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         295,168\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]       1,180,160\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 184, 4, 4]         848,056\n",
            "      BatchNorm2d-32            [-1, 184, 4, 4]             368\n",
            "             ReLU-33            [-1, 184, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 184, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]         848,384\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 11,968,114\n",
            "Trainable params: 11,968,114\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 6.44\n",
            "Params size (MB): 45.65\n",
            "Estimated Total Size (MB): 52.11\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(184, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 17:04:17 2022: Epoch [0], Iteration [0/391/], Data(s): 0.052, Loss(s): 0.004, Forward(s): 0.098, Backward(s): 0.258, Top1: 98.438, Top5: 100.0000, Loss: 0.103\n",
            "Mon Apr 25 17:04:36 2022: Epoch [0], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.038, Forward(s): 0.007, Backward(s): 0.015, Top1: 95.467, Top5: 99.8685, Loss: 0.142\n",
            "Mon Apr 25 17:04:55 2022: Epoch [0], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.038, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.316, Top5: 99.8562, Loss: 0.149\n",
            "Mon Apr 25 17:05:14 2022: Epoch [0], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.038, Forward(s): 0.006, Backward(s): 0.013, Top1: 95.315, Top5: 99.8624, Loss: 0.142\n",
            "Mon Apr 25 17:05:31 2022: Epoch [1], Iteration [0/391/], Data(s): 0.068, Loss(s): 0.038, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.875, Top5: 99.2188, Loss: 0.137\n",
            "Mon Apr 25 17:05:51 2022: Epoch [1], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.398, Top5: 99.8608, Loss: 0.141\n",
            "Mon Apr 25 17:06:10 2022: Epoch [1], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.379, Top5: 99.8562, Loss: 0.139\n",
            "Mon Apr 25 17:06:29 2022: Epoch [1], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.367, Top5: 99.8650, Loss: 0.142\n",
            "Mon Apr 25 17:06:46 2022: Epoch [2], Iteration [0/391/], Data(s): 0.068, Loss(s): 0.038, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.875, Top5: 100.0000, Loss: 0.136\n",
            "Mon Apr 25 17:07:05 2022: Epoch [2], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.707, Top5: 99.8994, Loss: 0.133\n",
            "Mon Apr 25 17:07:24 2022: Epoch [2], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.596, Top5: 99.9028, Loss: 0.136\n",
            "Mon Apr 25 17:07:43 2022: Epoch [2], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.588, Top5: 99.9040, Loss: 0.134\n",
            "Mon Apr 25 17:08:00 2022: Epoch [3], Iteration [0/391/], Data(s): 0.069, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.312, Top5: 100.0000, Loss: 0.138\n",
            "Mon Apr 25 17:08:19 2022: Epoch [3], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.390, Top5: 99.8917, Loss: 0.139\n",
            "Mon Apr 25 17:08:38 2022: Epoch [3], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.526, Top5: 99.8951, Loss: 0.131\n",
            "Mon Apr 25 17:08:57 2022: Epoch [3], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.564, Top5: 99.8858, Loss: 0.132\n",
            "Mon Apr 25 17:09:15 2022: Epoch [4], Iteration [0/391/], Data(s): 0.071, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.011, Top1: 97.656, Top5: 100.0000, Loss: 0.134\n",
            "Mon Apr 25 17:09:34 2022: Epoch [4], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.614, Top5: 99.8840, Loss: 0.134\n",
            "Mon Apr 25 17:09:53 2022: Epoch [4], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.655, Top5: 99.8989, Loss: 0.135\n",
            "Mon Apr 25 17:10:12 2022: Epoch [4], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.564, Top5: 99.8780, Loss: 0.135\n",
            "Mon Apr 25 17:10:29 2022: Epoch [5], Iteration [0/391/], Data(s): 0.068, Loss(s): 0.038, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.875, Top5: 100.0000, Loss: 0.127\n",
            "Mon Apr 25 17:10:48 2022: Epoch [5], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.668, Top5: 99.8762, Loss: 0.128\n",
            "Mon Apr 25 17:11:07 2022: Epoch [5], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.841, Top5: 99.8717, Loss: 0.128\n",
            "Mon Apr 25 17:11:26 2022: Epoch [5], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.725, Top5: 99.8728, Loss: 0.136\n",
            "Mon Apr 25 17:11:44 2022: Epoch [6], Iteration [0/391/], Data(s): 0.071, Loss(s): 0.038, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.875, Top5: 100.0000, Loss: 0.135\n",
            "Mon Apr 25 17:12:03 2022: Epoch [6], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.514, Top5: 99.8994, Loss: 0.132\n",
            "Mon Apr 25 17:12:22 2022: Epoch [6], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.627, Top5: 99.8795, Loss: 0.130\n",
            "Mon Apr 25 17:12:41 2022: Epoch [6], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.624, Top5: 99.8832, Loss: 0.129\n",
            "Mon Apr 25 17:12:58 2022: Epoch [7], Iteration [0/391/], Data(s): 0.068, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.011, Top1: 95.312, Top5: 100.0000, Loss: 0.132\n",
            "Mon Apr 25 17:13:17 2022: Epoch [7], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.800, Top5: 99.8840, Loss: 0.131\n",
            "Mon Apr 25 17:13:36 2022: Epoch [7], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.853, Top5: 99.8951, Loss: 0.126\n",
            "Mon Apr 25 17:13:55 2022: Epoch [7], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.839, Top5: 99.8884, Loss: 0.127\n",
            "Mon Apr 25 17:14:12 2022: Epoch [8], Iteration [0/391/], Data(s): 0.070, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.875, Top5: 100.0000, Loss: 0.121\n",
            "Mon Apr 25 17:14:32 2022: Epoch [8], Iteration [100/391/], Data(s): 0.052, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.016, Top5: 99.8530, Loss: 0.125\n",
            "Mon Apr 25 17:14:50 2022: Epoch [8], Iteration [200/391/], Data(s): 0.051, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.923, Top5: 99.8678, Loss: 0.124\n",
            "Mon Apr 25 17:15:09 2022: Epoch [8], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.876, Top5: 99.8754, Loss: 0.123\n",
            "Mon Apr 25 17:15:27 2022: Epoch [9], Iteration [0/391/], Data(s): 0.071, Loss(s): 0.038, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.094, Top5: 100.0000, Loss: 0.126\n",
            "Mon Apr 25 17:15:46 2022: Epoch [9], Iteration [100/391/], Data(s): 0.050, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.993, Top5: 99.9072, Loss: 0.122\n",
            "Mon Apr 25 17:16:05 2022: Epoch [9], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.973, Top5: 99.9106, Loss: 0.120\n",
            "Mon Apr 25 17:16:24 2022: Epoch [9], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.039, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.863, Top5: 99.9066, Loss: 0.128\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 17:16:49 2022: Test information, Data(s): 2.465, Forward(s): 0.567, Top1: 91.450, Top5: 99.280, \n",
            "\n",
            "Mon Apr 25 17:16:49 2022: conv10 Layer, 394 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 118, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(118, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(118, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]          73,856\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "             ReLU-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]         147,584\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         295,168\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]       1,180,160\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31            [-1, 118, 4, 4]         543,862\n",
            "      BatchNorm2d-32            [-1, 118, 4, 4]             236\n",
            "             ReLU-33            [-1, 118, 4, 4]               0\n",
            "        MaxPool2d-34            [-1, 118, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]         544,256\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 11,359,660\n",
            "Trainable params: 11,359,660\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 6.42\n",
            "Params size (MB): 43.33\n",
            "Estimated Total Size (MB): 49.76\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 118, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(118, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(118, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 17:16:51 2022: Epoch [0], Iteration [0/391/], Data(s): 0.052, Loss(s): 0.004, Forward(s): 0.081, Backward(s): 0.138, Top1: 94.531, Top5: 100.0000, Loss: 0.127\n",
            "Mon Apr 25 17:17:10 2022: Epoch [0], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.037, Forward(s): 0.007, Backward(s): 0.014, Top1: 96.287, Top5: 99.8994, Loss: 0.116\n",
            "Mon Apr 25 17:17:28 2022: Epoch [0], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.038, Forward(s): 0.006, Backward(s): 0.013, Top1: 96.210, Top5: 99.9028, Loss: 0.120\n",
            "Mon Apr 25 17:17:47 2022: Epoch [0], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.038, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.068, Top5: 99.8988, Loss: 0.125\n",
            "Mon Apr 25 17:18:04 2022: Epoch [1], Iteration [0/391/], Data(s): 0.066, Loss(s): 0.038, Forward(s): 0.006, Backward(s): 0.012, Top1: 94.531, Top5: 100.0000, Loss: 0.125\n",
            "Mon Apr 25 17:18:23 2022: Epoch [1], Iteration [100/391/], Data(s): 0.050, Loss(s): 0.038, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.862, Top5: 99.8917, Loss: 0.128\n",
            "Mon Apr 25 17:18:42 2022: Epoch [1], Iteration [200/391/], Data(s): 0.049, Loss(s): 0.038, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.923, Top5: 99.9184, Loss: 0.117\n",
            "Mon Apr 25 17:19:00 2022: Epoch [1], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.038, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.930, Top5: 99.9221, Loss: 0.121\n",
            "Mon Apr 25 17:19:18 2022: Epoch [2], Iteration [0/391/], Data(s): 0.068, Loss(s): 0.038, Forward(s): 0.006, Backward(s): 0.012, Top1: 95.312, Top5: 99.2188, Loss: 0.121\n",
            "Mon Apr 25 17:19:36 2022: Epoch [2], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.038, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.016, Top5: 99.8994, Loss: 0.117\n",
            "Mon Apr 25 17:19:55 2022: Epoch [2], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.038, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.129, Top5: 99.9028, Loss: 0.115\n",
            "Mon Apr 25 17:20:14 2022: Epoch [2], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.038, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.242, Top5: 99.9040, Loss: 0.109\n",
            "Mon Apr 25 17:20:31 2022: Epoch [3], Iteration [0/391/], Data(s): 0.069, Loss(s): 0.038, Forward(s): 0.005, Backward(s): 0.012, Top1: 96.094, Top5: 100.0000, Loss: 0.114\n",
            "Mon Apr 25 17:20:50 2022: Epoch [3], Iteration [100/391/], Data(s): 0.050, Loss(s): 0.038, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.310, Top5: 99.9149, Loss: 0.111\n",
            "Mon Apr 25 17:21:09 2022: Epoch [3], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.038, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.288, Top5: 99.9300, Loss: 0.112\n",
            "Mon Apr 25 17:21:27 2022: Epoch [3], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.038, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.182, Top5: 99.9299, Loss: 0.118\n",
            "Mon Apr 25 17:21:45 2022: Epoch [4], Iteration [0/391/], Data(s): 0.071, Loss(s): 0.038, Forward(s): 0.006, Backward(s): 0.012, Top1: 98.438, Top5: 100.0000, Loss: 0.115\n",
            "Mon Apr 25 17:22:04 2022: Epoch [4], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.038, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.001, Top5: 99.8994, Loss: 0.115\n",
            "Mon Apr 25 17:22:22 2022: Epoch [4], Iteration [200/391/], Data(s): 0.050, Loss(s): 0.038, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.024, Top5: 99.9067, Loss: 0.114\n",
            "Mon Apr 25 17:22:41 2022: Epoch [4], Iteration [300/391/], Data(s): 0.050, Loss(s): 0.038, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.169, Top5: 99.8988, Loss: 0.108\n",
            "Mon Apr 25 17:22:58 2022: Epoch [5], Iteration [0/391/], Data(s): 0.067, Loss(s): 0.038, Forward(s): 0.006, Backward(s): 0.011, Top1: 94.531, Top5: 100.0000, Loss: 0.111\n",
            "Mon Apr 25 17:23:17 2022: Epoch [5], Iteration [100/391/], Data(s): 0.051, Loss(s): 0.038, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.465, Top5: 99.9304, Loss: 0.111\n",
            "Mon Apr 25 17:23:36 2022: Epoch [5], Iteration [200/391/], Data(s): 0.049, Loss(s): 0.038, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.323, Top5: 99.9262, Loss: 0.112\n",
            "Mon Apr 25 17:23:54 2022: Epoch [5], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.038, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.252, Top5: 99.9325, Loss: 0.117\n",
            "Mon Apr 25 17:24:11 2022: Epoch [6], Iteration [0/391/], Data(s): 0.063, Loss(s): 0.038, Forward(s): 0.006, Backward(s): 0.011, Top1: 97.656, Top5: 100.0000, Loss: 0.119\n",
            "Mon Apr 25 17:24:30 2022: Epoch [6], Iteration [100/391/], Data(s): 0.049, Loss(s): 0.038, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.442, Top5: 99.9072, Loss: 0.104\n",
            "Mon Apr 25 17:24:49 2022: Epoch [6], Iteration [200/391/], Data(s): 0.049, Loss(s): 0.038, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.374, Top5: 99.9028, Loss: 0.108\n",
            "Mon Apr 25 17:25:07 2022: Epoch [6], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.038, Forward(s): 0.005, Backward(s): 0.012, Top1: 96.403, Top5: 99.9040, Loss: 0.109\n",
            "Mon Apr 25 17:25:24 2022: Epoch [7], Iteration [0/391/], Data(s): 0.065, Loss(s): 0.038, Forward(s): 0.005, Backward(s): 0.011, Top1: 96.875, Top5: 99.2188, Loss: 0.109\n",
            "Mon Apr 25 17:25:43 2022: Epoch [7], Iteration [100/391/], Data(s): 0.049, Loss(s): 0.038, Forward(s): 0.005, Backward(s): 0.012, Top1: 96.550, Top5: 99.9304, Loss: 0.107\n",
            "Mon Apr 25 17:26:01 2022: Epoch [7], Iteration [200/391/], Data(s): 0.049, Loss(s): 0.038, Forward(s): 0.005, Backward(s): 0.012, Top1: 96.374, Top5: 99.9223, Loss: 0.113\n",
            "Mon Apr 25 17:26:20 2022: Epoch [7], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.038, Forward(s): 0.005, Backward(s): 0.012, Top1: 96.382, Top5: 99.9143, Loss: 0.110\n",
            "Mon Apr 25 17:26:37 2022: Epoch [8], Iteration [0/391/], Data(s): 0.064, Loss(s): 0.038, Forward(s): 0.005, Backward(s): 0.011, Top1: 96.875, Top5: 100.0000, Loss: 0.103\n",
            "Mon Apr 25 17:26:56 2022: Epoch [8], Iteration [100/391/], Data(s): 0.050, Loss(s): 0.038, Forward(s): 0.006, Backward(s): 0.011, Top1: 96.550, Top5: 99.9226, Loss: 0.107\n",
            "Mon Apr 25 17:27:14 2022: Epoch [8], Iteration [200/391/], Data(s): 0.049, Loss(s): 0.038, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.622, Top5: 99.9145, Loss: 0.101\n",
            "Mon Apr 25 17:27:33 2022: Epoch [8], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.038, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.647, Top5: 99.9195, Loss: 0.104\n",
            "Mon Apr 25 17:27:50 2022: Epoch [9], Iteration [0/391/], Data(s): 0.064, Loss(s): 0.038, Forward(s): 0.006, Backward(s): 0.012, Top1: 92.188, Top5: 99.2188, Loss: 0.109\n",
            "Mon Apr 25 17:28:09 2022: Epoch [9], Iteration [100/391/], Data(s): 0.049, Loss(s): 0.038, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.488, Top5: 99.9691, Loss: 0.105\n",
            "Mon Apr 25 17:28:27 2022: Epoch [9], Iteration [200/391/], Data(s): 0.049, Loss(s): 0.038, Forward(s): 0.005, Backward(s): 0.012, Top1: 96.747, Top5: 99.9534, Loss: 0.096\n",
            "Mon Apr 25 17:28:46 2022: Epoch [9], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.038, Forward(s): 0.005, Backward(s): 0.012, Top1: 96.652, Top5: 99.9507, Loss: 0.104\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 17:29:11 2022: Test information, Data(s): 2.390, Forward(s): 0.521, Top1: 91.340, Top5: 99.330, \n",
            "\n",
            "Mon Apr 25 17:29:11 2022: conv10 Layer, 460 Channels pruned\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tPrune network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 52, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(52, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "         MaxPool2d-7           [-1, 64, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]          73,856\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "             ReLU-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]         147,584\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "        MaxPool2d-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15            [-1, 256, 8, 8]         295,168\n",
            "      BatchNorm2d-16            [-1, 256, 8, 8]             512\n",
            "             ReLU-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-19            [-1, 256, 8, 8]             512\n",
            "             ReLU-20            [-1, 256, 8, 8]               0\n",
            "           Conv2d-21            [-1, 256, 8, 8]         590,080\n",
            "      BatchNorm2d-22            [-1, 256, 8, 8]             512\n",
            "             ReLU-23            [-1, 256, 8, 8]               0\n",
            "        MaxPool2d-24            [-1, 256, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]       1,180,160\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-29            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-30            [-1, 512, 4, 4]               0\n",
            "           Conv2d-31             [-1, 52, 4, 4]         239,668\n",
            "      BatchNorm2d-32             [-1, 52, 4, 4]             104\n",
            "             ReLU-33             [-1, 52, 4, 4]               0\n",
            "        MaxPool2d-34             [-1, 52, 2, 2]               0\n",
            "           Conv2d-35            [-1, 512, 2, 2]         240,128\n",
            "      BatchNorm2d-36            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-37            [-1, 512, 2, 2]               0\n",
            "           Conv2d-38            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "           Conv2d-41            [-1, 512, 2, 2]       2,359,808\n",
            "      BatchNorm2d-42            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-43            [-1, 512, 2, 2]               0\n",
            "        MaxPool2d-44            [-1, 512, 1, 1]               0\n",
            "           Linear-45                  [-1, 512]         262,656\n",
            "      BatchNorm1d-46                  [-1, 512]           1,024\n",
            "           Linear-47                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 10,751,206\n",
            "Trainable params: 10,751,206\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 6.39\n",
            "Params size (MB): 41.01\n",
            "Estimated Total Size (MB): 47.42\n",
            "----------------------------------------------------------------\n",
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 52, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(52, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU(inplace=True)\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU(inplace=True)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tTrain network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 17:29:12 2022: Epoch [0], Iteration [0/391/], Data(s): 0.052, Loss(s): 0.004, Forward(s): 0.064, Backward(s): 0.127, Top1: 95.312, Top5: 100.0000, Loss: 0.107\n",
            "Mon Apr 25 17:29:30 2022: Epoch [0], Iteration [100/391/], Data(s): 0.049, Loss(s): 0.037, Forward(s): 0.006, Backward(s): 0.013, Top1: 96.860, Top5: 99.9459, Loss: 0.099\n",
            "Mon Apr 25 17:29:49 2022: Epoch [0], Iteration [200/391/], Data(s): 0.049, Loss(s): 0.037, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.887, Top5: 99.9417, Loss: 0.092\n",
            "Mon Apr 25 17:30:07 2022: Epoch [0], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.037, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.782, Top5: 99.9429, Loss: 0.102\n",
            "Mon Apr 25 17:30:24 2022: Epoch [1], Iteration [0/391/], Data(s): 0.063, Loss(s): 0.037, Forward(s): 0.006, Backward(s): 0.012, Top1: 97.656, Top5: 100.0000, Loss: 0.112\n",
            "Mon Apr 25 17:30:43 2022: Epoch [1], Iteration [100/391/], Data(s): 0.050, Loss(s): 0.037, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.728, Top5: 99.9149, Loss: 0.099\n",
            "Mon Apr 25 17:31:01 2022: Epoch [1], Iteration [200/391/], Data(s): 0.049, Loss(s): 0.037, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.622, Top5: 99.9184, Loss: 0.104\n",
            "Mon Apr 25 17:31:19 2022: Epoch [1], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.037, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.582, Top5: 99.9118, Loss: 0.105\n",
            "Mon Apr 25 17:31:36 2022: Epoch [2], Iteration [0/391/], Data(s): 0.067, Loss(s): 0.037, Forward(s): 0.006, Backward(s): 0.011, Top1: 97.656, Top5: 100.0000, Loss: 0.106\n",
            "Mon Apr 25 17:31:55 2022: Epoch [2], Iteration [100/391/], Data(s): 0.050, Loss(s): 0.037, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.713, Top5: 99.8994, Loss: 0.099\n",
            "Mon Apr 25 17:32:13 2022: Epoch [2], Iteration [200/391/], Data(s): 0.049, Loss(s): 0.037, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.681, Top5: 99.9184, Loss: 0.100\n",
            "Mon Apr 25 17:32:31 2022: Epoch [2], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.037, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.750, Top5: 99.9299, Loss: 0.093\n",
            "Mon Apr 25 17:32:48 2022: Epoch [3], Iteration [0/391/], Data(s): 0.068, Loss(s): 0.037, Forward(s): 0.006, Backward(s): 0.012, Top1: 93.750, Top5: 100.0000, Loss: 0.096\n",
            "Mon Apr 25 17:33:07 2022: Epoch [3], Iteration [100/391/], Data(s): 0.050, Loss(s): 0.037, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.813, Top5: 99.9304, Loss: 0.095\n",
            "Mon Apr 25 17:33:25 2022: Epoch [3], Iteration [200/391/], Data(s): 0.049, Loss(s): 0.037, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.793, Top5: 99.9495, Loss: 0.094\n",
            "Mon Apr 25 17:33:43 2022: Epoch [3], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.037, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.849, Top5: 99.9585, Loss: 0.093\n",
            "Mon Apr 25 17:34:00 2022: Epoch [4], Iteration [0/391/], Data(s): 0.078, Loss(s): 0.037, Forward(s): 0.006, Backward(s): 0.011, Top1: 96.094, Top5: 100.0000, Loss: 0.093\n",
            "Mon Apr 25 17:34:18 2022: Epoch [4], Iteration [100/391/], Data(s): 0.050, Loss(s): 0.037, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.713, Top5: 99.9304, Loss: 0.099\n",
            "Mon Apr 25 17:34:37 2022: Epoch [4], Iteration [200/391/], Data(s): 0.049, Loss(s): 0.037, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.813, Top5: 99.9456, Loss: 0.094\n",
            "Mon Apr 25 17:34:55 2022: Epoch [4], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.037, Forward(s): 0.005, Backward(s): 0.012, Top1: 96.826, Top5: 99.9533, Loss: 0.092\n",
            "Mon Apr 25 17:35:12 2022: Epoch [5], Iteration [0/391/], Data(s): 0.062, Loss(s): 0.037, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.094, Top5: 100.0000, Loss: 0.097\n",
            "Mon Apr 25 17:35:30 2022: Epoch [5], Iteration [100/391/], Data(s): 0.049, Loss(s): 0.037, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.952, Top5: 99.9459, Loss: 0.090\n",
            "Mon Apr 25 17:35:49 2022: Epoch [5], Iteration [200/391/], Data(s): 0.049, Loss(s): 0.037, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.852, Top5: 99.9223, Loss: 0.098\n",
            "Mon Apr 25 17:36:07 2022: Epoch [5], Iteration [300/391/], Data(s): 0.049, Loss(s): 0.037, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.880, Top5: 99.9481, Loss: 0.090\n",
            "Mon Apr 25 17:36:24 2022: Epoch [6], Iteration [0/391/], Data(s): 0.066, Loss(s): 0.037, Forward(s): 0.006, Backward(s): 0.011, Top1: 97.656, Top5: 100.0000, Loss: 0.090\n",
            "Mon Apr 25 17:36:42 2022: Epoch [6], Iteration [100/391/], Data(s): 0.049, Loss(s): 0.037, Forward(s): 0.006, Backward(s): 0.012, Top1: 97.208, Top5: 99.9536, Loss: 0.088\n",
            "Mon Apr 25 17:37:00 2022: Epoch [6], Iteration [200/391/], Data(s): 0.049, Loss(s): 0.037, Forward(s): 0.006, Backward(s): 0.012, Top1: 97.190, Top5: 99.9650, Loss: 0.081\n",
            "Mon Apr 25 17:37:19 2022: Epoch [6], Iteration [300/391/], Data(s): 0.048, Loss(s): 0.037, Forward(s): 0.005, Backward(s): 0.012, Top1: 97.119, Top5: 99.9533, Loss: 0.095\n",
            "Mon Apr 25 17:37:36 2022: Epoch [7], Iteration [0/391/], Data(s): 0.078, Loss(s): 0.037, Forward(s): 0.006, Backward(s): 0.011, Top1: 96.875, Top5: 100.0000, Loss: 0.089\n",
            "Mon Apr 25 17:37:54 2022: Epoch [7], Iteration [100/391/], Data(s): 0.049, Loss(s): 0.037, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.774, Top5: 99.9381, Loss: 0.093\n",
            "Mon Apr 25 17:38:12 2022: Epoch [7], Iteration [200/391/], Data(s): 0.049, Loss(s): 0.037, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.910, Top5: 99.9456, Loss: 0.090\n",
            "Mon Apr 25 17:38:31 2022: Epoch [7], Iteration [300/391/], Data(s): 0.048, Loss(s): 0.037, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.896, Top5: 99.9507, Loss: 0.091\n",
            "Mon Apr 25 17:38:47 2022: Epoch [8], Iteration [0/391/], Data(s): 0.065, Loss(s): 0.037, Forward(s): 0.006, Backward(s): 0.011, Top1: 95.312, Top5: 100.0000, Loss: 0.087\n",
            "Mon Apr 25 17:39:06 2022: Epoch [8], Iteration [100/391/], Data(s): 0.049, Loss(s): 0.037, Forward(s): 0.006, Backward(s): 0.012, Top1: 96.805, Top5: 99.9459, Loss: 0.095\n",
            "Mon Apr 25 17:39:24 2022: Epoch [8], Iteration [200/391/], Data(s): 0.049, Loss(s): 0.037, Forward(s): 0.006, Backward(s): 0.011, Top1: 97.038, Top5: 99.9417, Loss: 0.087\n",
            "Mon Apr 25 17:39:42 2022: Epoch [8], Iteration [300/391/], Data(s): 0.048, Loss(s): 0.037, Forward(s): 0.005, Backward(s): 0.011, Top1: 97.039, Top5: 99.9507, Loss: 0.088\n",
            "Mon Apr 25 17:39:59 2022: Epoch [9], Iteration [0/391/], Data(s): 0.064, Loss(s): 0.037, Forward(s): 0.006, Backward(s): 0.011, Top1: 98.438, Top5: 100.0000, Loss: 0.085\n",
            "Mon Apr 25 17:40:18 2022: Epoch [9], Iteration [100/391/], Data(s): 0.049, Loss(s): 0.037, Forward(s): 0.006, Backward(s): 0.012, Top1: 97.378, Top5: 99.9613, Loss: 0.080\n",
            "Mon Apr 25 17:40:36 2022: Epoch [9], Iteration [200/391/], Data(s): 0.048, Loss(s): 0.037, Forward(s): 0.005, Backward(s): 0.012, Top1: 97.213, Top5: 99.9611, Loss: 0.088\n",
            "Mon Apr 25 17:40:54 2022: Epoch [9], Iteration [300/391/], Data(s): 0.048, Loss(s): 0.037, Forward(s): 0.006, Backward(s): 0.012, Top1: 97.150, Top5: 99.9455, Loss: 0.089\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "\tEvalute network\n",
            "-*--*--*--*--*--*--*--*--*--*-\n",
            "Mon Apr 25 17:41:19 2022: Test information, Data(s): 2.387, Forward(s): 0.512, Top1: 91.380, Top5: 99.290, \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "GJVpYeSDsgaX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top1_accuracies"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de13c847-8617-4eec-fa90-5cc2b4493725",
        "id": "qFULLCfEsgtB"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'conv10': [90.07, 90.8, 90.96, 91.26, 91.45, 91.34, 91.38],\n",
              " 'conv3': [90.0, 90.57, 90.84, 90.92, 90.82, 90.72, 89.96],\n",
              " 'conv9': [90.06, 90.53, 91.08, 91.28, 91.23, 91.37, 91.42]}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top5_accuracies"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b37ef43-1c6f-41c5-8c71-d30bfd97b507",
        "id": "-mPS-kjIsgtC"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'conv10': [99.27, 99.3, 99.32, 99.31, 99.28, 99.33, 99.29],\n",
              " 'conv3': [99.27, 99.26, 99.28, 99.26, 99.3, 99.35, 99.24],\n",
              " 'conv9': [99.27, 99.3, 99.33, 99.35, 99.29, 99.34, 99.28]}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "WiM9FI4osgYZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "7_5QlE33sgVp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Final top1 and top5  accuracies"
      ],
      "metadata": {
        "id": "jBGTkOZdsgSu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top1_accuracies = {'conv10': [90.07, 90.8, 90.96, 91.26, 91.45, 91.34, 91.38],\n",
        " 'conv3': [90.0, 90.57, 90.84, 90.92, 90.82, 90.72, 89.96],\n",
        " 'conv9': [90.06, 90.53, 91.08, 91.28, 91.23, 91.37, 91.42],\n",
        " 'conv2': [90.05, 90.57, 90.78, 91.04, 90.95, 90.51, 88.92],\n",
        " 'conv7': [90.21, 90.68, 90.97, 91.12, 91.18, 90.88, 90.73],\n",
        " 'conv8': [90.06, 90.74, 91.06, 91.27, 91.51, 91.57, 91.24],\n",
        " 'conv11': [89.84, 90.73, 91.1, 91.27, 91.17, 91.28, 91.14],\n",
        " 'conv12': [89.88, 90.67, 91.07, 91.28, 91.41, 91.37, 91.2],\n",
        " 'conv13': [90.08, 90.66, 91.02, 91.33, 91.37, 91.47, 91.44],\n",
        " 'conv4': [90.06, 90.46, 90.86, 90.61, 90.41, 90.21, 88.37],\n",
        " 'conv5': [89.72, 90.54, 90.85, 91.05, 91.14, 90.72, 89.35],\n",
        " 'conv6': [89.97, 90.5, 91.08, 90.98, 91.08, 90.89, 90.37],\n",
        " 'conv1': [90.0, 90.58, 91.01, 91.2, 91.33, 91.32, 91.25]}"
      ],
      "metadata": {
        "id": "c5kHuSWbpNIm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top5_accuracies = {'conv10': [99.27, 99.3, 99.32, 99.31, 99.28, 99.33, 99.29],\n",
        " 'conv3': [99.27, 99.26, 99.28, 99.26, 99.3, 99.35, 99.24],\n",
        " 'conv9': [99.27, 99.3, 99.33, 99.35, 99.29, 99.34, 99.28],\n",
        " 'conv2': [99.28, 99.26, 99.29, 99.28, 99.26, 99.32, 99.21],\n",
        " 'conv7': [99.24, 99.31, 99.29, 99.32, 99.3, 99.26, 99.26],\n",
        " 'conv8': [99.27, 99.34, 99.32, 99.33, 99.25, 99.23, 99.31],\n",
        " 'conv11': [99.27, 99.31, 99.27, 99.3, 99.26, 99.23, 99.24],\n",
        " 'conv12': [99.33, 99.31, 99.32, 99.34, 99.25, 99.26, 99.32],\n",
        " 'conv13': [99.31, 99.32, 99.31, 99.25, 99.3, 99.25, 99.36],\n",
        " 'conv4': [99.23, 99.29, 99.32, 99.33, 99.26, 99.38, 99.32],\n",
        " 'conv5': [99.3, 99.29, 99.29, 99.34, 99.29, 99.37, 99.15],\n",
        " 'conv6': [99.25, 99.34, 99.32, 99.32, 99.38, 99.37, 99.27],\n",
        " 'conv1': [99.25, 99.3, 99.32, 99.31, 99.28, 99.32, 99.29]}"
      ],
      "metadata": {
        "id": "vzek6xSdtgS9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot the accuracy graph"
      ],
      "metadata": {
        "id": "SIIk3tspDBk4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "plt.figure(figsize=(7,5))\n",
        "for index, (key, value) in enumerate(top1_accuracies.items()):\n",
        "    line_style = colors[index%len(colors)] + lines[index//len(colors)] +'o'\n",
        "    plt.plot(np.linspace(0, 95, len(value)), value, line_style, label=key)\n",
        "\n",
        "plt.title(\"Data: %s, Model: %s, pruned smallest filters, retrain %d epochs\"%(args.data_set, args.vgg, args.retrain_epoch))\n",
        "plt.ylabel(\"Top1 Accuracy\")\n",
        "plt.xlabel(\"Filters Pruned Away (%)\")\n",
        "plt.legend(loc='lower left')\n",
        "plt.grid()\n",
        "# plt.xlim(0, 100)\n",
        "plt.savefig(\"figure3_top1.png\", dpi=150, bbox_inches='tight')\n",
        "plt.show()                \n",
        "\n",
        "plt.figure(figsize=(7,5))\n",
        "for index, (key, value) in enumerate(top5_accuracies.items()):\n",
        "    line_style = colors[index%len(colors)] + lines[index//len(colors)] +'o'\n",
        "    plt.plot(np.linspace(0, 95, len(value)), value, line_style, label=key)\n",
        "\n",
        "plt.title(\"Data: %s, Model: %s, pruned smallest filters, retrain %d epochs\"%(args.data_set, args.vgg, args.retrain_epoch))\n",
        "plt.ylabel(\"Top5 Accuracy\")\n",
        "plt.xlabel(\"Filters Pruned Away (%)\")\n",
        "plt.legend(loc='lower left')\n",
        "plt.grid()\n",
        "# plt.xlim(0, 100)\n",
        "# plt.ylim(bottom= 0)\n",
        "plt.savefig(\"figure3_top5.png\", dpi=150, bbox_inches='tight')\n",
        "plt.show()             "
      ],
      "metadata": {
        "id": "CaBnaopHC_xC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        },
        "outputId": "1e8d719e-b414-4858-a212-3b58213f1dd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 504x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 504x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "V5Mta-0sFfSq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}